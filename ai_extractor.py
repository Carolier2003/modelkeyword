"""
AIå…³é”®è¯æå–æ¨¡å— - ä½¿ç”¨Moonshot AIè¿›è¡Œå…³é”®è¯æå–
"""
import os
import time
from typing import List, Dict, Any, Optional
from openai import OpenAI
from dotenv import load_dotenv

from models import ModelInfo, KeywordResult
from base_extractor import BaseKeywordExtractor

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class KeywordExtractor(BaseKeywordExtractor):
    """å…³é”®è¯æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        super().__init__()  # è°ƒç”¨åŸºç±»åˆå§‹åŒ–
        self.client = OpenAI(
            api_key=os.getenv("MOONSHOT_API_KEY"), 
            base_url=os.getenv("MOONSHOT_BASE_URL", "https://api.moonshot.cn/v1"),
        )
        self.model = "kimi-k2-0905-preview"
        
        # ç§»é™¤å…¨å±€å…³é”®è¯å»é‡ï¼Œæ”¹ä¸ºåœ¨æŠ¥å‘Šç”Ÿæˆæ—¶å»é‡
    
    # build_prompt æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor
    
    def extract_keywords(self, model_info: ModelInfo) -> Optional[KeywordResult]:
        """
        æå–å•ä¸ªæ¨¡å‹çš„å…³é”®è¯ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œæ€§èƒ½ç›‘æ§ï¼‰
        
        Args:
            model_info: æ¨¡å‹ä¿¡æ¯
            
        Returns:
            å…³é”®è¯æå–ç»“æœ
        """
        import time
        start_time = time.time()
        
        max_retries = 3
        base_delay = 3  # å‡å°‘åŸºç¡€å»¶è¿Ÿ
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    # é‡è¯•æ—¶çš„å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼‰
                    retry_delay = base_delay * (2 ** (attempt - 1))
                    print(f"ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾… {retry_delay} ç§’...")
                    import time
                    time.sleep(retry_delay)
                
                prompt = self.build_prompt(model_info)
                
                if attempt == 0:
                    print(f"æ­£åœ¨ä¸ºæ¨¡å‹ {model_info.project_name} æå–å…³é”®è¯...")
                else:
                    print(f"é‡è¯•ä¸­ï¼šæ­£åœ¨ä¸ºæ¨¡å‹ {model_info.project_name} æå–å…³é”®è¯...")
                
                completion = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIé¡¹ç›®è¿è¥ä¸“å®¶å’ŒSEOå¤§å¸ˆï¼Œä¸“é—¨è´Ÿè´£ä»AIæ¨¡å‹é¡¹ç›®ä¸­æå–é«˜ä»·å€¼çš„å…³é”®è¯ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,  # é™ä½æ¸©åº¦ä¿æŒä¸€è‡´æ€§
                    max_tokens=500  # è¿›ä¸€æ­¥å‡å°‘tokenæ•°é‡ï¼Œæé«˜å“åº”é€Ÿåº¦
                )
                
                response_content = completion.choices[0].message.content
                
                # è§£æJSONå“åº”
                keywords = self._parse_keywords_response(response_content)
                
                if keywords:
                    elapsed_time = time.time() - start_time
                    if attempt > 0:
                        print(f"âœ… é‡è¯•æˆåŠŸï¼æå– {len(keywords)} ä¸ªå…³é”®è¯ (è€—æ—¶: {elapsed_time:.1f}ç§’)")
                    else:
                        print(f"âœ… æˆåŠŸæå– {len(keywords)} ä¸ªå…³é”®è¯ (è€—æ—¶: {elapsed_time:.1f}ç§’)")
                    return KeywordResult(
                        model_url=model_info.url,
                        keywords=keywords
                    )
                else:
                    print(f"âŒ æœªèƒ½æå–åˆ°æœ‰æ•ˆå…³é”®è¯ - æ¨¡å‹: {model_info.project_name}")
                    print(f"ğŸ” å¯èƒ½åŸå› : JSONè§£æå¤±è´¥ã€å…³é”®è¯æ•°é‡ä¸è¶³æˆ–æ ¼å¼éªŒè¯å¤±è´¥")
                    if attempt == max_retries:  # æœ€åä¸€æ¬¡å°è¯•æ‰æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                        print(f"ğŸ“ AIåŸå§‹è¿”å›å†…å®¹:")
                        print("=" * 80)
                        print(response_content[:1000] + ("..." if len(response_content) > 1000 else ""))
                        print("=" * 80)
                    return None
                    
            except Exception as e:
                error_message = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯APIé™æµé”™è¯¯
                if "429" in error_message or "rate_limit" in error_message.lower():
                    if attempt < max_retries:
                        retry_delay = 30 + (attempt * 10)  # é™æµæ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                        print(f"âš ï¸ APIé™æµé”™è¯¯ - æ¨¡å‹: {model_info.project_name}")
                        print(f"ğŸ• ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        import time
                        time.sleep(retry_delay)
                        continue
                    else:
                        print(f"âŒ APIé™æµé”™è¯¯ï¼Œé‡è¯•æ¬¡æ•°å·²ç”¨å®Œ - æ¨¡å‹: {model_info.project_name}")
                        print(f"ğŸ” é”™è¯¯è¯¦æƒ…: {e}")
                        return None
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œé”™è¯¯
                elif "timeout" in error_message.lower() or "connection" in error_message.lower():
                    if attempt < max_retries:
                        retry_delay = base_delay * 2  # ç½‘ç»œé”™è¯¯æ—¶ç­‰å¾…è¾ƒçŸ­æ—¶é—´
                        print(f"âš ï¸ ç½‘ç»œé”™è¯¯ - æ¨¡å‹: {model_info.project_name}")
                        print(f"ğŸ• ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        import time
                        time.sleep(retry_delay)
                        continue
                    else:
                        print(f"âŒ ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•æ¬¡æ•°å·²ç”¨å®Œ - æ¨¡å‹: {model_info.project_name}")
                        print(f"ğŸ” é”™è¯¯è¯¦æƒ…: {e}")
                        return None
                
                # å…¶ä»–é”™è¯¯ç›´æ¥å¤±è´¥
                else:
                    print(f"âŒ æå–å…³é”®è¯æ—¶å‡ºé”™ - æ¨¡å‹: {model_info.project_name}")
                    print(f"ğŸ” é”™è¯¯è¯¦æƒ…: {e}")
                    print(f"ğŸŒ æ¨¡å‹URL: {model_info.url}")
                    return None
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        print(f"âŒ æ‰€æœ‰é‡è¯•å°è¯•å‡å¤±è´¥ - æ¨¡å‹: {model_info.project_name}")
        return None
    
    # _parse_keywords_response æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor
    
    # _validate_keyword å’Œ _clean_keyword æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor
    
    def extract_batch_keywords(self, model_infos: List[ModelInfo]) -> List[KeywordResult]:
        """
        æ‰¹é‡æå–å…³é”®è¯ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            model_infos: æ¨¡å‹ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            å…³é”®è¯æå–ç»“æœåˆ—è¡¨
        """
        results = []
        total = len(model_infos)
        
        print(f"å¼€å§‹æ‰¹é‡æå– {total} ä¸ªæ¨¡å‹çš„å…³é”®è¯...")
        print(f"âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘å»¶è¿Ÿï¼Œæé«˜å¤„ç†é€Ÿåº¦")
        
        for i, model_info in enumerate(model_infos, 1):
            print(f"\nè¿›åº¦: {i}/{total}")
            
            # è·³è¿‡æ— æ•ˆçš„æ¨¡å‹ä¿¡æ¯
            # è¯´æ˜AIå°†åŸºäºçˆ¬å–çš„æ•°æ®è¿›è¡Œåˆ†æ
            print(f"ğŸ“¡ æ¨¡å‹ {model_info.project_name} - AIå°†åŸºäºçˆ¬å–çš„READMEå’Œæ ‡ç­¾ä¿¡æ¯è¿›è¡Œåˆ†æ")
            
            result = self.extract_keywords(model_info)
            if result:
                results.append(result)
                # âœ¨ å®æ—¶æ›´æ–°æ’é™¤é˜Ÿåˆ—
                self.update_exclusion_queue(result.keywords)
            
            # æ™ºèƒ½å»¶è¿Ÿï¼šæ ¹æ®å¤„ç†é€Ÿåº¦åŠ¨æ€è°ƒæ•´
            import time
            if i < total:  # æœ€åä¸€ä¸ªä¸éœ€è¦å»¶è¿Ÿ
                # å¦‚æœå¤„ç†é€Ÿåº¦å¿«ï¼Œå‡å°‘å»¶è¿Ÿï¼›å¦‚æœæ…¢ï¼Œä¿æŒé€‚å½“å»¶è¿Ÿ
                delay = 1 if i % 5 == 0 else 0.5  # æ¯5ä¸ªæ¨¡å‹ç¨å¾®é•¿ä¸€ç‚¹å»¶è¿Ÿ
                time.sleep(delay)
        
        print(f"\næ‰¹é‡æå–å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(results)} ä¸ªæ¨¡å‹")
        return results
    
    # deduplicate_keywords, _is_similar_keyword_exists, _fix_common_json_errors, _enhance_brand_keywords æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor


def test_extractor():
    """æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½"""
    extractor = KeywordExtractor()
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹ä¿¡æ¯
    test_model = ModelInfo(
        url="https://ai.gitcode.com/ifly_opensource/Spark-Chemistry-X1-13B",
        project_name="ifly_opensource/Spark-Chemistry-X1-13B",
        readme="Spark Chemistry X1 13B æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºåŒ–å­¦æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸºäºå…ˆè¿›çš„Transformeræ¶æ„ï¼Œç»è¿‡åŒ–å­¦ç›¸å…³æ•°æ®çš„æ·±åº¦è®­ç»ƒï¼Œèƒ½å¤Ÿè¿›è¡Œå¤æ‚çš„åŒ–å­¦åˆ†æã€ååº”é¢„æµ‹å’Œåˆ†å­è®¾è®¡ã€‚æ¨¡å‹æ”¯æŒå¤šç§åŒ–å­¦ä»»åŠ¡ï¼ŒåŒ…æ‹¬åŒ–å­¦ååº”é¢„æµ‹ã€åˆ†å­æ€§è´¨åˆ†æã€åŒ–å­¦æ–¹ç¨‹å¼å¹³è¡¡ç­‰ã€‚",
        tags=["æ–‡æœ¬ç”Ÿæˆ", "Transformers", "Safetensors", "è‹±æ–‡", "æ±‰è¯­", "Apache License 2.0", "chemistry", "scientific llm", "CoT", "reasoning"]
    )
    
    # æµ‹è¯•å…³é”®è¯æå–
    result = extractor.extract_keywords(test_model)
    
    if result:
        print(f"\næ¨¡å‹: {result.model_url}")
        print("æå–çš„å…³é”®è¯:")
        for kw in result.keywords:
            print(f"- {kw['keyword']} ({kw['dimension']}): {kw['reason']}")
    else:
        print("å…³é”®è¯æå–å¤±è´¥")


if __name__ == "__main__":
    test_extractor()
