"""
åŸºç¡€å…³é”®è¯æå–å™¨ - æå–å…¬å…±ä»£ç 
"""
import os
import re
import json
from typing import List, Dict, Any, Optional
from abc import ABC, abstractmethod

from models import ModelInfo, KeywordResult


class BaseKeywordExtractor(ABC):
    """åŸºç¡€å…³é”®è¯æå–å™¨æŠ½è±¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ’é™¤é˜Ÿåˆ—ç›¸å…³å±æ€§"""
        self.keyword_frequency = {}  # å…³é”®è¯é¢‘ç‡ç»Ÿè®¡
        self.excluded_keywords = []  # æ’é™¤é˜Ÿåˆ—
    
    def update_exclusion_queue(self, keywords: List[Dict[str, str]]):
        """æ›´æ–°æ’é™¤é˜Ÿåˆ— - æ¯å¤„ç†ä¸€ä¸ªæ¨¡å‹åè°ƒç”¨"""
        # ç»Ÿè®¡é¢‘ç‡
        for kw_dict in keywords:
            keyword = kw_dict.get('keyword', '')
            self.keyword_frequency[keyword] = self.keyword_frequency.get(keyword, 0) + 1
        
        # ç­›é€‰é«˜é¢‘è¯ï¼ˆå‡ºç°â‰¥10æ¬¡ï¼‰
        high_freq_keywords = [
            kw for kw, count in self.keyword_frequency.items() 
            if count >= 10
        ]
        
        # æŒ‰é¢‘ç‡æ’åºï¼Œå–Top 50
        high_freq_keywords.sort(
            key=lambda k: self.keyword_frequency[k], 
            reverse=True
        )
        self.excluded_keywords = high_freq_keywords[:50]
    
    def build_prompt(self, model_info: ModelInfo) -> str:
        """
        æ ¹æ®éœ€æ±‚æ–‡æ¡£æ„å»ºPrompt
        
        Args:
            model_info: æ¨¡å‹ä¿¡æ¯
            
        Returns:
            æ„å»ºå¥½çš„prompt
        """
        prompt = f"""ä½ æ˜¯AIé¡¹ç›®è¿è¥ä¸“å®¶ï¼Œä½ éœ€è¦åœ¨æ¨¡å‹é¡µé¢ä¸­æå–å¼•æµå…³é”®è¯ä»¥ä¾¿æŠ•æ”¾åˆ°åšå®¢ç½‘ç«™å½“ä¸­ã€‚

é¡¹ç›®: {model_info.project_name}
URL: {model_info.url}

READMEå†…å®¹ï¼ˆå‰800å­—ç¬¦ï¼‰ï¼š
{(model_info.readme[:800] + "...") if model_info.readme and len(model_info.readme) > 800 else (model_info.readme if model_info.readme else "æš‚æ— READMEå†…å®¹")}

æ ‡ç­¾: {', '.join(model_info.tags) if model_info.tags else "æš‚æ— æ ‡ç­¾"}

## æå–è§„åˆ™
1. åŸºäºåŸæ–‡å†…å®¹ï¼Œæå–4-8ä¸ªå¼•æµå…³é”®è¯
2. å“ç‰ŒååŠ "å¤§æ¨¡å‹"åç¼€ï¼šNVIDIAâ†’NVIDIAå¤§æ¨¡å‹
3. å‚æ•°ä¼˜åŒ–ï¼š6710äº¿â†’671Bå‚æ•°ï¼Œ25äº¿â†’2.5Bå‚æ•°ï¼Œ1060äº¿â†’106Bå‚æ•°
4. ç¦æ­¢ï¼šè®¸å¯è¯ã€é•œåƒã€ç‰ˆæœ¬å·ã€æ— æ„ä¹‰æ•°å­—

## 6ä¸ªç»´åº¦
1. **çƒ­é—¨æ¨¡å‹å“ç‰Œ**: InternLMå¤§æ¨¡å‹ã€GLMå¤§æ¨¡å‹ç­‰
2. **æ ¸å¿ƒæŠ€æœ¯æ¶æ„**: Transformerã€MoEæ¶æ„ã€FP8é‡åŒ–ç­‰  
3. **åº”ç”¨åœºæ™¯**: æ–‡æœ¬ç”Ÿæˆã€å›¾åƒç†è§£ã€ç§‘å­¦è®¡ç®—ç­‰
4. **éƒ¨ç½²é›†æˆ**: Ollamaéƒ¨ç½²ã€Transformersã€ComfyUIç­‰
5. **æ€§èƒ½è§„æ ¼**: 671Bå‚æ•°ã€128Kä¸Šä¸‹æ–‡ç­‰
6. **ä¸“ä¸šé¢†åŸŸ**: ç§‘å­¦è®¡ç®—ã€åŒ–å­¦åˆ†æã€ä»£ç ç¼–ç¨‹ç­‰

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ä»£ç å—ï¼š

{{
  "keywords": [
    {{
      "keyword": "InternLMå¤§æ¨¡å‹",
      "dimension": "çƒ­é—¨æ¨¡å‹å“ç‰Œ", 
      "reason": "çŸ¥åå¼€æºå¤§æ¨¡å‹ï¼Œæœç´¢çƒ­åº¦é«˜"
    }},
    {{
      "keyword": "å¤šæ¨¡æ€æ¨ç†",
      "dimension": "æ ¸å¿ƒæŠ€æœ¯æ¶æ„",
      "reason": "AIæŠ€æœ¯çƒ­ç‚¹ï¼Œå¼€å‘è€…å…³æ³¨åº¦é«˜"
    }}
  ]
}}

è¦æ±‚ï¼š4-8ä¸ªå…³é”®è¯ï¼Œæ¯ä¸ªåŒ…å«keywordã€dimensionã€reasonå­—æ®µã€‚"""

        # æ·»åŠ æ’é™¤é˜Ÿåˆ—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        exclusion_text = ""
        if self.excluded_keywords:
            exclusion_text = f"""

## ğŸš« å¼ºåˆ¶æ’é™¤å…³é”®è¯ï¼ˆé«˜é¢‘è¯ï¼‰
ä»¥ä¸‹å…³é”®è¯å·²è¢«å¤§é‡ä½¿ç”¨ï¼Œ**ä¸¥ç¦å†æ¬¡æå–**ï¼š
{', '.join(self.excluded_keywords[:50])}

ä½ å¿…é¡»æå–è¯¥æ¨¡å‹**ç‹¬ç‰¹çš„ã€æœ‰åŒºåˆ†åº¦çš„**å…³é”®è¯ï¼Œé¿å¼€ä¸Šè¿°æ‰€æœ‰é«˜é¢‘è¯ã€‚
"""
            prompt += exclusion_text

        return prompt
    
    def _parse_keywords_response(self, response: str) -> List[Dict[str, str]]:
        """
        è§£æAIå“åº”ä¸­çš„å…³é”®è¯JSON
        
        Args:
            response: AIå“åº”å†…å®¹
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šå°è¯•ç›´æ¥è§£æï¼ˆAIåº”è¯¥è¿”å›æ ‡å‡†JSONï¼‰
            cleaned_response = response.strip()
            
            # æ¸…ç†å¯èƒ½çš„ä¸­æ–‡å¼•å·é—®é¢˜
            json_str = cleaned_response.replace('"', '"').replace('"', '"')
            json_str = json_str.replace(''', "'").replace(''', "'")
            
            # ç›´æ¥å°è¯•è§£æ
            try:
                data = json.loads(json_str)
            except json.JSONDecodeError:
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                if '```json' in json_str:
                    start = json_str.find('```json') + 7
                    end = json_str.find('```', start)
                    if end != -1:
                        json_str = json_str[start:end].strip()
                    else:
                        json_str = json_str[start:].strip()
                else:
                    # æŸ¥æ‰¾JSONå¯¹è±¡è¾¹ç•Œ
                    start_pos = json_str.find('{')
                    if start_pos != -1:
                        end_pos = json_str.rfind('}')
                        if end_pos != -1 and end_pos > start_pos:
                            json_str = json_str[start_pos:end_pos+1]
                
                # å†æ¬¡æ¸…ç†å’Œè§£æ
                json_str = json_str.replace('"', '"').replace('"', '"')
                json_str = json_str.replace(''', "'").replace(''', "'")
                
                # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
                json_str = self._fix_common_json_errors(json_str)
                
                # å°è¯•ä¿®å¤æˆªæ–­çš„JSON
                json_str = self._fix_truncated_json(json_str)
                
                data = json.loads(json_str)
            
            keywords = data.get('keywords', [])
            
            # éªŒè¯å…³é”®è¯æ•°é‡ï¼ˆé€‚åº¦æ”¾å®½è‡³3-8ä¸ªä»¥å‡å°‘å¤±è´¥ç‡ï¼‰
            if len(keywords) < 3:
                print(f"âš ï¸ å…³é”®è¯æ•°é‡ä¸è¶³ï¼šåªæœ‰{len(keywords)}ä¸ªï¼Œè¦æ±‚è‡³å°‘3ä¸ª")
                return []
            elif len(keywords) > 8:
                print(f"âš ï¸ å…³é”®è¯æ•°é‡è¿‡å¤šï¼šæœ‰{len(keywords)}ä¸ªï¼Œè¦æ±‚3-8ä¸ªï¼Œå–å‰8ä¸ª")
                keywords = keywords[:8]
            else:
                print(f"âœ… å…³é”®è¯æ•°é‡ç¬¦åˆè¦æ±‚ï¼š{len(keywords)}ä¸ª")
            
            # éªŒè¯å’Œæ¸…ç†å…³é”®è¯
            cleaned_keywords = []
            for kw in keywords:
                if self._validate_keyword(kw):
                    cleaned_kw = self._clean_keyword(kw)
                    # åªæ£€æŸ¥å½“å‰æ¨¡å‹å†…çš„é‡å¤ï¼Œä¸è·¨æ¨¡å‹å»é‡
                    current_keywords = [k['keyword'] for k in cleaned_keywords]
                    if cleaned_kw['keyword'] not in current_keywords:
                        cleaned_keywords.append(cleaned_kw)
            
            return cleaned_keywords
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"ğŸ“ AIå®Œæ•´è¿”å›å†…å®¹:")
            print("=" * 80)
            print(response[:1500] + ("..." if len(response) > 1500 else ""))
            print("=" * 80)
            print("ğŸ’¡ æç¤ºï¼šAIå¯èƒ½æ²¡æœ‰æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›")
            return []
        except Exception as e:
            print(f"âŒ è§£æå“åº”æ—¶å‡ºé”™: {e}")
            print(f"ğŸ“ AIå®Œæ•´è¿”å›å†…å®¹:")
            print("=" * 80)
            print(response[:1500] + ("..." if len(response) > 1500 else ""))
            print("=" * 80)
            return []
    
    def _validate_keyword(self, keyword_obj: Dict[str, str]) -> bool:
        """
        éªŒè¯å…³é”®è¯å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            keyword_obj: å…³é”®è¯å¯¹è±¡
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        required_fields = ['keyword', 'dimension', 'reason']
        return all(field in keyword_obj and keyword_obj[field].strip() for field in required_fields)
    
    def _clean_keyword(self, keyword_obj: Dict[str, str]) -> Dict[str, str]:
        """
        æ¸…ç†å…³é”®è¯ï¼Œç¡®ä¿ç¬¦åˆæ ¼å¼è¦æ±‚
        
        Args:
            keyword_obj: åŸå§‹å…³é”®è¯å¯¹è±¡
            
        Returns:
            æ¸…ç†åçš„å…³é”®è¯å¯¹è±¡
        """
        keyword = keyword_obj['keyword'].strip()
        
        # ç§»é™¤æ‹¬å·
        keyword = re.sub(r'[()ï¼ˆï¼‰]', '', keyword)
        
        # æ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
        keyword = re.sub(r'\s+', '-', keyword)
        
        # åªä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦ã€ç‚¹å·
        keyword = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.-]', '', keyword)
        
        # ç§»é™¤è¿ç»­çš„è¿å­—ç¬¦å’Œç‚¹å·
        keyword = re.sub(r'-+', '-', keyword)
        keyword = re.sub(r'\.+', '.', keyword)
        
        # ç§»é™¤é¦–å°¾è¿å­—ç¬¦å’Œç‚¹å·
        keyword = keyword.strip('-.')
        
        # ä½†ä¿ç•™ç‰ˆæœ¬å·æ ¼å¼ï¼ˆå¦‚v2.0, FLUX.1ç­‰ï¼‰
        # å¦‚æœå…³é”®è¯ä»¥vå¼€å¤´ä¸”åŒ…å«ç‚¹å·ï¼Œä¿ç•™å®ƒ
        if keyword.lower().startswith('v') and '.' in keyword:
            pass  # ä¿æŒåŸæ ·ï¼Œä¸å†å¤„ç†
        # å¦‚æœæ˜¯å¸¸è§çš„ç‰ˆæœ¬å·æ ¼å¼ï¼Œä¹Ÿä¿ç•™
        elif re.match(r'^[A-Za-z0-9]+\.[0-9]+$', keyword):
            pass  # ä¿æŒåŸæ ·ï¼Œå¦‚FLUX.1, GPT.4ç­‰
        
        # å“ç‰Œåç§°æ™ºèƒ½æ‰©å±•ç­–ç•¥
        keyword = self._enhance_brand_keywords(keyword, keyword_obj['dimension'])
        
        return {
            'keyword': keyword,
            'dimension': keyword_obj['dimension'].strip(),
            'reason': keyword_obj['reason'].strip()
        }
    
    def _fix_common_json_errors(self, json_str: str) -> str:
        """
        ä¿®å¤AIç”ŸæˆJSONä¸­çš„å¸¸è§é”™è¯¯
        
        Args:
            json_str: å¾…ä¿®å¤çš„JSONå­—ç¬¦ä¸²
            
        Returns:
            ä¿®å¤åçš„JSONå­—ç¬¦ä¸²
        """
        import re
        
        # ä¿®å¤ç¼ºå¤±å¼€æ‹¬å·çš„æƒ…å†µï¼š},\n  "keyword" â†’ },\n  {"keyword"
        # åŒ¹é…ï¼š},åé¢è·Ÿç€æ¢è¡Œå’Œç©ºæ ¼ï¼Œç„¶åç›´æ¥æ˜¯"keyword"ï¼ˆè€Œä¸æ˜¯{ï¼‰
        pattern = r'(\},\s*\n\s*)("keyword":)'
        json_str = re.sub(pattern, r'\1{\2', json_str)
        
        # ä¿®å¤å¤šä½™é€—å·çš„æƒ…å†µï¼š},\n  }\n] â†’ }\n  }\n]
        json_str = re.sub(r',(\s*\}\s*\])', r'\1', json_str)
        
        # ä¿®å¤ç¼ºå¤±é€—å·çš„æƒ…å†µï¼š}\n  { â†’ },\n  {
        json_str = re.sub(r'(\})\s*\n\s*(\{)', r'\1,\n  \2', json_str)
        
        return json_str
    
    def _fix_truncated_json(self, json_str: str) -> str:
        """ä¿®å¤æˆªæ–­çš„JSON"""
        import re
        
        # å¦‚æœJSONè¢«æˆªæ–­ï¼Œå°è¯•ä¿®å¤
        if not json_str.endswith('}'):
            # æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
            last_complete_obj = json_str.rfind('}')
            if last_complete_obj != -1:
                # æ£€æŸ¥æ˜¯å¦åœ¨keywordsæ•°ç»„ä¸­
                before_last = json_str[:last_complete_obj]
                if '"keywords"' in before_last:
                    # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„keywordå¯¹è±¡
                    keyword_objects = re.findall(r'\{[^}]*"keyword"[^}]*\}', before_last)
                    if keyword_objects:
                        # ä½¿ç”¨æœ€åä¸€ä¸ªå®Œæ•´çš„keywordå¯¹è±¡
                        last_keyword = keyword_objects[-1]
                        # é‡æ–°æ„å»ºJSON
                        json_str = before_last[:before_last.rfind(last_keyword)] + last_keyword + '}]}'
                    else:
                        # å¦‚æœæ²¡æœ‰å®Œæ•´çš„keywordå¯¹è±¡ï¼Œå°è¯•æ·»åŠ ç¼ºå¤±çš„ç»“æŸç¬¦
                        json_str = before_last + '}]}'
        
        return json_str
    
    def _enhance_brand_keywords(self, keyword: str, dimension: str) -> str:
        """
        å“ç‰Œå…³é”®è¯æ™ºèƒ½æ‰©å±•ç­–ç•¥
        
        Args:
            keyword: åŸå§‹å…³é”®è¯
            dimension: å…³é”®è¯ç»´åº¦
            
        Returns:
            æ‰©å±•åçš„å…³é”®è¯
        """
        # åªå¯¹"å“ç‰Œä¸èº«ä»½"ç»´åº¦çš„å…³é”®è¯è¿›è¡Œæ‰©å±•
        if dimension != "å“ç‰Œä¸èº«ä»½":
            return keyword
        
        # å®šä¹‰éœ€è¦æ‰©å±•çš„å“ç‰Œåç§°åˆ—è¡¨
        brand_names = {
            # ä¸­å›½å¤§å‚
            "ç™¾åº¦": "ç™¾åº¦å¤§æ¨¡å‹",
            "è…¾è®¯": "è…¾è®¯å¤§æ¨¡å‹", 
            "é˜¿é‡Œ": "é˜¿é‡Œå¤§æ¨¡å‹",
            "é˜¿é‡Œå·´å·´": "é˜¿é‡Œå·´å·´å¤§æ¨¡å‹",
            "å­—èŠ‚": "å­—èŠ‚å¤§æ¨¡å‹",
            "å­—èŠ‚è·³åŠ¨": "å­—èŠ‚è·³åŠ¨å¤§æ¨¡å‹",
            "åä¸º": "åä¸ºå¤§æ¨¡å‹",
            "å°ç±³": "å°ç±³å¤§æ¨¡å‹",
            "å¿«æ‰‹": "å¿«æ‰‹å¤§æ¨¡å‹",
            "ç½‘æ˜“": "ç½‘æ˜“å¤§æ¨¡å‹",
            "äº¬ä¸œ": "äº¬ä¸œå¤§æ¨¡å‹",
            "ç¾å›¢": "ç¾å›¢å¤§æ¨¡å‹",
            "æ»´æ»´": "æ»´æ»´å¤§æ¨¡å‹",
            
            # å›½é™…å¤§å‚
            "OpenAI": "OpenAIå¤§æ¨¡å‹",
            "Google": "Googleå¤§æ¨¡å‹", 
            "è°·æ­Œ": "è°·æ­Œå¤§æ¨¡å‹",
            "Microsoft": "Microsoftå¤§æ¨¡å‹",
            "å¾®è½¯": "å¾®è½¯å¤§æ¨¡å‹",
            "Meta": "Metaå¤§æ¨¡å‹",
            "Facebook": "Facebookå¤§æ¨¡å‹",
            "Amazon": "Amazonå¤§æ¨¡å‹",
            "äºšé©¬é€Š": "äºšé©¬é€Šå¤§æ¨¡å‹",
            "Apple": "Appleå¤§æ¨¡å‹",
            "è‹¹æœ": "è‹¹æœå¤§æ¨¡å‹",
            "NVIDIA": "NVIDIAå¤§æ¨¡å‹",
            "è‹±ä¼Ÿè¾¾": "è‹±ä¼Ÿè¾¾å¤§æ¨¡å‹",
            
            # AIåˆ›ä¸šå…¬å¸
            "æ™ºè°±": "æ™ºè°±å¤§æ¨¡å‹",
            "æœˆä¹‹æš—é¢": "æœˆä¹‹æš—é¢å¤§æ¨¡å‹",
            "é›¶ä¸€ä¸‡ç‰©": "é›¶ä¸€ä¸‡ç‰©å¤§æ¨¡å‹",
            "æ·±åº¦æ±‚ç´¢": "æ·±åº¦æ±‚ç´¢å¤§æ¨¡å‹",
            "å•†æ±¤": "å•†æ±¤å¤§æ¨¡å‹",
            "æ—·è§†": "æ—·è§†å¤§æ¨¡å‹",
            "ç§‘å¤§è®¯é£": "ç§‘å¤§è®¯é£å¤§æ¨¡å‹",
            "äº‘çŸ¥å£°": "äº‘çŸ¥å£°å¤§æ¨¡å‹",
            "å‡ºé—¨é—®é—®": "å‡ºé—¨é—®é—®å¤§æ¨¡å‹",
            "å°å†°": "å°å†°å¤§æ¨¡å‹"
        }
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºéœ€è¦æ‰©å±•çš„å“ç‰Œåç§°
        for brand, enhanced in brand_names.items():
            if keyword == brand:
                print(f"ğŸ”„ å“ç‰Œæ‰©å±•: {brand} â†’ {enhanced}")
                return enhanced
        
        return keyword
    
    def deduplicate_keywords(self, keyword_results: List[KeywordResult]) -> List[KeywordResult]:
        """
        ä¸è¿›è¡Œå»é‡ï¼Œç›´æ¥è¿”å›åŸå§‹ç»“æœ
        å»é‡å°†åœ¨CSVç”Ÿæˆé˜¶æ®µç»Ÿä¸€å¤„ç†
        
        Args:
            keyword_results: å…³é”®è¯æå–ç»“æœåˆ—è¡¨
            
        Returns:
            åŸå§‹ç»“æœåˆ—è¡¨ï¼ˆæ— å»é‡ï¼‰
        """
        print("è·³è¿‡å…³é”®è¯å»é‡ï¼Œå°†åœ¨CSVç”Ÿæˆæ—¶ç»Ÿä¸€å»é‡")
        return keyword_results
    
    def _is_similar_keyword_exists(self, keyword: str, existing_keywords: set) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸ä¼¼çš„å…³é”®è¯ï¼ˆå®½æ¾ç‰ˆï¼šåªæ£€æŸ¥å®Œå…¨é‡å¤ï¼‰
        
        Args:
            keyword: å¾…æ£€æŸ¥çš„å…³é”®è¯
            existing_keywords: å·²å­˜åœ¨çš„å…³é”®è¯é›†åˆ
            
        Returns:
            æ˜¯å¦å­˜åœ¨ç›¸ä¼¼å…³é”®è¯
        """
        keyword_lower = keyword.lower()
        
        for existing in existing_keywords:
            existing_lower = existing.lower()
            
            # åªæ£€æŸ¥å®Œå…¨ç›¸åŒçš„æƒ…å†µï¼Œä¸å†æ£€æŸ¥åŒ…å«å…³ç³»
            # è¿™æ ·å¯ä»¥ä¿ç•™æ›´å¤šæœ‰æ„ä¹‰çš„å…³é”®è¯å˜ä½“
            if keyword_lower == existing_lower:
                return True
        
        return False
    
    @abstractmethod
    def extract_keywords(self, model_info: ModelInfo) -> Optional[KeywordResult]:
        """æå–å…³é”®è¯çš„æŠ½è±¡æ–¹æ³•"""
        pass
    
    @abstractmethod
    def extract_batch_keywords(self, model_infos: List[ModelInfo]) -> List[KeywordResult]:
        """æ‰¹é‡æå–å…³é”®è¯çš„æŠ½è±¡æ–¹æ³•"""
        pass
