"""
åŸºç¡€å…³é”®è¯æå–å™¨ - æå–å…¬å…±ä»£ç 
"""
import os
import re
import json
from typing import List, Dict, Any, Optional
from abc import ABC, abstractmethod

from models import ModelInfo, KeywordResult


class BaseKeywordExtractor(ABC):
    """åŸºç¡€å…³é”®è¯æå–å™¨æŠ½è±¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ’é™¤é˜Ÿåˆ—ç›¸å…³å±æ€§"""
        self.keyword_frequency = {}  # å…³é”®è¯é¢‘ç‡ç»Ÿè®¡
        self.excluded_keywords = []  # æ’é™¤é˜Ÿåˆ—
    
    def update_exclusion_queue(self, keywords: List[Dict[str, str]]):
        """æ›´æ–°æ’é™¤é˜Ÿåˆ— - æ¯å¤„ç†ä¸€ä¸ªæ¨¡å‹åè°ƒç”¨"""
        # ç»Ÿè®¡é¢‘ç‡
        for kw_dict in keywords:
            keyword = kw_dict.get('keyword', '')
            self.keyword_frequency[keyword] = self.keyword_frequency.get(keyword, 0) + 1
        
        # ç­›é€‰é«˜é¢‘è¯ï¼ˆå‡ºç°â‰¥10æ¬¡ï¼‰
        high_freq_keywords = [
            kw for kw, count in self.keyword_frequency.items() 
            if count >= 10
        ]
        
        # æŒ‰é¢‘ç‡æ’åºï¼Œå–Top 50
        high_freq_keywords.sort(
            key=lambda k: self.keyword_frequency[k], 
            reverse=True
        )
        self.excluded_keywords = high_freq_keywords[:50]
    
    def build_prompt(self, model_info: ModelInfo) -> str:
        """
        æ ¹æ®éœ€æ±‚æ–‡æ¡£æ„å»ºPrompt
        
        Args:
            model_info: æ¨¡å‹ä¿¡æ¯
            
        Returns:
            æ„å»ºå¥½çš„prompt
        """
        prompt = f"""ä½ æ˜¯AIé¡¹ç›®è¿è¥ä¸“å®¶ï¼Œä½ éœ€è¦åœ¨æ¨¡å‹é¡µé¢ä¸­æå–å¼•æµå…³é”®è¯ä»¥ä¾¿æŠ•æ”¾åˆ°åšå®¢ç½‘ç«™å½“ä¸­ã€‚

é¡¹ç›®: {model_info.project_name}
URL: {model_info.url}

READMEå†…å®¹ï¼ˆå‰800å­—ç¬¦ï¼‰ï¼š
{(model_info.readme[:800] + "...") if model_info.readme and len(model_info.readme) > 800 else (model_info.readme if model_info.readme else "æš‚æ— READMEå†…å®¹")}

æ ‡ç­¾: {', '.join(model_info.tags) if model_info.tags else "æš‚æ— æ ‡ç­¾"}

## æ ¸å¿ƒåŸåˆ™ï¼šé«˜äº®è¯æ˜¯"ç”¨æˆ·æœç´¢AIæ¨¡å‹æ—¶ä¼šç”¨çš„è¯"

**å¼•æµé€»è¾‘**ï¼š
ç”¨æˆ·åœ¨CSDNæœç´¢"SD-XL" â†’ çœ‹åˆ°åšå®¢ â†’ ç‚¹å‡»åšå®¢ä¸­çš„"SD-XL"é«˜äº®è¯ â†’ è·³è½¬åˆ°GitCodeæŸ¥çœ‹SD-XLæ¨¡å‹

**âš ï¸ æœ€é‡è¦è§„åˆ™ï¼šåªæå–å½“å‰æ¨¡å‹è‡ªèº«çš„å…³é”®è¯ï¼Œä¸¥ç¦æå–å…¶ä»–æ¨¡å‹çš„åç§°**

**æ­£ç¡®ç¤ºä¾‹**ï¼š
- âœ… å½“å‰æ¨¡å‹ï¼šDeepSeek-R1-Distill-Qwen â†’ æå–ï¼šDeepSeek-R1ã€é“¾å¼æ€ç»´ã€è‡ªæˆ‘éªŒè¯
- âŒ READMEæåˆ°"è¶…è¶ŠOpenAI-o1" â†’ ä¸è¦æå–"OpenAI-o1"ï¼ˆè¿™æ˜¯å…¶ä»–æ¨¡å‹ï¼‰
- âŒ READMEæåˆ°"åŸºäºQwen2.5" â†’ ä¸è¦æå–"Qwen2.5"ï¼ˆè¿™æ˜¯åŸºç¡€æ¨¡å‹ï¼Œä¸æ˜¯å½“å‰æ¨¡å‹ï¼‰
- âŒ READMEæåˆ°"å¯¹æ ‡GPT-4" â†’ ä¸è¦æå–"GPT-4"ï¼ˆè¿™æ˜¯å¯¹æ¯”å¯¹è±¡ï¼Œä¸æ˜¯å½“å‰æ¨¡å‹ï¼‰

**å› æ­¤é«˜äº®è¯å¿…é¡»æ˜¯å½“å‰æ¨¡å‹è‡ªèº«çš„**ï¼š
- âœ… å½“å‰æ¨¡å‹çš„åç§°ï¼ˆä»é¡¹ç›®åç§°æå–ï¼Œå¦‚DeepSeek-R1ã€JanusFlowã€GLM-4ï¼‰
- âœ… å½“å‰æ¨¡å‹çš„åŠŸèƒ½/ç”¨é€”ï¼ˆæ–‡ç”Ÿå›¾ã€ç¼–ç¨‹åŠ©æ‰‹ã€AIå†™ä½œï¼‰
- âœ… å½“å‰æ¨¡å‹çš„éƒ¨ç½²æ–¹å¼ï¼ˆOllamaéƒ¨ç½²ã€æœ¬åœ°éƒ¨ç½²ã€ComfyUIï¼‰
- âœ… å½“å‰æ¨¡å‹çš„æŠ€æœ¯ç‰¹æ€§ï¼ˆå¤šæ¨¡æ€ã€é‡åŒ–æ¨¡å‹ã€MoEæ¶æ„ã€é“¾å¼æ€ç»´ï¼‰

**ä¸¥ç¦æå–**ï¼š
- âŒ **å…¶ä»–æ¨¡å‹åç§°**ï¼ˆOpenAI-o1ã€GPT-4ã€Claudeã€Qwen2.5ã€Llamaç­‰ï¼‰â†’ READMEä¸­ä½œä¸ºå¯¹æ¯”/åŸºç¡€çš„æ¨¡å‹
- âŒ ç¡¬ä»¶ç›¸å…³ï¼ˆæ¶ˆè´¹çº§æ˜¾å¡ã€A100ã€GPUï¼‰â†’ ç”¨æˆ·æœè¿™ä¸ªæ˜¯ä¹°æ˜¾å¡ï¼Œä¸æ˜¯æ‰¾æ¨¡å‹
- âŒ é€šç”¨å½¢å®¹è¯ï¼ˆé«˜æ•ˆã€é«˜æ¸…ã€å¼ºå¤§ã€ä¼˜ç§€ï¼‰â†’ å¤ªæ³›æ³›ï¼Œæ²¡æœ‰æŒ‡å‘æ€§
- âŒ æŠ€æœ¯ç»†èŠ‚ï¼ˆ128Kè¯è¡¨ã€8192ä¸Šä¸‹æ–‡é•¿åº¦ï¼‰â†’ å¤ªä¸“ä¸šï¼Œæ™®é€šç”¨æˆ·ä¸æœ

## æå–è§„åˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰
1. åŸºäºåŸæ–‡å†…å®¹ï¼Œæå–5-8ä¸ª**ç”¨æˆ·ä¼šæœç´¢çš„AIæ¨¡å‹ç›¸å…³è¯**
2. **æ¨¡å‹åç§°ç®€åŒ–**ï¼š
   - âœ… JanusFlowã€GLM-4ã€DeepSeek-V2ã€SD-XLï¼ˆç®€æ´å“ç‰Œåï¼‰
   - âŒ JanusFlow-1.3Bã€GLM-4-32B-0414ï¼ˆå¸¦ç‰ˆæœ¬å·å¤ªé•¿ï¼‰
3. **åŠŸèƒ½åœºæ™¯è¯**ï¼š
   - âœ… æ–‡ç”Ÿå›¾ã€AIå†™ä½œã€ç¼–ç¨‹åŠ©æ‰‹ã€æ™ºèƒ½å¯¹è¯ï¼ˆç”¨æˆ·æœç´¢æ„å›¾æ˜ç¡®ï¼‰
   - âŒ é«˜æ•ˆå¤„ç†ã€é«˜æ¸…ç”Ÿæˆï¼ˆå¤ªæ³›æ³›ï¼‰
4. **è¿æ¥ç¬¦ä½¿ç”¨è§„èŒƒ**ï¼š
   - âœ… SD-XLã€BERT-baseã€DeepSeek-V2ï¼ˆè‹±æ–‡-è‹±æ–‡å¯ä»¥ç”¨è¿å­—ç¬¦ï¼‰
   - âœ… æ–‡ç”Ÿå›¾ã€ç¼–ç¨‹åŠ©æ‰‹ã€AIå†™ä½œï¼ˆçº¯ä¸­æ–‡ï¼Œä¸éœ€è¦è¿å­—ç¬¦ï¼‰
   - âœ… PyTorchã€Transformerã€HuggingFaceï¼ˆçº¯è‹±æ–‡ï¼Œä¸éœ€è¦è¿å­—ç¬¦ï¼‰
   - âŒ æ–‡ç”Ÿå›¾-TextToImageã€ç¼–ç¨‹åŠ©æ‰‹-CodeAssistantï¼ˆä¸­æ–‡-è‹±æ–‡ç¦æ­¢ç”¨è¿å­—ç¬¦ï¼‰
5. **å‚æ•°è§„æ ¼**ï¼š
   - âœ… 7Bå‚æ•°ã€32Bå‚æ•°ï¼ˆä¸»æµè§„æ ¼ï¼Œç”¨æˆ·ä¼šæœï¼‰
   - âŒ 304Må‚æ•°ã€1.68å€åŠ é€Ÿï¼ˆå¤ªç»†èŠ‚æˆ–æ€§èƒ½æŒ‡æ ‡ï¼‰
6. **ä¸¥ç¦æå–ï¼ˆç‰¹åˆ«é‡è¦ï¼‰**ï¼š
   - âŒ **å…¶ä»–æ¨¡å‹åç§°**ï¼ˆOpenAI-o1ã€GPT-4ã€Claudeã€Geminiã€Qwen2.5ã€Llama3ã€Mistralç­‰ï¼‰
     â†’ READMEä¸­ä½œä¸ºå¯¹æ¯”ã€åŸºç¡€ã€å‚è€ƒçš„å…¶ä»–æ¨¡å‹ï¼Œç»å¯¹ä¸èƒ½æå–
   - âŒ ç¡¬ä»¶è¯æ±‡ï¼ˆæ¶ˆè´¹çº§æ˜¾å¡ã€A100ã€GPUã€æ˜¾å­˜ï¼‰
   - âŒ é€šç”¨å½¢å®¹è¯ï¼ˆé«˜æ•ˆã€é«˜æ¸…ã€å¼ºå¤§ã€ä¼˜ç§€ã€å…ˆè¿›ï¼‰
   - âŒ çº¯æ•°å­—ï¼ˆ50.0ã€1860863627ï¼‰
   - âŒ æ€§èƒ½æŒ‡æ ‡ï¼ˆ1.68å€åŠ é€Ÿã€250å€åŠ é€Ÿï¼‰
   - âŒ è¿‡é•¿æè¿°ï¼ˆColabå…è´¹GPUæ”¯æŒã€A100H100æ¨ç†ï¼‰
   - âŒ æŠ€æœ¯ç»†èŠ‚ï¼ˆ128Kè¯è¡¨ã€8192è¾“å…¥é•¿åº¦ï¼‰
   - âŒ æŠ½è±¡æ¦‚å¿µï¼ˆå®šç†è¯æ˜ã€é›¶æ ·æœ¬é¢„æµ‹ï¼‰
   - âŒ è¯­è¨€ç±»å‹ï¼ˆè‹±æ–‡æ‘˜è¦ã€ä¸­æ–‡ã€å¤šè¯­è¨€ï¼‰
   - âŒ **ä¸­æ–‡-è‹±æ–‡æ ¼å¼**ï¼ˆæ–‡ç”Ÿå›¾-TextToImageã€ç¼–ç¨‹åŠ©æ‰‹-CodeAssistantï¼‰

## 5ä¸ªç»´åº¦ï¼ˆç”¨æˆ·æœç´¢AIæ¨¡å‹æ—¶ä¼šç”¨çš„è¯ï¼‰
1. **å½“å‰æ¨¡å‹å“ç‰Œå**: åªæå–å½“å‰æ¨¡å‹çš„åç§°ï¼ˆä»é¡¹ç›®åç§°æå–ï¼‰
   - âœ… ç¤ºä¾‹ï¼šJanusFlowã€GLM-4ã€DeepSeek-R1ã€SD-XLã€MiniCPM
   - âŒ ç¦æ­¢ï¼šOpenAI-o1ã€GPT-4ã€Claudeï¼ˆREADMEä¸­æåˆ°çš„å…¶ä»–æ¨¡å‹ï¼‰
   
   **âš ï¸ å›½äº§å¤§æ¨¡å‹å“ç‰Œåæ˜ å°„è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰**ï¼š
   - ERNIE â†’ æå–"æ–‡å¿ƒä¸€è¨€"æˆ–"ç™¾åº¦å¤§æ¨¡å‹"
   - Qwen â†’ æå–"é€šä¹‰åƒé—®"æˆ–"é˜¿é‡Œå¤§æ¨¡å‹"
   - Hunyuan â†’ æå–"æ··å…ƒ"æˆ–"è…¾è®¯å¤§æ¨¡å‹"
   - GLM-4 â†’ æå–"æ™ºè°±AI"
   - ByteDance-Seed â†’ æå–"è±†åŒ…"æˆ–"å­—èŠ‚å¤§æ¨¡å‹"
   - MoonshotAI â†’ æå–"Kimi"æˆ–"æœˆä¹‹æš—é¢"

2. **åŠŸèƒ½åœºæ™¯**: æ–‡ç”Ÿå›¾ã€æ–‡ç”Ÿè§†é¢‘ã€AIå†™ä½œã€ç¼–ç¨‹åŠ©æ‰‹ã€æ™ºèƒ½å¯¹è¯ã€å›¾åƒä¿®å¤
3. **éƒ¨ç½²å·¥å…·**: Ollamaéƒ¨ç½²ã€æœ¬åœ°éƒ¨ç½²ã€ComfyUIã€é‡åŒ–æ¨¡å‹ã€APIè°ƒç”¨
4. **æŠ€æœ¯ç‰¹æ€§**: å¤šæ¨¡æ€ã€MoEæ¶æ„ã€Transformerã€è‡ªå›å½’æ¨¡å‹ã€é“¾å¼æ€ç»´
5. **å‚æ•°è§„æ ¼**: 7Bå‚æ•°ã€32Bå‚æ•°ã€671Bå‚æ•°ï¼ˆä»…ä¸»æµè§„æ ¼ï¼‰

## æ ¼å¼è§„èŒƒï¼ˆçœŸå®å†™ä½œä¹ æƒ¯ï¼‰
- âœ… **è‹±æ–‡-è‹±æ–‡**ï¼šSD-XLã€BERT-baseã€DeepSeek-V2ï¼ˆå¯ä»¥ç”¨è¿å­—ç¬¦ï¼‰
- âœ… **çº¯ä¸­æ–‡**ï¼šç¼–ç¨‹åŠ©æ‰‹ã€AIå†™ä½œã€æ–‡ç”Ÿå›¾
- âœ… **çº¯è‹±æ–‡**ï¼šTransformerã€PyTorchã€HuggingFace
- âŒ **ä¸­æ–‡-è‹±æ–‡**ï¼šæ–‡ç”Ÿå›¾-TextToImageã€ç¼–ç¨‹åŠ©æ‰‹-CodeAssistantï¼ˆç¦æ­¢ç”¨è¿å­—ç¬¦è¿æ¥ä¸­è‹±æ–‡ï¼‰

## è¾“å‡ºç¤ºä¾‹ï¼ˆç”¨æˆ·åœ¨CSDNæœç´¢æ—¶ä¼šç”¨çš„è¯ï¼‰

**ç¤ºä¾‹1 - æ™®é€šæ¨¡å‹**ï¼š
{{
  "keywords": [
    {{
      "keyword": "DeepSeek-R1",
      "dimension": "å½“å‰æ¨¡å‹å“ç‰Œå", 
      "reason": "ä»é¡¹ç›®åç§°æå–çš„å½“å‰æ¨¡å‹åç§°"
    }},
    {{
      "keyword": "é“¾å¼æ€ç»´",
      "dimension": "æŠ€æœ¯ç‰¹æ€§",
      "reason": "å½“å‰æ¨¡å‹çš„æ ¸å¿ƒæŠ€æœ¯ç‰¹æ€§"
    }},
    {{
      "keyword": "ç¼–ç¨‹åŠ©æ‰‹",
      "dimension": "åŠŸèƒ½åœºæ™¯",
      "reason": "å½“å‰æ¨¡å‹çš„åº”ç”¨åœºæ™¯"
    }}
  ]
}}

**ç¤ºä¾‹2 - å›½äº§å¤§æ¨¡å‹ï¼ˆéµå¾ªæ˜ å°„è§„åˆ™ï¼‰**ï¼š
{{
  "keywords": [
    {{
      "keyword": "é€šä¹‰åƒé—®",
      "dimension": "å½“å‰æ¨¡å‹å“ç‰Œå", 
      "reason": "é¡¹ç›®åç§°ä¸­æœ‰Qwenï¼Œæ˜ å°„ä¸ºé€šä¹‰åƒé—®"
    }},
    {{
      "keyword": "é˜¿é‡Œå¤§æ¨¡å‹",
      "dimension": "å½“å‰æ¨¡å‹å“ç‰Œå", 
      "reason": "Qwenå±äºé˜¿é‡Œå¤§æ¨¡å‹ç³»åˆ—"
    }},
    {{
      "keyword": "7Bå‚æ•°",
      "dimension": "å‚æ•°è§„æ ¼",
      "reason": "å½“å‰æ¨¡å‹çš„å‚æ•°è§„æ ¼"
    }}
  ]
}}

âš ï¸ **é”™è¯¯ç¤ºä¾‹ï¼ˆç»å¯¹ç¦æ­¢ï¼‰**ï¼š
- âŒ æå–"OpenAI-o1"ï¼ˆè¿™æ˜¯READMEä¸­ä½œä¸ºå¯¹æ¯”çš„å…¶ä»–æ¨¡å‹ï¼‰
- âŒ æå–"Qwen2.5"ï¼ˆå¦‚æœå½“å‰æ¨¡å‹ä¸æ˜¯Qwen2.5ï¼Œä¸è¦æå–ï¼‰
- âŒ æå–"GPT-4"ï¼ˆè¿™æ˜¯READMEä¸­ä½œä¸ºå‚è€ƒçš„å…¶ä»–æ¨¡å‹ï¼‰
- âŒ æå–"Qwen"ï¼ˆåº”è¯¥æ˜ å°„ä¸º"é€šä¹‰åƒé—®"æˆ–"é˜¿é‡Œå¤§æ¨¡å‹"ï¼‰

è¦æ±‚ï¼š5-8ä¸ªå…³é”®è¯ï¼Œæ¯ä¸ªåŒ…å«keywordã€dimensionã€reasonå­—æ®µã€‚"""

        # æ·»åŠ æ’é™¤é˜Ÿåˆ—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        exclusion_text = ""
        if self.excluded_keywords:
            exclusion_text = f"""

## ğŸš« å¼ºåˆ¶æ’é™¤å…³é”®è¯ï¼ˆé«˜é¢‘è¯ï¼‰
ä»¥ä¸‹å…³é”®è¯å·²è¢«å¤§é‡ä½¿ç”¨ï¼Œ**ä¸¥ç¦å†æ¬¡æå–**ï¼š
{', '.join(self.excluded_keywords[:50])}

ä½ å¿…é¡»æå–è¯¥æ¨¡å‹**ç‹¬ç‰¹çš„ã€æœ‰åŒºåˆ†åº¦çš„**å…³é”®è¯ï¼Œé¿å¼€ä¸Šè¿°æ‰€æœ‰é«˜é¢‘è¯ã€‚
"""
            prompt += exclusion_text

        return prompt
    
    def _parse_keywords_response(self, response: str) -> List[Dict[str, str]]:
        """
        è§£æAIå“åº”ä¸­çš„å…³é”®è¯JSON
        
        Args:
            response: AIå“åº”å†…å®¹
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šå°è¯•ç›´æ¥è§£æï¼ˆAIåº”è¯¥è¿”å›æ ‡å‡†JSONï¼‰
            cleaned_response = response.strip()
            
            # æ¸…ç†å¯èƒ½çš„ä¸­æ–‡å¼•å·é—®é¢˜
            json_str = cleaned_response.replace('"', '"').replace('"', '"')
            json_str = json_str.replace(''', "'").replace(''', "'")
            
            # ç›´æ¥å°è¯•è§£æ
            try:
                data = json.loads(json_str)
            except json.JSONDecodeError:
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                if '```json' in json_str:
                    start = json_str.find('```json') + 7
                    end = json_str.find('```', start)
                    if end != -1:
                        json_str = json_str[start:end].strip()
                    else:
                        json_str = json_str[start:].strip()
                else:
                    # æŸ¥æ‰¾JSONå¯¹è±¡è¾¹ç•Œ
                    start_pos = json_str.find('{')
                    if start_pos != -1:
                        end_pos = json_str.rfind('}')
                        if end_pos != -1 and end_pos > start_pos:
                            json_str = json_str[start_pos:end_pos+1]
                
                # å†æ¬¡æ¸…ç†å’Œè§£æ
                json_str = json_str.replace('"', '"').replace('"', '"')
                json_str = json_str.replace(''', "'").replace(''', "'")
                
                # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
                json_str = self._fix_common_json_errors(json_str)
                
                # å°è¯•ä¿®å¤æˆªæ–­çš„JSON
                json_str = self._fix_truncated_json(json_str)
                
                data = json.loads(json_str)
            
            keywords = data.get('keywords', [])
            
            # éªŒè¯å…³é”®è¯æ•°é‡ï¼ˆé€‚åº¦æ”¾å®½è‡³3-8ä¸ªä»¥å‡å°‘å¤±è´¥ç‡ï¼‰
            if len(keywords) < 3:
                print(f"âš ï¸ å…³é”®è¯æ•°é‡ä¸è¶³ï¼šåªæœ‰{len(keywords)}ä¸ªï¼Œè¦æ±‚è‡³å°‘3ä¸ª")
                return []
            elif len(keywords) > 8:
                print(f"âš ï¸ å…³é”®è¯æ•°é‡è¿‡å¤šï¼šæœ‰{len(keywords)}ä¸ªï¼Œè¦æ±‚3-8ä¸ªï¼Œå–å‰8ä¸ª")
                keywords = keywords[:8]
            else:
                print(f"âœ… å…³é”®è¯æ•°é‡ç¬¦åˆè¦æ±‚ï¼š{len(keywords)}ä¸ª")
            
            # éªŒè¯å’Œæ¸…ç†å…³é”®è¯
            cleaned_keywords = []
            for kw in keywords:
                if self._validate_keyword(kw):
                    cleaned_kw = self._clean_keyword(kw)
                    # åªæ£€æŸ¥å½“å‰æ¨¡å‹å†…çš„é‡å¤ï¼Œä¸è·¨æ¨¡å‹å»é‡
                    current_keywords = [k['keyword'] for k in cleaned_keywords]
                    if cleaned_kw['keyword'] not in current_keywords:
                        cleaned_keywords.append(cleaned_kw)
            
            return cleaned_keywords
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"ğŸ“ AIå®Œæ•´è¿”å›å†…å®¹:")
            print("=" * 80)
            print(response[:1500] + ("..." if len(response) > 1500 else ""))
            print("=" * 80)
            print("ğŸ’¡ æç¤ºï¼šAIå¯èƒ½æ²¡æœ‰æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›")
            return []
        except Exception as e:
            print(f"âŒ è§£æå“åº”æ—¶å‡ºé”™: {e}")
            print(f"ğŸ“ AIå®Œæ•´è¿”å›å†…å®¹:")
            print("=" * 80)
            print(response[:1500] + ("..." if len(response) > 1500 else ""))
            print("=" * 80)
            return []
    
    def _validate_keyword(self, keyword_obj: Dict[str, str]) -> bool:
        """
        éªŒè¯å…³é”®è¯å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            keyword_obj: å…³é”®è¯å¯¹è±¡
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        required_fields = ['keyword', 'dimension', 'reason']
        return all(field in keyword_obj and keyword_obj[field].strip() for field in required_fields)
    
    def _clean_keyword(self, keyword_obj: Dict[str, str]) -> Dict[str, str]:
        """
        æ¸…ç†å…³é”®è¯ï¼Œç¡®ä¿ç¬¦åˆæ ¼å¼è¦æ±‚
        
        Args:
            keyword_obj: åŸå§‹å…³é”®è¯å¯¹è±¡
            
        Returns:
            æ¸…ç†åçš„å…³é”®è¯å¯¹è±¡
        """
        keyword = keyword_obj['keyword'].strip()
        
        # ç§»é™¤æ‹¬å·
        keyword = re.sub(r'[()ï¼ˆï¼‰]', '', keyword)
        
        # æ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
        keyword = re.sub(r'\s+', '-', keyword)
        
        # åªä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦ã€ç‚¹å·
        keyword = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\.-]', '', keyword)
        
        # ç§»é™¤è¿ç»­çš„è¿å­—ç¬¦å’Œç‚¹å·
        keyword = re.sub(r'-+', '-', keyword)
        keyword = re.sub(r'\.+', '.', keyword)
        
        # ç§»é™¤é¦–å°¾è¿å­—ç¬¦å’Œç‚¹å·
        keyword = keyword.strip('-.')
        
        # ä½†ä¿ç•™ç‰ˆæœ¬å·æ ¼å¼ï¼ˆå¦‚v2.0, FLUX.1ç­‰ï¼‰
        # å¦‚æœå…³é”®è¯ä»¥vå¼€å¤´ä¸”åŒ…å«ç‚¹å·ï¼Œä¿ç•™å®ƒ
        if keyword.lower().startswith('v') and '.' in keyword:
            pass  # ä¿æŒåŸæ ·ï¼Œä¸å†å¤„ç†
        # å¦‚æœæ˜¯å¸¸è§çš„ç‰ˆæœ¬å·æ ¼å¼ï¼Œä¹Ÿä¿ç•™
        elif re.match(r'^[A-Za-z0-9]+\.[0-9]+$', keyword):
            pass  # ä¿æŒåŸæ ·ï¼Œå¦‚FLUX.1, GPT.4ç­‰
        
        # å“ç‰Œåç§°æ™ºèƒ½æ‰©å±•ç­–ç•¥
        keyword = self._enhance_brand_keywords(keyword, keyword_obj['dimension'])
        
        return {
            'keyword': keyword,
            'dimension': keyword_obj['dimension'].strip(),
            'reason': keyword_obj['reason'].strip()
        }
    
    def _fix_common_json_errors(self, json_str: str) -> str:
        """
        ä¿®å¤AIç”ŸæˆJSONä¸­çš„å¸¸è§é”™è¯¯
        
        Args:
            json_str: å¾…ä¿®å¤çš„JSONå­—ç¬¦ä¸²
            
        Returns:
            ä¿®å¤åçš„JSONå­—ç¬¦ä¸²
        """
        import re
        
        # ä¿®å¤ç¼ºå¤±å¼€æ‹¬å·çš„æƒ…å†µï¼š},\n  "keyword" â†’ },\n  {"keyword"
        # åŒ¹é…ï¼š},åé¢è·Ÿç€æ¢è¡Œå’Œç©ºæ ¼ï¼Œç„¶åç›´æ¥æ˜¯"keyword"ï¼ˆè€Œä¸æ˜¯{ï¼‰
        pattern = r'(\},\s*\n\s*)("keyword":)'
        json_str = re.sub(pattern, r'\1{\2', json_str)
        
        # ä¿®å¤å¤šä½™é€—å·çš„æƒ…å†µï¼š},\n  }\n] â†’ }\n  }\n]
        json_str = re.sub(r',(\s*\}\s*\])', r'\1', json_str)
        
        # ä¿®å¤ç¼ºå¤±é€—å·çš„æƒ…å†µï¼š}\n  { â†’ },\n  {
        json_str = re.sub(r'(\})\s*\n\s*(\{)', r'\1,\n  \2', json_str)
        
        return json_str
    
    def _fix_truncated_json(self, json_str: str) -> str:
        """ä¿®å¤æˆªæ–­çš„JSON"""
        import re
        
        # å¦‚æœJSONè¢«æˆªæ–­ï¼Œå°è¯•ä¿®å¤
        if not json_str.endswith('}'):
            # æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
            last_complete_obj = json_str.rfind('}')
            if last_complete_obj != -1:
                # æ£€æŸ¥æ˜¯å¦åœ¨keywordsæ•°ç»„ä¸­
                before_last = json_str[:last_complete_obj]
                if '"keywords"' in before_last:
                    # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„keywordå¯¹è±¡
                    keyword_objects = re.findall(r'\{[^}]*"keyword"[^}]*\}', before_last)
                    if keyword_objects:
                        # ä½¿ç”¨æœ€åä¸€ä¸ªå®Œæ•´çš„keywordå¯¹è±¡
                        last_keyword = keyword_objects[-1]
                        # é‡æ–°æ„å»ºJSON
                        json_str = before_last[:before_last.rfind(last_keyword)] + last_keyword + '}]}'
                    else:
                        # å¦‚æœæ²¡æœ‰å®Œæ•´çš„keywordå¯¹è±¡ï¼Œå°è¯•æ·»åŠ ç¼ºå¤±çš„ç»“æŸç¬¦
                        json_str = before_last + '}]}'
        
        return json_str
    
    def _enhance_brand_keywords(self, keyword: str, dimension: str) -> str:
        """
        å“ç‰Œå…³é”®è¯æ™ºèƒ½æ‰©å±•ç­–ç•¥
        
        Args:
            keyword: åŸå§‹å…³é”®è¯
            dimension: å…³é”®è¯ç»´åº¦
            
        Returns:
            æ‰©å±•åçš„å…³é”®è¯
        """
        # åªå¯¹"å“ç‰Œä¸èº«ä»½"ç»´åº¦çš„å…³é”®è¯è¿›è¡Œæ‰©å±•
        if dimension != "å“ç‰Œä¸èº«ä»½":
            return keyword
        
        # å®šä¹‰éœ€è¦æ‰©å±•çš„å“ç‰Œåç§°åˆ—è¡¨
        brand_names = {
            # ä¸­å›½å¤§å‚
            "ç™¾åº¦": "ç™¾åº¦å¤§æ¨¡å‹",
            "è…¾è®¯": "è…¾è®¯å¤§æ¨¡å‹", 
            "é˜¿é‡Œ": "é˜¿é‡Œå¤§æ¨¡å‹",
            "é˜¿é‡Œå·´å·´": "é˜¿é‡Œå·´å·´å¤§æ¨¡å‹",
            "å­—èŠ‚": "å­—èŠ‚å¤§æ¨¡å‹",
            "å­—èŠ‚è·³åŠ¨": "å­—èŠ‚è·³åŠ¨å¤§æ¨¡å‹",
            "åä¸º": "åä¸ºå¤§æ¨¡å‹",
            "å°ç±³": "å°ç±³å¤§æ¨¡å‹",
            "å¿«æ‰‹": "å¿«æ‰‹å¤§æ¨¡å‹",
            "ç½‘æ˜“": "ç½‘æ˜“å¤§æ¨¡å‹",
            "äº¬ä¸œ": "äº¬ä¸œå¤§æ¨¡å‹",
            "ç¾å›¢": "ç¾å›¢å¤§æ¨¡å‹",
            "æ»´æ»´": "æ»´æ»´å¤§æ¨¡å‹",
            
            # å›½é™…å¤§å‚
            "OpenAI": "OpenAIå¤§æ¨¡å‹",
            "Google": "Googleå¤§æ¨¡å‹", 
            "è°·æ­Œ": "è°·æ­Œå¤§æ¨¡å‹",
            "Microsoft": "Microsoftå¤§æ¨¡å‹",
            "å¾®è½¯": "å¾®è½¯å¤§æ¨¡å‹",
            "Meta": "Metaå¤§æ¨¡å‹",
            "Facebook": "Facebookå¤§æ¨¡å‹",
            "Amazon": "Amazonå¤§æ¨¡å‹",
            "äºšé©¬é€Š": "äºšé©¬é€Šå¤§æ¨¡å‹",
            "Apple": "Appleå¤§æ¨¡å‹",
            "è‹¹æœ": "è‹¹æœå¤§æ¨¡å‹",
            "NVIDIA": "NVIDIAå¤§æ¨¡å‹",
            "è‹±ä¼Ÿè¾¾": "è‹±ä¼Ÿè¾¾å¤§æ¨¡å‹",
            
            # AIåˆ›ä¸šå…¬å¸
            "æ™ºè°±": "æ™ºè°±å¤§æ¨¡å‹",
            "æœˆä¹‹æš—é¢": "æœˆä¹‹æš—é¢å¤§æ¨¡å‹",
            "é›¶ä¸€ä¸‡ç‰©": "é›¶ä¸€ä¸‡ç‰©å¤§æ¨¡å‹",
            "æ·±åº¦æ±‚ç´¢": "æ·±åº¦æ±‚ç´¢å¤§æ¨¡å‹",
            "å•†æ±¤": "å•†æ±¤å¤§æ¨¡å‹",
            "æ—·è§†": "æ—·è§†å¤§æ¨¡å‹",
            "ç§‘å¤§è®¯é£": "ç§‘å¤§è®¯é£å¤§æ¨¡å‹",
            "äº‘çŸ¥å£°": "äº‘çŸ¥å£°å¤§æ¨¡å‹",
            "å‡ºé—¨é—®é—®": "å‡ºé—¨é—®é—®å¤§æ¨¡å‹",
            "å°å†°": "å°å†°å¤§æ¨¡å‹"
        }
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºéœ€è¦æ‰©å±•çš„å“ç‰Œåç§°
        for brand, enhanced in brand_names.items():
            if keyword == brand:
                print(f"ğŸ”„ å“ç‰Œæ‰©å±•: {brand} â†’ {enhanced}")
                return enhanced
        
        return keyword
    
    def deduplicate_keywords(self, keyword_results: List[KeywordResult]) -> List[KeywordResult]:
        """
        ä¸è¿›è¡Œå»é‡ï¼Œç›´æ¥è¿”å›åŸå§‹ç»“æœ
        å»é‡å°†åœ¨CSVç”Ÿæˆé˜¶æ®µç»Ÿä¸€å¤„ç†
        
        Args:
            keyword_results: å…³é”®è¯æå–ç»“æœåˆ—è¡¨
            
        Returns:
            åŸå§‹ç»“æœåˆ—è¡¨ï¼ˆæ— å»é‡ï¼‰
        """
        print("è·³è¿‡å…³é”®è¯å»é‡ï¼Œå°†åœ¨CSVç”Ÿæˆæ—¶ç»Ÿä¸€å»é‡")
        return keyword_results
    
    def _is_similar_keyword_exists(self, keyword: str, existing_keywords: set) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸ä¼¼çš„å…³é”®è¯ï¼ˆå®½æ¾ç‰ˆï¼šåªæ£€æŸ¥å®Œå…¨é‡å¤ï¼‰
        
        Args:
            keyword: å¾…æ£€æŸ¥çš„å…³é”®è¯
            existing_keywords: å·²å­˜åœ¨çš„å…³é”®è¯é›†åˆ
            
        Returns:
            æ˜¯å¦å­˜åœ¨ç›¸ä¼¼å…³é”®è¯
        """
        keyword_lower = keyword.lower()
        
        for existing in existing_keywords:
            existing_lower = existing.lower()
            
            # åªæ£€æŸ¥å®Œå…¨ç›¸åŒçš„æƒ…å†µï¼Œä¸å†æ£€æŸ¥åŒ…å«å…³ç³»
            # è¿™æ ·å¯ä»¥ä¿ç•™æ›´å¤šæœ‰æ„ä¹‰çš„å…³é”®è¯å˜ä½“
            if keyword_lower == existing_lower:
                return True
        
        return False
    
    @abstractmethod
    def extract_keywords(self, model_info: ModelInfo) -> Optional[KeywordResult]:
        """æå–å…³é”®è¯çš„æŠ½è±¡æ–¹æ³•"""
        pass
    
    @abstractmethod
    def extract_batch_keywords(self, model_infos: List[ModelInfo]) -> List[KeywordResult]:
        """æ‰¹é‡æå–å…³é”®è¯çš„æŠ½è±¡æ–¹æ³•"""
        pass
