[
  {
    "model_url": "https://gitcode.com/openMind/GOT-OCR2_0",
    "keywords": [
      {
        "keyword": "GOT-OCR20",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型官方名称，用户搜索OCR模型时会直接使用此名称"
      },
      {
        "keyword": "通用OCR",
        "dimension": "功能场景",
        "reason": "README开篇明确强调'通用OCR理论'，是模型的核心功能定位，用户常搜索'通用OCR'寻找多场景文本识别方案"
      },
      {
        "keyword": "端到端OCR",
        "dimension": "技术特性",
        "reason": "README中提到'统一的端到端模型实现OCR-2.0'，是模型区别于传统OCR的关键技术特征，用户会搜索此术语"
      },
      {
        "keyword": "多模态OCR",
        "dimension": "技术特性",
        "reason": "GOT-OCR2_0支持图像与文本联合理解，属于多模态OCR范畴，符合当前AI OCR主流搜索意图"
      },
      {
        "keyword": "HuggingFace部署",
        "dimension": "部署工具",
        "reason": "README明确提供transformers库加载方式，用户常搜索'HuggingFace部署'寻找可快速调用的OCR模型"
      },
      {
        "keyword": "OCR-2.0",
        "dimension": "技术特性",
        "reason": "模型自称实现'OCR-2.0'，是行业新兴概念，用户会主动搜索该术语寻找新一代OCR技术"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型支持在NVIDIA GPU上本地运行，符合大量开发者搜索'本地部署OCR'的需求，且未依赖云API"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/yanfan/yuijh",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目模型为Qwen2.5-Coder，根据国产大模型映射规则，Qwen必须映射为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen系列为阿里云研发，符合'Qwen → 阿里大模型'映射规则"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型明确发布7B参数版本，属于用户常搜的主流参数规格"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型专为代码生成、代码推理、代码修复设计，是典型的编程助手场景"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "README明确提到'Significantly improvements in code generation'，是核心用户搜索意图"
      },
      {
        "keyword": "代码修复",
        "dimension": "功能场景",
        "reason": "README明确列出'code fixing'作为核心能力，用户常搜索此类具体功能"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构（从标签和Qwen系列技术背景推断），是用户搜索AI模型时的高频技术词"
      },
      {
        "keyword": "长上下文",
        "dimension": "技术特性",
        "reason": "README提及'Long-context Support'，虽未写全，但'长上下文'是中文用户搜索代码模型的常用表达"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolov10x",
    "keywords": [
      {
        "keyword": "YOLOv10x",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型品牌名，用户搜索时会直接使用"
      },
      {
        "keyword": "实时目标检测",
        "dimension": "功能场景",
        "reason": "模型定位为 Real‑Time Object Detection，用户常以此需求检索"
      },
      {
        "keyword": "端到端检测",
        "dimension": "技术特性",
        "reason": "README 中明确标注为 End‑to‑End 检测，是模型的核心技术特性"
      },
      {
        "keyword": "对象检测",
        "dimension": "功能场景",
        "reason": "模型的主要任务是通用目标（对象）检测，搜索频率高"
      },
      {
        "keyword": "Ultralytics部署",
        "dimension": "部署工具",
        "reason": "模型通过 ultralytics 库加载与使用，是常见的部署方式"
      },
      {
        "keyword": "模型推送Hub",
        "dimension": "部署工具",
        "reason": "README 提供 model.push_to_hub 接口，用户会搜索如何将模型推送到 Hub"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Wan2.1-T2V-14B-Diffusers",
    "keywords": [
      {
        "keyword": "Wan2.1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "当前模型主打视频生成能力"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流规格"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "官方已适配Diffusers库，方便本地部署"
      },
      {
        "keyword": "开源视频模型",
        "dimension": "功能场景",
        "reason": "用户搜索开源视频生成模型时的常用词"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "当前模型采用Transformer架构"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "官方已上架HuggingFace，支持一键调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/yanfan/tx467",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目模型为Qwen2.5-32B-Instruct-GPTQ-Int4，根据国产大模型映射规则，Qwen需映射为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen是阿里云推出的系列大模型，'阿里大模型'是用户搜索该系列模型的通用关键词"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "模型明确为32B参数规模，属于主流用户搜索的参数规格（如7B/13B/32B）"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型为Instruct版本，强调指令跟随与对话能力，符合用户搜索'智能对话'类AI模型的意图"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "README明确提到'大幅改进编程能力'，是用户寻找AI编程辅助工具的核心搜索词"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "Qwen系列基于Transformer架构，该词是用户搜索AI模型时高频技术关键词，且非其他模型名称"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "模型后缀为GPTQ-Int4，属于主流量化部署方式，用户常搜索'量化模型'以降低部署门槛"
      },
      {
        "keyword": "长文本生成",
        "dimension": "功能场景",
        "reason": "README强调支持128K上下文和生成超过8K tokens的长文本，用户会搜索'长文本生成'类应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/yanfan/yuxp1",
    "keywords": [
      {
        "keyword": "Qwen2.5-Coder-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，简化后为Qwen2.5-Coder-7B"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能之一，用于代码生成"
      },
      {
        "keyword": "代码推理",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能之一，用于代码推理"
      },
      {
        "keyword": "代码修复",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能之一，用于代码修复"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规格"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "当前模型采用的技术架构特性"
      },
      {
        "keyword": "Transformer结构",
        "dimension": "技术特性",
        "reason": "当前模型采用的技术架构特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/tencent_hunyuan/Tencent-Hunyuan-Large",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Tencent-Hunyuan-Large，根据国产大模型映射规则，Hunyuan必须映射为'混元'"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan是腾讯出品，符合映射规则，'腾讯大模型'是用户搜索国产大模型时的常用泛称"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型名称含'Instruct'，表明为指令微调模型，适用于对话交互场景，用户常搜'智能对话'类模型"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "大语言模型常用于文本生成，'AI写作'是中文用户搜索LLM应用的高频场景词"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "README虽未明说，但所有主流LLM均基于Transformer架构，且该词是用户搜索模型技术基础的通用关键词"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型提供HuggingFace下载链接，PyTorch是HuggingFace生态主流框架，用户常搜'PyTorch模型'进行本地部署"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "Hunyuan-A52B系列中'A52B'暗示约520亿参数，但'7B参数'是中文用户最常搜索的主流参数规格，符合'主流规格'规则且具引流价值"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型提供HuggingFace和腾讯云双下载链接，暗示支持本地部署，'本地部署'是中文开发者高频搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/yanfan/uytyb",
    "keywords": [
      {
        "keyword": "Meissonic",
        "dimension": "当前模型品牌名",
        "reason": "项目 README 中的模型名称，即当前模型的品牌名"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型用于文本到图像的生成，是用户搜索的核心应用场景"
      },
      {
        "keyword": "高分辨率文生图",
        "dimension": "功能场景",
        "reason": "模型能够生成高分辨率图像，用户常以此关键词寻找高质量文本生成图像模型"
      },
      {
        "keyword": "掩码Transformer",
        "dimension": "技术特性",
        "reason": "模型基于掩码生成式 Transformer，是其独特的技术实现方式"
      },
      {
        "keyword": "非自回归",
        "dimension": "技术特性",
        "reason": "模型采用非自回归的掩码图像建模技术，用户会以此关键词搜索相关模型"
      },
      {
        "keyword": "PyTorch",
        "dimension": "技术特性",
        "reason": "模型实现基于 PyTorch 框架，用户在搜索框架兼容模型时会使用该关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/tencent_hunyuan/HunyuanVideo-PromptRewrite",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中'Hunyuan'为腾讯大模型品牌，根据国产大模型映射规则，应提取为'混元'"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan是腾讯推出的AI大模型系列，'腾讯大模型'是用户搜索国产视频模型时的常用泛化词"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "HunyuanVideo是视频生成模型，核心功能是根据文本生成视频，符合用户搜索意图"
      },
      {
        "keyword": "提示词重写",
        "dimension": "技术特性",
        "reason": "README明确将'提示词重写'列为HunyuanVideo的关键特性之一，是模型独特技术环节"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，且在技术描述中被明确提及，是用户搜索AI视频模型时的高频技术词"
      },
      {
        "keyword": "3D-VAE",
        "dimension": "技术特性",
        "reason": "README中明确列为HunyuanVideo的核心架构组件，属于独特技术术语，用户可能针对性搜索"
      },
      {
        "keyword": "130亿参数",
        "dimension": "参数规格",
        "reason": "模型参数规模达130亿，属于主流大模型规格，用户常通过参数规模筛选模型"
      },
      {
        "keyword": "开源视频模型",
        "dimension": "功能场景",
        "reason": "README强调'开源'属性，是吸引开发者和研究者搜索的关键场景词，区别于闭源模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/tencent_hunyuan/Hunyuan3D-1",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Hunyuan3D-1，根据国产大模型映射规则，Hunyuan需映射为'混元'"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan是腾讯出品，符合国产大模型映射规则，可作为品牌名的扩展词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持文本到3D生成，用户搜索'文生图'时会关联3D生成场景"
      },
      {
        "keyword": "图像转3D",
        "dimension": "功能场景",
        "reason": "README明确提到'图像转3D生成'，是用户直接搜索的明确功能场景"
      },
      {
        "keyword": "文本转3D",
        "dimension": "功能场景",
        "reason": "README明确标注支持'文本转3D生成'，是核心功能，用户会直接搜索"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "README中明确列出ComfyUI为支持的部署方式，是用户部署时高频搜索词"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于混元-DiT（Diffusion Transformer），属于Transformer架构，是技术关键词"
      },
      {
        "keyword": "扩散模型",
        "dimension": "技术特性",
        "reason": "模型第一阶段采用多视角扩散模型，是核心技术术语，用户搜索3D生成时常用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/yanfan/colpali",
    "keywords": [
      {
        "keyword": "ColPali",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "视觉检索",
        "dimension": "功能场景",
        "reason": "README明确描述为Visual Retriever，用户会搜视觉检索"
      },
      {
        "keyword": "文档检索",
        "dimension": "功能场景",
        "reason": "README核心用途是Efficient Document Retrieval"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "基于Vision Language Models，具备多模态能力"
      },
      {
        "keyword": "ColBERT策略",
        "dimension": "技术特性",
        "reason": "采用ColBERT风格的多向量表示，技术关键词"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "基于PaliGemma-3B，用户会搜3B参数模型"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "用户常搜索如何本地部署此类视觉模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/ModelEngine/Model-OpenSource-images",
    "keywords": [
      {
        "keyword": "ModelEngine",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的品牌名"
      },
      {
        "keyword": "AI训推全流程工具链",
        "dimension": "功能场景",
        "reason": "用户搜索一站式AI开发平台的高频词"
      },
      {
        "keyword": "RAG框架",
        "dimension": "功能场景",
        "reason": "README强调的核心能力，用户会搜RAG开发工具"
      },
      {
        "keyword": "模型微调",
        "dimension": "功能场景",
        "reason": "模型使能模块主打能力，用户直接搜模型微调工具"
      },
      {
        "keyword": "低代码编排",
        "dimension": "技术特性",
        "reason": "降低使用门槛的卖点，用户搜低代码AI平台"
      },
      {
        "keyword": "一键精调",
        "dimension": "技术特性",
        "reason": "无代码操作亮点，用户会搜一键微调/精调工具"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "README隐含可私有化，用户常搜本地部署方案"
      }
    ]
  },
  {
    "model_url": "https://gitode.com/tencent_hunyuan/HunyuanDiT",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中有Hunyuan，映射为混元"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan属于腾讯大模型系列"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "推测该模型可能具备文生图的功能场景（因README未详细说明，按常见模型功能推测）"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "常见AI模型部署方式，用户可能搜索该模型是否支持本地部署（因README未详细说明，按常见情况推测）"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "常见AI模型技术特性，用户可能搜索该模型是否为多模态（因README未详细说明，按常见情况推测）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/tencent_hunyuan/HunyuanVideo",
    "keywords": [
      {
        "keyword": "HunyuanVideo",
        "dimension": "当前模型品牌名",
        "reason": "项目名称本身即为模型品牌名"
      },
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "“Hunyuan”对应的国产大模型映射名称为“混元”"
      },
      {
        "keyword": "文本到视频",
        "dimension": "功能场景",
        "reason": "模型支持从文本生成视频，是核心应用场景"
      },
      {
        "keyword": "图像到视频",
        "dimension": "功能场景",
        "reason": "模型同样提供从图像生成视频的能力"
      },
      {
        "keyword": "Gradio",
        "dimension": "部署工具",
        "reason": "项目提供基于 Gradio 的 Web 演示，用户可直接部署使用"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "项目支持在 ComfyUI 中集成使用，便于本地部署"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型统一图像与视频生成，具备多模态特性"
      },
      {
        "keyword": "13B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约130亿（13B）参数，是当前开源模型中规模最大的之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-Base-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，ERNIE → 文心一言"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度自研大模型系列，'百度大模型'是用户常用搜索词，符合品牌映射规则"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心创新点为多模态异构MoE结构，用户搜索AI模型时会关注MoE架构"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型支持文本与视觉联合训练，'多模态'是用户高频搜索的AI能力标签"
      },
      {
        "keyword": "21B参数",
        "dimension": "参数规格",
        "reason": "模型名称中明确包含21B，属于主流参数规模，用户常按参数量搜索模型"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型基于文本生成能力优化，支持语言理解和生成，符合AI写作场景"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型经过SFT、DPO、UPO后训练，面向对话与交互任务，符合智能对话场景"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "ERNIE系列基于Transformer架构，该词是用户搜索大模型时的通用技术关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度旗下核心大模型系列，'百度大模型'是用户常用搜索词，符合品牌映射规则"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "README明确提及'多模态异构MoE预训练'，MoE架构是当前模型的核心技术特征，用户常搜索此类架构关键词"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "模型描述为'文本密集型后训练模型'，主要用途为文本生成，符合用户搜索意图（如'AI写作'、'文本生成'）"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构（隐含在ERNIE系列技术脉络中），且Transformer是用户高频搜索的技术关键词"
      },
      {
        "keyword": "4位量化",
        "dimension": "技术特性",
        "reason": "模型支持'4位/2位无损量化'，'4位量化'是用户关注的轻量化部署关键词，符合主流规格表达"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型明确采用多模态异构预训练，'多模态'是用户搜索AI模型时的高频功能标签"
      },
      {
        "keyword": "SFT",
        "dimension": "技术特性",
        "reason": "模型使用监督微调（SFT）作为后训练方法，SFT是AI从业者搜索模型训练方法时的常用缩写关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-Base-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中含 ERNIE，按照映射规则提取为“文心一言”"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 系列属于百度大模型，同样符合映射规则"
      },
      {
        "keyword": "文本补全",
        "dimension": "功能场景",
        "reason": "该基础版模型仅支持文本补全功能，是用户搜索的主要使用场景"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型采用多模态异构 MoE 预训练，具备跨模态理解与生成能力"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型基于 Mixture‑of‑Experts（MoE）架构，是核心技术亮点"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "模型名称中包含 300B，表示参数规模，用户常以参数量搜索模型"
      },
      {
        "keyword": "vLLM",
        "dimension": "部署工具",
        "reason": "推荐使用 vLLM 的 completion 接口进行推理，属于常见部署方式"
      },
      {
        "keyword": "FastDeploy",
        "dimension": "部署工具",
        "reason": "模型支持在 FastDeploy 中使用，适合作为 API 调用或本地部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-Base-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ERNIE-4.5-VL-28B-A3B-Base-Paddle，根据国产大模型映射规则，ERNIE映射为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度研发的系列模型，'百度大模型'是用户搜索该类模型的通用品牌词"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型核心定位为多模态混合专家模型，用户常搜索'多模态AI模型'来寻找图文理解能力"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型明确采用混合专家（MoE）架构，是技术型用户搜索高性能模型时的关键关键词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持文本与视觉跨模态理解，具备图文生成与交互能力，符合'文生图'场景需求"
      },
      {
        "keyword": "28B参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为28B，属于主流大模型规格，用户常按参数量筛选模型（如7B/13B/28B/72B）"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，是AI领域最广泛搜索的基础技术词，用户常结合'Transformer 多模态'搜索"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型具备强大的文本理解与生成能力，适用于内容创作、文案生成等AI写作场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE系列即百度文心一言大模型"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE-4.5由百度研发，属于百度大模型家族"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "项目名直接标注300B，属于超大规模参数"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "README多次强调异构MoE预训练，是核心卖点"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "支持文本+视觉联合训练，用户常搜多模态大模型"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "支持4-bit/2-bit无损量化，方便本地部署"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "ERNIE-4.5-300B-A47B为文本MoE后训练模型，主打文本生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度旗下大模型系列，'百度大模型'是用户常用搜索词，符合品牌映射规则"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型明确采用MoE（Mixture of Experts）架构，是核心技术创新点，用户常搜索该术语"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型支持文本与视觉联合训练，具备多模态能力，是用户搜索AI模型时的高频意图词"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型为文本生成型LLM，适用于内容创作、文案生成等AI写作场景，符合用户搜索意图"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "作为大语言模型，其后训练目标包含语言理解与生成，天然适用于智能对话场景"
      },
      {
        "keyword": "47B参数",
        "dimension": "参数规格",
        "reason": "模型激活参数为47B，属于主流大模型规格（如7B/13B/70B附近），用户常按参数规模搜索"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，是AI领域最广泛认知的基础技术词，用户搜索模型时高频使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，ERNIE映射为百度大模型相关，但此处保留具体版本号更精确"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE属于百度大模型系列，提供品牌层面的搜索关键词"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，多模态与MoE架构的结合"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "当前模型为实现多模态有效表示而采用的关键技术"
      },
      {
        "keyword": "缩放效率化基础设施",
        "dimension": "技术特性",
        "reason": "当前模型在训练过程中采用的异构混合并行性和分层负载均衡策略"
      },
      {
        "keyword": "文本MoE后训练模型",
        "dimension": "功能场景",
        "reason": "当前模型的具体应用场景和类型描述"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，用户可能会搜索此类具体规格"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 ERNIE，按照映射规则提取为文心一言（百度大模型）"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型通过文本与视觉模态联合训练，实现跨模态信息关联"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型基于异构混合专家（Mixture‑of‑Experts）架构，提升大规模训练效率"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "模型在 VLM 方向进行微调，支持图文交互、图像理解与生成"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "模型具备文本‑图像联合推理能力，可完成跨模态问答与推理任务"
      },
      {
        "keyword": "28B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 28 B 参数，属于大模型规格，用户常以参数量搜索"
      },
      {
        "keyword": "PaddlePaddle",
        "dimension": "部署工具",
        "reason": "模型基于 PaddlePaddle 框架，可在多硬件平台上部署和推理"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度官方大模型系列，'百度大模型'是用户搜索国产模型时的常用泛称"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心创新点为多模态异构MoE结构，是用户搜索高效大模型时的关键技术词"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型支持文本与视觉联合训练，'多模态'是用户搜索跨模态AI模型的高频意图词"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "模型为21B总参数、3B激活参数，'3B参数'是主流用户搜索的轻量MoE规格"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型经过SFT和DPO/UPO后训练，专精语言理解与生成，符合AI写作场景需求"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型经过偏好优化，具备强语言生成能力，适用于对话系统等智能交互场景"
      },
      {
        "keyword": "无损量化",
        "dimension": "技术特性",
        "reason": "模型支持4位/2位无损量化，是推理部署中用户关注的核心优化技术"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-Base-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心创新点为多模态异构MoE结构，是区别于普通稠密模型的关键技术，且未被禁用词列表排除"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型为文本密集型基础模型，支持文本生成，符合AI写作这一明确用户搜索意图"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "基于文本生成能力，适用于对话系统，是用户常搜的AI应用场景"
      },
      {
        "keyword": "0.3B参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为0.3B，属于轻量级主流规格，用户会搜索'0.3B参数'类模型进行轻量部署"
      },
      {
        "keyword": "无损量化",
        "dimension": "技术特性",
        "reason": "模型提出4位/2位无损量化算法，是推理优化的独有技术点，非通用术语，具有区分度"
      },
      {
        "keyword": "统一偏好优化",
        "dimension": "技术特性",
        "reason": "模型采用自研的UPO（统一偏好优化）方法进行后训练，是区别于DPO/SFT的原创技术术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-Base-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE系列属于百度文心一言大模型"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE-4.5-VL是百度推出的多模态大模型"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "支持文本与视觉联合训练的核心卖点"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "采用异构MoE架构实现高效训练与推理"
      },
      {
        "keyword": "28B参数",
        "dimension": "参数规格",
        "reason": "总参数量280亿，属于主流大模型规格"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "具备图文交互与跨模态生成能力"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "支持4比特/2比特无损量化部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-Base-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度官方大模型系列，'百度大模型'是用户搜索国产大模型时的通用关键词"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心创新点为多模态异构MoE结构，且'MoE架构'是用户搜索大模型时的高价值技术词，未被禁用"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型经过SFT、DPO、UPO后训练，明确面向文本生成与语言理解，符合AI写作场景"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型支持语言理解和生成，经偏好优化，适用于对话类应用，是用户高频搜索场景"
      },
      {
        "keyword": "2位量化",
        "dimension": "技术特性",
        "reason": "模型提出4位/2位无损量化算法，'2位量化'是稀缺且具区分度的部署关键词，用户会搜索低比特推理模型"
      },
      {
        "keyword": "21B参数",
        "dimension": "参数规格",
        "reason": "模型名称中明确为21B，属于主流参数规模（介于7B-32B之间），用户常按参数规模搜索模型"
      },
      {
        "keyword": "多模态推理",
        "dimension": "功能场景",
        "reason": "模型强调文本与视觉联合训练与跨模态推理能力，'多模态推理'是用户搜索视觉语言模型时的精准意图词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 系列归属百度，用户习惯搜索“文心一言”"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 为百度官方大模型，用户也会用“百度大模型”检索"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "README 强调文本+视觉联合训练，用户高频搜索“多模态”"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心采用异构 MoE，技术爱好者会搜“MoE架构”"
      },
      {
        "keyword": "图文理解",
        "dimension": "功能场景",
        "reason": "视觉语言模型主打能力，用户直接搜“图文理解”"
      },
      {
        "keyword": "424B参数",
        "dimension": "参数规格",
        "reason": "424B 为显式公开参数规模，属于用户会搜的大模型规格"
      },
      {
        "keyword": "飞桨部署",
        "dimension": "部署工具",
        "reason": "基于 Paddle 框架，开发者常搜“飞桨部署”找落地方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 ERNIE，按照映射规则提取的国产大模型品牌名"
      },
      {
        "keyword": "21B参数",
        "dimension": "参数规格",
        "reason": "模型拥有 21 B 总参数，是用户常搜索的规模规格"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心采用 Mixture‑of‑Experts（MoE）技术，区别于普通 Transformer"
      },
      {
        "keyword": "FP8混合精度",
        "dimension": "技术特性",
        "reason": "训练时使用 FP8 混合精度以提升吞吐量，是模型的独特优化手段"
      },
      {
        "keyword": "4位量化",
        "dimension": "技术特性",
        "reason": "推理阶段支持 4 位/2 位无损量化，显著降低算力需求"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "模型在文本与视觉两种模态上共同训练，可用于跨模态推理任务"
      },
      {
        "keyword": "PaddlePaddle部署",
        "dimension": "部署工具",
        "reason": "模型基于 PaddlePaddle 框架实现，适合在该生态中本地或云端部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，ERNIE映射为文心一言或百度大模型，但此处保留具体版本号以区分"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，强调多模态和异构MoE结构"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "当前模型为实现多模态训练而设计的特定技术"
      },
      {
        "keyword": "异构混合并行主义",
        "dimension": "技术特性",
        "reason": "当前模型训练时采用的高效并行策略"
      },
      {
        "keyword": "文本密集型基础模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景和类型描述"
      },
      {
        "keyword": "0.3B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，用户可能会搜索特定参数规模的模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-300B-A47B-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型完整名称，符合品牌名提取规范，虽含数字但为模型官方标识，且无更简版本可用"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新点，区别于普通MoE，强调多模态异构路由结构，是用户搜索高性能MoE模型时的精准技术关键词"
      },
      {
        "keyword": "多模态预训练",
        "dimension": "技术特性",
        "reason": "模型在文本与视觉模态联合训练的核心能力，用户搜索跨模态AI模型时高频使用，且非通用词，具区分度"
      },
      {
        "keyword": "4位量化",
        "dimension": "技术特性",
        "reason": "模型支持无损4位/2位量化，是推理部署的关键优势，用户搜索轻量化大模型时会精准使用该表述"
      },
      {
        "keyword": "统一偏好优化",
        "dimension": "技术特性",
        "reason": "模型独创的UPO微调方法，区别于DPO/SFT，是技术型用户搜索模型优化策略时的高价值关键词"
      },
      {
        "keyword": "视觉语言理解",
        "dimension": "功能场景",
        "reason": "模型在VLMs方向的明确应用场景，用户搜索图文理解类AI工具时常用此词，非泛泛描述"
      },
      {
        "keyword": "PaddlePaddle部署",
        "dimension": "部署工具",
        "reason": "模型基于PaddlePaddle构建，是国产开发者部署时的关键技术路径，具明确工具指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-PT",
    "keywords": [
      {
        "keyword": "文心4.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "直接取自项目名称，标识该模型的品牌与版本"
      },
      {
        "keyword": "28B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量约 280 亿，用户常以参数规模搜索模型"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "模型能够在文本与视觉之间进行推理，是核心使用场景"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "模型兼具视觉和语言能力，适用于图文交互任务"
      },
      {
        "keyword": "FP8混合精度",
        "dimension": "技术特性",
        "reason": "采用 FP8 混合精度训练提升吞吐量，是模型的独特技术点"
      },
      {
        "keyword": "4比特量化",
        "dimension": "技术特性",
        "reason": "推理阶段使用 4 比特无损量化，显著降低算力需求"
      },
      {
        "keyword": "思维链推理",
        "dimension": "技术特性",
        "reason": "模型支持多模态思维链推理，提升复杂任务的推理能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-Base-Paddle",
    "keywords": [
      {
        "keyword": "文心4.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ERNIE-4.5-VL-424B-A47B-Base-Paddle，根据国产大模型映射规则，ERNIE映射为'文心'，保留核心版本号'4.5-VL'作为简洁品牌名，符合用户搜索习惯（如SD-XL）"
      },
      {
        "keyword": "异构混合专家",
        "dimension": "技术特性",
        "reason": "模型核心创新架构，原文明确提及'异构混合专家架构'，是区别于普通MoE的独特技术点，用户会搜索此类专业但非泛化的架构关键词"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "原文独创技术术语，用于解决多模态干扰，具有高区分度，属于模型专属机制，非通用词，符合用户搜索技术细节的意图"
      },
      {
        "keyword": "多模态大模型",
        "dimension": "功能场景",
        "reason": "模型明确用于视觉语言理解，原文定义为'多模态大模型(VLM)'，是用户搜索AI图文理解类应用时的典型关键词，且未被强制排除"
      },
      {
        "keyword": "4比特量化",
        "dimension": "技术特性",
        "reason": "原文提及'4比特/2比特无损量化'，'4比特量化'是主流用户关注的部署优化关键词，属于可搜索的参数量化规格，非泛泛性能描述"
      },
      {
        "keyword": "动态角色切换",
        "dimension": "技术特性",
        "reason": "原文提出'PD解耦技术'实现动态角色切换，是提升推理效率的专属机制，术语独特，非通用词，具备高搜索价值"
      },
      {
        "keyword": "分阶段训练",
        "dimension": "技术特性",
        "reason": "模型采用'前两阶段仅训练文本参数→最终引入视觉模块'的分阶段训练策略，是区别于端到端训练的显著技术特征，用户会搜索此类训练方法"
      },
      {
        "keyword": "文图相互增强",
        "dimension": "功能场景",
        "reason": "原文核心目标为'实现图文模态的相互增强'，精准描述模型能力，是用户搜索图文协同任务时的自然搜索词，非泛化表达"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-PT",
    "keywords": [
      {
        "keyword": "文心4.5",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE-4.5-VL-424B-A47B-PT 的简称，用户搜索国产大模型时常用"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 系列归属百度，用户会直接用品牌名搜索"
      },
      {
        "keyword": "424B参数",
        "dimension": "参数规格",
        "reason": "4240 亿参数是模型核心卖点，用户会按参数规模检索"
      },
      {
        "keyword": "异构混合专家",
        "dimension": "技术特性",
        "reason": "README 强调的创新 MoE 架构，技术爱好者会搜索"
      },
      {
        "keyword": "图像理解",
        "dimension": "功能场景",
        "reason": "VLM 版本主打视觉语言理解，用户搜索多模态能力时常用"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "支持 4 比特/2 比特无损量化，用户部署时关注"
      },
      {
        "keyword": "飞桨框架",
        "dimension": "部署工具",
        "reason": "基于 PaddlePaddle 优化，开发者搜索部署方案时会提及"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-FP8-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型主品牌"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "超大规模参数，用户会搜"
      },
      {
        "keyword": "FP8量化",
        "dimension": "部署工具",
        "reason": "低比特无损量化，部署热点"
      },
      {
        "keyword": "PaddlePaddle",
        "dimension": "部署工具",
        "reason": "框架专属部署关键词"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "区别于普通MoE的架构亮点"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "文本MoE后训练模型的核心用途"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-0.3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态异构MoE预训练",
        "dimension": "技术特性",
        "reason": "当前模型在文本和视觉两种模态上联合训练的独特技术"
      },
      {
        "keyword": "规模效率化基础设施",
        "dimension": "技术特性",
        "reason": "当前模型有效训练的独特基础设施策略"
      },
      {
        "keyword": "模态特定后训练",
        "dimension": "技术特性",
        "reason": "当前模型针对不同模态变体进行微调的独特方法"
      },
      {
        "keyword": "文本密集型",
        "dimension": "功能场景",
        "reason": "当前模型主要应用于文本密集型任务的描述"
      },
      {
        "keyword": "0.3B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/saulcy/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
    "keywords": [
      {
        "keyword": "puncct-transformer",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一名称，是用户搜索中文标点预测模型时可能使用的精准关键词"
      },
      {
        "keyword": "中文标点预测",
        "dimension": "功能场景",
        "reason": "模型核心用途是为中文文本添加标点，属于用户在AI语音后处理场景中明确搜索的功能词"
      },
      {
        "keyword": "FunASR",
        "dimension": "部署工具",
        "reason": "模型基于FunASR框架，是用户在寻找中文ASR+标点联合部署方案时会搜索的工具名称"
      },
      {
        "keyword": "可控时延标点",
        "dimension": "技术特性",
        "reason": "模型核心创新点是'Controllable Time-delay'，中文用户会搜索'可控时延'来寻找避免标点刷新的解决方案"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型以PyTorch格式发布，是开发者搜索可下载、可本地部署的中文标点模型时的高频技术关键词"
      },
      {
        "keyword": "语音识别后处理",
        "dimension": "功能场景",
        "reason": "模型专用于ASR输出文本的标点补全，是语音AI工程中明确的下游任务，用户会直接搜索该场景词"
      },
      {
        "keyword": "纯文本标点",
        "dimension": "功能场景",
        "reason": "模型支持纯文本输入标点预测，区别于端到端ASR，是独立应用场景，用户会用此词搜索非语音输入的标点工具"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/ascend-tribe/openpangu-embedded-1b-model",
    "keywords": [
      {
        "keyword": "openPangu-Embedded-1B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化命名规范（无版本号后缀）"
      },
      {
        "keyword": "端侧语言模型",
        "dimension": "功能场景",
        "reason": "模型明确设计用于端侧设备运行，是用户搜索轻量级AI对话模型时的核心意图词"
      },
      {
        "keyword": "快思考模型",
        "dimension": "技术特性",
        "reason": "README中多次强调'快思考'，是该模型区别于传统大模型的核心能力标签，用户会搜索此类术语"
      },
      {
        "keyword": "1B参数",
        "dimension": "参数规格",
        "reason": "1B是主流轻量级参数规模，用户常搜索'1B参数模型'寻找端侧部署方案，符合规格提取规则"
      },
      {
        "keyword": "昇腾NPU",
        "dimension": "部署工具",
        "reason": "模型专为昇腾NPU优化，是国产AI开发者搜索适配Ascend硬件模型时的关键搜索词"
      },
      {
        "keyword": "GQA注意力",
        "dimension": "技术特性",
        "reason": "GQA（分组查询注意力）是模型高效架构的关键技术，属于专业但可搜索的技术关键词，非通用术语"
      },
      {
        "keyword": "32k上下文",
        "dimension": "技术特性",
        "reason": "32k是端侧模型中罕见的长上下文能力，用户会搜索'32k上下文语言模型'寻找轻量长文本处理方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-Base-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "直接取自项目名称的核心品牌标识"
      },
      {
        "keyword": "424B参数",
        "dimension": "参数规格",
        "reason": "模型规模在名称中标明，为用户常搜索的参数规格"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "技术特性",
        "reason": "模型具备文本与视觉之间的推理能力，是其核心技术亮点"
      },
      {
        "keyword": "图文理解",
        "dimension": "功能场景",
        "reason": "模型支持图像与文字的联合理解，符合用户的实际使用需求"
      },
      {
        "keyword": "FP8混合精度训练",
        "dimension": "技术特性",
        "reason": "采用 FP8 混合精度提升训练效率，是模型的独特技术特征"
      },
      {
        "keyword": "4比特量化",
        "dimension": "技术特性",
        "reason": "推理阶段实现 4 比特无损量化，提升部署时的算力利用率"
      },
      {
        "keyword": "PaddlePaddle部署",
        "dimension": "部署工具",
        "reason": "模型基于飞桨框架，可直接在 PaddlePaddle 环境中部署使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/ascend-tribe/openpangu-ultra-moe-718b-model",
    "keywords": [
      {
        "keyword": "openPangu-Ultra-MoE-718B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "大规模混合专家语言模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性描述"
      },
      {
        "keyword": "快慢思考融合能力",
        "dimension": "技术特性",
        "reason": "当前模型具备的独特能力"
      },
      {
        "keyword": "Multi-head-Latent-Attention",
        "dimension": "技术特性",
        "reason": "当前模型架构采用的技术"
      },
      {
        "keyword": "718B参数",
        "dimension": "参数规格",
        "reason": "当前模型的总参数量"
      },
      {
        "keyword": "39B激活参数",
        "dimension": "参数规格",
        "reason": "当前模型的激活参数量"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/saulcy/speech_fsmn_vad_zh-cn-16k-common-pytorch",
    "keywords": [
      {
        "keyword": "FSMN-VAD",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型简称，用户搜索时会用"
      },
      {
        "keyword": "语音端点检测",
        "dimension": "功能场景",
        "reason": "模型核心功能，用户直接搜索该场景"
      },
      {
        "keyword": "FunASR",
        "dimension": "部署工具",
        "reason": "官方基于FunASR框架，用户会搜部署方式"
      },
      {
        "keyword": "16k中文VAD",
        "dimension": "功能场景",
        "reason": "明确采样率与语言，用户精准搜索"
      },
      {
        "keyword": "Monophone建模",
        "dimension": "技术特性",
        "reason": "模型独特技术亮点，区别于传统VAD"
      },
      {
        "keyword": "长音频切分",
        "dimension": "功能场景",
        "reason": "典型应用需求，用户搜索如何切分长语音"
      },
      {
        "keyword": "PyTorch实现",
        "dimension": "部署工具",
        "reason": "用户常搜PyTorch版本以方便本地部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/ascend-tribe/openpangu-embedded-7b-model",
    "keywords": [
      {
        "keyword": "openPangu-Embedded-7B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型品牌，符合用户搜索AI模型时的精确命名习惯"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "7B是主流参数规模，用户常搜索此类规模模型进行对比与部署评估"
      },
      {
        "keyword": "快慢思考融合",
        "dimension": "技术特性",
        "reason": "模型核心创新点，用户搜索‘具备快慢思考的AI模型’时可能命中此独特能力"
      },
      {
        "keyword": "GQA注意力机制",
        "dimension": "技术特性",
        "reason": "GQA（分组查询注意力）是模型架构关键设计，技术型用户会搜索此术语寻找高效推理模型"
      },
      {
        "keyword": "32k上下文",
        "dimension": "技术特性",
        "reason": "32k是当前主流长上下文模型的关键门槛，用户搜索‘长上下文大模型’时高频匹配"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型在MMLU、CMMLU、C-Eval等中文通用能力测评中表现优异，适合写作类应用场景"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "在LiveCodeBench和MBPP+上表现突出，明确具备代码生成能力，符合编程助手类搜索意图"
      },
      {
        "keyword": "昇腾NPU",
        "dimension": "部署工具",
        "reason": "模型专为昇腾NPU从零训练，是国产AI硬件生态的关键部署标签，用户搜索‘昇腾部署大模型’时精准匹配"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/ChatGLM3-6B",
    "keywords": [
      {
        "keyword": "ChatGLM3-6B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提供的模型完整品牌名"
      },
      {
        "keyword": "6B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 6 B 参数，是用户常搜索的规格关键词"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型支持流畅的多轮对话，是核心使用场景"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "ChatGLM3-6B 原生支持 Function Call（工具调用）功能"
      },
      {
        "keyword": "代码解释器",
        "dimension": "功能场景",
        "reason": "模型内置 Code Interpreter（代码解释器）能力，适合编程辅助"
      },
      {
        "keyword": "Agent任务",
        "dimension": "功能场景",
        "reason": "支持 Agent 任务的执行，覆盖更复杂的智能应用"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型部署门槛低，可在本地机器上直接运行"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/Speech_Paraformer_ASR_6K",
    "keywords": [
      {
        "keyword": "Paraformer",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Speech_Paraformer_ASR_6K，模型核心名称为Paraformer，是达摩院自研的非自回归ASR框架，符合品牌名提取规则且无其他模型混淆"
      },
      {
        "keyword": "FunASR",
        "dimension": "当前模型品牌名",
        "reason": "项目明确归属于FunASR开源项目，是该模型的发布平台和生态品牌，用户搜索语音识别模型时会直接搜索‘FunASR’"
      },
      {
        "keyword": "中文语音识别",
        "dimension": "功能场景",
        "reason": "模型明确针对中文语音识别优化，训练数据为数万小时中文标注音频，是用户在CSDN等平台搜索中文ASR时的高频意图词"
      },
      {
        "keyword": "长音频识别",
        "dimension": "功能场景",
        "reason": "README强调‘可直接对时长为数小时音频进行识别’，这是该模型区别于普通短语音识别的核心应用场景，用户会搜索‘长音频识别’"
      },
      {
        "keyword": "带标点语音识别",
        "dimension": "功能场景",
        "reason": "模型输出包含标点符号，是工业级语音识别的关键需求，用户搜索‘带标点语音识别’可精准匹配该功能"
      },
      {
        "keyword": "时间戳语音识别",
        "dimension": "功能场景",
        "reason": "模型支持输出时间戳，适用于会议纪要、字幕生成等场景，是用户在AI语音应用中明确搜索的垂直功能词"
      },
      {
        "keyword": "热词增强",
        "dimension": "技术特性",
        "reason": "模型提供‘热词版’并支持基于列表的激励增强，提升热词召回率，是工业部署中独特且用户会搜索的技术点"
      },
      {
        "keyword": "非自回归语音识别",
        "dimension": "技术特性",
        "reason": "模型结构明确为非自回归（non-autoregressive），区别于传统自回归ASR，是技术型用户搜索高性能语音模型时的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/ocr_small",
    "keywords": [
      {
        "keyword": "ocrsmall",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "验证码识别",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "纯数字型",
        "dimension": "功能场景",
        "reason": "当前模型可识别的验证码类型之一"
      },
      {
        "keyword": "数字字母型",
        "dimension": "功能场景",
        "reason": "当前模型可识别的验证码类型之一"
      },
      {
        "keyword": "纯字母型",
        "dimension": "功能场景",
        "reason": "当前模型可识别的验证码类型之一"
      },
      {
        "keyword": "web网页版",
        "dimension": "部署工具",
        "reason": "当前模型提供的代码使用方式之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/dots.ocr",
    "keywords": [
      {
        "keyword": "dots-ocr",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提取的模型品牌名"
      },
      {
        "keyword": "布局检测",
        "dimension": "功能场景",
        "reason": "模型能够统一进行文档的布局检测"
      },
      {
        "keyword": "内容识别",
        "dimension": "功能场景",
        "reason": "模型在单一视觉‑语言模型中实现文本内容的识别"
      },
      {
        "keyword": "表格识别",
        "dimension": "功能场景",
        "reason": "在 OmniDocBench 上实现 SOTA 表格解析能力"
      },
      {
        "keyword": "公式识别",
        "dimension": "功能场景",
        "reason": "提供与更大模型相当的公式识别效果"
      },
      {
        "keyword": "阅读顺序",
        "dimension": "功能场景",
        "reason": "保持良好的文档阅读顺序是模型的核心特性"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "技术特性",
        "reason": "模型基于 Vision‑Language 架构统一处理布局与 OCR"
      },
      {
        "keyword": "1.7B参数",
        "dimension": "参数规格",
        "reason": "模型采用 1.7B 参数的轻量化 LLM 基础"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/Qwen-Image",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名Qwen-Image对应阿里通义千问系列"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen-Image属于阿里开源大模型家族"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "README明确标注pipeline_tag为text-to-image"
      },
      {
        "keyword": "中文渲染",
        "dimension": "技术特性",
        "reason": "README强调在中文文本渲染上的显著优势"
      },
      {
        "keyword": "图像编辑",
        "dimension": "功能场景",
        "reason": "README指出具备精确图像编辑能力"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "library_name字段显示官方支持Diffusers库调用"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "文生图社区常用ComfyUI工作流部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/saulcy/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
    "keywords": [
      {
        "keyword": "Paraformer-large",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型系列"
      },
      {
        "keyword": "FunASR",
        "dimension": "当前模型品牌名",
        "reason": "阿里开源的语音识别工具链，当前模型归属项目"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Paraformer由达摩院发布，属于阿里大模型生态"
      },
      {
        "keyword": "长音频识别",
        "dimension": "功能场景",
        "reason": "用户会搜“几小时音频一次转文字”的解决方案"
      },
      {
        "keyword": "热词定制",
        "dimension": "功能场景",
        "reason": "模型支持通过热词列表提升专有名词召回，用户高频需求"
      },
      {
        "keyword": "非自回归",
        "dimension": "技术特性",
        "reason": "Paraformer的核心架构卖点，区别于传统自回归ASR"
      },
      {
        "keyword": "带时间戳字幕",
        "dimension": "功能场景",
        "reason": "直接输出每句话对应时间，满足会议纪要、字幕生成需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/Wan2.2-T2V-A14B",
    "keywords": [
      {
        "keyword": "Wan2.2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 openharmony-models/Wan2.2-T2V-A14B 中提取的核心模型品牌名，符合简化规则，去除了冗余后缀T2V-A14B"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型为视频生成模型（T2V = Text-to-Video），是用户搜索AI视频生成时的核心意图词，且未被强制排除"
      },
      {
        "keyword": "Cinematic-level-Aesthetics",
        "dimension": "技术特性",
        "reason": "模型明确强调‘电影级美学’作为核心创新点，是区别于其他视频模型的独特卖点，用户可能搜索‘电影级视频生成’等变体"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "README明确指出采用Mixture-of-Experts架构，且该词虽在排除列表中，但‘MoE架构’是技术术语缩写，与排除词‘MoE架构’完全一致，需重新判断——但根据规则，**排除列表中已明确禁止‘MoE架构’**，因此必须跳过。"
      },
      {
        "keyword": "视频扩散模型",
        "dimension": "技术特性",
        "reason": "README中提及‘video diffusion models’，是当前模型的技术基础，用户搜索‘视频扩散模型’时会精准匹配，且未被强制排除"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "README标签中明确包含PyTorch，是主流框架，用户常搜索‘PyTorch视频模型’进行部署，且非通用词"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "README中提供Hugging Face链接，表明模型支持该平台部署，用户会搜索‘HuggingFace视频模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/t5_small",
    "keywords": [
      {
        "keyword": "t5small",
        "dimension": "当前模型品牌名",
        "reason": "从项目URL和README标题提取的当前模型名称"
      },
      {
        "keyword": "Text-To-Text-Transfer-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术框架描述"
      },
      {
        "keyword": "统一文本格式",
        "dimension": "技术特性",
        "reason": "当前模型将所有NLP任务统一为文本输入输出的特性"
      },
      {
        "keyword": "NLP任务",
        "dimension": "功能场景",
        "reason": "当前模型的应用领域"
      },
      {
        "keyword": "模型框架",
        "dimension": "技术特性",
        "reason": "当前模型使用的技术框架类型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/LongWriter-glm4-9b",
    "keywords": [
      {
        "keyword": "LongWriter-glm4-9b",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型全称，符合用户搜索具体模型的意图"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "根据国产大模型映射规则，GLM-4 对应 '智谱AI'，是用户搜索国产长文本模型时的高频品牌词"
      },
      {
        "keyword": "长文生成",
        "dimension": "功能场景",
        "reason": "模型核心能力是一次性生成10,000+字长文，用户会搜索'长文生成'而非泛泛的'AI写作'"
      },
      {
        "keyword": "10000字生成",
        "dimension": "功能场景",
        "reason": "模型明确支持生成10000+字内容，该具体数字场景是用户精准搜索的关键词，具有强意图性"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "代码示例展示使用transformers本地加载，符合用户寻找可私有化部署模型的搜索习惯"
      },
      {
        "keyword": "chatglm",
        "dimension": "当前模型品牌名",
        "reason": "模型基于GLM-4，且代码中使用'model.chat()'，用户常搜索'chatglm'作为GLM系列对话模型的统称"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "GLM-4-9b 属于主流7B-10B参数区间，用户常搜索'7B参数'寻找轻量级长文本模型，符合主流规格标准"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/DeepSeek-R1-Distill-Llama-8B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "当前模型通过强化学习自然涌现的思维链能力"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "当前模型在推理过程中具备的自我验证与反思能力"
      },
      {
        "keyword": "强化学习",
        "dimension": "技术特性",
        "reason": "当前模型采用的大规模强化学习后训练方法"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规模"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "当前模型在代码与推理任务上的应用"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "用户可在本地运行当前模型的部署方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Llama2-Chinese-7b-Chat",
    "keywords": [
      {
        "keyword": "Llama2-Chinese-7b-Chat",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索中文优化Llama2模型时的精准关键词"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为7B，属于主流参数规格，用户常搜索'7B参数 中文对话模型'等组合"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型基于Llama-2-7b-chat-hf微调，专为中文对话优化，符合用户搜索'中文智能对话模型'意图"
      },
      {
        "keyword": "LoRA微调",
        "dimension": "技术特性",
        "reason": "模型采用LoRA微调技术提升中文能力，是开发者关注的高效适配方法，具技术区分度"
      },
      {
        "keyword": "中文指令集",
        "dimension": "技术特性",
        "reason": "模型核心训练方式为中文指令集微调，是区别于原版Llama2的关键技术标签"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型为完整参数版本，开箱即用，适合本地部署，符合开发者搜索'中文LLM本地部署'需求"
      },
      {
        "keyword": "PyTorch",
        "dimension": "技术特性",
        "reason": "代码示例明确使用PyTorch加载模型，是中文模型部署时高频搜索的技术栈关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openharmony-models/DeepSeek-R1-Distill-Qwen-7B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的模型品牌名称"
      },
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含 Qwen，按照国产大模型映射规则对应为通义千问"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 7B 参数，是用户常搜索的规格关键词"
      },
      {
        "keyword": "量化模型",
        "dimension": "技术特性",
        "reason": "README 中标明为量化版，属于模型的技术特性"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型适配鸿蒙 PC，可在本地环境直接部署使用"
      },
      {
        "keyword": "鸿蒙PC",
        "dimension": "部署工具",
        "reason": "特定的操作系统平台适配信息，用户搜索时会关注该平台的部署支持"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/instruct-pix2pix",
    "keywords": [
      {
        "keyword": "InstructPix2Pix",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源，是用户搜索该模型时最可能使用的精准品牌名"
      },
      {
        "keyword": "图像编辑指令",
        "dimension": "功能场景",
        "reason": "模型核心能力是根据自然语言指令修改图像，用户会搜索‘图像编辑指令’这类具体功能词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "虽然‘文生图’是高频词，但本模型属于‘指令驱动的图像编辑’，是文生图的子场景，且未被排除列表禁止，符合用户搜索意图（如‘文生图工具’）"
      },
      {
        "keyword": "图像到图像",
        "dimension": "功能场景",
        "reason": "模型本质是图像到图像转换（image-to-image），是其区别于普通文生图模型的关键特征，用户搜索‘图像到图像生成’时会命中"
      },
      {
        "keyword": "StableDiffusionInstructPix2PixPipeline",
        "dimension": "部署工具",
        "reason": "这是官方代码中调用的唯一核心类名，开发者会直接搜索该类名进行部署，属于精准技术关键词"
      },
      {
        "keyword": "diffusers",
        "dimension": "部署工具",
        "reason": "模型依赖Hugging Face diffusers库部署，开发者常搜索‘diffusers 图像编辑’来寻找相关模型"
      },
      {
        "keyword": "PyTorch",
        "dimension": "技术特性",
        "reason": "模型基于PyTorch构建，且代码明确使用torch_dtype、to('cuda')等PyTorch语法，是开发者部署时的关键技术标签"
      },
      {
        "keyword": "EulerAncestralDiscreteScheduler",
        "dimension": "技术特性",
        "reason": "模型使用该特定调度器，是其推理配置中的关键组件，技术用户会搜索该调度器名来复现效果"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Qwen2.5_7B_Instruct",
    "keywords": [
      {
        "keyword": "Qwen2.57BInstruct",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "指令精调模型",
        "dimension": "技术特性",
        "reason": "当前模型为指令精调模型，属于其技术特性"
      },
      {
        "keyword": "代码与数学领域",
        "dimension": "功能场景",
        "reason": "当前模型在代码与数学领域表现突出，属于其应用场景"
      },
      {
        "keyword": "长文本生成",
        "dimension": "功能场景",
        "reason": "当前模型具备长文本生成能力，属于其应用场景"
      },
      {
        "keyword": "结构化数据理解",
        "dimension": "功能场景",
        "reason": "当前模型具备结构化数据理解能力，属于其应用场景"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规格为7B"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "当前模型覆盖29种语言，属于其功能场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/bloom_7b1",
    "keywords": [
      {
        "keyword": "bloom7b1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接为bloom_7b1，是当前模型的唯一标识，用户搜索时会使用该精确名称"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为7B，属于主流规格，用户常按参数量搜索模型，如'7B模型'、'7B参数'"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "代码示例明确使用PyTorch加载模型，是用户部署该模型时的关键技术栈，搜索意图明确"
      },
      {
        "keyword": "Text-Generation",
        "dimension": "功能场景",
        "reason": "模型标签中明确包含'Text Generation'，且示例为指令响应生成，符合用户搜索'文本生成模型'的意图"
      },
      {
        "keyword": "多语言",
        "dimension": "功能场景",
        "reason": "README开篇强调'多语言开放访问语言模型'，是该模型区别于其他英文模型的核心功能，用户会搜索'多语言大模型'"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "虽然未直接出现，但代码使用'AutoModelForCausalLM'和'from_pretrained'，是HuggingFace生态标准接口，用户常搜'HuggingFace模型'来查找此类模型"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "bloom系列是典型自回归语言模型，虽未明写，但根据其因果语言建模（Causal LM）结构和示例代码可合理推断，属于用户搜索的底层技术分类"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/blip_vqa_base",
    "keywords": [
      {
        "keyword": "BLIP",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称blip_vqa_base提取的当前模型品牌名"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "README中明确提到的核心功能"
      },
      {
        "keyword": "图像标题生成",
        "dimension": "功能场景",
        "reason": "当前模型支持的条件/无条件图像标题生成能力"
      },
      {
        "keyword": "ViT主干网络",
        "dimension": "技术特性",
        "reason": "README中提到的ViT基础主干网络架构"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "README中给出的PyTorch模型使用方式"
      },
      {
        "keyword": "视觉语言预训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的VLP技术路线"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/albert_large_v2",
    "keywords": [
      {
        "keyword": "ALBERT-Large-v2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为albert_large_v2，按规则保留简洁品牌名，不带版本号后缀，符合用户搜索习惯"
      },
      {
        "keyword": "遮蔽语言建模",
        "dimension": "技术特性",
        "reason": "模型核心预训练目标之一，用户搜索BERT类模型时常用关键词，且未被高频词列表排除"
      },
      {
        "keyword": "句子顺序预测",
        "dimension": "技术特性",
        "reason": "ALBERT独有预训练任务，区别于BERT的NSP，具有高区分度，用户在对比模型时可能搜索"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型支持框架，纯英文术语，用户搜索模型部署时常用关键词，且未被禁止"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "模型支持框架，与PyTorch并列，是主流框架搜索词，符合用户查找可部署版本的需求"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型由Hugging Face托管，用户常通过该平台搜索和加载模型，属于高搜索意图词"
      },
      {
        "keyword": "英语语言模型",
        "dimension": "功能场景",
        "reason": "模型明确用于英语语料预训练，用户搜索‘英语NLP模型’或‘英文BERT’时会使用该词，具场景指向性"
      },
      {
        "keyword": "层权重共享",
        "dimension": "技术特性",
        "reason": "ALBERT核心创新点，区别于BERT的参数效率设计，用户研究轻量模型时可能搜索该技术术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/glm-4v-9b",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4系列归属智谱AI，国产大模型品牌映射"
      },
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提取的当前模型简称"
      },
      {
        "keyword": "视觉理解",
        "dimension": "功能场景",
        "reason": "GLM-4V-9B主打多模态视觉理解能力"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "用户常搜长文本推理的上下文长度卖点"
      },
      {
        "keyword": "Function-Call",
        "dimension": "技术特性",
        "reason": "支持自定义工具调用，开发者高频搜索点"
      },
      {
        "keyword": "9B参数",
        "dimension": "参数规格",
        "reason": "当前模型主流参数量，用户选型常搜"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "开源模型用户关注能否本地私有化部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/albert_base_v2",
    "keywords": [
      {
        "keyword": "ALBERT-base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称 albert_base_v2 提取的简洁模型名称"
      },
      {
        "keyword": "掩码语言模型",
        "dimension": "功能场景",
        "reason": "模型采用 MLM（Masked Language Modeling）进行预训练，是其核心功能"
      },
      {
        "keyword": "句子排序预测",
        "dimension": "技术特性",
        "reason": "ALBERT 使用的 SOP（Sentence Order Prediction）目标，区别于其他模型的预训练方式"
      },
      {
        "keyword": "参数共享层",
        "dimension": "技术特性",
        "reason": "模型在所有 Transformer 层之间共享权重，显著降低内存占用"
      },
      {
        "keyword": "不区分大小写",
        "dimension": "功能场景",
        "reason": "模型对英文大小写不敏感，适用于大小写混合的文本处理"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "README 中说明模型已添加对 NPU（神经网络处理单元）的支持，适合特定硬件加速部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/camembert_ner",
    "keywords": [
      {
        "keyword": "camembert-ner",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的模型品牌名，是用户搜索该特定NER模型的核心关键词"
      },
      {
        "keyword": "命名实体识别",
        "dimension": "功能场景",
        "reason": "模型的核心功能，用户搜索中文AI模型时常用‘命名实体识别’作为意图关键词"
      },
      {
        "keyword": "法语NER",
        "dimension": "功能场景",
        "reason": "模型基于wikiner-fr（法语数据集）训练，专攻法语实体识别，是区别于其他NER模型的显著特征"
      },
      {
        "keyword": "小写实体识别",
        "dimension": "技术特性",
        "reason": "README明确指出模型在‘不以大写字母开头的实体’上表现更好，这是其独特技术优势"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "模型通过HuggingFace的pipeline加载，用户常搜索‘HuggingFace模型’来寻找可直接调用的预训练模型"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "模型明确支持NPU部署，是国产AI硬件用户关注的差异化部署特性"
      },
      {
        "keyword": "openMind框架",
        "dimension": "部署工具",
        "reason": "模型使用openMind库加载，是其部署生态的专属技术标签，非通用HuggingFace标准"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/vit_msn_base",
    "keywords": [
      {
        "keyword": "vitmsnbase",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型的唯一标识，用户搜索模型时会使用此精确名称"
      },
      {
        "keyword": "MSN预训练",
        "dimension": "技术特性",
        "reason": "模型核心创新点为MSN（Masked Siamese Networks）预训练方法，是区别于其他ViT模型的关键技术标签"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "模型主要用途是通过预训练学习图像表示，用于下游特征提取任务，符合用户搜索意图"
      },
      {
        "keyword": "少样本学习",
        "dimension": "功能场景",
        "reason": "论文明确指出该模型在少量样本和极端少样本场景下表现优异，是用户关注的核心应用场景"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "示例代码明确使用PyTorch框架，是用户部署该模型时最可能搜索的工具名称"
      },
      {
        "keyword": "ViT",
        "dimension": "技术特性",
        "reason": "Vision Transformer是模型的基础架构，用户搜索视觉Transformer模型时会使用此通用但精准的缩写"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/chatglm3_6b",
    "keywords": [
      {
        "keyword": "ChatGLM3-6B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "智能体任务",
        "dimension": "功能场景",
        "reason": "当前模型原生集成的复杂场景功能"
      },
      {
        "keyword": "代码解释器",
        "dimension": "功能场景",
        "reason": "当前模型原生集成的复杂场景功能"
      },
      {
        "keyword": "6B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "当前模型原生集成的复杂场景功能"
      },
      {
        "keyword": "语义理解",
        "dimension": "技术特性",
        "reason": "当前模型在基准测试中展现出的能力"
      },
      {
        "keyword": "数学推理",
        "dimension": "技术特性",
        "reason": "当前模型在基准测试中展现出的能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bert_large_uncased",
    "keywords": [
      {
        "keyword": "BERT-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称bert_large_uncased提取的当前模型名称"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心预训练任务"
      },
      {
        "keyword": "英文预训练",
        "dimension": "功能场景",
        "reason": "当前模型专为英文文本理解与生成设计"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "当前模型可通过HuggingFace Transformers直接调用"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "当前模型官方支持PyTorch框架加载"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "当前模型同时提供TensorFlow版本权重"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bert_base_uncased",
    "keywords": [
      {
        "keyword": "BERT-base-uncased",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型标准名称，用户搜索英文BERT模型时常用此精确格式"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "当前模型的核心预训练技术，用户搜索BERT原理时高频搜索词，且未被列为高频排除词"
      },
      {
        "keyword": "下一句预测",
        "dimension": "技术特性",
        "reason": "BERT独有的双任务预训练机制之一，是区别于GPT等模型的关键技术点，用户研究NLP预训练时会搜索"
      },
      {
        "keyword": "未区分大小写",
        "dimension": "技术特性",
        "reason": "当前模型的显著特征，用户对比BERT-cased/uncased时会使用此关键词，具有明确区分度"
      },
      {
        "keyword": "英语预训练",
        "dimension": "功能场景",
        "reason": "明确描述模型的语言适用场景，用户寻找英文NLP模型时常用此组合词，非泛泛描述"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "虽然HuggingFace是平台，但用户常搜索'XXX HuggingFace模型'来获取可直接加载的模型，且未被列为排除词"
      },
      {
        "keyword": "BERT基础版",
        "dimension": "当前模型品牌名",
        "reason": "中文用户常搜索'BERT基础版'指代bert-base系列，是口语化但高搜索量的中文表达，且非其他模型名称"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/distilbert_base_uncased",
    "keywords": [
      {
        "keyword": "DistilBERT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'distilbert_base_uncased' 提取的核心模型品牌名，简化为通用称呼，用户搜索蒸馏模型时常用"
      },
      {
        "keyword": "BERT-base",
        "dimension": "当前模型品牌名",
        "reason": "模型是BERT基础版本的蒸馏体，用户常搜索'BERT-base'作为对比或基础模型，属于当前模型的直接关联名称"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "功能场景",
        "reason": "模型核心预训练目标之一，用户搜索文本补全、填空任务时高频使用，是当前模型的主要应用场景"
      },
      {
        "keyword": "模型蒸馏",
        "dimension": "技术特性",
        "reason": "模型的核心技术方法，区别于原生BERT，是DistilBERT的唯一标识性技术，用户搜索轻量级BERT时会用此词"
      },
      {
        "keyword": "下一句预测",
        "dimension": "功能场景",
        "reason": "模型明确支持的任务，属于NLP经典任务，用户在搜索文本连贯性分析、句子关系判断时会使用该词"
      },
      {
        "keyword": "轻量级BERT",
        "dimension": "功能场景",
        "reason": "用户搜索‘更快的BERT’‘小模型BERT’时常用口语化表达，DistilBERT正是该类模型的代表，具有强搜索意图"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型通过HuggingFace Transformers库发布和使用，是用户部署该模型时必用平台，属于关键工具词"
      },
      {
        "keyword": "自监督预训练",
        "dimension": "技术特性",
        "reason": "模型预训练方式的核心描述，区别于有监督模型，是技术型用户搜索无标签训练模型时的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/chatglm3_6b",
    "keywords": [
      {
        "keyword": "ChatGLM3-6B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "智能体任务",
        "dimension": "功能场景",
        "reason": "当前模型支持智能体任务等复杂场景处理能力"
      },
      {
        "keyword": "代码解释器",
        "dimension": "功能场景",
        "reason": "当前模型原生集成代码解释器功能"
      },
      {
        "keyword": "NPU加速",
        "dimension": "技术特性",
        "reason": "当前模型优化示例代码，新增NPU加速支持"
      },
      {
        "keyword": "6B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模为6B"
      },
      {
        "keyword": "对话流畅",
        "dimension": "技术特性",
        "reason": "当前模型延续前两代模型对话流畅的优势"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/flan_t5_base",
    "keywords": [
      {
        "keyword": "flan-t5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'flan_t5_base' 提取的简化品牌名，符合模型命名规范，用户搜索时常用此简称"
      },
      {
        "keyword": "text2text-generation",
        "dimension": "功能场景",
        "reason": "README中明确提及该模型用于文本生成任务，是用户搜索AI文本生成模型时的核心关键词"
      },
      {
        "keyword": "instruction-tuning",
        "dimension": "技术特性",
        "reason": "模型核心优势在于指令微调（instruction fine-tuning），是区别于普通T5的关键技术点，用户会搜索此术语"
      },
      {
        "keyword": "1000-tasks",
        "dimension": "技术特性",
        "reason": "模型经过1000多个任务微调，是其性能优势的直接体现，用户在对比模型能力时会搜索此类量化特征"
      },
      {
        "keyword": "few-shot-performance",
        "dimension": "技术特性",
        "reason": "README强调其在少样本场景下表现优异，是用户寻找低数据需求模型时的高频搜索意图"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型通过HuggingFace发布，是用户查找和加载该模型的主要平台，属于部署入口关键词"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "模型支持Safetensors格式，该格式在社区中被广泛用于安全加载模型，是技术用户搜索时的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/flan_t5_small",
    "keywords": [
      {
        "keyword": "FLAN-T5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "模型通过 Instruction Fine‑tuning（指令微调）提升性能，是其核心技术特性"
      },
      {
        "keyword": "Few-shot能力",
        "dimension": "技术特性",
        "reason": "模型在少样本（few‑shot）设置下仍能保持强劲表现，用户常以此为搜索关键词"
      },
      {
        "keyword": "多任务微调",
        "dimension": "功能场景",
        "reason": "模型在 1000+ 任务上进行微调，适用于多种下游任务"
      },
      {
        "keyword": "1000任务",
        "dimension": "功能场景",
        "reason": "强调模型覆盖的大规模任务数量，区别于其他小模型"
      },
      {
        "keyword": "小型模型",
        "dimension": "参数规格",
        "reason": "相较于同系列大模型，FLAN‑T5 small 属于轻量级、参数更少的版本"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/convnext_tiny_224",
    "keywords": [
      {
        "keyword": "ConvNeXT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌名"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "README明确说明用于ImageNet-1k图像分类任务"
      },
      {
        "keyword": "224分辨率",
        "dimension": "技术特性",
        "reason": "模型专为224×224输入分辨率优化，是用户搜索时的关键规格"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "README新增openMind NPU适配，是部署亮点"
      },
      {
        "keyword": "ConvNet现代化",
        "dimension": "技术特性",
        "reason": "模型卖点：用Transformer思路改造传统卷积网络"
      },
      {
        "keyword": "ImageNet-1k",
        "dimension": "功能场景",
        "reason": "训练数据集名称，用户常以此搜索对应模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/stable-diffusion-xl-base-1_0",
    "keywords": [
      {
        "keyword": "SD-XL",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为stable-diffusion-xl-base-1_0，简化后为用户搜索习惯的SD-XL，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型核心功能是根据文本提示生成图像，符合用户搜索'文生图'的明确意图，且未被强制排除"
      },
      {
        "keyword": "潜在扩散",
        "dimension": "技术特性",
        "reason": "模型基于'潜在扩散流程'（latent diffusion），是其核心技术架构，具有区分度且未被高频词排除"
      },
      {
        "keyword": "双编码器",
        "dimension": "技术特性",
        "reason": "模型使用'双固定预训练文本编码器（OpenCLIP-ViT/G与CLIP-ViT/L）'，'双编码器'是其独特结构特征，非通用术语"
      },
      {
        "keyword": "SDEdit",
        "dimension": "技术特性",
        "reason": "模型支持SDEdit技术（图生图）作为可选流程，是SDXL特有的细化方法，技术术语且非高频词"
      },
      {
        "keyword": "OpenCLIP",
        "dimension": "技术特性",
        "reason": "模型使用OpenCLIP-ViT/G作为文本编码器，是其关键组件，属于专有技术名词，非通用词且未被排除"
      },
      {
        "keyword": "Refiner模型",
        "dimension": "技术特性",
        "reason": "模型设计依赖专精去噪的Refiner模型进行后处理，是SDXL架构的标志性组成部分，具有明确区分度"
      },
      {
        "keyword": "CreativeML-Open-RAIL-M",
        "dimension": "许可协议",
        "reason": "模型使用该特定开源许可，是用户在合规使用时可能搜索的关键标识，非通用词且具唯一性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/flan_t5_large",
    "keywords": [
      {
        "keyword": "FLAN-T5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称flan_t5_large提取的当前模型名称"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "FLAN-T5的核心训练方式，用户常搜此关键词"
      },
      {
        "keyword": "多语言模型",
        "dimension": "功能场景",
        "reason": "支持40+语言，用户搜索多语言大模型时会用"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "FLAN-T5主打文本到文本生成，用户高频搜索词"
      },
      {
        "keyword": "少样本学习",
        "dimension": "技术特性",
        "reason": "模型亮点之一，用户搜少样本/小样本时会用"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "官方检查点托管在HuggingFace，用户搜部署入口"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mbart_large_50_many_to_many_mmt",
    "keywords": [
      {
        "keyword": "mBART-large-50",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称'mbart_large_50_many_to_many_mmt'中提取的核心品牌名，简化为用户易搜索的简洁形式"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "mBART-large-50的核心用途是跨50种语言的文本翻译，用户搜索AI翻译模型时常用此词"
      },
      {
        "keyword": "many-to-many翻译",
        "dimension": "功能场景",
        "reason": "模型名称中明确包含'many_to_many_mmt'，代表其支持任意语言对之间的双向翻译，是独特功能标签"
      },
      {
        "keyword": "50种语言",
        "dimension": "功能场景",
        "reason": "模型支持50种语言，是用户在搜索多语言AI模型时的关键筛选条件，具有明确搜索意图"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "mBART系列模型主要通过HuggingFace分发，用户常搜索'HuggingFace模型'来获取预训练权重"
      },
      {
        "keyword": "序列到序列",
        "dimension": "技术特性",
        "reason": "mBART是基于序列到序列（Seq2Seq）架构的预训练模型，这是其核心技术本质，用户搜索翻译模型时会用到"
      },
      {
        "keyword": "预训练翻译模型",
        "dimension": "功能场景",
        "reason": "用户在寻找可微调的翻译模型时，常搜索'预训练翻译模型'，该词精准匹配mBART的定位"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/qwen1.5_7b",
    "keywords": [
      {
        "keyword": "qwen1.57b",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "仅解码器语言模型",
        "dimension": "技术特性",
        "reason": "当前模型基于Transformer架构的仅解码器语言模型，是其核心特性"
      },
      {
        "keyword": "多语言支持",
        "dimension": "技术特性",
        "reason": "当前模型的基础模型和聊天模型均支持多语言，是其重要特性"
      },
      {
        "keyword": "32K上下文长度",
        "dimension": "技术特性",
        "reason": "当前模型所有尺寸均稳定支持32K上下文长度，是其技术优势"
      },
      {
        "keyword": "SwiGLU激活函数",
        "dimension": "技术特性",
        "reason": "当前模型采用了SwiGLU激活函数等技术，是其技术特点之一"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "当前模型为7B参数版本，是用户可能搜索的规格信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/t5_large",
    "keywords": [
      {
        "keyword": "T5-Large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称，简洁品牌形式，符合用户搜索习惯（如SD-XL）"
      },
      {
        "keyword": "文本到文本",
        "dimension": "技术特性",
        "reason": "T5模型最核心的创新理念，用户搜索NLP统一框架时会使用该术语，具有高区分度"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "T5-Large明确支持的典型下游任务，是用户在博客中搜索AI翻译模型时的高频意图词"
      },
      {
        "keyword": "文档摘要",
        "dimension": "功能场景",
        "reason": "T5-Large官方明确列出的核心应用场景，区别于其他模型，具有明确搜索意图"
      },
      {
        "keyword": "问答系统",
        "dimension": "功能场景",
        "reason": "T5-Large支持的三大NLP任务之一，用户常搜索‘AI问答模型’时会匹配该词"
      },
      {
        "keyword": "情感分析",
        "dimension": "功能场景",
        "reason": "T5-Large支持的分类任务代表，用户搜索‘AI情感识别’或‘文本分类模型’时可能使用该词"
      },
      {
        "keyword": "C4数据集",
        "dimension": "训练数据",
        "reason": "T5-Large预训练使用的核心无监督数据集，专业用户会搜索‘T5 C4训练’等组合词，具独特性"
      },
      {
        "keyword": "7.7亿参数",
        "dimension": "参数规格",
        "reason": "模型明确标注的参数规模，属于主流规格（介于B级与B+级之间），用户会搜索‘7亿参数模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/internlm2_chat_7b",
    "keywords": [
      {
        "keyword": "InternLM2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "200K上下文",
        "dimension": "技术特性",
        "reason": "当前模型主打超长上下文能力，用户会搜"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规格"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "当前模型专为对话场景优化"
      },
      {
        "keyword": "LMDeploy",
        "dimension": "部署工具",
        "reason": "README明确推荐用LMDeploy实现200K上下文推理"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "README强调在代码任务上表现领先"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/gpt2",
    "keywords": [
      {
        "keyword": "GPT-2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型的官方名称"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "模型的主要应用是根据提示生成自然语言文本"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "GPT-2 基于因果（自回归）语言模型进行训练"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "模型通过预测下一个词实现自回归生成"
      },
      {
        "keyword": "124M参数",
        "dimension": "参数规格",
        "reason": "该版本是 GPT-2 的最小模型，拥有约 124M 参数"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "README 示例展示了通过 pipeline 接口进行模型调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/conformer_ms",
    "keywords": [
      {
        "keyword": "Conformer",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为conformer_ms，核心模型名称为Conformer，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "语音识别",
        "dimension": "功能场景",
        "reason": "模型明确用于自动语音识别（ASR），是用户搜索AI语音模型时的核心意图词"
      },
      {
        "keyword": "卷积增强Transformer",
        "dimension": "技术特性",
        "reason": "Conformer的核心创新点，是区别于普通Transformer的专属技术描述，用户会搜索该组合词"
      },
      {
        "keyword": "ConformerBlock",
        "dimension": "技术特性",
        "reason": "模型结构中的关键组件名称，具有唯一性，技术爱好者会搜索该术语"
      },
      {
        "keyword": "马卡龙结构",
        "dimension": "技术特性",
        "reason": "README中原创比喻，描述ConformerBlock的双FFN夹Attention与Conv的结构，独特且易传播"
      },
      {
        "keyword": "Aishell-1",
        "dimension": "功能场景",
        "reason": "模型训练/测试所用的公开中文语音数据集，用户搜索中文ASR模型时会关联该数据集"
      },
      {
        "keyword": "NPU推理",
        "dimension": "部署工具",
        "reason": "模型明确支持NPU部署，是国产AI芯片场景下的关键部署关键词，有差异化价值"
      },
      {
        "keyword": "在线速度扰动",
        "dimension": "技术特性",
        "reason": "模型训练中使用'online speed perturb'作为数据增强技术，属于语音ASR领域专业但用户会搜索的术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/wavegrad_ms",
    "keywords": [
      {
        "keyword": "WaveGrad",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 openMind/wavegrad_ms 直接提取的核心模型名称，符合简洁品牌名规则"
      },
      {
        "keyword": "文本转语音",
        "dimension": "功能场景",
        "reason": "README明确说明模型专为'文本转语音系统设计'，是用户搜索AI语音生成时的明确意图关键词"
      },
      {
        "keyword": "扩散模型声码器",
        "dimension": "技术特性",
        "reason": "模型基于扩散模型实现声码器功能，是其区别于Vocoder（如WaveNet、MelGAN）的核心技术标签，用户会搜索此类技术组合"
      },
      {
        "keyword": "梅尔频谱图转波形",
        "dimension": "技术特性",
        "reason": "模型核心功能是将梅尔频谱图迭代优化为波形，属于具体可搜索的技术流程描述，非泛泛术语"
      },
      {
        "keyword": "MindSpore声码器",
        "dimension": "部署工具",
        "reason": "模型基于MindSpore框架实现，且项目明确标注MindSpore版本，用户搜索'MindSpore 声码器'有明确部署意图"
      },
      {
        "keyword": "LJSpeech声码器",
        "dimension": "功能场景",
        "reason": "模型在LJSpeech-1.1数据集上预训练，该数据集是英语TTS领域标准数据集，用户会搜索'LJSpeech 声码器'来寻找对应语音模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bloom_7b1",
    "keywords": [
      {
        "keyword": "bloom7b1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "大规模多语言模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，强调其大规模和多语言能力"
      },
      {
        "keyword": "开放科学开放获取",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性，突出其开放性和可获取性"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "当前模型采用自回归架构，是其技术特点之一"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "当前模型可用于智能对话场景，是用户可能搜索的功能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/inceptionv3_ms",
    "keywords": [
      {
        "keyword": "InceptionV3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型的官方名称"
      },
      {
        "keyword": "卷积分解",
        "dimension": "技术特性",
        "reason": "InceptionV3 通过 Factorization 将大卷积分解为一维卷积，是核心技术创新"
      },
      {
        "keyword": "Batch-Normalization",
        "dimension": "技术特性",
        "reason": "模型引入批归一化，加速收敛并降低过拟合，是显著的技术特性"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "InceptionV3 主要用于 ImageNet 等数据集的图像分类任务"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于 MindSpore 框架实现，可直接在该平台部署与训练"
      },
      {
        "keyword": "299x299输入尺寸",
        "dimension": "技术特性",
        "reason": "相较于前代，InceptionV3 将输入分辨率提升至 299×299，提升特征表达能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/baichuan2_7b_chat_ms",
    "keywords": [
      {
        "keyword": "百川2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为baichuan2_7b_chat_ms，根据国产大模型映射规则，'Baichuan'应提取为品牌简称'百川2'，符合用户搜索习惯且区别于其他模型"
      },
      {
        "keyword": "百川大模型",
        "dimension": "当前模型品牌名",
        "reason": "README中多次使用'百川大模型'作为官方称呼，是用户在中文社区搜索该系列模型时的高频品牌词，且未被列为高频排除词"
      },
      {
        "keyword": "192K长上下文",
        "dimension": "技术特性",
        "reason": "192K上下文窗口是当前模型核心差异化功能，用户会搜索'长上下文模型'，该词具象且未被排除，区别于通用'128K'等参数"
      },
      {
        "keyword": "知识库检索",
        "dimension": "功能场景",
        "reason": "README明确提及'新增知识库检索功能'，是用户寻找能连接外部知识的AI对话模型时的明确搜索意图词"
      },
      {
        "keyword": "4bit量化版",
        "dimension": "部署工具",
        "reason": "模型提供4bit量化版本，是开发者关心的轻量化部署方式，属于用户搜索'低显存模型'时的精准关键词，且未被排除"
      },
      {
        "keyword": "开源大语言模型",
        "dimension": "功能场景",
        "reason": "README强调'开源'与'大语言模型'，该组合是中文开发者搜索可商用开源模型时的典型搜索短语，具有明确意图且非通用形容词"
      },
      {
        "keyword": "免费商用",
        "dimension": "功能场景",
        "reason": "模型明确说明'免费用于商业场景'，这是开发者筛选模型时的关键决策词，区别于普通开源模型，具有强引流价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/hrnet_ms",
    "keywords": [
      {
        "keyword": "HRNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型简称"
      },
      {
        "keyword": "高分辨率网络",
        "dimension": "当前模型品牌名",
        "reason": "HRNet的中文全称，用户常用搜索词"
      },
      {
        "keyword": "人体姿态估计",
        "dimension": "功能场景",
        "reason": "README明确列出的核心应用场景"
      },
      {
        "keyword": "语义分割",
        "dimension": "功能场景",
        "reason": "README明确列出的核心应用场景"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "README明确列出的核心应用场景"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "项目基于MindSpore框架，用户会搜MindSpore部署"
      },
      {
        "keyword": "ImageNet-1K",
        "dimension": "技术特性",
        "reason": "模型在ImageNet-1K上训练，用户搜预训练权重时常用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/dit_ms",
    "keywords": [
      {
        "keyword": "DiT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为dit_ms，模型核心名称为DiT（Diffusion Transformer），是当前模型的唯一品牌标识"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型用于图像生成，属于扩散模型典型应用场景，用户常搜索'文生图'寻找此类模型"
      },
      {
        "keyword": "扩散模型",
        "dimension": "技术特性",
        "reason": "DiT是基于扩散机制的生成模型，该词是用户搜索生成类AI模型的核心技术标签"
      },
      {
        "keyword": "Transformer架构",
        "dimension": "技术特性",
        "reason": "模型明确基于Transformer而非U-Net，这是其区别于Stable Diffusion等模型的核心技术差异点"
      },
      {
        "keyword": "图像生成",
        "dimension": "功能场景",
        "reason": "模型用途明确指向艺术创作、设计等图像生成任务，是用户搜索的直接意图词"
      },
      {
        "keyword": "可扩展扩散模型",
        "dimension": "技术特性",
        "reason": "README中强调DiT是'可扩展架构'，该短语是模型独有的技术定位，具有区分度"
      },
      {
        "keyword": "Patchify",
        "dimension": "技术特性",
        "reason": "模型采用'patchify'将图像转为token序列，是DiT区别于其他扩散模型的关键预处理技术术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/deepspeech2_ms",
    "keywords": [
      {
        "keyword": "DeepSpeech2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型的官方名称"
      },
      {
        "keyword": "语音识别",
        "dimension": "功能场景",
        "reason": "模型的核心应用场景是将语音转换为文字"
      },
      {
        "keyword": "CTC损失",
        "dimension": "技术特性",
        "reason": "模型采用的关键训练方法，用户常以此关键词搜索相关模型"
      },
      {
        "keyword": "双向-LSTM",
        "dimension": "技术特性",
        "reason": "模型结构中使用的关键循环网络层，具备显著的搜索热度"
      },
      {
        "keyword": "MindAudio",
        "dimension": "部署工具",
        "reason": "模型在 MindAudio 框架下提供训练、推理和部署指南"
      },
      {
        "keyword": "端到端模型",
        "dimension": "技术特性",
        "reason": "模型实现了从原始音频到文字的完整端到端流程，用户常以此关键词定位模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mistral_7b_v0.1",
    "keywords": [
      {
        "keyword": "Mistral-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "7B级轻量模型常被用于搭建聊天机器人"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "社区最常用的本地运行Mistral-7B方案"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "用户搜索4-bit/8-bit量化以节省显存"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "主流轻量级参数规模，搜索量高"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "用户惯用HF平台下载与调用该模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/nasnet_ms",
    "keywords": [
      {
        "keyword": "NasNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为nasnet_ms，模型核心名称为NasNet，是用户搜索神经架构搜索图像模型时的直接关键词"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "模型明确用于ImageNet-1K图像分类任务，是用户搜索AI图像识别模型时的核心意图词"
      },
      {
        "keyword": "神经架构搜索",
        "dimension": "技术特性",
        "reason": "模型基于NAS（Neural Architecture Search）技术构建，是其核心技术标签，用户会搜索此类方法论模型"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于MindSpore框架实现，是其唯一指定的AI框架，用户会搜索'MindSpore模型'来寻找兼容生态"
      },
      {
        "keyword": "Ascend-910",
        "dimension": "部署工具",
        "reason": "模型训练明确使用Ascend 910 NPU，是国产AI芯片生态中的关键部署标识，用户会搜索该硬件配套模型"
      },
      {
        "keyword": "5.33M参数",
        "dimension": "参数规格",
        "reason": "模型参数为5.33M，属于轻量级模型规格，用户会搜索'轻量图像分类模型'或具体参数值进行对比"
      },
      {
        "keyword": "图模式训练",
        "dimension": "部署工具",
        "reason": "模型训练采用'图模式（G）'，是MindSpore特有执行模式，为开发者部署时的关键技术关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/coat_ms",
    "keywords": [
      {
        "keyword": "CoaT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "协同尺度卷积注意力",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，描述了其独特的机制"
      },
      {
        "keyword": "图像分类器",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "多尺度上下文建模",
        "dimension": "技术特性",
        "reason": "当前模型赋予的能力，是其技术特点之一"
      },
      {
        "keyword": "coatlitetiny",
        "dimension": "当前模型品牌名（变体）",
        "reason": "当前模型的一个具体变体名称，用户可能搜索"
      },
      {
        "keyword": "coatlitemini",
        "dimension": "当前模型品牌名（变体）",
        "reason": "当前模型的另一个具体变体名称，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/qwen_7b_base_ms",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为qwen_7b_base_ms，Qwen需映射为国产大模型品牌名'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen是阿里旗下的大模型系列，符合国产大模型映射规则"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型名称中明确包含7B，属于主流参数规模，用户常搜索"
      },
      {
        "keyword": "基础模型",
        "dimension": "功能场景",
        "reason": "模型后缀为_base，表明其为通用基础模型，非微调版，用户会搜索此类术语"
      },
      {
        "keyword": "中文预训练",
        "dimension": "技术特性",
        "reason": "Qwen系列以中文优化见长，'base'版本通常指原生中文预训练，符合用户搜索意图"
      },
      {
        "keyword": "开源模型",
        "dimension": "部署工具",
        "reason": "项目托管于GitCode，属于公开开源模型，用户常搜索'开源模型'寻找可商用/可部署版本"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/ecapatdnn_ms",
    "keywords": [
      {
        "keyword": "ECAPA-TDNN",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称ecapatdnn_ms提取的当前模型名称"
      },
      {
        "keyword": "说话人验证",
        "dimension": "功能场景",
        "reason": "README首句明确的功能定位"
      },
      {
        "keyword": "声纹识别",
        "dimension": "功能场景",
        "reason": "README提到的VoxSRC2020比赛场景"
      },
      {
        "keyword": "通道注意力",
        "dimension": "技术特性",
        "reason": "ECAPA-TDNN引入的核心机制"
      },
      {
        "keyword": "Squeeze-Excitation",
        "dimension": "技术特性",
        "reason": "模型结构中的关键SE模块"
      },
      {
        "keyword": "MindAudio",
        "dimension": "部署工具",
        "reason": "README指向的MindAudio仓库用于训练与推理"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/baichuan2_13b_chat_ms",
    "keywords": [
      {
        "keyword": "百川2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Baichuan2，提取为简洁品牌名“百川2”"
      },
      {
        "keyword": "13B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 13B 参数，是用户常搜索的规格关键词"
      },
      {
        "keyword": "4位量化",
        "dimension": "技术特性",
        "reason": "Chat 版本提供 4 位量化方案，突出模型的量化技术特性"
      },
      {
        "keyword": "知识库检索",
        "dimension": "功能场景",
        "reason": "新增的知识库检索功能是模型的核心应用场景之一"
      },
      {
        "keyword": "搜索增强",
        "dimension": "功能场景",
        "reason": "API 已支持搜索增强，用户会以此关键词搜索相关模型"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型通过 API 提供服务，是常见的调用方式"
      },
      {
        "keyword": "192K长文本窗口",
        "dimension": "技术特性",
        "reason": "支持 192K 长文本窗口，体现模型的超长上下文能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/opus-mt-zh-en",
    "keywords": [
      {
        "keyword": "Opus-MT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型品牌，直接对应模型的官方名称"
      },
      {
        "keyword": "中文-英语翻译",
        "dimension": "功能场景",
        "reason": "模型的主要应用场景是将中文文本翻译为英文"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "模型属于机器翻译类别，用户常以此关键词搜索相应模型"
      },
      {
        "keyword": "SentencePiece",
        "dimension": "技术特性",
        "reason": "模型使用 SentencePiece 进行分词和词表构建，是其关键技术之一"
      },
      {
        "keyword": "OPUS数据集",
        "dimension": "训练数据",
        "reason": "模型训练使用 OPUS 语料库，用户会搜索该数据集关联的模型"
      },
      {
        "keyword": "Helsinki-NLP",
        "dimension": "开发者/品牌",
        "reason": "模型由赫尔辛基大学语言技术研究小组（Helsinki‑NLP）发布，是辨识模型来源的重要信息"
      },
      {
        "keyword": "CC-BY-4.0许可证",
        "dimension": "许可证",
        "reason": "模型采用 CC‑BY‑4.0 开源许可证，用户在寻找可商用或可再分发模型时会关注此信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolov3_ms",
    "keywords": [
      {
        "keyword": "yolov3ms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "YOLOv3模型通常用于目标检测任务，是用户可能搜索的功能场景"
      },
      {
        "keyword": "实时检测",
        "dimension": "功能场景",
        "reason": "YOLOv3模型以其高效性著称，适用于实时检测场景，是用户可能的需求"
      },
      {
        "keyword": "轻量化模型",
        "dimension": "技术特性",
        "reason": "YOLOv3_ms可能代表YOLOv3的一个轻量化或优化版本，适合资源受限环境"
      },
      {
        "keyword": "深度学习",
        "dimension": "技术特性",
        "reason": "YOLOv3是基于深度学习的目标检测模型，这是其技术基础"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolov7_ms",
    "keywords": [
      {
        "keyword": "yolov7ms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索YOLOv7改进版时会使用此名称"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "YOLOv7系列的核心用途是实时目标检测，这是用户搜索该类模型时的明确意图"
      },
      {
        "keyword": "轻量化检测",
        "dimension": "功能场景",
        "reason": "ms后缀暗示模型优化方向为轻量级（mobile/small），用户会搜索‘轻量化目标检测模型’"
      },
      {
        "keyword": "实时检测",
        "dimension": "功能场景",
        "reason": "YOLO系列主打实时推理，‘实时检测’是用户在CSDN等平台高频搜索的场景词"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "YOLOv7常被集成到ComfyUI工作流中用于视觉生成任务，是用户部署时的关键搜索词"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "ms版本通常针对边缘设备优化，量化是其核心部署手段，用户会搜索‘YOLOv7 量化模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/glm-edge-4b-chat",
    "keywords": [
      {
        "keyword": "GLM-Edge",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称glm-edge-4b-chat提取的当前模型品牌名"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM系列属于智谱AI官方出品"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "当前模型为40亿参数规模，用户会搜"
      },
      {
        "keyword": "聊天模型",
        "dimension": "功能场景",
        "reason": "项目名称含chat，主打对话能力"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "用户常用Ollama一键运行GLM-Edge"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "4B规模适合量化后本地运行"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/internlm_20b_base_ms",
    "keywords": [
      {
        "keyword": "InternLM-20B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "书生浦语",
        "dimension": "当前模型品牌名",
        "reason": "InternLM官方中文品牌名"
      },
      {
        "keyword": "20B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规格"
      },
      {
        "keyword": "16K上下文",
        "dimension": "技术特性",
        "reason": "用户会搜超长上下文能力"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "当前模型主打的能力场景"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "README强调编程能力提升，用户高频搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Qwen3-8B",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen3-8B，根据国产大模型映射规则，Qwen必须映射为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "通义千问是阿里旗下大模型系列，'阿里大模型'是用户搜索的通用品牌词"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型核心创新点：在单一模型内无缝切换思维模式与非思维模式，具有高度区分度"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在代码生成方面表现突出，是用户明确搜索的AI应用场景，且未被高频词列表排除"
      },
      {
        "keyword": "131K上下文",
        "dimension": "参数规格",
        "reason": "通过YaRN扩展至131,072 tokens，属于主流长上下文规格，用户常搜'128K上下文'，131K具搜索价值"
      },
      {
        "keyword": "智能体工具调用",
        "dimension": "功能场景",
        "reason": "模型在开源模型中智能体任务表现领先，'智能体工具调用'是精准功能场景词，非泛泛描述"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "支持100+语言指令遵循与翻译，是用户搜索多语言AI模型时的明确意图关键词"
      },
      {
        "keyword": "HuggingFace部署",
        "dimension": "部署工具",
        "reason": "明确提及集成至Hugging Face transformers，是用户部署该模型时最可能搜索的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/gemma-3-1b-it",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称gemma-3-1b-it中提取的核心品牌名，简化为用户搜索习惯的‘Gemma 3’，不带参数后缀"
      },
      {
        "keyword": "1B参数",
        "dimension": "参数规格",
        "reason": "模型为1B参数规模，属于主流轻量级参数规格，用户常搜索‘1B参数模型’寻找轻量部署方案"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "128K上下文窗口是Gemma 3的核心差异化能力，用户会搜索‘长上下文模型’或‘128K上下文’寻找处理长文本需求"
      },
      {
        "keyword": "多语言支持",
        "dimension": "技术特性",
        "reason": "支持140+语言是Gemma 3明确宣传的特性，用户搜索‘多语言AI模型’时会匹配该关键词"
      },
      {
        "keyword": "文生文",
        "dimension": "功能场景",
        "reason": "模型仅生成文本输出，区别于多模态模型，用户搜索‘文生文’场景时精准匹配，且未被高频词库排除"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "README明确提及Safetensors格式，是开发者部署时高频搜索的权重安全格式，非通用词且未被禁用"
      },
      {
        "keyword": "开源模型",
        "dimension": "技术特性",
        "reason": "模型强调‘open weights’，用户常搜索‘开源大模型’寻找可商用、可本地部署的模型，该词具高搜索意图且未被高频词库覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Qwen1.5-1.8b",
    "keywords": [
      {
        "keyword": "Qwen1.5-1.8b",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "纯解码器语言模型",
        "dimension": "技术特性",
        "reason": "当前模型基于Transformer架构的纯解码器语言模型，是其核心技术特性"
      },
      {
        "keyword": "多语言能力",
        "dimension": "功能场景",
        "reason": "当前模型支持多语言能力，是其应用场景之一"
      },
      {
        "keyword": "32K上下文长度",
        "dimension": "技术特性",
        "reason": "当前模型全尺寸稳定支持32K上下文长度，是其技术特性之一"
      },
      {
        "keyword": "SwiGLU激活函数",
        "dimension": "技术特性",
        "reason": "当前模型采用SwiGLU激活函数，是其创新设计之一"
      },
      {
        "keyword": "1.8B参数",
        "dimension": "参数规格",
        "reason": "当前模型包含1.8B参数版本，是其参数规格之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/QwQ-32B",
    "keywords": [
      {
        "keyword": "QwQ-32B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型名称，符合用户搜索习惯"
      },
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "QwQ属于Qwen系列，根据国产大模型映射规则，Qwen应映射为'通义千问'"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "32.5B参数属于主流规格，用户常搜索'32B参数'类关键词，且未被高频词列表排除"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "README明确指出QwQ是'能够思考和推理的模型'，符合'链式思维'这一核心推理能力描述"
      },
      {
        "keyword": "AI推理",
        "dimension": "功能场景",
        "reason": "模型定位为'推理模型'，区别于普通指令模型，'AI推理'是用户搜索推理类模型的高频意图词"
      },
      {
        "keyword": "131K上下文",
        "dimension": "技术特性",
        "reason": "131,072令牌上下文是当前模型显著特性，用户常搜索'128K上下文'、'131K上下文'等长上下文模型，属于可接受的规格级描述"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "模型类型为'因果语言模型'，即自回归模型，是技术圈常用术语，具有区分度且未被高频词列表排除"
      },
      {
        "keyword": "QwQ模型",
        "dimension": "当前模型品牌名",
        "reason": "用户可能搜索简化的'QwQ模型'而非完整名称，作为品牌名的口语化变体，符合搜索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/deepseek-coder-6.7b-instruct",
    "keywords": [
      {
        "keyword": "DeepSeek-Coder",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的品牌名称，用户搜索时会直接使用"
      },
      {
        "keyword": "6.7B参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模为 6.7 B，属于用户常搜索的规格标签"
      },
      {
        "keyword": "项目级代码补全",
        "dimension": "功能场景",
        "reason": "模型支持在整个项目层面进行代码补全与填充，是核心使用场景"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型定位为代码生成与编程辅助工具，用户常以此关键词检索"
      },
      {
        "keyword": "16K上下文窗口",
        "dimension": "技术特性",
        "reason": "模型采用 16 K 长度的上下文窗口，区别于多数模型的 2 K‑4 K 限制"
      },
      {
        "keyword": "填空任务",
        "dimension": "技术特性",
        "reason": "在预训练阶段加入填空任务，提升项目级代码补全能力"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "模型在 20 亿指令数据上进行微调，属于其独特的训练方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Qwen3-0.6B",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen3，根据国产大模型映射规则，Qwen必须映射为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen系列是阿里巴巴推出的旗舰大模型，'阿里大模型'是用户搜索该系列的通用关键词"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "Qwen3-0.6B独有的核心功能，用户可搜索'思维模式切换'来寻找支持逻辑与对话双模式的模型"
      },
      {
        "keyword": "32K上下文",
        "dimension": "参数规格",
        "reason": "32,768上下文长度属于主流长上下文规格，用户常搜索'32K上下文'寻找长文本处理模型，且未被高频词列表排除"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在代码生成任务中表现优异，且'编程助手'是用户高频搜索意图，未在强制排除列表中"
      },
      {
        "keyword": "智能体工具调用",
        "dimension": "功能场景",
        "reason": "模型支持在思维/非思维模式下精准调用外部工具，这是区别于普通对话模型的特色功能，用户可能搜索该词"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "支持超100种语言与方言的指令理解与翻译，是明确的用户搜索场景，且未被高频词列表排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Meta-Llama-3.1-8B-Instruct",
    "keywords": [
      {
        "keyword": "Llama-3.1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，去掉版本后缀8B-Instruct"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规格，用户常搜"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "Instruct后缀表明模型经过指令微调，用户搜索高频"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "Llama系列在Ollama社区热度高，用户搜索部署方式"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "8B规格常被量化后本地运行，用户搜索关键词"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "Instruct模型官方推荐场景之一，开发者搜索量大"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Step-Audio",
    "keywords": [
      {
        "keyword": "Step-Audio",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "实时语音交互",
        "dimension": "功能场景",
        "reason": "README明确强调的产品级实时语音交互系统"
      },
      {
        "keyword": "语音克隆",
        "dimension": "功能场景",
        "reason": "当前模型支持全流程语音克隆功能"
      },
      {
        "keyword": "RAP哼唱",
        "dimension": "功能场景",
        "reason": "README突出支持的RAP与哼唱语音生成"
      },
      {
        "keyword": "情感方言控制",
        "dimension": "技术特性",
        "reason": "可精准调节情感与方言的语音生成技术"
      },
      {
        "keyword": "1300亿参数",
        "dimension": "参数规格",
        "reason": "开源的千亿级多模态模型Step-Audio-Chat参数规模"
      },
      {
        "keyword": "昇腾NPU优化",
        "dimension": "部署工具",
        "reason": "官方已适配昇腾NPU并优化推理代码"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/DeepSeek-R1-Distill-Qwen-1.5B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的核心模型名称，是用户搜索该模型的唯一标识"
      },
      {
        "keyword": "DeepSeek-R1-Distill-Qwen-1.5B",
        "dimension": "当前模型品牌名",
        "reason": "项目完整名称，虽带参数但为唯一标识符，用户可能直接搜索此完整名称以定位该特定蒸馏版本"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "模型通过纯强化学习自然涌现出的核心推理能力，是README中明确强调的原创技术亮点"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "模型在无SFT前提下通过RL实现的关键推理行为，具有高度独特性且非通用术语"
      },
      {
        "keyword": "推理模型",
        "dimension": "功能场景",
        "reason": "模型明确被定义为‘第一代推理模型’，是用户搜索AI推理能力时的精准意图词"
      },
      {
        "keyword": "1.5B参数",
        "dimension": "参数规格",
        "reason": "当前模型为1.5B规模，属于轻量级主流参数规格，用户常搜索此类小模型用于本地部署"
      },
      {
        "keyword": "蒸馏模型",
        "dimension": "技术特性",
        "reason": "模型是通过从DeepSeek-R1蒸馏而来，'蒸馏模型'是用户搜索轻量高效模型时的高频意图词"
      },
      {
        "keyword": "无监督微调",
        "dimension": "技术特性",
        "reason": "模型采用纯RL训练，无需SFT，这一技术路径在开源社区中极具辨识度和搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/swin2SR_classical_sr_x2_64",
    "keywords": [
      {
        "keyword": "Swin2SR",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像超分辨率",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "图像放大2倍",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能描述"
      },
      {
        "keyword": "SwinV2-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型使用的核心技术架构"
      },
      {
        "keyword": "压缩图像恢复",
        "dimension": "功能场景",
        "reason": "当前模型在压缩图像恢复方面的应用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Janus-Pro-1B",
    "keywords": [
      {
        "keyword": "Janus-Pro",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型品牌名，简洁且唯一，符合用户搜索AI模型时的命名习惯"
      },
      {
        "keyword": "统一多模态",
        "dimension": "技术特性",
        "reason": "模型核心创新点，强调‘统一理解与生成’，是区别于其他模型的独有技术标签，用户会搜索此类功能描述"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型明确支持图像生成（使用16倍降采样标记器），且为统一框架中的生成能力，符合用户搜索‘文生图’类模型的意图"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "README明确指出是‘自回归框架’，这是模型架构的核心属性，非通用词，具有技术区分度"
      },
      {
        "keyword": "SigLIP-L",
        "dimension": "技术特性",
        "reason": "模型使用的专属视觉编码器名称，是其多模态理解的关键组件，属于模型自身技术栈，非通用词"
      },
      {
        "keyword": "1B参数",
        "dimension": "参数规格",
        "reason": "模型名称含‘1B’，属于主流小参数规模，用户常搜索‘1B参数’模型用于轻量部署，且非高频排除词（排除的是7B/32B）"
      },
      {
        "keyword": "视觉编码解耦",
        "dimension": "技术特性",
        "reason": "模型核心创新机制，原文强调‘解耦视觉编码’以解决角色冲突，是独特技术术语，用户在研究多模态架构时可能搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/blip-image-captioning-large",
    "keywords": [
      {
        "keyword": "BLIP-image-captioning-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型完整名称，是用户搜索该特定模型时的精准关键词"
      },
      {
        "keyword": "图像标注",
        "dimension": "功能场景",
        "reason": "模型核心用途为生成图像描述文本，用户常搜索'图像标注'而非'图像描述'等泛词，且未被高频词列表排除"
      },
      {
        "keyword": "视觉语言预训练",
        "dimension": "技术特性",
        "reason": "论文核心提出的技术框架名称，具有唯一性，非通用术语，用户在研究VLP模型时会搜索该术语"
      },
      {
        "keyword": "引导标注",
        "dimension": "技术特性",
        "reason": "BLIP论文独创的噪声数据处理技术，是区别于其他模型的关键创新点，非通用词且未被高频词覆盖"
      },
      {
        "keyword": "图像-文本检索",
        "dimension": "功能场景",
        "reason": "模型在论文中明确优化的任务类型，是专业用户搜索视觉语言模型时的精准场景词"
      },
      {
        "keyword": "零样本视频语言",
        "dimension": "功能场景",
        "reason": "模型在视频语言任务上的零样本能力是论文强调的亮点，具有独特性，非泛用词，未被高频词列表包含"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/Aquila-7B",
    "keywords": [
      {
        "keyword": "Aquila-7B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型名称"
      },
      {
        "keyword": "悟道天鹰",
        "dimension": "当前模型品牌名",
        "reason": "官方中文品牌名，用户会搜"
      },
      {
        "keyword": "中英双语大模型",
        "dimension": "功能场景",
        "reason": "官方强调的核心卖点，用户搜索意图明确"
      },
      {
        "keyword": "商用许可开源",
        "dimension": "功能场景",
        "reason": "商用友好是用户关注重点"
      },
      {
        "keyword": "国内数据合规",
        "dimension": "功能场景",
        "reason": "国内用户搜索合规大模型时的关键词"
      },
      {
        "keyword": "BMTrain并行训练",
        "dimension": "技术特性",
        "reason": "官方提到的独特训练加速技术，用户会搜"
      },
      {
        "keyword": "中文语料40",
        "dimension": "技术特性",
        "reason": "中文比例高是用户搜索国产大模型时的关注点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/Ascend_AI4S/prot_bert",
    "keywords": [
      {
        "keyword": "ProtBert",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "蛋白质特征提取",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景之一"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性"
      },
      {
        "keyword": "自监督预训练",
        "dimension": "技术特性",
        "reason": "当前模型的训练方式"
      },
      {
        "keyword": "Bert架构",
        "dimension": "技术特性",
        "reason": "当前模型基于的架构"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/stable-diffusion-xl-base-1_0",
    "keywords": [
      {
        "keyword": "SD-XL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的模型品牌名，用户搜索AI图像生成模型时最常使用的简称"
      },
      {
        "keyword": "稳定扩散",
        "dimension": "功能场景",
        "reason": "中文用户对'Stable Diffusion'的通用译名，是文生图领域核心搜索词，且未被列入高频排除词库"
      },
      {
        "keyword": "两阶段生成",
        "dimension": "技术特性",
        "reason": "模型核心架构特征，指基础模型+细化模型的两步流程，具有技术独特性，非通用术语"
      },
      {
        "keyword": "SDEdit",
        "dimension": "技术特性",
        "reason": "模型支持的关键技术名称，用于高分辨率图像细化，是SDXL区别于其他版本的专属技术点"
      },
      {
        "keyword": "专家集成",
        "dimension": "技术特性",
        "reason": "模型原文明确使用的术语，指多个专家模型协同生成，是SDXL架构的核心设计概念"
      },
      {
        "keyword": "OpenCLIP-ViTG",
        "dimension": "技术特性",
        "reason": "模型使用的固定文本编码器名称，属于模型自身技术组件，非通用词，具有唯一识别性"
      },
      {
        "keyword": "CLIP-ViTL",
        "dimension": "技术特性",
        "reason": "模型使用的第二个固定文本编码器，与OpenCLIP-ViT/G并列，构成模型文本理解双引擎"
      },
      {
        "keyword": "Refiner模型",
        "dimension": "技术特性",
        "reason": "SDXL配套的专用细化模块名称，用户搜索高质量图像生成时会关联此术语，非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/AquilaChat-7b",
    "keywords": [
      {
        "keyword": "AquilaChat",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "Aquila-7B",
        "dimension": "当前模型品牌名",
        "reason": "模型系列的基础版本名称，属于当前模型自身的品牌标识"
      },
      {
        "keyword": "中英双语",
        "dimension": "功能场景",
        "reason": "模型具备中文和英文双语知识，满足中英双语对话与写作需求"
      },
      {
        "keyword": "商业许可",
        "dimension": "技术特性",
        "reason": "模型采用 Apache 2.0 代码协议并提供《智源Aquila系列模型许可协议》，支持商业化使用"
      },
      {
        "keyword": "国内数据合规",
        "dimension": "技术特性",
        "reason": "模型使用的中文语料全部来源于国内站点和权威机构，符合中国数据合规要求"
      },
      {
        "keyword": "BMTrain并行",
        "dimension": "技术特性",
        "reason": "采用升级版 BMTrain 并行训练方法，实现高效的分布式训练"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型提供标准化 API 接口，便于在业务系统中直接调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bloom_1b7",
    "keywords": [
      {
        "keyword": "智谱清言",
        "dimension": "当前模型品牌名",
        "reason": "项目中明确标注为'智谱清言-1b7'，根据国产大模型映射规则，'智谱清言'是模型品牌名，且未被高频词列表排除"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "根据国产大模型映射规则，GLM系列映射为'智谱AI'，本模型为智谱清言系列，属同一公司产品线，可作为品牌名延伸使用，且未被高频词列表禁止"
      },
      {
        "keyword": "bloom",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为'bloom_1b7'，'bloom'是模型核心标识，虽源自BigScience，但当前项目已将其作为自有模型名称使用，且未被排除，符合'当前模型自身名称'提取原则"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "模型使用AutoModelForCausalLM，属于典型的自回归语言模型，该术语是用户搜索模型类型时的明确关键词，且未在高频词列表中"
      },
      {
        "keyword": "多语种语言模型",
        "dimension": "功能场景",
        "reason": "README明确描述为'大规模科学开放访问多语种语言模型'，'多语种语言模型'是用户搜索跨语言AI能力时的精准意图词，非泛泛描述"
      },
      {
        "keyword": "OpenMind",
        "dimension": "部署工具",
        "reason": "代码中使用'from openmind import AutoModelForCausalLM'，表明该模型通过OpenMind框架加载，是当前模型特有的部署入口，具有区分度且未被高频词排除"
      },
      {
        "keyword": "NPU部署",
        "dimension": "部署工具",
        "reason": "模型加载路径为'PyTorch-NPU/bloom_1b7'，明确支持NPU（昇腾等国产AI芯片），'NPU部署'是国产AI生态用户高频搜索的精准场景词，且未被高频词列表覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/albert_xxlarge_v2",
    "keywords": [
      {
        "keyword": "ALBERT-XXLarge-v2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型的完整官方名称，是用户搜索该特定版本时的精准关键词"
      },
      {
        "keyword": "遮蔽语言建模",
        "dimension": "技术特性",
        "reason": "模型核心预训练目标之一，用户在研究BERT类模型原理时会搜索该术语，且非高频词库中的通用词"
      },
      {
        "keyword": "句子排序预测",
        "dimension": "技术特性",
        "reason": "ALBERT独有且区别于BERT的预训练任务，技术独特性强，用户搜索模型差异点时会使用"
      },
      {
        "keyword": "层权重共享",
        "dimension": "技术特性",
        "reason": "ALBERT架构的核心创新点，用于降低参数量，是区别于其他Transformer模型的关键技术描述"
      },
      {
        "keyword": "英语预训练模型",
        "dimension": "功能场景",
        "reason": "明确描述模型语言范围与用途，用户搜索‘英文NLP模型’‘英语BERT替代’等意图时会匹配"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "模型由Hugging Face托管并提供，用户在寻找可直接加载的预训练模型时会搜索该平台名称"
      },
      {
        "keyword": "ALBERT-v2",
        "dimension": "当前模型品牌名",
        "reason": "用户常搜索模型版本号（如v1 vs v2），'ALBERT v2'是简洁且高频搜索的变体名称，非完整版但符合简化规则"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/byt5_large",
    "keywords": [
      {
        "keyword": "ByT5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为byt5_large，模型品牌名为ByT5，符合简化命名规则且为当前模型唯一标识"
      },
      {
        "keyword": "字节到字节",
        "dimension": "技术特性",
        "reason": "论文标题明确强调'byte-to-byte'，是ByT5区别于其他Token化模型的核心技术特征，用户可能搜索‘字节到字节模型’"
      },
      {
        "keyword": "无token模型",
        "dimension": "技术特性",
        "reason": "论文标题提及'token-free future'，该模型颠覆传统分词方式，是其最独特、可搜索的技术卖点"
      },
      {
        "keyword": "字节级模型",
        "dimension": "技术特性",
        "reason": "ByT5直接处理字节序列，不依赖词表分词，‘字节级模型’是用户搜索非传统NLP模型时的精准关键词"
      },
      {
        "keyword": "T5架构",
        "dimension": "技术特性",
        "reason": "模型基于T5架构，虽非原创，但作为当前模型的底层结构，用户会搜索‘T5架构模型’来寻找同类变体"
      },
      {
        "keyword": "ByteT5",
        "dimension": "当前模型品牌名",
        "reason": "论文和社区中常将ByT5写作ByteT5，属于同一模型的常见别名，需作为品牌名补充以覆盖搜索变体"
      },
      {
        "keyword": "编码器-解码器",
        "dimension": "技术特性",
        "reason": "ByT5继承T5的编码器-解码器结构，是其任务适配能力（如翻译、摘要）的关键架构，用户搜索此类结构时会命中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/baichuan_7b",
    "keywords": [
      {
        "keyword": "Baichuan-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "中英双语",
        "dimension": "功能场景",
        "reason": "当前模型支持的语言特性，是用户搜索时可能关注的点"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "当前模型基于Transformer结构，属于自回归模型，是技术上的一个关键特性"
      },
      {
        "keyword": "宽松开源协议",
        "dimension": "部署工具",
        "reason": "当前模型使用更宽松的开源协议，允许商业使用，这是部署时的一个重要考虑因素"
      },
      {
        "keyword": "SOTA水平",
        "dimension": "技术特性",
        "reason": "当前模型在同尺寸模型中达到了SOTA的水平，体现了其技术优势"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/deepseek-coder-33b-instruct",
    "keywords": [
      {
        "keyword": "DeepSeek-Coder",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的模型品牌，用户搜代码模型必用"
      },
      {
        "keyword": "33B参数",
        "dimension": "参数规格",
        "reason": "大参数代码模型稀缺，33B是用户搜索高亮词"
      },
      {
        "keyword": "代码补全",
        "dimension": "功能场景",
        "reason": "README强调项目级代码补全与填充，开发者高频搜索"
      },
      {
        "keyword": "16K窗口",
        "dimension": "技术特性",
        "reason": "长上下文代码生成卖点，用户会直接用16K窗口作为检索词"
      },
      {
        "keyword": "填空任务",
        "dimension": "技术特性",
        "reason": "独特的预训练任务，用户想了解支持填充的模型时会搜"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "社区常用Ollama跑大模型，搜索量高且未被列入禁用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/deberta_v3_base",
    "keywords": [
      {
        "keyword": "DeBERTa-v3-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型标准名称，用户搜索具体模型版本时会使用该完整标识"
      },
      {
        "keyword": "梯度解耦嵌入共享",
        "dimension": "技术特性",
        "reason": "DeBERTa V3独有的核心技术，区别于BERT/RoBERTa/ELECTRA，是论文核心创新点，用户研究模型架构时会搜索该术语"
      },
      {
        "keyword": "ELECTRA风格预训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特预训练范式，虽借鉴ELECTRA但为DeBERTa V3专属实现，是区别于其他模型的关键技术标签"
      },
      {
        "keyword": "128K词表",
        "dimension": "参数规格",
        "reason": "128K是当前模型显著区别于主流模型（如RoBERTa的50K）的词表规模，属于用户对比模型容量时会关注的高区分度规格"
      },
      {
        "keyword": "SQuAD-2.0",
        "dimension": "功能场景",
        "reason": "模型在SQuAD 2.0上表现优异，该任务是中文/英文问答领域的标准基准，用户搜索‘SQuAD 2.0模型’时会定位到该模型"
      },
      {
        "keyword": "MNLI",
        "dimension": "功能场景",
        "reason": "MNLI是自然语言推理的核心任务，DeBERTa-v3-base在此任务上达到SOTA，用户搜索‘MNLI高性能模型’会指向该模型"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "模型明确新增NPU支持，是国产AI芯片部署的关键适配点，用户搜索‘NPU部署模型’时具有高相关性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/convnextv2_tiny_1k_224",
    "keywords": [
      {
        "keyword": "ConvNeXt-V2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型名称"
      },
      {
        "keyword": "FCMAE",
        "dimension": "技术特性",
        "reason": "ConvNeXt V2 引入的全卷积遮蔽自编码器框架，是其核心技术亮点"
      },
      {
        "keyword": "GRN层",
        "dimension": "技术特性",
        "reason": "全局响应归一化层，ConvNeXt V2 新增的关键组件"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "README 明确说明该模型用于 ImageNet-1K 图像分类任务"
      },
      {
        "keyword": "224分辨率",
        "dimension": "参数规格",
        "reason": "模型在 224×224 分辨率下微调，是用户搜索时常见的分辨率关键词"
      },
      {
        "keyword": "纯卷积网络",
        "dimension": "技术特性",
        "reason": "强调模型为纯 ConvNet 架构，区别于 Transformer 类模型"
      },
      {
        "keyword": "ImageNet-1K",
        "dimension": "功能场景",
        "reason": "模型训练与微调的数据集，用户常以此搜索对应模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mt5_base",
    "keywords": [
      {
        "keyword": "mt5base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为mt5_base，是当前模型的官方简洁名称，符合用户搜索AI模型时的直接命名习惯"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "模型基于mC4预训练，覆盖101种语言，核心用途是跨语言翻译，用户常搜索'多语言翻译模型'等意图词"
      },
      {
        "keyword": "mC4预训练",
        "dimension": "技术特性",
        "reason": "模型在mC4语料库上预训练，是其区别于其他T5变体的核心技术标签，用户会搜索'基于mC4的模型'"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "mT5基于Transformer架构，虽为通用结构，但用户在搜索具体模型时仍会关联该技术词，且未被强制排除（排除列表中为'Transformer'本身，非禁止词）"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "mT5系列模型普遍通过HuggingFace发布，用户常通过'HuggingFace mT5'搜索模型，属于主流部署平台关键词"
      },
      {
        "keyword": "英文-中文翻译",
        "dimension": "功能场景",
        "reason": "README明确列出English和Chinese为支持语言，用户常搜索具体语言对的翻译模型，此为高意图场景词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/xglm_1.7b",
    "keywords": [
      {
        "keyword": "XGLM-1.7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简洁命名规范"
      },
      {
        "keyword": "多语言模型",
        "dimension": "功能场景",
        "reason": "模型核心能力是支持50种语言的跨语言理解与生成，用户会搜索‘多语言模型’来寻找类似工具"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "README明确说明是‘autoregressive language model’，属于模型底层技术架构，非高频词且具区分度"
      },
      {
        "keyword": "500亿子词",
        "dimension": "技术特性",
        "reason": "训练数据规模是模型关键亮点，‘500亿子词’是用户搜索大语料模型时可能使用的精准术语，非通用描述"
      },
      {
        "keyword": "少样本学习",
        "dimension": "功能场景",
        "reason": "论文标题明确提及‘Few-shot Learning’，是该模型设计的核心目标，用户会搜索‘少样本学习模型’寻找相关实现"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "README中明确提到‘add npu support’，是当前模型区别于原版的唯一修改点，具有独特部署价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/falcon_7b",
    "keywords": [
      {
        "keyword": "Falcon-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "因果解码器模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性"
      },
      {
        "keyword": "RefinedWeb-1.5万亿标记",
        "dimension": "技术特性",
        "reason": "当前模型训练所使用的数据集规模"
      },
      {
        "keyword": "FlashAttention",
        "dimension": "技术特性",
        "reason": "当前模型架构中采用的关键技术"
      },
      {
        "keyword": "multiquery",
        "dimension": "技术特性",
        "reason": "当前模型架构中采用的关键技术"
      },
      {
        "keyword": "Apache-2.0许可协议",
        "dimension": "技术特性",
        "reason": "当前模型遵循的开放许可协议"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/xlm_roberta_base",
    "keywords": [
      {
        "keyword": "XLM-RoBERTa",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型官方名称，是用户搜索多语言预训练模型的核心关键词"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "模型预训练的核心机制（MLM），用户搜索多语言模型原理时会使用该术语，且未被高频词库排除"
      },
      {
        "keyword": "跨语言表示学习",
        "dimension": "技术特性",
        "reason": "论文核心贡献术语，直接来自README原文，是该模型区别于其他模型的独有技术标签"
      },
      {
        "keyword": "100种语言",
        "dimension": "功能场景",
        "reason": "明确描述模型支持的语言广度，用户搜索多语言NLP任务时会使用该量化描述词"
      },
      {
        "keyword": "无监督预训练",
        "dimension": "技术特性",
        "reason": "模型训练方式的核心特征，区别于有监督模型，是技术型用户搜索的关键语义词"
      },
      {
        "keyword": "CommonCrawl数据",
        "dimension": "技术特性",
        "reason": "模型训练数据来源的独特标识，专业用户在比较多语言模型数据集时会搜索该词"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "README中明确新增的部署特性，指向国产硬件适配，具有差异化和搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bluelm_7b_chat",
    "keywords": [
      {
        "keyword": "BlueLM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "32K上下文",
        "dimension": "技术特性",
        "reason": "模型支持32K级别的长文本上下文，区别于普通2K上下文模型"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "模型在中文、英文、日语、韩语等多语言语料上训练，可用于多语言对话和生成"
      },
      {
        "keyword": "CEval领先",
        "dimension": "技术特性",
        "reason": "在C‑Eval基准测试中取得领先成绩，体现模型的中文理解与推理能力"
      },
      {
        "keyword": "CMMLU领先",
        "dimension": "技术特性",
        "reason": "在CMMLU评测中表现优异，展示模型在多学科知识问答上的优势"
      },
      {
        "keyword": "NPU加速",
        "dimension": "部署工具",
        "reason": "README中提到模型已优化支持NPU硬件，可在对应平台上实现高效推理"
      },
      {
        "keyword": "开源商业授权",
        "dimension": "部署工具",
        "reason": "模型采用开放授权协议，支持学术研究与商业应用，区别于仅限科研的模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mt5_large",
    "keywords": [
      {
        "keyword": "mt5large",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为mt5_large，是当前模型的直接标识，用户搜索时会使用该完整名称"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "mT5基于mC4预训练，支持101种语言，核心用途是跨语言文本生成与翻译，用户会搜索‘多语言翻译’这类明确场景词"
      },
      {
        "keyword": "文本到文本",
        "dimension": "技术特性",
        "reason": "论文标题明确使用‘文本到文本转换器’（Text-to-Text Transformer），这是mT5的核心架构范式，区别于其他模型的输出形式"
      },
      {
        "keyword": "mC4预训练",
        "dimension": "技术特性",
        "reason": "mT5唯一使用的预训练数据集是mC4，这是其区别于其他多语言模型（如mBART、XLM-R）的关键技术标签，用户会搜索该数据集名称"
      },
      {
        "keyword": "无监督多语言",
        "dimension": "技术特性",
        "reason": "README强调‘只在mC4上预训练，无任何监督训练’，这是其核心训练范式，用户搜索‘无监督多语言模型’时会匹配该特征"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "标签中明确包含'TensorFlow'，且是官方支持的框架之一，用户在寻找可部署框架时会搜索该词（非高频词，未被排除）"
      },
      {
        "keyword": "JAX",
        "dimension": "部署工具",
        "reason": "标签中包含'JAX'，是Google官方推荐的训练框架，属于mT5的专属部署生态，用户搜索JAX相关模型时会用到"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/rembert",
    "keywords": [
      {
        "keyword": "RemBERT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该模型的唯一品牌标识"
      },
      {
        "keyword": "非绑定嵌入",
        "dimension": "技术特性",
        "reason": "RemBERT核心创新点：输入与输出嵌入未绑定，区别于mBERT，是其关键技术特征"
      },
      {
        "keyword": "多语言分类",
        "dimension": "功能场景",
        "reason": "模型明确设计用于110种语言的分类任务，是其主要下游应用场景"
      },
      {
        "keyword": "轻量级预训练",
        "dimension": "技术特性",
        "reason": "因省略输出嵌入权重，模型更轻量，是其部署优势，用户会搜索轻量多语言模型"
      },
      {
        "keyword": "MLM预训练",
        "dimension": "技术特性",
        "reason": "模型基于遮蔽语言模型（MLM）目标预训练，是其训练方式的核心标签"
      },
      {
        "keyword": "跨语言NER",
        "dimension": "功能场景",
        "reason": "论文中明确提及应用于命名实体识别（NER），是除分类外的重要下游任务"
      },
      {
        "keyword": "多语言词性标注",
        "dimension": "功能场景",
        "reason": "论文验证的典型任务，用户搜索多语言NLP任务时可能精准匹配"
      },
      {
        "keyword": "Wikipedia多语言预训练",
        "dimension": "训练数据",
        "reason": "模型在110种语言维基百科上预训练，是其数据来源的唯一性特征"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/open_llama_7b",
    "keywords": [
      {
        "keyword": "OpenLLaMA",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为OpenLLaMA，是用户搜索该开源复现模型的核心关键词"
      },
      {
        "keyword": "开源复现",
        "dimension": "技术特性",
        "reason": "README强调其为Meta LLaMA的开源复现，用户会搜“开源复现 LLaMA”"
      },
      {
        "keyword": "Apache-2.0许可",
        "dimension": "技术特性",
        "reason": "宽松许可吸引商用与二次开发，用户常搜“Apache 2.0 大模型”"
      },
      {
        "keyword": "EasyLM框架",
        "dimension": "部署工具",
        "reason": "官方提供EasyLM格式权重与框架，用户会搜“EasyLM 部署”"
      },
      {
        "keyword": "HuggingFace权重",
        "dimension": "部署工具",
        "reason": "支持HuggingFace transformers直接加载，用户常搜“HuggingFace OpenLLaMA”"
      },
      {
        "keyword": "1T标记训练",
        "dimension": "技术特性",
        "reason": "7B模型基于1T token训练，用户会搜“1T token 大模型”"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/albert_base_v2",
    "keywords": [
      {
        "keyword": "ALBERT-base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为albert_base_v2，按规则简化为ALBERT-base，是用户搜索预训练模型时的常用简洁形式"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "模型核心预训练目标之一，用户搜索英文预训练模型技术时会使用该中文术语"
      },
      {
        "keyword": "句子排序预测",
        "dimension": "技术特性",
        "reason": "ALBERT独有的SOP预训练任务，区别于BERT，是其关键技术特征，具有区分度"
      },
      {
        "keyword": "层权重共享",
        "dimension": "技术特性",
        "reason": "ALBERT的核心创新设计，降低参数量但保持性能，是区别于其他Transformer模型的关键点"
      },
      {
        "keyword": "英文预训练模型",
        "dimension": "功能场景",
        "reason": "模型明确用于英文语言理解，用户搜索英文NLP任务时会使用该组合词"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "模型由Hugging Face团队维护并提供卡片，用户常通过HuggingFace平台搜索和加载此类模型"
      },
      {
        "keyword": "无监督预训练",
        "dimension": "技术特性",
        "reason": "模型基于自监督MLM和SOP训练，无人工标注，是其训练范式的核心描述词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mobilebert_uncased",
    "keywords": [
      {
        "keyword": "MobileBERT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌名"
      },
      {
        "keyword": "手机端BERT",
        "dimension": "功能场景",
        "reason": "专为移动设备优化的轻量BERT，用户会搜手机端部署"
      },
      {
        "keyword": "掩码填空",
        "dimension": "功能场景",
        "reason": "README示例展示的核心任务，用户搜索fill-mask时会用"
      },
      {
        "keyword": "NPU加速",
        "dimension": "部署工具",
        "reason": "README强调对NPU设备的原生支持，吸引移动端开发者"
      },
      {
        "keyword": "512序列长度",
        "dimension": "参数规格",
        "reason": "模型配置中明确给出的输入长度，用户对比轻量模型时关注"
      },
      {
        "keyword": "24层瓶颈结构",
        "dimension": "技术特性",
        "reason": "MobileBERT独有的瓶颈平衡设计，技术博客常提及"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mt5_small",
    "keywords": [
      {
        "keyword": "mT5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型名称，用户搜索时会直接使用“mT5”。"
      },
      {
        "keyword": "mC4",
        "dimension": "技术特性",
        "reason": "模型在 mC4 语料库上进行大规模预训练，是其核心数据来源。"
      },
      {
        "keyword": "101语言",
        "dimension": "技术特性",
        "reason": "模型覆盖 101 种语言，体现其强大的多语言能力，用户常以此关键词检索。"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "mT5 采用 Text‑to‑Text 方式，广泛用于跨语言翻译任务。"
      },
      {
        "keyword": "文本到文本模型",
        "dimension": "技术特性",
        "reason": "模型采用 T5 的 Text‑to‑Text 框架，适用于生成、翻译、摘要等多种任务。"
      },
      {
        "keyword": "无监督预训练",
        "dimension": "技术特性",
        "reason": "模型仅在无标签的 mC4 数据上进行预训练，需在下游任务中微调。"
      },
      {
        "keyword": "跨语言迁移学习",
        "dimension": "技术特性",
        "reason": "模型在多语言语料上训练，可实现语言之间的迁移学习，满足跨语言任务需求。"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/t5_small",
    "keywords": [
      {
        "keyword": "T5-Small",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为t5_small，按规则简化为通用品牌名'T5 Small'，是用户搜索轻量级文本模型时的常用关键词"
      },
      {
        "keyword": "文本到文本",
        "dimension": "功能场景",
        "reason": "模型核心理念是将所有NLP任务统一为文本到文本格式，这是T5系列区别于BERT等模型的独特功能描述，用户会搜索此类任务类型"
      },
      {
        "keyword": "Text-To-Text",
        "dimension": "技术特性",
        "reason": "模型官方提出的统一框架名称，是技术文档中高频术语，搜索该英文术语的用户精准指向T5类模型"
      },
      {
        "keyword": "C4数据集",
        "dimension": "训练细节",
        "reason": "模型在C4数据集上训练，该数据集是T5系列专用预训练语料，专业用户会以此作为模型来源关键词"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型支持ONNX格式导出，是企业级部署的关键格式，用户搜索'ONNX 模型'时可能精准匹配该模型"
      },
      {
        "keyword": "SafeTensors",
        "dimension": "部署工具",
        "reason": "模型支持SafeTensors格式，该格式因安全性和兼容性在社区中被专门搜索，是区别于普通PyTorch模型的部署标签"
      },
      {
        "keyword": "JAX",
        "dimension": "部署工具",
        "reason": "模型提供JAX版本支持，JAX是科研和Google生态中用于Transformer模型的专用框架，搜索该词的用户有明确工具需求"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "部署工具",
        "reason": "开源协议是开发者选型关键因素，'Apache License 2.0 模型'是开发者在寻找可商用模型时的高频搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/openai_gpt",
    "keywords": [
      {
        "keyword": "openai-gpt",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "GPT-1",
        "dimension": "当前模型品牌名",
        "reason": "模型的别名，与openai-gpt指向同一模型"
      },
      {
        "keyword": "因果变压器",
        "dimension": "技术特性",
        "reason": "模型是基于因果（单向）变压器的语言模型，这是其技术特性"
      },
      {
        "keyword": "长距离依赖性",
        "dimension": "技术特性",
        "reason": "模型在具有长距离依赖性的大型语料库上进行预训练，这是其技术特点"
      },
      {
        "keyword": "MIT许可",
        "dimension": "技术特性",
        "reason": "模型使用的许可类型，是用户可能关心的技术特性之一"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "模型可用于文本生成的管道中，这是其主要功能场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/edgenext_ms",
    "keywords": [
      {
        "keyword": "EdgeNeXt",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'edgenext_ms' 提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词"
      },
      {
        "keyword": "SDTA编码器",
        "dimension": "技术特性",
        "reason": "模型独有的分裂深度卷积转置注意力（Split Depthwise Transformer Attention）架构，是其核心创新点，用户会搜索该技术术语来查找同类高效架构"
      },
      {
        "keyword": "CNN-Transformer融合",
        "dimension": "技术特性",
        "reason": "模型的核心设计理念，明确描述其混合架构特性，是移动视觉领域用户搜索高效轻量模型时的高频技术组合词"
      },
      {
        "keyword": "移动视觉",
        "dimension": "功能场景",
        "reason": "模型明确面向移动视觉应用，是其主要部署场景，用户搜索‘移动视觉模型’‘边缘视觉模型’时会精准匹配"
      },
      {
        "keyword": "轻量级图像分类",
        "dimension": "功能场景",
        "reason": "模型在ImageNet-1K上验证，参数量低至1.33M，专为轻量图像分类设计，区别于通用大模型，是用户寻找移动端分类模型时的精准搜索词"
      },
      {
        "keyword": "MindSpore模型",
        "dimension": "部署工具",
        "reason": "模型基于MindSpore框架训练与部署，是国产AI生态中用户寻找适配昇腾NPU的模型时的关键搜索词"
      },
      {
        "keyword": "2.34M参数模型",
        "dimension": "参数规格",
        "reason": "edgenext_x_small参数量为2.34M，属于移动端主流轻量级规模（介于1M-5M），用户会搜索‘2M参数模型’‘轻量分类模型’等关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/qwen1.5_7b_chat",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名qwen1.5_7b_chat对应通义千问系列"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "通义千问属于阿里巴巴开源的大模型"
      },
      {
        "keyword": "32K上下文",
        "dimension": "技术特性",
        "reason": "README明确提到稳定支持32K长上下文"
      },
      {
        "keyword": "NPU推理",
        "dimension": "部署工具",
        "reason": "README新增NPU支持，适合昇腾芯片部署"
      },
      {
        "keyword": "openMind适配",
        "dimension": "部署工具",
        "reason": "README强调已适配openMind框架"
      },
      {
        "keyword": "无需trustremotecode",
        "dimension": "技术特性",
        "reason": "README突出安全优势，用户可直接加载"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/crossvit_ms",
    "keywords": [
      {
        "keyword": "CrossViT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型品牌名，用户搜索时会直接使用"
      },
      {
        "keyword": "双分支架构",
        "dimension": "技术特性",
        "reason": "模型采用独特的双分支设计用于处理不同尺度的图像块"
      },
      {
        "keyword": "交叉注意力模块",
        "dimension": "技术特性",
        "reason": "核心的交叉注意力机制实现了高效的特征融合，是模型的关键技术"
      },
      {
        "keyword": "多尺度特征",
        "dimension": "技术特性",
        "reason": "模型能够提取并融合不同尺度的视觉特征，提升分类表现"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "模型的主要应用场景是图像分类任务，用户常以此关键词检索"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于 MindSpore 框架实现，用户会搜索对应的部署/运行环境"
      },
      {
        "keyword": "ImageNet-1K评测",
        "dimension": "功能场景",
        "reason": "模型在 ImageNet-1K 上取得的成绩是用户关注的性能指标"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/internlm_20b_chat_ms",
    "keywords": [
      {
        "keyword": "InternLM-20B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 openMind/internlm_20b_chat_ms 提取的核心模型名称，符合简化规则（去后缀_chat_ms，保留主品牌）"
      },
      {
        "keyword": "20B参数",
        "dimension": "参数规格",
        "reason": "模型明确为200亿参数，属于主流参数规模（10B-30B区间），用户常搜索此类规格对比模型能力"
      },
      {
        "keyword": "16k上下文",
        "dimension": "技术特性",
        "reason": "模型支持16k上下文长度（通过推理外推实现），是区别于7B/13B模型的关键能力，用户会搜索‘长上下文模型’"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在代码数据上预训练，且性能评估中编程能力显著优于Llama-13B，明确具备编程辅助场景"
      },
      {
        "keyword": "推理能力",
        "dimension": "技术特性",
        "reason": "模型在推理维度得分54.9，远超13B级模型，是其核心宣传亮点，用户会搜索‘强推理AI模型’"
      },
      {
        "keyword": "价值对齐",
        "dimension": "技术特性",
        "reason": "模型经过RLHF训练，强调‘更优的价值对齐’，是安全对话场景的关键卖点，区别于普通模型"
      },
      {
        "keyword": "60层架构",
        "dimension": "技术特性",
        "reason": "模型采用60层深度设计，远超常规32-40层，是其结构创新点，用户可能搜索‘深层语言模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/halonet_ms",
    "keywords": [
      {
        "keyword": "HaloNet",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Blocked-Self-Attention",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性之一"
      },
      {
        "keyword": "Haloing操作",
        "dimension": "技术特性",
        "reason": "当前模型中用于信息扩展的独特技术操作"
      },
      {
        "keyword": "视觉主干网络",
        "dimension": "功能场景",
        "reason": "当前模型的应用领域，即作为视觉处理的主干网络"
      },
      {
        "keyword": "参数高效",
        "dimension": "技术特性",
        "reason": "当前模型在参数使用上的高效性，是其特点之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolov5_ms",
    "keywords": [
      {
        "keyword": "YOLOv5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接使用的模型名称"
      },
      {
        "keyword": "对象检测",
        "dimension": "功能场景",
        "reason": "模型的核心应用是进行目标（对象）检测"
      },
      {
        "keyword": "COCO预训练",
        "dimension": "技术特性",
        "reason": "模型在 COCO 数据集上完成了预训练，属于重要技术特性"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于 MindSpore 框架进行训练和推理"
      },
      {
        "keyword": "P5系列模型",
        "dimension": "技术特性",
        "reason": "项目实现了 YOLOv5 的 P5 系列架构（N、S、M、L、X）"
      },
      {
        "keyword": "86.7M参数",
        "dimension": "参数规格",
        "reason": "YOLOv5‑X 版本的参数量约为 86.7M，用户常以参数规模搜索模型"
      },
      {
        "keyword": "MindYOLO",
        "dimension": "部署工具",
        "reason": "README 中提到可参考 MindYOLO 项目进行模型的训练与推理"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/cmt_ms",
    "keywords": [
      {
        "keyword": "CMT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为cmt_ms，模型核心名称为CMT，是当前模型的官方简称，用户搜索时会直接使用该缩写"
      },
      {
        "keyword": "卷积神经网络遇见视觉变换器",
        "dimension": "技术特性",
        "reason": "模型核心创新点的直白描述，是用户在中文技术社区中可能搜索的关键词，体现CNN与ViT融合的独特架构"
      },
      {
        "keyword": "轻量级MHSA",
        "dimension": "技术特性",
        "reason": "模型为降低计算成本采用的专属技术组件，具有区分度，非通用术语，符合用户搜索‘轻量级自注意力’等技术方案的意图"
      },
      {
        "keyword": "深度卷积与逐点卷积",
        "dimension": "技术特性",
        "reason": "模型借鉴MobileNet的结构设计，是其高效性的关键技术词，非通用词汇，具有技术独特性"
      },
      {
        "keyword": "ImageNet-1K",
        "dimension": "功能场景",
        "reason": "模型在ImageNet-1K上达成SOTA，用户搜索‘ImageNet-1K模型’或‘ImageNet分类模型’时会精准匹配，属于任务场景关键词"
      },
      {
        "keyword": "MindSpore训练",
        "dimension": "部署工具",
        "reason": "模型明确使用MindSpore框架训练，是国产AI框架下的典型部署方式，用户会搜索‘MindSpore模型’或‘MindSpore图像分类’"
      },
      {
        "keyword": "83.24-Top-1",
        "dimension": "参数规格",
        "reason": "83.24%是模型在ImageNet-1K上报告的Top-1准确率，属于主流性能锚点，用户会搜索‘ImageNet Top-1 83%模型’等性能导向关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/ghostnet_ms",
    "keywords": [
      {
        "keyword": "GhostNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ghostnet_ms，核心模型名称为GhostNet，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "Ghost模块",
        "dimension": "技术特性",
        "reason": "论文核心创新点，指代低成本生成特征图的独有结构，非通用术语"
      },
      {
        "keyword": "Ghost瓶颈",
        "dimension": "技术特性",
        "reason": "基于Ghost模块构建的专用网络堆叠结构，是GhostNet架构的关键组件"
      },
      {
        "keyword": "轻量级CNN",
        "dimension": "功能场景",
        "reason": "模型明确用于构建轻量级卷积神经网络，是用户搜索边缘设备部署时的精准意图词"
      },
      {
        "keyword": "ImageNet分类",
        "dimension": "功能场景",
        "reason": "模型在ImageNet-1K上验证，用户搜索‘轻量模型 ImageNet分类’时是明确搜索意图"
      },
      {
        "keyword": "MindSpore模型",
        "dimension": "部署工具",
        "reason": "训练环境明确使用MindSpore，且提供yaml配置和权重文件，是该模型的专属部署生态"
      },
      {
        "keyword": "5.2M参数",
        "dimension": "参数规格",
        "reason": "ghostnet_100参数量为5.20M，属于主流轻量级模型规模，用户会搜索‘5M参数模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/latte_ms",
    "keywords": [
      {
        "keyword": "Latte",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为latte_ms，品牌名简化为Latte"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "Latte专为视频生成设计，用户会搜文生视频"
      },
      {
        "keyword": "Latent-Diffusion-Transformer",
        "dimension": "技术特性",
        "reason": "模型核心架构，用户可能直接搜全称"
      },
      {
        "keyword": "DiT",
        "dimension": "技术特性",
        "reason": "Latte基于DiT改进，技术爱好者会搜DiT"
      },
      {
        "keyword": "VAE压缩",
        "dimension": "技术特性",
        "reason": "Latte先用VAE压缩视频数据，技术关键词"
      },
      {
        "keyword": "空间-时间token",
        "dimension": "技术特性",
        "reason": "Latte提取时空token建模，技术亮点"
      },
      {
        "keyword": "ComfyUI插件",
        "dimension": "部署工具",
        "reason": "用户常用ComfyUI部署视频生成模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/convit_ms",
    "keywords": [
      {
        "keyword": "ConViT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为 ConViT，直接代表该模型的品牌"
      },
      {
        "keyword": "GPSA",
        "dimension": "技术特性",
        "reason": "Gated Positional Self‑Attention 是 ConViT 的核心注意力机制，用户常以 GPSA 搜索相关实现"
      },
      {
        "keyword": "软卷积归纳偏置",
        "dimension": "技术特性",
        "reason": "ConViT 引入的 Soft Convolutional Inductive Bias，区别于传统 ViT 的关键技术点"
      },
      {
        "keyword": "局部注意力门控",
        "dimension": "技术特性",
        "reason": "通过门控参数实现局部性与全局性的平衡，是模型独有的创新点"
      },
      {
        "keyword": "位置自注意力",
        "dimension": "技术特性",
        "reason": "ConViT 中的定位自注意力机制，用户在搜索定位注意力相关模型时会使用该词"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "ConViT 主要用于图像分类任务，且在 ImageNet 上取得领先成绩"
      },
      {
        "keyword": "ImageNet基准超越",
        "dimension": "结果表现",
        "reason": "模型在 ImageNet 基准上超过 DeiT，用户常以此关键词查找高性能视觉模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mixnet_ms",
    "keywords": [
      {
        "keyword": "MixNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为mixnet_ms，模型核心名称为MixNet，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "MixConv",
        "dimension": "技术特性",
        "reason": "论文提出的核心创新模块，混合深度卷积，是该模型区别于其他轻量级网络的独特技术"
      },
      {
        "keyword": "混合深度卷积",
        "dimension": "技术特性",
        "reason": "MixConv的中文技术术语，用户搜索轻量级CNN优化方案时可能使用此描述"
      },
      {
        "keyword": "MobileNet优化",
        "dimension": "功能场景",
        "reason": "论文明确指出该模型用于改进MobileNet，在图像分类与目标检测场景中作为直接替换模块"
      },
      {
        "keyword": "高效ConvNet",
        "dimension": "功能场景",
        "reason": "论文核心目标是构建高效卷积网络，该词精准描述模型定位，且未在高频排除词列表中"
      },
      {
        "keyword": "ImageNet分类",
        "dimension": "功能场景",
        "reason": "模型在ImageNet上验证性能，是用户搜索轻量级图像分类模型时的典型搜索场景"
      },
      {
        "keyword": "COCO目标检测",
        "dimension": "功能场景",
        "reason": "模型在COCO数据集上验证检测性能，是计算机视觉领域高频搜索场景，且具模型特异性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/codellama_34b_ms",
    "keywords": [
      {
        "keyword": "codellama34bms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "34B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，具有独特性"
      },
      {
        "keyword": "代码合成",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能之一，用于代码合成"
      },
      {
        "keyword": "代码理解",
        "dimension": "功能场景",
        "reason": "当前模型具备代码理解的能力"
      },
      {
        "keyword": "代码补全",
        "dimension": "功能场景",
        "reason": "当前模型支持代码补全功能"
      },
      {
        "keyword": "Python专家",
        "dimension": "功能场景",
        "reason": "当前模型在Python编程方面具有专长"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/stable-diffusion-v2_ms",
    "keywords": [
      {
        "keyword": "Stable-Diffusion-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'stable-diffusion-v2_ms' 提取的核心模型品牌名，用户搜索文生图模型时会直接使用此名称"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "当前模型基于MindSpore框架开发，是区别于PyTorch/TensorFlow模型的关键部署标识，用户会搜索'MindSpore 文生图'等组合词"
      },
      {
        "keyword": "OpenCLIP-ViTG",
        "dimension": "技术特性",
        "reason": "当前模型使用的固定文本编码器，是SD2.0区别于SD1.5和SD-XL的技术特征，专业用户会以此为关键词筛选模型"
      },
      {
        "keyword": "Latent-Diffusion-Model",
        "dimension": "技术特性",
        "reason": "模型类型明确标注为Latent Diffusion Model，是SD2.0的核心技术标签，区别于其他扩散模型的搜索关键词"
      },
      {
        "keyword": "CreativeML-Open-RAIL-M",
        "dimension": "技术特性",
        "reason": "当前模型的专属许可证名称，开发者在寻找可商用/开源合规的文生图模型时会搜索此完整许可证名"
      },
      {
        "keyword": "sdv2base",
        "dimension": "当前模型品牌名",
        "reason": "模型Checkpoint的官方命名前缀，用户在GitCode或模型库中下载时会直接使用此标识符进行搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/pit_ms",
    "keywords": [
      {
        "keyword": "PiT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为 PiT，直接提取为模型品牌名"
      },
      {
        "keyword": "池化视觉模型",
        "dimension": "技术特性",
        "reason": "模型在 ViT 基础上加入池化层，实现空间维度递减的核心技术特性"
      },
      {
        "keyword": "空间维度递减",
        "dimension": "技术特性",
        "reason": "相较于传统 ViT，PiT 在每层通过池化降低空间分辨率，属于独特的结构优势"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "PiT 主要用于 ImageNet‑1K 等图像分类任务，是模型的主要应用场景"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型代码基于 MindSpore 框架，适用于该平台的部署与推理"
      },
      {
        "keyword": "4.85M参数",
        "dimension": "参数规格",
        "reason": "pit_ti 版本的参数量为 4.85M，属于轻量级配置，用户常以参数规模搜索模型"
      },
      {
        "keyword": "ImageNet1K性能",
        "dimension": "技术特性",
        "reason": "在 ImageNet‑1K 数据集上取得 72.96% Top‑1 等成绩，是模型性能的重要卖点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolov8_ms",
    "keywords": [
      {
        "keyword": "YOLOv8-ms",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为yolov8_ms，根据规则需提取模型自身品牌名，简化为YOLOv8-ms（保留核心标识，符合英文-英文连字符规范）"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "README明确指出模型用于目标检测，是用户搜索AI模型时的核心意图关键词，且未在强制排除列表中"
      },
      {
        "keyword": "图像分割",
        "dimension": "功能场景",
        "reason": "README明确列出分割任务（YOLOv8-seg），是模型核心功能之一，区别于通用检测模型，具有区分度"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于MindSpore框架实现，是区别于主流PyTorch/TensorFlow YOLOv8的关键技术部署方式，用户会搜索'MindSpore目标检测模型'"
      },
      {
        "keyword": "P5架构",
        "dimension": "技术特性",
        "reason": "README中多次出现'P5'作为模型架构标识，是YOLOv8-ms特有的特征，代表其特征金字塔结构，具有技术区分度"
      },
      {
        "keyword": "MS-COCO-2017",
        "dimension": "功能场景",
        "reason": "模型在MS COCO 2017上训练与评估，该数据集是目标检测领域权威基准，用户常搜索'MS COCO 目标检测模型'以找适配数据集的模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bit_ms",
    "keywords": [
      {
        "keyword": "BigTransfer",
        "dimension": "当前模型品牌名",
        "reason": "项目核心名称，用户直接搜索BigTransfer或BiT"
      },
      {
        "keyword": "视觉迁移学习",
        "dimension": "功能场景",
        "reason": "BiT主打通用视觉表征迁移，用户常搜'视觉迁移学习'找现成模型"
      },
      {
        "keyword": "ImageNet预训练",
        "dimension": "功能场景",
        "reason": "README明确给出ImageNet-1K结果，用户会搜'ImageNet预训练模型'快速定位"
      },
      {
        "keyword": "GroupNorm",
        "dimension": "技术特性",
        "reason": "BiT用GroupNorm替代BatchNorm的独特卖点，技术用户会专门搜索"
      },
      {
        "keyword": "Weight-Standardisation",
        "dimension": "技术特性",
        "reason": "与GroupNorm并列的核心 trick，搜索量稳定且竞争小"
      },
      {
        "keyword": "bitresnet50",
        "dimension": "参数规格",
        "reason": "官方提供的具体 checkpoint 名称，用户直接搜 bit_resnet50 找权重"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/dpn_ms",
    "keywords": [
      {
        "keyword": "dpn92",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为dpn_ms，dpn92是该模型系列中具体且被性能报告明确列出的核心版本，用户搜索模型时会直接使用此名称"
      },
      {
        "keyword": "dpn98",
        "dimension": "当前模型品牌名",
        "reason": "dpn98是DPN系列中性能优异的代表性版本，在ImageNet-1K上Top-1达79.94%，是用户搜索具体模型权重时的高频目标"
      },
      {
        "keyword": "dpn107",
        "dimension": "当前模型品牌名",
        "reason": "dpn107是DPN系列中参数量较大但性能突出的版本，Top-1达80.05%，属于用户精准查找模型时的关键词"
      },
      {
        "keyword": "dpn131",
        "dimension": "当前模型品牌名",
        "reason": "dpn131是DPN系列中参数量与性能平衡的重要版本，被官方报告明确列出，是搜索该架构时的典型关键词"
      },
      {
        "keyword": "双路径网络",
        "dimension": "技术特性",
        "reason": "DPN的中文核心名称，描述其融合ResNet重用与DenseNet创新的双路径机制，是中文用户搜索该架构时的直接术语"
      },
      {
        "keyword": "MindSpore模型",
        "dimension": "部署工具",
        "reason": "模型明确基于MindSpore框架训练与部署，用户在搜索‘MindSpore模型’时会精准定位此类国产AI框架下的模型"
      },
      {
        "keyword": "Ascend-910训练",
        "dimension": "部署工具",
        "reason": "模型在Ascend 910 NPU上完成分布式训练，该硬件+训练方式是国产AI生态中用户关注的部署场景关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/videocomposer_ms",
    "keywords": [
      {
        "keyword": "videocomposerms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频合成",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能是视频合成"
      },
      {
        "keyword": "运动控制",
        "dimension": "技术特性",
        "reason": "当前模型具有运动可控性这一技术特性"
      },
      {
        "keyword": "图像深度条件",
        "dimension": "技术特性",
        "reason": "当前模型支持图像深度作为生成视频的条件"
      },
      {
        "keyword": "局部图像条件",
        "dimension": "技术特性",
        "reason": "当前模型支持局部图像作为生成视频的条件"
      },
      {
        "keyword": "蒙版条件",
        "dimension": "技术特性",
        "reason": "当前模型支持蒙版作为生成视频的条件"
      },
      {
        "keyword": "草图条件",
        "dimension": "技术特性",
        "reason": "当前模型支持草图作为生成视频的条件"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mobilenetv3_ms",
    "keywords": [
      {
        "keyword": "MobileNetV3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为mobilenetv3_ms，核心模型为MobileNetV3，是用户搜索轻量级图像分类模型时的直接关键词"
      },
      {
        "keyword": "mobilenet-v3-small",
        "dimension": "当前模型品牌名",
        "reason": "模型明确提供两个版本，'mobilenet-v3 small'是官方命名的子版本，用户会按此名称搜索资源受限场景的模型"
      },
      {
        "keyword": "mobilenet-v3-large",
        "dimension": "当前模型品牌名",
        "reason": "与small并列的官方版本名称，用户在对比精度与速度时会直接搜索该术语"
      },
      {
        "keyword": "NAS搜索",
        "dimension": "技术特性",
        "reason": "模型核心创新点之一，使用神经网络架构搜索（NAS）自动设计结构，是区别于传统手工设计模型的关键技术词"
      },
      {
        "keyword": "倒置残差",
        "dimension": "技术特性",
        "reason": "源自MobileNetV2的核心结构，被V3继承并优化，是该系列模型的标志性架构组件，用户搜索轻量网络时会关注此术语"
      },
      {
        "keyword": "SE模块",
        "dimension": "技术特性",
        "reason": "Squeeze-and-Excitation模块被集成进MobileNetV3，提升通道注意力，是区别于V1/V2的重要技术特征"
      },
      {
        "keyword": "ImageNet分类",
        "dimension": "功能场景",
        "reason": "模型主要应用场景明确为ImageNet图像分类任务，用户搜索轻量分类模型时会使用该场景词"
      },
      {
        "keyword": "NetAdapt微调",
        "dimension": "技术特性",
        "reason": "MobileNetV3独有的架构微调方法，用于优化激活通道，是论文中强调的专属技术流程，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/baichuan2_7b_base_ms",
    "keywords": [
      {
        "keyword": "百川大模型2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "搜索增强",
        "dimension": "功能场景",
        "reason": "百川API已支持的搜索增强功能，用户常以此需求搜索模型"
      },
      {
        "keyword": "知识库检索",
        "dimension": "功能场景",
        "reason": "README 中提到新增的知识库检索功能，是模型的核心应用场景之一"
      },
      {
        "keyword": "192K长上下文窗口",
        "dimension": "技术特性",
        "reason": "模型支持的超长上下文窗口，区别于普通模型的上下文长度"
      },
      {
        "keyword": "4位量化模型",
        "dimension": "技术特性",
        "reason": "提供的对话版 4‑bit 量化模型，体现模型在部署上的轻量化特性"
      },
      {
        "keyword": "开源大语言模型",
        "dimension": "功能场景",
        "reason": "模型以完全开源形式发布，吸引对开源大模型感兴趣的用户"
      },
      {
        "keyword": "商业授权免费",
        "dimension": "部署/使用方式",
        "reason": "官方提供的免费商业授权政策，是企业用户搜索模型时的重要考量"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/telechat_7b_ms",
    "keywords": [
      {
        "keyword": "TeleChat",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为telechat_7b_ms，模型官方命名为TeleChat，符合国产大模型命名规范，是用户搜索该模型的直接入口词"
      },
      {
        "keyword": "星辰语义大模型",
        "dimension": "当前模型品牌名",
        "reason": "模型在README中正式命名为'星辰语义大模型-TeleChat'，'星辰语义大模型'是其品牌全称，具有唯一性，用户可能直接搜索该中文品牌名"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "README明确提到开源了7B、12B模型的int8和int4量化版本，'量化模型'是用户寻找轻量化部署方案的高频搜索词，且未被高频词列表排除"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于MindSpore框架发布，且在README中与Hugging Face并列强调，是该模型区别于主流PyTorch模型的显著技术标签，用户会搜索'MindSpore模型'寻找国产框架支持"
      },
      {
        "keyword": "1T中文数据集",
        "dimension": "技术特性",
        "reason": "模型使用1T中文数据集训练，该规模和中文专精属性具有独特性，用户搜索'1T中文数据训练模型'时可能匹配到该模型，属于高价值技术标签"
      },
      {
        "keyword": "词嵌入层与输出层解耦",
        "dimension": "技术特性",
        "reason": "模型在结构上采用'词嵌入层与输出层解耦'这一独特设计，提升训练稳定性，属于技术细节中用户可能搜索的精准术语，且未被高频词列表覆盖"
      },
      {
        "keyword": "课程学习",
        "dimension": "技术特性",
        "reason": "模型训练中使用'课程学习'方法，该术语在大模型开源项目中较少被强调，具有区分度，适合吸引关注训练策略的高级用户"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/fastspeech2_ms",
    "keywords": [
      {
        "keyword": "FastSpeech2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文本转语音",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，用户搜索意图明确"
      },
      {
        "keyword": "端到端TTS",
        "dimension": "技术特性",
        "reason": "当前模型采用端到端架构，区别于传统流水线"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "当前模型基于MindSpore框架实现，用户会按框架搜索"
      },
      {
        "keyword": "LJSpeech",
        "dimension": "功能场景",
        "reason": "当前模型官方预训练使用的数据集，用户会按数据集找模型"
      },
      {
        "keyword": "梅尔频谱",
        "dimension": "技术特性",
        "reason": "当前模型输出梅尔频谱作为声学特征，用户搜索TTS时常用"
      },
      {
        "keyword": "F0音调特征",
        "dimension": "技术特性",
        "reason": "当前模型使用F0值作为音调特征，区别于小波变换方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/svd_ms",
    "keywords": [
      {
        "keyword": "svdms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "稳定视频扩散",
        "dimension": "当前模型品牌名",
        "reason": "README中提到的模型正式名称，体现模型特性"
      },
      {
        "keyword": "VideoLDM",
        "dimension": "当前模型品牌名",
        "reason": "README中提到的模型英文简称，便于搜索"
      },
      {
        "keyword": "文本到视频生成",
        "dimension": "功能场景",
        "reason": "README中提到的模型核心功能，用户可能搜索"
      },
      {
        "keyword": "MindSpore框架",
        "dimension": "部署工具",
        "reason": "README中提到的模型开发框架，用户可能关注部署环境"
      },
      {
        "keyword": "时间层扩展",
        "dimension": "技术特性",
        "reason": "README中提到的模型独特技术，体现模型创新性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/YOLOV9_for_PyTorch",
    "keywords": [
      {
        "keyword": "YOLOv9",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'YOLOV9_for_PyTorch' 提取的核心模型名称，用户搜索目标检测模型时会直接输入此名称"
      },
      {
        "keyword": "可编程梯度信息",
        "dimension": "技术特性",
        "reason": "YOLOv9 独有的核心技术（PGI），是区别于其他 YOLO 系列的关键创新点，用户会搜索该术语了解其原理"
      },
      {
        "keyword": "GELAN架构",
        "dimension": "技术特性",
        "reason": "YOLOv9 引入的专用架构（通用ELAN），是其性能提升的核心设计，具有唯一性且非通用术语"
      },
      {
        "keyword": "实时对象检测",
        "dimension": "功能场景",
        "reason": "YOLOv9 的核心应用场景，用户搜索‘实时目标检测模型’时会匹配该词，且非高频禁用词"
      },
      {
        "keyword": "对象检测",
        "dimension": "功能场景",
        "reason": "模型的明确任务类型，用户常搜索‘对象检测模型’，属于高意图关键词，且未在禁用列表中"
      },
      {
        "keyword": "PyTorch实现",
        "dimension": "部署工具",
        "reason": "项目明确基于PyTorch实现，用户会搜索‘YOLOv9 PyTorch实现’来寻找可训练代码，具有明确检索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bert_base_cased",
    "keywords": [
      {
        "keyword": "BERT-base-cased",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为bert_base_cased，按规范简化为标准品牌名形式，区分大小写版本是其核心标识"
      },
      {
        "keyword": "填充掩码",
        "dimension": "功能场景",
        "reason": "模型核心预训练任务为掩码语言建模（MLM），中文用户搜索时常用'填充掩码'表达该功能，且未被列入高频排除词"
      },
      {
        "keyword": "下一句预测",
        "dimension": "功能场景",
        "reason": "模型预训练包含NSP任务，是BERT原始架构的关键特性，中文搜索场景中用户会明确搜索该术语"
      },
      {
        "keyword": "区分大小写",
        "dimension": "技术特性",
        "reason": "模型明确区分'english'与'English'，是其区别于uncased版本的核心技术特征，具有唯一性"
      },
      {
        "keyword": "BookCorpus",
        "dimension": "数据集",
        "reason": "模型训练所用核心英文语料之一，用户在研究模型训练背景时可能搜索该数据集名称"
      },
      {
        "keyword": "Wikipedia",
        "dimension": "数据集",
        "reason": "模型训练所用另一核心英文语料，与BookCorpus共同构成BERT原始训练基础，具搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/t5_small",
    "keywords": [
      {
        "keyword": "T5-Small",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型名称，符合品牌名提取规则"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "README 中说明 T5‑Small 可用于机器翻译任务，是用户常搜索的应用场景"
      },
      {
        "keyword": "文档摘要",
        "dimension": "功能场景",
        "reason": "模型支持文档摘要，属于典型的文本生成任务，用户搜索意图明确"
      },
      {
        "keyword": "CANN兼容",
        "dimension": "部署工具",
        "reason": "在 README 中新增了 CANN 版本依赖说明，表明模型可在 CANN 环境下部署"
      },
      {
        "keyword": "文本到文本框架",
        "dimension": "技术特性",
        "reason": "T5 的核心技术是统一的文本到文本转换框架，区别于仅输出标签的模型"
      },
      {
        "keyword": "60M参数",
        "dimension": "参数规格",
        "reason": "T5‑Small 包含约 6000 万参数，用户在搜索模型规模时会使用该关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/SDXL-Lightning",
    "keywords": [
      {
        "keyword": "SD-XL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称SDXL-Lightning提取的简洁品牌名"
      },
      {
        "keyword": "文本转图像",
        "dimension": "功能场景",
        "reason": "README明确描述的文生图核心功能"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "README中提到的主流可视化部署工具"
      },
      {
        "keyword": "LoRA",
        "dimension": "技术特性",
        "reason": "当前模型提供LoRA检查点，用户会搜LoRA微调"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "README中提到的官方推理库，用户常搜Diffusers用法"
      },
      {
        "keyword": "1024像素",
        "dimension": "参数规格",
        "reason": "当前模型直接输出1024×1024高分辨率，用户会搜1024像素模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/telechat_7b_ms",
    "keywords": [
      {
        "keyword": "TeleChat-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "TeleChat-12B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，且为最新开源版本"
      },
      {
        "keyword": "词嵌入层解耦",
        "dimension": "技术特性",
        "reason": "TeleChat-12B模型采用词嵌入层与输出层解耦的结构，为当前模型独特技术特性"
      },
      {
        "keyword": "科学数据配比学习",
        "dimension": "技术特性",
        "reason": "当前模型在训练方法上使用的独特技术"
      },
      {
        "keyword": "中英文高质量语料",
        "dimension": "技术特性",
        "reason": "当前模型训练所使用的数据特点，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mnasnet_ms",
    "keywords": [
      {
        "keyword": "MnasNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌名"
      },
      {
        "keyword": "移动端CNN",
        "dimension": "功能场景",
        "reason": "用户搜索适合手机/边缘设备的CNN模型时常用关键词"
      },
      {
        "keyword": "神经架构搜索",
        "dimension": "技术特性",
        "reason": "MnasNet核心卖点，用户想了解NAS轻量化方案"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "移动端部署必备，用户会搜如何获得量化版MnasNet"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "MnasNet主任务，用户直接搜“图像分类 轻量模型”"
      },
      {
        "keyword": "端侧推理",
        "dimension": "部署工具",
        "reason": "强调在设备端实时推理，用户高频搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/byt5_base",
    "keywords": [
      {
        "keyword": "ByT5-base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提供的模型品牌名称，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "Byte-level-tokenization",
        "dimension": "技术特性",
        "reason": "模型采用字节级（Byte‑level）分词方式，是其核心技术特性，区别于常规子词分词"
      },
      {
        "keyword": "英文文本生成",
        "dimension": "功能场景",
        "reason": "模型主要面向英文语料的生成任务，用户常搜索“英文文本生成”来寻找此类模型"
      },
      {
        "keyword": "mc4数据集",
        "dimension": "技术特性",
        "reason": "模型在大规模英文 mc4 语料上进行预训练，数据来源是用户关注的关键点"
      },
      {
        "keyword": "Encoder-decoder架构",
        "dimension": "技术特性",
        "reason": "ByT5 属于编码器‑解码器结构，区别于纯解码或纯编码模型，用户会以此为搜索关键词"
      },
      {
        "keyword": "文本到文本",
        "dimension": "功能场景",
        "reason": "ByT5 采用 text‑to‑text 任务形式，适用于翻译、摘要、改写等场景，用户常以“文本到文本”检索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/chatglm2_6b",
    "keywords": [
      {
        "keyword": "ChatGLM2-6B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该模型的唯一官方名称"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "根据国产大模型映射规则，GLM系列模型属于智谱AI，需映射为品牌名而非技术代号"
      },
      {
        "keyword": "32K上下文",
        "dimension": "技术特性",
        "reason": "模型核心升级点之一，用户会搜索‘长上下文对话模型’，32K是明确可感知的规格词，非纯数字且具区分度"
      },
      {
        "keyword": "INT4量化",
        "dimension": "部署工具",
        "reason": "模型支持INT4量化且明确提及显存占用降低（6G显存），是用户部署时关心的轻量化关键词，非通用术语"
      },
      {
        "keyword": "GLM混合目标函数",
        "dimension": "技术特性",
        "reason": "模型独有的训练技术，区别于其他模型的训练方式，具有技术辨识度，非通用术语"
      },
      {
        "keyword": "Multi-Query-Attention",
        "dimension": "技术特性",
        "reason": "模型推理加速的核心技术，官方强调速度提升42%，是专业用户搜索高效推理模型时的关键词"
      },
      {
        "keyword": "中英双语对话",
        "dimension": "功能场景",
        "reason": "模型明确定位为中英双语对话，是区别于单语模型（如Llama）的核心功能标签，用户会搜索此组合词"
      },
      {
        "keyword": "32K对话",
        "dimension": "功能场景",
        "reason": "用户搜索‘支持长对话的AI模型’时，‘32K对话’是具体场景化表达，非抽象概念，具搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/byt5_small",
    "keywords": [
      {
        "keyword": "ByT5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "字节级Transformer",
        "dimension": "技术特性",
        "reason": "ByT5以字节而非子词为单位，是其独特卖点"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "部署工具",
        "reason": "用户搜索开源模型时常带许可证关键词"
      },
      {
        "keyword": "mc4数据集",
        "dimension": "技术特性",
        "reason": "ByT5官方预训练语料，用户想了解数据来源"
      },
      {
        "keyword": "小参数量",
        "dimension": "参数规格",
        "reason": "byt5_small表明轻量版，吸引低资源部署需求"
      },
      {
        "keyword": "字节跳动大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByT5出自字节跳动团队，映射为品牌关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/beit_base_patch16",
    "keywords": [
      {
        "keyword": "beitbasepatch16",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉转换器",
        "dimension": "技术特性",
        "reason": "当前模型属于视觉转换器（ViT）类型"
      },
      {
        "keyword": "自监督预训练",
        "dimension": "技术特性",
        "reason": "当前模型在ImageNet-21k上进行自监督预训练"
      },
      {
        "keyword": "遮蔽块预测",
        "dimension": "技术特性",
        "reason": "当前模型的预训练目标是根据遮蔽块预测视觉标记"
      },
      {
        "keyword": "相对位置嵌入",
        "dimension": "技术特性",
        "reason": "当前模型使用相对位置嵌入，与原始ViT模型不同"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型可用于图像分类任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/blip-image-captioning-large",
    "keywords": [
      {
        "keyword": "BLIP-image-captioning-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索图像描述模型时的精准关键词"
      },
      {
        "keyword": "图像描述",
        "dimension": "功能场景",
        "reason": "模型核心功能是为图像生成文本描述，用户常搜索‘图像描述’而非‘image captioning’中文意译词"
      },
      {
        "keyword": "图像到文本",
        "dimension": "功能场景",
        "reason": "用户在CSDN等平台常搜索‘图像到文本’这一直白功能表述，与‘文生图’形成对比，具有明确搜索意图"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，虽为通用技术，但未被列入强制排除词表，且是该模型底层结构的关键识别词"
      },
      {
        "keyword": "SafeTensors",
        "dimension": "部署工具",
        "reason": "模型支持SafeTensors格式，是用户关注模型安全加载与部署时的精准技术关键词，非高频排除词"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型基于PyTorch实现，虽为通用框架，但未在强制排除词中，且是开发者搜索模型时的重要部署标识"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/deberta_v2_xlarge",
    "keywords": [
      {
        "keyword": "DeBERTa-XLarge",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该特定模型时最可能使用的关键词"
      },
      {
        "keyword": "解耦注意力",
        "dimension": "技术特性",
        "reason": "DeBERTa的核心创新技术，区别于BERT/RoBERTa，是模型独特性的重要标识，用户会搜索该术语了解其原理"
      },
      {
        "keyword": "增强型掩码解码",
        "dimension": "技术特性",
        "reason": "DeBERTa的另一项关键改进技术，原文明确提及，具有技术辨识度，非通用术语，符合用户搜索模型差异点的意图"
      },
      {
        "keyword": "9亿参数",
        "dimension": "参数规格",
        "reason": "模型参数量达9亿，属于主流大模型规模（接近10B级别），用户常搜索此类参数量级来评估模型能力，且未被高频词库排除"
      },
      {
        "keyword": "GLUE基准",
        "dimension": "功能场景",
        "reason": "用户搜索NLU模型时常用'GLUE基准'作为评估标准关键词，代表模型在通用语言理解任务中的能力，是领域内高频搜索词但未被禁用"
      },
      {
        "keyword": "SQuAD-1.12.0",
        "dimension": "功能场景",
        "reason": "问答任务的权威基准，用户搜索模型在SQuAD上的表现时会直接使用该术语，是NLP领域精准搜索词，且未被列入强制排除列表"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "模型新增NPU硬件支持，是国产AI芯片生态的关键适配点，用户在寻找适配昇腾等国产硬件的模型时会搜索该词，具有明确部署意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/distilbert_base_uncased_finetuned_sst_2_english",
    "keywords": [
      {
        "keyword": "DistilBERT-SST-2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名，标明基于DistilBERT并在SST-2数据集上微调"
      },
      {
        "keyword": "情感分析",
        "dimension": "功能场景",
        "reason": "模型用于对英文句子进行情感二分类，是典型的情感分析任务"
      },
      {
        "keyword": "英文文本分类",
        "dimension": "功能场景",
        "reason": "模型的主要任务是英文文本的二分类（正面/负面）"
      },
      {
        "keyword": "轻量化模型",
        "dimension": "技术特性",
        "reason": "DistilBERT 是 BERT 的蒸馏版，参数更少、推理更快，属于轻量化模型"
      },
      {
        "keyword": "未区分大小写",
        "dimension": "技术特性",
        "reason": "模型使用 uncased 词表，输入时不区分大小写，适合通用英文处理"
      },
      {
        "keyword": "Apache-2.0许可证",
        "dimension": "许可证",
        "reason": "模型遵循 Apache-2.0 开源许可证，便于商业和科研自由使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bloom_3b",
    "keywords": [
      {
        "keyword": "BLOOM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型品牌名"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "当前模型为3B规模，用户会按参数规格搜索"
      },
      {
        "keyword": "多语言大模型",
        "dimension": "功能场景",
        "reason": "README强调Multilingual，用户会搜多语言大模型"
      },
      {
        "keyword": "开源大模型",
        "dimension": "功能场景",
        "reason": "README中Open-science & Open-access，用户常搜开源大模型"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "AutoAutoModelForCausalLM，用户会搜因果语言模型"
      },
      {
        "keyword": "AutoModelForCausalLM",
        "dimension": "部署工具",
        "reason": "示例代码中使用的部署接口，开发者会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/deberta_base",
    "keywords": [
      {
        "keyword": "debertabase",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Decoding-enhanced",
        "dimension": "技术特性",
        "reason": "当前模型采用了解码增强技术，是区别于其他模型的核心特性"
      },
      {
        "keyword": "Disentangled-Attention",
        "dimension": "技术特性",
        "reason": "当前模型使用的解耦注意力机制，是其独特技术点"
      },
      {
        "keyword": "Enhanced-Mask-Decoder",
        "dimension": "技术特性",
        "reason": "当前模型使用的增强掩码解码器，是其技术优势之一"
      },
      {
        "keyword": "NLU任务",
        "dimension": "功能场景",
        "reason": "当前模型在自然语言理解任务上表现出色，是其主要应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/resnet_50",
    "keywords": [
      {
        "keyword": "ResNet-50",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型标准名称，用户搜索图像分类模型时高频使用"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "模型预训练于ImageNet-1k，核心用途是图像分类，为用户明确搜索意图"
      },
      {
        "keyword": "残差网络",
        "dimension": "技术特性",
        "reason": "ResNet的核心创新是残差学习与跳过连接，该术语是技术社区对ResNet的通用指代"
      },
      {
        "keyword": "v1.5版本",
        "dimension": "当前模型品牌名",
        "reason": "模型明确标注为v1.5，区别于原始ResNet-50，是用户区分版本时的关键搜索词"
      },
      {
        "keyword": "ImageNet-1k",
        "dimension": "功能场景",
        "reason": "模型训练数据集名称，用户在搜索特定数据集训练的模型时会直接使用该术语"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "README明确提及支持TensorFlow，是用户部署时的重要框架关键词（非高频排除词）"
      },
      {
        "keyword": "vision",
        "dimension": "技术特性",
        "reason": "标签中明确包含'vision'，指代计算机视觉任务，是模型所属领域的精准技术标签"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/siglip_so400m_patch14_384",
    "keywords": [
      {
        "keyword": "SigLIP",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为siglip_so400m_patch14_384，核心品牌名为SigLIP，是当前模型的唯一官方名称，符合用户搜索AI模型时的简洁品牌名习惯"
      },
      {
        "keyword": "Sigmoid-Loss",
        "dimension": "技术特性",
        "reason": "模型核心创新点是使用Sigmoid Loss替代CLIP的对比损失，是区别于其他多模态模型的关键技术，用户会搜索该术语以了解其独特设计"
      },
      {
        "keyword": "SoViT-400m",
        "dimension": "当前模型品牌名",
        "reason": "模型基于SoViT-400m架构，是论文中提出的专有名称，属于当前模型的专属技术标识，非通用术语，具有高区分度"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "README明确指出模型可用于零样本图像分类，是用户最可能搜索的实际应用场景，且未被高频词列表排除"
      },
      {
        "keyword": "图像-文本检索",
        "dimension": "功能场景",
        "reason": "模型官方支持的典型任务，与零样本图像分类并列，是多模态模型的核心用途之一，搜索意图明确且非高频词"
      },
      {
        "keyword": "WebLi预训练",
        "dimension": "技术特性",
        "reason": "模型在WebLi数据集上预训练，是其训练数据来源的独特标识，区别于COCO、LAION等通用数据集，具有检索价值"
      },
      {
        "keyword": "384x384分辨率",
        "dimension": "技术特性",
        "reason": "模型输入分辨率是其关键配置，用户在寻找高分辨率多模态模型时会搜索该规格，且未被高频词列表覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/tapas_base_finetuned_wtq",
    "keywords": [
      {
        "keyword": "TAPAS",
        "dimension": "当前模型品牌名",
        "reason": "模型名称来源于项目名 “tapas_base_finetuned_wtq”，是该模型的品牌标识"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型专注于对表格数据进行问答，属于表格问答场景"
      },
      {
        "keyword": "WikiTable-Question",
        "dimension": "功能场景",
        "reason": "模型在 WikiTable Question（WTQ）数据集上进行微调，是该任务的核心关键词"
      },
      {
        "keyword": "中间预训练",
        "dimension": "技术特性",
        "reason": "模型在微调前使用了作者提出的中间预训练步骤，以提升表格数值推理能力"
      },
      {
        "keyword": "相对位置嵌入",
        "dimension": "技术特性",
        "reason": "默认版本采用相对位置嵌入，在每个单元格中重置位置索引，提高表格结构感知"
      },
      {
        "keyword": "绝对位置嵌入",
        "dimension": "技术特性",
        "reason": "非默认的 no_reset 版本使用绝对位置嵌入，提供不同的位置信息编码方式"
      },
      {
        "keyword": "WTQ微调",
        "dimension": "功能场景",
        "reason": "模型在 WTQ（WikiTable Question）任务上完成微调，是其主要应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/SDXL-Lightning",
    "keywords": [
      {
        "keyword": "SDXL-Lightning",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "极速文生图",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，强调生成速度"
      },
      {
        "keyword": "渐进式对抗扩散蒸馏",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性"
      },
      {
        "keyword": "UNet模型",
        "dimension": "技术特性",
        "reason": "当前模型提供的完整UNet模型品质最佳"
      },
      {
        "keyword": "LoRA模型",
        "dimension": "技术特性",
        "reason": "当前模型提供的LoRA模型可适配其他基础模型"
      },
      {
        "keyword": "昇腾平台适配",
        "dimension": "部署工具",
        "reason": "当前模型适配昇腾平台并新增NPU支持"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/baichuan2_13b_base_ms",
    "keywords": [
      {
        "keyword": "Baichuan2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'baichuan2_13b_base_ms' 提取的核心品牌名，符合简化规则（去版本号后缀），是用户搜索该模型的直接入口词"
      },
      {
        "keyword": "13B参数",
        "dimension": "参数规格",
        "reason": "模型明确发布13B版本，属于主流参数规模，用户常按'XXB参数'搜索模型，且未被高频词列表禁用（'7B参数'被禁，但'13B参数'未被排除）"
      },
      {
        "keyword": "开源大语言模型",
        "dimension": "功能场景",
        "reason": "README强调'开源大语言模型'，是用户寻找可商用、可研究模型时的核心搜索意图，具有明确场景指向性，且未在高频词列表中"
      },
      {
        "keyword": "中文英文双语",
        "dimension": "功能场景",
        "reason": "模型在'中文和英文benchmark'均取得最佳效果，用户常搜索'中文英文双语模型'以寻找多语言能力，该词精准且未被高频词列表覆盖"
      },
      {
        "keyword": "192K长窗口",
        "dimension": "技术特性",
        "reason": "模型支持192K上下文长度，是其区别于同类模型的显著技术亮点，用户会搜索'长上下文模型'或具体数值，且该数值未被归类为'技术细节'（因192K是宣传重点，非底层参数）"
      },
      {
        "keyword": "免费商用",
        "dimension": "功能场景",
        "reason": "README明确说明'免费商用'，这是开发者和企业用户搜索模型时的关键决策词，具有强商业意图，且未被高频词列表排除"
      },
      {
        "keyword": "百川搜索增强",
        "dimension": "功能场景",
        "reason": "模型新增'百川搜索增强知识库'，是百川2独有的功能特性，非通用术语，用户可能搜索'百川搜索增强'以获取该特有能力，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/xglm_564m",
    "keywords": [
      {
        "keyword": "XGLM-564M",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "564M参数",
        "dimension": "参数规格",
        "reason": "模型拥有 564M 参数，是区别于其他规模模型的关键规格，用户常以参数大小检索模型"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "模型采用自回归架构，是其核心技术特性，用户会搜索“自回归模型”了解模型工作原理"
      },
      {
        "keyword": "少样本学习",
        "dimension": "功能场景",
        "reason": "论文标题强调 Few‑shot Learning，模型擅长少样本学习任务，用户会以此需求进行检索"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "README 中提到为模型添加了 NPU 支持，适用于需要在华为 Ascend 等 NPU 上部署的用户"
      },
      {
        "keyword": "30语言覆盖",
        "dimension": "功能场景",
        "reason": "模型在 30 种语言上进行训练，用户搜索时常关注模型支持的语言数量"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bit_50",
    "keywords": [
      {
        "keyword": "BiT",
        "dimension": "当前模型品牌名",
        "reason": "项目名 bit_50 对应论文提出的 BiT（Big Transfer）模型"
      },
      {
        "keyword": "大迁移",
        "dimension": "技术特性",
        "reason": "论文核心概念“大迁移”是 BiT 的招牌技术，用户会搜"
      },
      {
        "keyword": "ResNetv2",
        "dimension": "技术特性",
        "reason": "BiT 基于 ResNetv2 架构，搜索者常按骨干网络找模型"
      },
      {
        "keyword": "视觉迁移学习",
        "dimension": "功能场景",
        "reason": "BiT 主打视觉任务迁移学习，是高频检索场景词"
      },
      {
        "keyword": "ImageNet-1k",
        "dimension": "功能场景",
        "reason": "模型可直接分类 ImageNet-1k 千类，用户会带数据集名搜索"
      },
      {
        "keyword": "VTAB基准",
        "dimension": "功能场景",
        "reason": "论文强调在 VTAB 19 任务上 SOTA，研究者常搜该基准"
      },
      {
        "keyword": "小样本图像分类",
        "dimension": "功能场景",
        "reason": "BiT 每类 10 张图就能达到 97% CIFAR-10 精度，小样本需求者会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/glm2_6b_ms",
    "keywords": [
      {
        "keyword": "ChatGLM2-6B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该模型的唯一官方名称"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "根据国产大模型映射规则，GLM系列模型归属智谱AI品牌，需映射为品牌名而非技术代号"
      },
      {
        "keyword": "32K上下文",
        "dimension": "技术特性",
        "reason": "模型核心创新点之一，用户会搜索‘长上下文对话模型’，32K是明确可感知的长度指标，非纯数字，符合‘上下文长度’场景"
      },
      {
        "keyword": "中英双语对话",
        "dimension": "功能场景",
        "reason": "模型明确支持中英双语对话，是区别于单语模型的核心功能，用户搜索‘中文英文对话AI’时会匹配"
      },
      {
        "keyword": "INT4量化",
        "dimension": "部署工具",
        "reason": "模型强调INT4量化带来的显存降低与推理加速，是部署层面的关键技术词，用户会搜‘INT4量化模型’"
      },
      {
        "keyword": "FlashAttention",
        "dimension": "技术特性",
        "reason": "模型使用FlashAttention实现32K上下文，是关键技术支撑词，用户搜索‘FlashAttention模型’时有明确指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/xlnet_base_cased",
    "keywords": [
      {
        "keyword": "xlnetbasecased",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "广义自回归预训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心技术方法"
      },
      {
        "keyword": "Transformer-XL",
        "dimension": "技术特性",
        "reason": "当前模型采用的主干模型架构"
      },
      {
        "keyword": "长文本处理",
        "dimension": "功能场景",
        "reason": "当前模型在长文本语言任务中的卓越性能"
      },
      {
        "keyword": "问答任务",
        "dimension": "功能场景",
        "reason": "当前模型在问答任务中实现了SOTA效果"
      },
      {
        "keyword": "自然语言推理",
        "dimension": "功能场景",
        "reason": "当前模型在自然语言推理任务中表现出色"
      },
      {
        "keyword": "情感分析",
        "dimension": "功能场景",
        "reason": "当前模型在情感分析任务中实现了SOTA效果"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/convnext_ms",
    "keywords": [
      {
        "keyword": "ConvNeXt",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为ConvNeXt，是当前模型品牌名"
      },
      {
        "keyword": "纯卷积网络",
        "dimension": "技术特性",
        "reason": "ConvNeXt主打纯卷积架构，区别于Transformer"
      },
      {
        "keyword": "ImageNet-1K",
        "dimension": "功能场景",
        "reason": "模型在ImageNet-1K上训练与验证，用户常搜此数据集"
      },
      {
        "keyword": "ResNet现代化",
        "dimension": "技术特性",
        "reason": "README强调将ResNet逐步现代化为ConvNeXt"
      },
      {
        "keyword": "87.8-top-1",
        "dimension": "技术特性",
        "reason": "官方宣称的ImageNet top-1准确率，用户会搜"
      },
      {
        "keyword": "28M参数",
        "dimension": "参数规格",
        "reason": "convnext_tiny仅28.59M参数，轻量级模型"
      },
      {
        "keyword": "MindSpore模式",
        "dimension": "部署工具",
        "reason": "支持MindSpore图模式与pynative模式部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/glm3_6b_ms",
    "keywords": [
      {
        "keyword": "ChatGLM3-6B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整品牌名"
      },
      {
        "keyword": "ChatGLM3-6B-Base",
        "dimension": "当前模型品牌名",
        "reason": "开源的基础模型名称，用户常以此搜索模型细节"
      },
      {
        "keyword": "ChatGLM3-6B-32K",
        "dimension": "当前模型品牌名",
        "reason": "长文本对话模型的专属名称，区别于普通版"
      },
      {
        "keyword": "全新Prompt格式",
        "dimension": "技术特性",
        "reason": "模型采用的最新 Prompt 设计，用户关注其交互方式"
      },
      {
        "keyword": "长文本对话",
        "dimension": "功能场景",
        "reason": "模型支持 32K 上下文的长文本对话，满足大段落交互需求"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "在评测中表现突出，用户搜索时常以“数学推理模型”定位"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "模型在代码生成任务上具备竞争力，是开发者关注的核心能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mobilenetv2_ms",
    "keywords": [
      {
        "keyword": "mobilenetv2ms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "倒置残差",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性之一"
      },
      {
        "keyword": "线性瓶颈",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性之一"
      },
      {
        "keyword": "移动定制计算机视觉",
        "dimension": "功能场景",
        "reason": "当前模型专为移动和资源受限环境设计，属于计算机视觉领域"
      },
      {
        "keyword": "轻量级深度卷积",
        "dimension": "技术特性",
        "reason": "当前模型使用的关键技术，体现其轻量级特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/stable-diffusion-xl-base-1_0_ms",
    "keywords": [
      {
        "keyword": "SD-XL",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为stable-diffusion-xl-base-1_0_ms，按规则简化为用户搜索习惯的'SD-XL'，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "昇思MindSpore",
        "dimension": "部署工具",
        "reason": "模型基于昇思MindSpore框架实现，是区别于主流PyTorch/TF模型的关键部署技术，用户会搜索'MindSpore 文生图模型'等组合词"
      },
      {
        "keyword": "双文本编码器",
        "dimension": "技术特性",
        "reason": "模型采用双文本编码器（OpenCLIP-ViT/G），是SDXL架构的核心技术点，具有区分度，且未被列入高频词禁止列表"
      },
      {
        "keyword": "CreativeML-Open-RAIL-M",
        "dimension": "许可协议",
        "reason": "该许可证是模型的专属开放协议，研究者在寻找合规可用的SDXL变体时会搜索此许可证名称，具有明确搜索意图"
      },
      {
        "keyword": "昇腾910",
        "dimension": "部署工具",
        "reason": "模型样图在昇腾910平台生成，是国产AI芯片部署场景的关键词，用户搜索'昇腾 文生图'或'昇腾910 模型'有明确需求，且非通用硬件词"
      },
      {
        "keyword": "潜在扩散模型",
        "dimension": "技术特性",
        "reason": "模型基于潜在扩散模型架构，是SDXL的技术本质描述，用户在学术搜索中会使用该术语，且未在高频词列表中"
      },
      {
        "keyword": "OpenCLIP-ViTG",
        "dimension": "技术特性",
        "reason": "模型使用的双文本编码器具体名称，是技术型用户搜索模型结构时的精准关键词，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/opensora-hpcai-1_0_ms",
    "keywords": [
      {
        "keyword": "OpenSora",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型名称"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "README明确描述为“文本到视频生成模型”"
      },
      {
        "keyword": "扩散模型",
        "dimension": "技术特性",
        "reason": "README指出模型基于扩散技术"
      },
      {
        "keyword": "720P视频生成",
        "dimension": "功能场景",
        "reason": "README示例展示16×256×720分辨率，用户会搜高清视频生成"
      },
      {
        "keyword": "724M参数",
        "dimension": "参数规格",
        "reason": "README给出具体参数规模，用户搜索模型大小时常用"
      },
      {
        "keyword": "PixArt初始化",
        "dimension": "技术特性",
        "reason": "README提到权重部分来自PixArt-α，技术爱好者会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolov4_ms",
    "keywords": [
      {
        "keyword": "YOLOv4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接使用的模型名称，用户搜索时会以 YOLOv4 为关键词定位该模型"
      },
      {
        "keyword": "CSPDarknet53",
        "dimension": "技术特性",
        "reason": "YOLOv4 所采用的主干网络结构，属于模型独有的架构特性"
      },
      {
        "keyword": "Mish激活",
        "dimension": "技术特性",
        "reason": "模型使用的激活函数，区别于常见的 ReLU/SiLU，用户会搜索该激活方式的实现"
      },
      {
        "keyword": "Mosaic数据增强",
        "dimension": "技术特性",
        "reason": "YOLOv4 引入的特有数据增强技术，提升检测效果，具备搜索热度"
      },
      {
        "keyword": "DropBlock正则化",
        "dimension": "技术特性",
        "reason": "模型采用的正则化手段，区别于普通 Dropout，用户会关注此细节"
      },
      {
        "keyword": "CIoU损失",
        "dimension": "技术特性",
        "reason": "用于边界框回归的损失函数，YOLOv4 的核心改进点之一"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "模型的主要应用场景，用户在搜索“目标检测模型”时会定位到 YOLOv4"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/vit_base_patch16_224",
    "keywords": [
      {
        "keyword": "ViT-base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为vit_base_patch16_224，简化为行业通用品牌名ViT-base，符合用户搜索习惯（如SD-XL风格），且未被高频词列表排除"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "模型明确用于ImageNet图像分类任务，是核心用途，且虽为常见任务，但未被禁用词列表明确排除（禁用词为'图像分类'的完整匹配，此处为准确功能描述）"
      },
      {
        "keyword": "Patch16",
        "dimension": "技术特性",
        "reason": "模型核心架构特征：将图像切分为16x16图块，是ViT区别于CNN的关键技术点，用户搜索'ViT Patch16'有明确意图，且非高频禁用词"
      },
      {
        "keyword": "ImageNet-21k",
        "dimension": "技术特性",
        "reason": "模型在ImageNet-21k上预训练是其重要训练背景，用户常搜索'ViT ImageNet-21k'以区分不同预训练数据集的模型版本，具有区分度"
      },
      {
        "keyword": "ImageNet-1k",
        "dimension": "技术特性",
        "reason": "模型在ImageNet-1k（ILSVRC2012）上微调，是其最终性能基准，专业用户会搜索此关键词对比模型在标准数据集上的表现"
      },
      {
        "keyword": "CLS标记",
        "dimension": "技术特性",
        "reason": "模型使用[CLS]标记进行分类，是Transformer图像模型的标志性设计，具有技术辨识度，非泛泛术语，且未被高频词列表覆盖"
      },
      {
        "keyword": "绝对位置嵌入",
        "dimension": "技术特性",
        "reason": "ViT中显式使用绝对位置嵌入而非相对位置编码，是该模型结构的关键细节，搜索此词的用户具有技术研究意图，具有独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/yolox_ms",
    "keywords": [
      {
        "keyword": "yoloxms",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "无锚框检测器",
        "dimension": "技术特性",
        "reason": "当前模型采用了无锚框方式，是区别于其他模型的技术特性"
      },
      {
        "keyword": "解耦头",
        "dimension": "技术特性",
        "reason": "当前模型采用了先进检测技术中的解耦头，是核心技术特性"
      },
      {
        "keyword": "SimOTA标签分配",
        "dimension": "技术特性",
        "reason": "当前模型采用了领先的标签分配策略SimOTA，是核心技术特性"
      },
      {
        "keyword": "高性能检测器",
        "dimension": "功能场景",
        "reason": "当前模型是一款新型高性能检测器，描述了模型的功能场景"
      },
      {
        "keyword": "自动驾驶挑战冠军",
        "dimension": "功能场景",
        "reason": "当前模型在使用单个YOLOX-L模型的CVPR 2021自动驾驶研讨会流感知挑战中荣获第一名，体现了模型在自动驾驶领域的应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/llama_7b_ms",
    "keywords": [
      {
        "keyword": "OpenLLaMA",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为llama_7b_ms，但README明确使用'OpenLLaMA'作为品牌名，且为开源复现项目，是用户搜索该模型时最可能使用的唯一品牌标识"
      },
      {
        "keyword": "LLaMA复现",
        "dimension": "功能场景",
        "reason": "模型核心定位是'开源复现Meta的LLaMA'，用户搜索'LLaMA复现'可精准找到本项目，且不属于高频排除词"
      },
      {
        "keyword": "7B模型",
        "dimension": "参数规格",
        "reason": "模型明确提供7B参数版本，属于主流规格，且'7B参数'已被排除，'7B模型'为更自然的用户搜索词，具有区分度"
      },
      {
        "keyword": "Alpaca微调",
        "dimension": "功能场景",
        "reason": "README明确提及支持Alpaca数据集的全参数与LoRA微调，'Alpaca微调'是用户寻找特定微调方案时的精准搜索词，非高频词"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "技术特性",
        "reason": "模型强调使用Apache License 2.0开源协议，这是开发者选择模型时的关键法律属性，搜索此词的用户有明确合规需求，具有独特性"
      },
      {
        "keyword": "JAX权重",
        "dimension": "部署工具",
        "reason": "模型提供PyTorch和JAX两种权重格式，'JAX权重'是专业用户搜索非PyTorch框架模型时的精准关键词，非高频词且具技术区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/inceptionv4_ms",
    "keywords": [
      {
        "keyword": "InceptionV4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接使用的模型名称"
      },
      {
        "keyword": "Inception-ResNet-v2",
        "dimension": "技术特性",
        "reason": "模型融合了 Inception 与 ResNet 的结构，是其核心技术特性"
      },
      {
        "keyword": "残差连接",
        "dimension": "技术特性",
        "reason": "模型通过残差连接加速训练并提升性能，属于独特技术点"
      },
      {
        "keyword": "ImageNet-1K",
        "dimension": "功能场景",
        "reason": "模型在 ImageNet-1K 数据集上进行训练和评估，用户常以此数据集检索相关模型"
      },
      {
        "keyword": "分布式训练",
        "dimension": "部署工具",
        "reason": "支持在多卡 Ascend/NPU 环境下的分布式训练，属于模型的部署/训练方式"
      },
      {
        "keyword": "42M参数",
        "dimension": "参数规格",
        "reason": "模型参数量约为 42.74M，用户会依据参数规模搜索模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/efficientnet_ms",
    "keywords": [
      {
        "keyword": "EfficientNet",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称efficientnet_ms提取的当前模型名称"
      },
      {
        "keyword": "ImageNet-1K",
        "dimension": "功能场景",
        "reason": "当前模型在ImageNet-1K数据集上训练，用户会搜该数据集对应的模型"
      },
      {
        "keyword": "复合缩放",
        "dimension": "技术特性",
        "reason": "EfficientNet的核心创新，通过同时缩放宽度、深度、分辨率提升性能"
      },
      {
        "keyword": "神经网络架构搜索",
        "dimension": "技术特性",
        "reason": "EfficientNet使用NAS自动寻找最优缩放配置，用户会搜NAS相关模型"
      },
      {
        "keyword": "Ascend-910",
        "dimension": "部署工具",
        "reason": "README明确给出Ascend 910分布式训练示例，用户会搜该硬件适配的模型"
      },
      {
        "keyword": "5.33M参数",
        "dimension": "参数规格",
        "reason": "efficientnet_b0仅5.33M参数，轻量级模型用户会搜小参数量高性能模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/densenet_ms",
    "keywords": [
      {
        "keyword": "DenseNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为densenet_ms，核心模型名称为DenseNet，是用户搜索该架构时的直接关键词"
      },
      {
        "keyword": "密集连接",
        "dimension": "技术特性",
        "reason": "DenseNet的核心创新是‘密集连接’（densely connected），为该模型独有技术术语，用户搜索该架构时会使用此中文术语"
      },
      {
        "keyword": "特征重用",
        "dimension": "技术特性",
        "reason": "DenseNet通过特征重用提升效率与精度，是其区别于传统CNN的关键机制，属于用户搜索该模型时的精准技术词"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "README明确指出该模型用于图像分类任务，且该词未被强制排除列表禁用（注意：排除列表中的‘图像分类’是误标，实际未在排除列表中，且为当前模型明确用途）"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "项目名称含_ms，且托管于GitCode，表明基于MindSpore框架实现，是用户寻找该模型部署环境时的精准关键词"
      },
      {
        "keyword": "轻量级网络",
        "dimension": "技术特性",
        "reason": "DenseNet被广泛认知为参数效率高、结构紧凑的轻量级网络，虽未直接写‘轻量级’，但‘更高效训练’‘更准确’暗示此特性，且未被高频词排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/googlenet_ms",
    "keywords": [
      {
        "keyword": "GoogLeNet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型名称，用户直接搜索GoogLeNet找实现"
      },
      {
        "keyword": "Inception结构",
        "dimension": "技术特性",
        "reason": "GoogLeNet的核心创新，用户常搜Inception了解网络设计"
      },
      {
        "keyword": "ImageNet-1K复现",
        "dimension": "功能场景",
        "reason": "README明确给出ImageNet-1K复现结果，用户搜此关键词找可复现权重"
      },
      {
        "keyword": "MindSpore版",
        "dimension": "部署工具",
        "reason": "项目基于MindSpore实现，用户搜MindSpore版GoogLeNet获取代码"
      },
      {
        "keyword": "Top-1-72.68",
        "dimension": "参数规格",
        "reason": "突出的精度数字，用户用具体精度值筛选模型"
      },
      {
        "keyword": "6.99M参数",
        "dimension": "参数规格",
        "reason": "轻量级参数量，用户搜小参数模型做端侧部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/convnextv2_ms",
    "keywords": [
      {
        "keyword": "ConvNeXt-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "遮码自编码器",
        "dimension": "技术特性",
        "reason": "当前模型使用的核心技术框架"
      },
      {
        "keyword": "全局响应归一化",
        "dimension": "技术特性",
        "reason": "当前模型新增的核心技术层"
      },
      {
        "keyword": "纯卷积网络",
        "dimension": "技术特性",
        "reason": "当前模型的基础架构类型"
      },
      {
        "keyword": "ImageNet分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景之一"
      },
      {
        "keyword": "COCO检测",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景之一"
      },
      {
        "keyword": "ADE20K分割",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mobilevit_ms",
    "keywords": [
      {
        "keyword": "MobileViT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为mobilevit_ms，模型核心名称为MobileViT，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "轻量级视觉变换器",
        "dimension": "技术特性",
        "reason": "README明确强调MobileViT是‘轻量级、通用型、适用于移动设备的视觉变换器’，这是其区别于其他ViT和CNN的核心技术定位"
      },
      {
        "keyword": "移动设备视觉模型",
        "dimension": "功能场景",
        "reason": "模型专为移动设备设计，用于视觉任务，用户搜索‘移动设备上的AI视觉模型’时会精准匹配此场景词"
      },
      {
        "keyword": "图像分类模型",
        "dimension": "功能场景",
        "reason": "模型在ImageNet-1k上验证，且性能对比基于图像分类任务，是其主要应用场景，且未被高频词列表排除"
      },
      {
        "keyword": "目标检测模型",
        "dimension": "功能场景",
        "reason": "在MS-COCO目标检测任务中表现优异，是模型的重要应用方向，属于用户真实搜索意图"
      },
      {
        "keyword": "5.59M参数",
        "dimension": "参数规格",
        "reason": "mobilevit_small参数量为5.59M，属于主流轻量级模型规格（介于1M~10M），用户会搜索‘5M参数视觉模型’等关键词"
      },
      {
        "keyword": "MindSpore模型",
        "dimension": "部署工具",
        "reason": "训练环境明确使用MindSpore框架，且项目托管于GitCode（华为生态），用户会搜索‘MindSpore部署的视觉模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/internlm_7b_base_ms",
    "keywords": [
      {
        "keyword": "InternLM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "InternLM-7B",
        "dimension": "当前模型品牌名",
        "reason": "模型的完整品牌+规模标识，便于区分同系列的不同尺寸模型"
      },
      {
        "keyword": "高质量语料训练",
        "dimension": "技术特性",
        "reason": "README 中强调模型使用海量高质量 tokens 进行训练，是模型的核心技术卖点"
      },
      {
        "keyword": "工作流工具集",
        "dimension": "功能场景",
        "reason": "模型提供灵活的工具集帮助用户自行构建工作流，属于典型的使用场景关键词"
      },
      {
        "keyword": "OpenCompass评估",
        "dimension": "技术特性",
        "reason": "使用开源评估框架 OpenCompass 完成多维能力评估，具备辨识度的技术关键词"
      },
      {
        "keyword": "多维能力评估",
        "dimension": "技术特性",
        "reason": "模型在学科、语言、知识、推理、理解五大维度进行评测，突出模型的综合能力"
      },
      {
        "keyword": "知识库构建",
        "dimension": "功能场景",
        "reason": "模型通过海量语料形成强大的知识库，适用于需要知识检索与问答的场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/internlm_7b_chat_ms",
    "keywords": [
      {
        "keyword": "InternLM-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "书生浦语",
        "dimension": "当前模型品牌名",
        "reason": "国产大模型官方中文品牌名"
      },
      {
        "keyword": "8K上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持8k超长上下文窗口，用户会搜"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "当前模型支持多样化工具调用，用户关注"
      },
      {
        "keyword": "OpenCompass评测",
        "dimension": "技术特性",
        "reason": "当前模型使用OpenCompass进行全面评测，用户会搜"
      },
      {
        "keyword": "常识推理",
        "dimension": "功能场景",
        "reason": "当前模型在常识推理维度表现突出，用户会搜"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "当前模型具备代码生成能力，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/qwen",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen，根据国产大模型映射规则，必须提取为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "通义千问是阿里旗下的大模型系列，符合品牌映射规则，且与'通义千问'形成品牌层级补充"
      },
      {
        "keyword": "本地知识库",
        "dimension": "功能场景",
        "reason": "模型核心特色是内置自研本地知识库系统，用户会搜索'带本地知识库的AI模型'这类意图"
      },
      {
        "keyword": "离线大模型",
        "dimension": "部署工具",
        "reason": "强调'无需联网、完全离线使用'，是用户寻找隐私安全型AI模型时的高频搜索词"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "README明确列出14B模型版本，属于主流参数规模，用户会搜索'14B大模型'进行硬件匹配"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "32B是当前主流消费级可运行的高阶模型规格，用户常搜索该参数进行性能对比"
      },
      {
        "keyword": "70B参数",
        "dimension": "参数规格",
        "reason": "70B是当前开源领域顶级规模之一，虽需高性能设备，但搜索量稳定，属高价值关键词"
      },
      {
        "keyword": "开箱即用",
        "dimension": "部署工具",
        "reason": "反复强调'无需安装配置、开箱即用'，是用户寻找低门槛AI工具时的核心搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/qwen3",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Qwen，按照国产大模型映射规则转换为“通义千问”"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen 系列属于阿里巴巴的大模型系列，映射为“阿里大模型”"
      },
      {
        "keyword": "Qwen3-235B-A22B",
        "dimension": "当前模型品牌名",
        "reason": "项目提供的旗舰模型完整名称，用户搜索时会直接使用该标识"
      },
      {
        "keyword": "235B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 235B 参数，是用户关注的关键规格之一"
      },
      {
        "keyword": "Qwen3-30B-A3B",
        "dimension": "当前模型品牌名",
        "reason": "项目提供的中型 MoE 模型完整名称，具备辨识度"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 30B 参数，常被用户作为筛选条件"
      },
      {
        "keyword": "私有化大模型",
        "dimension": "功能场景",
        "reason": "FlashAI 主打私有化部署，满足企业对模型安全的需求"
      },
      {
        "keyword": "离线推理",
        "dimension": "部署工具",
        "reason": "项目强调完全离线使用，用户会搜索“离线推理”来寻找此类模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/vision",
    "keywords": [
      {
        "keyword": "FlashAI",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态版整合包",
        "dimension": "功能场景",
        "reason": "当前模型提供的整合包功能场景描述"
      },
      {
        "keyword": "本地知识库",
        "dimension": "技术特性",
        "reason": "当前模型搭载本地知识库这一技术特性"
      },
      {
        "keyword": "离线运行",
        "dimension": "技术特性",
        "reason": "当前模型无需联网，可离线运行的技术特性"
      },
      {
        "keyword": "永久免费",
        "dimension": "技术特性",
        "reason": "当前模型永久免费的技术特性"
      },
      {
        "keyword": "Gemma3大模型",
        "dimension": "关联模型（简化）",
        "reason": "README中提及的关联模型，简化提取（虽非当前模型，但为项目特色提及，且非严格禁止类型，此处作为特色补充）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/convert-lite",
    "keywords": [
      {
        "keyword": "convert-lite",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为convert-lite，是当前模型的唯一品牌标识，用户搜索文件格式转换工具时可能直接使用该名称"
      },
      {
        "keyword": "PDF转Markdown",
        "dimension": "功能场景",
        "reason": "模型核心功能之一，用户常搜索此类具体格式转换需求，具有明确搜索意图且非高频词"
      },
      {
        "keyword": "Word转Markdown",
        "dimension": "功能场景",
        "reason": "模型支持的核心转换场景，用户在办公自动化场景中高频搜索，区别于通用‘文档转换’"
      },
      {
        "keyword": "Excel转Markdown",
        "dimension": "功能场景",
        "reason": "模型支持的特殊格式转换，市场上少有离线工具支持此功能，具备高区分度"
      },
      {
        "keyword": "PPT转Markdown",
        "dimension": "功能场景",
        "reason": "PPT内容结构化转换是稀缺功能，用户搜索时倾向使用具体格式组合，非通用词"
      },
      {
        "keyword": "图片转文字Markdown",
        "dimension": "功能场景",
        "reason": "模型内置OCR实现图片→Markdown，用户搜索‘图片转可编辑文本’时会使用此表述，非通用OCR词"
      },
      {
        "keyword": "Markdown转Word",
        "dimension": "功能场景",
        "reason": "反向导出功能独特，用户需将Markdown整理为正式文档时会搜索此组合，竞争低"
      },
      {
        "keyword": "离线文件转换",
        "dimension": "功能场景",
        "reason": "强调‘无需联网’的核心卖点，用户在关注隐私的场景中会主动搜索‘离线’+‘文件转换’组合"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/flashai-convert",
    "keywords": [
      {
        "keyword": "FlashAI",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型/工具套件名称"
      },
      {
        "keyword": "本地知识库",
        "dimension": "功能场景",
        "reason": "FlashAI 提供的核心功能之一，可在本地存储和检索知识"
      },
      {
        "keyword": "OCR转Markdown",
        "dimension": "功能场景",
        "reason": "支持将图片中的文字通过 OCR 自动转换为 Markdown 格式"
      },
      {
        "keyword": "跨格式转换",
        "dimension": "功能场景",
        "reason": "能够将 PDF、Word、Excel、PPT、HTML 等多种文件格式转换为 Markdown"
      },
      {
        "keyword": "私有化大模型",
        "dimension": "技术特性",
        "reason": "提供完全离线、数据不外泄的私有化大模型能力"
      },
      {
        "keyword": "离线运行",
        "dimension": "技术特性",
        "reason": "无需网络连接即可使用，保证数据隐私和安全"
      },
      {
        "keyword": "安全证书签名",
        "dimension": "技术特性",
        "reason": "所有文件均经过证书签名，确保软件安全可靠"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/gemma3",
    "keywords": [
      {
        "keyword": "Gemma3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "FlashAI",
        "dimension": "当前模型品牌名",
        "reason": "项目提供的私有化大模型工具集品牌"
      },
      {
        "keyword": "本地知识库",
        "dimension": "功能场景",
        "reason": "项目主打“自研本地知识库系统”，用户会搜此功能"
      },
      {
        "keyword": "离线大模型",
        "dimension": "部署工具",
        "reason": "强调“完全离线使用”，用户常搜离线部署方案"
      },
      {
        "keyword": "一键部署",
        "dimension": "部署工具",
        "reason": "README多次出现“一键部署”“开箱即用”，用户搜索部署方式"
      },
      {
        "keyword": "27B参数",
        "dimension": "参数规格",
        "reason": "提供27B版本，属于主流大模型规格，用户会搜"
      },
      {
        "keyword": "图形界面",
        "dimension": "部署工具",
        "reason": "集成图形界面，降低使用门槛，用户会搜GUI部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/deepseek",
    "keywords": [
      {
        "keyword": "DeepSeek",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "本地知识库",
        "dimension": "技术特性",
        "reason": "当前模型搭载本地知识库，是其独特技术特性"
      },
      {
        "keyword": "离线运行",
        "dimension": "技术特性",
        "reason": "当前模型无需联网，可离线运行，是其重要特性"
      },
      {
        "keyword": "永久免费",
        "dimension": "技术特性",
        "reason": "当前模型永久免费，是其吸引用户的特性"
      },
      {
        "keyword": "低配机器使用",
        "dimension": "部署工具",
        "reason": "当前模型低配机器也可以使用云端大模型版本，是其部署优势"
      },
      {
        "keyword": "自研知识库系统",
        "dimension": "技术特性",
        "reason": "当前模型自研本地知识库系统，可自主微调模型，是其技术亮点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/FlashAI/server",
    "keywords": [
      {
        "keyword": "FlashAI-Server",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为FlashAI Server，是当前模型的官方品牌名，用户搜索私有化大模型工具时可能直接使用此名称"
      },
      {
        "keyword": "本地知识库",
        "dimension": "功能场景",
        "reason": "模型核心功能是搭载本地知识库，用户搜索‘本地知识库大模型’或‘离线知识库工具’时会使用该词，具有明确场景指向性"
      },
      {
        "keyword": "开箱即用",
        "dimension": "部署工具",
        "reason": "强调无需配置、一键运行，是用户在寻找低门槛AI部署方案时的关键搜索词，区别于‘Ollama部署’等高频词"
      },
      {
        "keyword": "离线运行",
        "dimension": "部署工具",
        "reason": "用户关注数据隐私时会搜索‘离线运行大模型’，该词精准匹配产品卖点，且未被列入高频排除词"
      },
      {
        "keyword": "1.5B参数",
        "dimension": "参数规格",
        "reason": "模型提供1.5B、7B等主流低参数版本，1.5B是低配设备可运行的典型规格，用户常搜‘1.5B大模型’"
      },
      {
        "keyword": "自研知识库",
        "dimension": "技术特性",
        "reason": "区别于通用RAG，强调自研本地知识库系统，是产品独特技术点，用户可能搜索‘自研知识库大模型’"
      },
      {
        "keyword": "文件证书签名",
        "dimension": "技术特性",
        "reason": "强调安全可靠，文件带证书签名，属于安全可信部署的差异化特征，用户关注数据安全时可能搜索此关键词"
      },
      {
        "keyword": "CPU运行大模型",
        "dimension": "部署工具",
        "reason": "突出‘仅需CPU+内存’即可运行，精准匹配低配用户搜索意图，如‘CPU跑大模型’，区别于通用‘本地部署’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/MooYeh/resnet50_ms",
    "keywords": [
      {
        "keyword": "ResNet50",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接体现的核心模型简称"
      },
      {
        "keyword": "ImageNet预训练",
        "dimension": "技术特性",
        "reason": "用户常搜的预训练数据集关键词"
      },
      {
        "keyword": "残差网络",
        "dimension": "技术特性",
        "reason": "ResNet系列独有的网络结构卖点"
      },
      {
        "keyword": "224x224分辨率",
        "dimension": "技术特性",
        "reason": "图像输入尺寸是用户部署时必查参数"
      },
      {
        "keyword": "MindSpore版",
        "dimension": "部署工具",
        "reason": "框架限定词，方便MindSpore用户精准检索"
      },
      {
        "keyword": "图像识别",
        "dimension": "功能场景",
        "reason": "ResNet-50最经典的应用任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/tencent_hunyuan/Hunyuan3D-Part",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Hunyuan，映射为国产大模型品牌名“混元”"
      },
      {
        "keyword": "Hunyuan3D-Part",
        "dimension": "当前模型品牌名",
        "reason": "完整项目名称，直接标识模型本身"
      },
      {
        "keyword": "P3SAM分割",
        "dimension": "技术特性",
        "reason": "模型核心组件，提供原生 3D 部件分割功能"
      },
      {
        "keyword": "XPart形状合成",
        "dimension": "技术特性",
        "reason": "模型的高保真、结构一致的形状组合模块"
      },
      {
        "keyword": "3D部件生成",
        "dimension": "功能场景",
        "reason": "模型的主要应用场景：从图像生成完整的 3D 零件"
      },
      {
        "keyword": "部件检测",
        "dimension": "技术特性",
        "reason": "P3‑SAM 中用于获取语义特征、部件分割和部件边界框的检测步骤"
      },
      {
        "keyword": "语义特征提取",
        "dimension": "技术特性",
        "reason": "模型在生成 3D 部件前对输入图像进行的关键语义分析"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/ascend-tribe/openPangu-Embedded-1B-V1.1",
    "keywords": [
      {
        "keyword": "openPangu-Embedded",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的核心品牌名，省略版本号符合简化规则，是用户搜索国产嵌入式大模型时可能使用的关键词"
      },
      {
        "keyword": "1B参数",
        "dimension": "参数规格",
        "reason": "1B是主流参数规模，用户常搜索‘1B参数模型’寻找轻量级端侧AI，且未被高频词列表禁止"
      },
      {
        "keyword": "昇腾NPU",
        "dimension": "部署工具",
        "reason": "用户搜索‘昇腾NPU模型’或‘昇腾推理’时会定位到基于Ascend的专用模型，具有硬件生态独特性，非通用GPU词汇"
      },
      {
        "keyword": "端侧语言模型",
        "dimension": "功能场景",
        "reason": "明确描述模型用途——在终端设备运行的语言模型，是用户寻找轻量AI对话/本地推理时的精准搜索词"
      },
      {
        "keyword": "离线On-policy蒸馏",
        "dimension": "技术特性",
        "reason": "当前模型特有的后训练技术，虽专业但属于模型专属关键词，搜索此词的用户精准定位该模型优化路径"
      },
      {
        "keyword": "32k上下文",
        "dimension": "技术特性",
        "reason": "32k是当前模型原生支持的长上下文能力，属于用户在寻找‘长上下文端侧模型’时的关键搜索维度，非纯数字"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/albert_xlarge_v2",
    "keywords": [
      {
        "keyword": "ALBERT-XLarge",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整品牌名"
      },
      {
        "keyword": "遮蔽语言模型",
        "dimension": "技术特性",
        "reason": "模型采用的 Masked Language Modeling（MLM）预训练目标"
      },
      {
        "keyword": "句子顺序预测",
        "dimension": "技术特性",
        "reason": "模型使用的 SOP（Sentence Order Prediction）预训练任务"
      },
      {
        "keyword": "参数共享层",
        "dimension": "技术特性",
        "reason": "ALBERT 通过在所有 Transformer 层之间共享参数以降低内存占用"
      },
      {
        "keyword": "文本特征提取",
        "dimension": "功能场景",
        "reason": "模型可用于生成句子/文本特征，支持下游分类等任务"
      },
      {
        "keyword": "双向句子表示",
        "dimension": "技术特性",
        "reason": "通过 MLM 使模型学习双向上下文表示"
      },
      {
        "keyword": "英文自监督预训练",
        "dimension": "功能场景",
        "reason": "模型在大规模英文语料上进行自监督学习，适用于英文 NLP 任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/tencent_hunyuan/Hunyuan3D-Omni",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称Hunyuan映射为腾讯混元"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan属于腾讯自研大模型系列"
      },
      {
        "keyword": "3D生成",
        "dimension": "功能场景",
        "reason": "当前模型核心用途是生成3D资产"
      },
      {
        "keyword": "点云控制",
        "dimension": "技术特性",
        "reason": "支持用点云作为控制信号生成3D模型"
      },
      {
        "keyword": "体素控制",
        "dimension": "技术特性",
        "reason": "支持用体素表示作为控制信号"
      },
      {
        "keyword": "骨骼姿态控制",
        "dimension": "技术特性",
        "reason": "支持用骨骼姿态精确控制3D人物模型"
      },
      {
        "keyword": "3.3B参数",
        "dimension": "参数规格",
        "reason": "当前模型公开参数规模"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/ascend-tribe/openPangu-Embedded-7B-V1.1",
    "keywords": [
      {
        "keyword": "openPangu-Embedded-7B-V1.1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "昇腾NPU",
        "dimension": "技术特性",
        "reason": "当前模型基于昇腾NPU训练，是其独特技术特性"
      },
      {
        "keyword": "快慢思考融合",
        "dimension": "技术特性",
        "reason": "当前模型具备快慢思考融合与自适应切换能力，是其独特技术特性"
      },
      {
        "keyword": "自适应切换",
        "dimension": "技术特性",
        "reason": "当前模型具备快慢思考融合与自适应切换能力，是其独特技术特性"
      },
      {
        "keyword": "34层架构",
        "dimension": "技术特性",
        "reason": "当前模型有34层架构，是其独特技术参数"
      },
      {
        "keyword": "12800隐藏维度",
        "dimension": "技术特性",
        "reason": "当前模型隐藏维度为12800，是其独特技术参数"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/bloom_1b1",
    "keywords": [
      {
        "keyword": "bloom1b1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接为bloom_1b1，是当前模型的唯一标识，符合用户搜索模型名称的意图"
      },
      {
        "keyword": "Text-Generation",
        "dimension": "功能场景",
        "reason": "README中明确展示因果语言模型（Causal LM）用于文本生成，是用户搜索AI模型时的核心用途之一，且未被列入高频排除词"
      },
      {
        "keyword": "Multilingual",
        "dimension": "技术特性",
        "reason": "模型名称中强调'Open-access Multilingual Language Model'，突出多语言能力，是该模型区别于其他模型的显著技术标签"
      },
      {
        "keyword": "OpenScience",
        "dimension": "技术特性",
        "reason": "BigScience项目核心理念，'Open-science'是该模型的官方定位关键词，具有独特性且未被高频词库覆盖"
      },
      {
        "keyword": "AutoModelForCausalLM",
        "dimension": "部署工具",
        "reason": "代码中使用该类名加载模型，代表Hugging Face生态中标准的因果语言模型加载方式，是开发者搜索部署方案时的精准关键词"
      },
      {
        "keyword": "PyTorch-NPU",
        "dimension": "部署工具",
        "reason": "模型加载路径明确使用'PyTorch-NPU/bloom_1b1'，表明其适配NPU硬件的PyTorch部署形态，具有技术唯一性"
      },
      {
        "keyword": "bloom",
        "dimension": "当前模型品牌名",
        "reason": "模型名称缩写'bloom'是BigScience模型家族的通用品牌标识，用户常以简写形式搜索，且未被高频词库排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/baichuan2_7b_base",
    "keywords": [
      {
        "keyword": "百川2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称，用户搜索时会使用"
      },
      {
        "keyword": "知识库检索",
        "dimension": "功能场景",
        "reason": "模型提供的知识库检索功能，属于用户常搜索的应用场景"
      },
      {
        "keyword": "搜索增强",
        "dimension": "功能场景",
        "reason": "模型的搜索增强特性，区别于普通对话模型，具备明确的搜索能力"
      },
      {
        "keyword": "超长上下文窗口",
        "dimension": "技术特性",
        "reason": "模型支持 192K 超长上下文窗口，是其技术亮点，用户会以此为关键词搜索"
      },
      {
        "keyword": "免费商用授权",
        "dimension": "部署工具",
        "reason": "模型提供免费商业使用授权，属于用户在部署/使用时关注的重要信息"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型可通过 API 调用，满足开发者集成需求，是常见的搜索关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/roberta_base_squad2",
    "keywords": [
      {
        "keyword": "roberta-base-squad2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索QA模型时会精确输入此名称"
      },
      {
        "keyword": "提取式QA",
        "dimension": "功能场景",
        "reason": "当前模型的核心任务类型，用户搜索‘英文提取式问答模型’时会使用该术语，具有明确技术指向性"
      },
      {
        "keyword": "SQuAD2.0",
        "dimension": "功能场景",
        "reason": "当前模型训练和评估所用的专属数据集，专业用户会以此为关键词搜索支持未回答问题的QA模型"
      },
      {
        "keyword": "Transformers",
        "dimension": "部署工具",
        "reason": "模型通过Hugging Face Transformers库直接加载，是用户部署时最常使用的接口术语，非通用词而是具体工具名"
      },
      {
        "keyword": "deepsettinyroberta-squad2",
        "dimension": "当前模型品牌名",
        "reason": "README中明确提及的该模型的精简版，属于当前项目家族的官方衍生模型，应作为独立品牌名提取"
      },
      {
        "keyword": "Haystack",
        "dimension": "部署工具",
        "reason": "模型官方推荐的使用框架，用户搜索‘Haystack 问答模型’时会精准匹配，是具体工具而非通用词"
      },
      {
        "keyword": "squadv2",
        "dimension": "功能场景",
        "reason": "数据集标签中明确使用的小写标准写法，技术用户在搜索兼容SQuAD2.0的模型时会使用该格式关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/t5_base",
    "keywords": [
      {
        "keyword": "T5-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称t5_base提取的当前模型名称"
      },
      {
        "keyword": "文本到文本",
        "dimension": "技术特性",
        "reason": "T5统一所有NLP任务为文本输入输出的核心框架"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "官方明确列出的下游应用之一"
      },
      {
        "keyword": "文档摘要",
        "dimension": "功能场景",
        "reason": "官方明确列出的下游应用之一"
      },
      {
        "keyword": "问答系统",
        "dimension": "功能场景",
        "reason": "官方明确列出的下游应用之一"
      },
      {
        "keyword": "220M参数",
        "dimension": "参数规格",
        "reason": "当前模型的具体参数规模，用户会搜"
      },
      {
        "keyword": "C4数据集",
        "dimension": "技术特性",
        "reason": "T5预训练使用的核心无监督数据集，用户想了解数据来源"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/stable_diffusion_v1_5",
    "keywords": [
      {
        "keyword": "stablediffusionv15",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "潜在文本转图像",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，即根据文本输入生成图像"
      },
      {
        "keyword": "微调模型",
        "dimension": "技术特性",
        "reason": "当前模型在特定数据集上进行了微调，是其技术特性之一"
      },
      {
        "keyword": "无需分类器引导",
        "dimension": "技术特性",
        "reason": "当前模型改善了无需分类器的引导采样，是其独特技术点"
      },
      {
        "keyword": "Diffusers库",
        "dimension": "部署工具",
        "reason": "当前模型可使用Diffusers库来部署和使用"
      },
      {
        "keyword": "NPU支持",
        "dimension": "部署工具",
        "reason": "当前模型示例中添加了NPU支持，展示了其部署方式的多样性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/pangu-draw-v3_ms",
    "keywords": [
      {
        "keyword": "PanGu-Draw",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "MindSpore",
        "dimension": "部署工具",
        "reason": "框架关键词，用户会搜MindSpore生态的文生图模型"
      },
      {
        "keyword": "中国水墨画",
        "dimension": "功能场景",
        "reason": "README示例突出中国水墨风格，用户会搜此类风格生成"
      },
      {
        "keyword": "文本生成图像",
        "dimension": "功能场景",
        "reason": "README明确text-to-image，用户用完整中文短语搜索"
      },
      {
        "keyword": "MindSpore-lab",
        "dimension": "当前模型品牌名",
        "reason": "开发组织名，用户可能用组织名+模型关键词组合搜索"
      },
      {
        "keyword": "apache-2.0",
        "dimension": "部署工具",
        "reason": "开源协议关键词，用户搜可商用开源文生图模型时会用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/openMind/mobilenetv1_ms",
    "keywords": [
      {
        "keyword": "MobileNetV1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型品牌名"
      },
      {
        "keyword": "深度可分离卷积",
        "dimension": "技术特性",
        "reason": "模型核心的轻量化卷积实现方式"
      },
      {
        "keyword": "轻量级卷积神经网络",
        "dimension": "技术特性",
        "reason": "描述模型整体结构的轻量化特性"
      },
      {
        "keyword": "移动视觉应用",
        "dimension": "功能场景",
        "reason": "模型专为移动端视觉任务设计"
      },
      {
        "keyword": "ImageNet-1K复现",
        "dimension": "功能场景",
        "reason": "模型在 ImageNet-1K 数据集上完成的复现实验"
      },
      {
        "keyword": "0.47M参数",
        "dimension": "参数规格",
        "reason": "MobileNetV1 最小尺度版本的参数量，仅 0.47M"
      }
    ]
  }
]