# 模型关键词提取分析报告

## 概览统计

- 📊 **CSV读取模型数**: 217
- ✅ **成功提取模型数**: 217
- ❌ **失败模型数**: 0
- 📈 **成功率**: 100.0%
- 🔍 **原始关键词总数**: 1457
- ✂️ **去重后关键词总数**: 950
- 📉 **去重率**: 34.8%
- 📊 **平均每模型关键词数**: 4.4
- 🕐 **生成时间**: 2025-10-22 16:44:03

## 维度分布

| 维度 | 关键词数量 | 占比 |
|------|------------|------|
| 技术特性 | 349 | 36.7% |
| 功能场景 | 241 | 25.4% |
| 当前模型品牌名 | 204 | 21.5% |
| 部署工具 | 82 | 8.6% |
| 参数规格 | 60 | 6.3% |
| 训练数据 | 3 | 0.3% |
| 当前模型品牌名（变体） | 2 | 0.2% |
| 许可证 | 2 | 0.2% |
| 数据集 | 2 | 0.2% |
| 许可协议 | 1 | 0.1% |
| 开发者/品牌 | 1 | 0.1% |
| 结果表现 | 1 | 0.1% |
| 部署/使用方式 | 1 | 0.1% |
| 关联模型（简化） | 1 | 0.1% |

## 原始数据高频关键词分析

> 基于去重前的原始提取数据，展示整个数据集中最常见的关键词

| 排名 | 关键词 | 原始出现次数 | 最终保留次数 |
|------|--------|-------------|-------------|
| 1 | MoE架构 | 14 | 1 |
| 2 | 7B参数 | 13 | 1 |
| 3 | 多模态 | 13 | 1 |
| 4 | 文心一言 | 13 | 1 |
| 5 | Transformer | 12 | 1 |
| 6 | 智能对话 | 12 | 1 |
| 7 | PyTorch | 12 | 1 |
| 8 | 百度大模型 | 12 | 1 |
| 9 | 图像分类 | 12 | 1 |
| 10 | MindSpore | 12 | 1 |
| 11 | 本地部署 | 11 | 1 |
| 12 | 通义千问 | 11 | 1 |
| 13 | 量化模型 | 11 | 1 |
| 14 | 阿里大模型 | 10 | 1 |
| 15 | 编程助手 | 10 | 1 |
| 16 | HuggingFace | 10 | 1 |
| 17 | AI写作 | 10 | 1 |
| 18 | 文生图 | 10 | 1 |
| 19 | 自回归模型 | 9 | 1 |
| 20 | NPU支持 | 9 | 1 |

## 所有关键词列表


### 关联模型（简化） (1个)

- **Gemma3大模型**

### 功能场景 (246个)

- **10000字生成** • **1000任务** • **100种语言** • **16k中文VAD** • **30语言覆盖**
- **32K对话** • **3D生成** • **3D部件生成** • **50种语言** • **720P视频生成**
- **ADE20K分割** • **AI写作** • **AI推理** • **AI训推全流程工具链** • **Agent任务**
- **Aishell-1** • **Alpaca微调** • **COCO检测** • **COCO目标检测** • **Excel转Markdown**
- **GLUE基准** • **ImageNet-1K** • **ImageNet-1K复现** • **ImageNet-1K评测** • **ImageNet-1k**
- **ImageNet分类** • **ImageNet预训练** • **LJSpeech** • **LJSpeech声码器** • **LLaMA复现**
- **MNLI** • **MS-COCO-2017** • **Markdown转Word** • **MobileNet优化** • **NLP任务**
- **NLU任务** • **OCR转Markdown** • **PDF转Markdown** • **PPT转Markdown** • **Python专家**
- **RAG框架** • **RAP哼唱** • **SQuAD-1.12.0** • **SQuAD-2.0** • **SQuAD2.0**
- **Text-Generation** • **VTAB基准** • **WTQ微调** • **WikiTable-Question** • **Word转Markdown**
- **many-to-many翻译** • **squadv2** • **text2text-generation** • **下一句预测** • **不区分大小写**
- **中国水墨画** • **中文-英语翻译** • **中文标点预测** • **中文英文双语** • **中文语音识别**
- **中英双语** • **中英双语大模型** • **中英双语对话** • **人体姿态估计** • **代码与数学领域**
- **代码修复** • **代码合成** • **代码推理** • **代码理解** • **代码生成**
- **代码补全** • **代码解释器** • **免费商用** • **公式识别** • **内容识别**
- **压缩图像恢复** • **命名实体识别** • **商用许可开源** • **国内数据合规** • **图像-文本检索**
- **图像分割** • **图像分类** • **图像分类器** • **图像分类模型** • **图像到图像**
- **图像到文本** • **图像到视频** • **图像描述** • **图像放大2倍** • **图像标注**
- **图像标题生成** • **图像特征提取** • **图像理解** • **图像生成** • **图像编辑**
- **图像编辑指令** • **图像识别** • **图像超分辨率** • **图像转3D** • **图文理解**
- **图片转文字Markdown** • **基础模型** • **填充掩码** • **声纹识别** • **多任务微调**
- **多模态大模型** • **多模态推理** • **多模态版整合包** • **多语种语言模型** • **多语言**
- **多语言分类** • **多语言大模型** • **多语言支持** • **多语言模型** • **多语言翻译**
- **多语言能力** • **多语言词性标注** • **实时对象检测** • **实时检测** • **实时目标检测**
- **实时语音交互** • **对象检测** • **小样本图像分类** • **少样本学习** • **工作流工具集**
- **工具调用** • **布局检测** • **带时间戳字幕** • **带标点语音识别** • **常识推理**
- **开源大模型** • **开源大语言模型** • **开源视频模型** • **情感分析** • **手机端BERT**
- **推理模型** • **掩码填空** • **掩码语言建模** • **掩码语言模型** • **提取式QA**
- **搜索增强** • **数字字母型** • **数学推理** • **文图相互增强** • **文本MoE后训练模型**
- **文本到文本** • **文本到视频** • **文本到视频生成** • **文本密集型** • **文本密集型基础模型**
- **文本特征提取** • **文本生成** • **文本生成图像** • **文本补全** • **文本转3D**
- **文本转图像** • **文本转语音** • **文档摘要** • **文档检索** • **文生图**
- **文生文** • **文生视频** • **时间戳语音识别** • **智能体任务** • **智能体工具调用**
- **智能对话** • **本地知识库** • **机器翻译** • **极速文生图** • **模型微调**
- **法语NER** • **潜在文本转图像** • **热词定制** • **百川搜索增强** • **目标检测**
- **目标检测模型** • **知识库构建** • **知识库检索** • **离线文件转换** • **私有化大模型**
- **移动定制计算机视觉** • **移动端CNN** • **移动视觉** • **移动视觉应用** • **移动设备视觉模型**
- **稳定扩散** • **端侧语言模型** • **纯字母型** • **纯数字型** • **纯文本标点**
- **结构化数据理解** • **编程助手** • **聊天模型** • **自动驾驶挑战冠军** • **自然语言推理**
- **英文-中文翻译** • **英文文本分类** • **英文文本生成** • **英文自监督预训练** • **英文预训练**
- **英文预训练模型** • **英语语言模型** • **英语预训练** • **英语预训练模型** • **蛋白质特征提取**
- **表格识别** • **表格问答** • **视觉主干网络** • **视觉检索** • **视觉理解**
- **视觉语言模型** • **视觉语言理解** • **视觉迁移学习** • **视觉问答** • **视频合成**
- **语义分割** • **语音克隆** • **语音端点检测** • **语音识别** • **语音识别后处理**
- **说话人验证** • **跨格式转换** • **跨模态推理** • **跨语言NER** • **轻量化检测**
- **轻量级BERT** • **轻量级CNN** • **轻量级图像分类** • **通用OCR** • **长文本处理**
- **长文本对话** • **长文本生成** • **长文生成** • **长音频切分** • **长音频识别**
- **问答任务** • **问答系统** • **阅读顺序** • **零样本图像分类** • **零样本视频语言**
- **项目级代码补全** • **预训练翻译模型** • **验证码识别** • **高分辨率文生图** • **高性能检测器**
- **高效ConvNet**

### 参数规格 (61个)

- **0.3B参数** • **0.47M参数** • **1.5B参数** • **1.7B参数** • **1.8B参数**
- **1024像素** • **124M参数** • **128K词表** • **1300亿参数** • **130亿参数**
- **131K上下文** • **13B参数** • **14B参数** • **1B参数** • **2.34M参数模型**
- **20B参数** • **21B参数** • **220M参数** • **224分辨率** • **235B参数**
- **27B参数** • **28B参数** • **28M参数** • **3.3B参数** • **300B参数**
- **30B参数** • **32B参数** • **32K上下文** • **33B参数** • **34B参数**
- **39B激活参数** • **3B参数** • **4.85M参数** • **424B参数** • **42M参数**
- **47B参数** • **4B参数** • **5.2M参数** • **5.33M参数** • **5.59M参数**
- **512序列长度** • **564M参数** • **6.7B参数** • **6.99M参数** • **60M参数**
- **6B参数** • **7.7亿参数** • **70B参数** • **718B参数** • **724M参数**
- **7B参数** • **7B模型** • **83.24-Top-1** • **86.7M参数** • **8B参数**
- **9B参数** • **9亿参数** • **Top-1-72.68** • **bitresnet50** • **小参数量**
- **小型模型**

### 开发者/品牌 (1个)

- **Helsinki-NLP**

### 当前模型品牌名 (205个)

- **ALBERT-Large-v2** • **ALBERT-XLarge** • **ALBERT-XXLarge-v2** • **ALBERT-base** • **ALBERT-v2**
- **Aquila-7B** • **AquilaChat** • **BERT-base** • **BERT-base-cased** • **BERT-base-uncased**
- **BERT-large** • **BERT基础版** • **BLIP** • **BLIP-image-captioning-large** • **BLOOM**
- **Baichuan-7B** • **Baichuan2** • **BiT** • **BigTransfer** • **BlueLM**
- **ByT5** • **ByT5-base** • **ByteT5** • **CMT** • **ChatGLM2-6B**
- **ChatGLM3-6B** • **ChatGLM3-6B-32K** • **ChatGLM3-6B-Base** • **CoaT** • **ColPali**
- **ConViT** • **Conformer** • **ConvNeXT** • **ConvNeXt** • **ConvNeXt-V2**
- **CrossViT** • **DeBERTa-XLarge** • **DeBERTa-v3-base** • **DeepSeek** • **DeepSeek-Coder**
- **DeepSeek-R1** • **DeepSeek-R1-Distill-Qwen-1.5B** • **DeepSpeech2** • **DenseNet** • **DiT**
- **DistilBERT** • **DistilBERT-SST-2** • **ECAPA-TDNN** • **ERNIE-4.5** • **ERNIE-4.5-0.3B**
- **ERNIE-4.5-300B-A47B-Base** • **ERNIE-4.5-VL** • **EdgeNeXt** • **EfficientNet** • **FLAN-T5**
- **FSMN-VAD** • **Falcon-7B** • **FastSpeech2** • **FlashAI** • **FlashAI-Server**
- **FunASR** • **GLM-4** • **GLM-Edge** • **GOT-OCR20** • **GPT-1**
- **GPT-2** • **Gemma-3** • **Gemma3** • **GhostNet** • **GoogLeNet**
- **HRNet** • **HaloNet** • **Hunyuan3D-Part** • **HunyuanVideo** • **InceptionV3**
- **InceptionV4** • **InstructPix2Pix** • **InternLM** • **InternLM-20B** • **InternLM-7B**
- **InternLM2** • **Janus-Pro** • **Latte** • **Llama-3.1** • **Llama2-Chinese-7b-Chat**
- **LongWriter-glm4-9b** • **Meissonic** • **MindSpore-lab** • **Mistral-7B** • **MixNet**
- **MnasNet** • **MobileBERT** • **MobileNetV1** • **MobileNetV3** • **MobileViT**
- **ModelEngine** • **NasNet** • **OpenLLaMA** • **OpenSora** • **Opus-MT**
- **PanGu-Draw** • **Paraformer** • **Paraformer-large** • **PiT** • **ProtBert**
- **QwQ-32B** • **QwQ模型** • **Qwen1.5-1.8b** • **Qwen2.5-Coder-7B** • **Qwen2.57BInstruct**
- **Qwen3-235B-A22B** • **Qwen3-30B-A3B** • **RemBERT** • **ResNet-50** • **ResNet50**
- **SD-XL** • **SDXL-Lightning** • **SigLIP** • **SoViT-400m** • **Stable-Diffusion-v2**
- **Step-Audio** • **Swin2SR** • **T5-Base** • **T5-Large** • **T5-Small**
- **TAPAS** • **TeleChat** • **TeleChat-12B** • **TeleChat-7B** • **ViT-base**
- **VideoLDM** • **Wan2.1** • **Wan2.2** • **WaveGrad** • **XGLM-1.7B**
- **XGLM-564M** • **XLM-RoBERTa** • **YOLOv10x** • **YOLOv4** • **YOLOv5**
- **YOLOv8-ms** • **YOLOv9** • **beitbasepatch16** • **bloom** • **bloom1b1**
- **bloom7b1** • **camembert-ner** • **chatglm** • **codellama34bms** • **convert-lite**
- **debertabase** • **deepsettinyroberta-squad2** • **dots-ocr** • **dpn107** • **dpn131**
- **dpn92** • **dpn98** • **flan-t5** • **mBART-large-50** • **mT5**
- **mobilenet-v3-large** • **mobilenet-v3-small** • **mobilenetv2ms** • **mt5base** • **mt5large**
- **ocrsmall** • **openPangu-Embedded** • **openPangu-Embedded-1B** • **openPangu-Embedded-7B** • **openPangu-Embedded-7B-V1.1**
- **openPangu-Ultra-MoE-718B** • **openai-gpt** • **puncct-transformer** • **qwen1.57b** • **roberta-base-squad2**
- **sdv2base** • **stablediffusionv15** • **svdms** • **t5small** • **v1.5版本**
- **videocomposerms** • **vitmsnbase** • **xlnetbasecased** • **yolov3ms** • **yolov7ms**
- **yoloxms** • **书生浦语** • **字节跳动大模型** • **悟道天鹰** • **文心4.5**
- **文心4.5-VL** • **文心一言** • **星辰语义大模型** • **智谱AI** • **智谱清言**
- **混元** • **百川2** • **百川大模型** • **百川大模型2** • **百度大模型**
- **稳定视频扩散** • **腾讯大模型** • **通义千问** • **阿里大模型** • **高分辨率网络**

### 当前模型品牌名（变体） (2个)

- **coatlitemini** • **coatlitetiny**

### 技术特性 (368个)

- **1000-tasks** • **101语言** • **12800隐藏维度** • **128K上下文** • **131K上下文**
- **16K上下文** • **16K上下文窗口** • **16K窗口** • **16k上下文** • **192K长上下文**
- **192K长上下文窗口** • **192K长文本窗口** • **192K长窗口** • **1T中文数据集** • **1T标记训练**
- **200K上下文** • **224x224分辨率** • **224分辨率** • **24层瓶颈结构** • **299x299输入尺寸**
- **2位量化** • **32K上下文** • **32K上下文长度** • **32k上下文** • **34层架构**
- **384x384分辨率** • **3D-VAE** • **4位量化** • **4位量化模型** • **4比特量化**
- **500亿子词** • **60层架构** • **87.8-top-1** • **8K上下文** • **Apache-2.0许可**
- **Apache-2.0许可协议** • **Apache-License-2.0** • **BMTrain并行** • **BMTrain并行训练** • **Batch-Normalization**
- **Bert架构** • **Blocked-Self-Attention** • **Byte-level-tokenization** • **C4数据集** • **CEval领先**
- **CIoU损失** • **CLIP-ViTL** • **CLS标记** • **CMMLU领先** • **CNN-Transformer融合**
- **COCO预训练** • **CSPDarknet53** • **CTC损失** • **Cinematic-level-Aesthetics** • **ColBERT策略**
- **CommonCrawl数据** • **ConformerBlock** • **ConvNet现代化** • **CreativeML-Open-RAIL-M** • **Decoding-enhanced**
- **DiT** • **Disentangled-Attention** • **DropBlock正则化** • **ELECTRA风格预训练** • **Encoder-decoder架构**
- **Enhanced-Mask-Decoder** • **EulerAncestralDiscreteScheduler** • **F0音调特征** • **FCMAE** • **FP8混合精度**
- **FP8混合精度训练** • **Few-shot能力** • **FlashAttention** • **Function-Call** • **GELAN架构**
- **GLM混合目标函数** • **GPSA** • **GQA注意力** • **GQA注意力机制** • **GRN层**
- **Ghost模块** • **Ghost瓶颈** • **GroupNorm** • **Haloing操作** • **ImageNet-1K**
- **ImageNet-1k** • **ImageNet-21k** • **ImageNet1K性能** • **ImageNet预训练** • **Inception-ResNet-v2**
- **Inception结构** • **Latent-Diffusion-Model** • **Latent-Diffusion-Transformer** • **LoRA** • **LoRA微调**
- **LoRA模型** • **MIT许可** • **MLM预训练** • **MSN预训练** • **Mish激活**
- **MixConv** • **MoE架构** • **Monophone建模** • **Mosaic数据增强** • **Multi-Query-Attention**
- **Multi-head-Latent-Attention** • **Multilingual** • **NAS搜索** • **NPU加速** • **NetAdapt微调**
- **OCR-2.0** • **OpenCLIP** • **OpenCLIP-ViTG** • **OpenCompass评估** • **OpenCompass评测**
- **OpenScience** • **P3SAM分割** • **P5架构** • **P5系列模型** • **Patch16**
- **Patchify** • **PixArt初始化** • **PyTorch** • **RefinedWeb-1.5万亿标记** • **Refiner模型**
- **ResNetv2** • **ResNet现代化** • **SDEdit** • **SDTA编码器** • **SE模块**
- **SFT** • **SOTA水平** • **SentencePiece** • **SigLIP-L** • **Sigmoid-Loss**
- **SimOTA标签分配** • **Squeeze-Excitation** • **SwiGLU激活函数** • **SwinV2-Transformer** • **T5架构**
- **Text-To-Text** • **Text-To-Text-Transfer-Transformer** • **Transformer** • **Transformer-XL** • **Transformer架构**
- **Transformer结构** • **UNet模型** • **VAE压缩** • **ViT** • **ViT主干网络**
- **WebLi预训练** • **Weight-Standardisation** • **XPart形状合成** • **few-shot-performance** • **instruction-tuning**
- **mC4** • **mC4预训练** • **mc4数据集** • **multiquery** • **vision**
- **一键精调** • **下一句预测** • **专家集成** • **两阶段生成** • **中文指令集**
- **中文渲染** • **中文语料40** • **中文预训练** • **中英文高质量语料** • **中间预训练**
- **交叉注意力模块** • **仅解码器语言模型** • **价值对齐** • **位置自注意力** • **低代码编排**
- **体素控制** • **倒置残差** • **全局响应归一化** • **全新Prompt格式** • **分阶段训练**
- **动态角色切换** • **区分大小写** • **协同尺度卷积注意力** • **卷积分解** • **卷积增强Transformer**
- **卷积神经网络遇见视觉变换器** • **参数共享层** • **参数高效** • **双分支架构** • **双向-LSTM**
- **双向句子表示** • **双文本编码器** • **双编码器** • **双路径网络** • **句子排序预测**
- **句子顺序预测** • **可扩展扩散模型** • **可控时延标点** • **可编程梯度信息** • **商业许可**
- **因果变压器** • **因果解码器模型** • **因果语言模型** • **国内数据合规** • **图像深度条件**
- **在线速度扰动** • **填空任务** • **增强型掩码解码** • **复合缩放** • **多尺度上下文建模**
- **多尺度特征** • **多模态** • **多模态OCR** • **多模态异构MoE** • **多模态异构MoE预训练**
- **多模态预训练** • **多维能力评估** • **多语言支持** • **大规模多语言模型** • **大规模混合专家语言模型**
- **大迁移** • **字节到字节** • **字节级Transformer** • **字节级模型** • **安全证书签名**
- **密集连接** • **对话流畅** • **小写实体识别** • **少样本学习** • **局部图像条件**
- **局部注意力门控** • **层权重共享** • **广义自回归预训练** • **序列到序列** • **开放科学开放获取**
- **开源复现** • **开源模型** • **异构MoE** • **异构混合专家** • **异构混合并行主义**
- **引导标注** • **强化学习** • **微调模型** • **快思考模型** • **快慢思考融合**
- **快慢思考融合能力** • **思维模式切换** • **思维链推理** • **情感方言控制** • **扩散模型**
- **扩散模型声码器** • **指令微调** • **指令精调模型** • **推理能力** • **掩码Transformer**
- **掩码语言建模** • **提示词重写** • **数学推理** • **文件证书签名** • **文本到文本**
- **文本到文本框架** • **文本到文本模型** • **无token模型** • **无损量化** • **无监督多语言**
- **无监督微调** • **无监督预训练** • **无锚框检测器** • **无需trustremotecode** • **无需分类器引导**
- **时间层扩展** • **昇腾NPU** • **未区分大小写** • **本地知识库** • **梅尔频谱**
- **梅尔频谱图转波形** • **梯度解耦嵌入共享** • **模型框架** • **模型蒸馏** • **模态特定后训练**
- **模态隔离路由** • **残差网络** • **残差连接** • **永久免费** • **池化视觉模型**
- **深度卷积与逐点卷积** • **深度可分离卷积** • **深度学习** • **混合深度卷积** • **渐进式对抗扩散蒸馏**
- **潜在扩散** • **潜在扩散模型** • **点云控制** • **热词增强** • **特征重用**
- **相对位置嵌入** • **神经架构搜索** • **神经网络架构搜索** • **离线On-policy蒸馏** • **离线运行**
- **私有化大模型** • **科学数据配比学习** • **空间-时间token** • **空间维度递减** • **端到端OCR**
- **端到端TTS** • **端到端检测** • **端到端模型** • **纯卷积网络** • **纯解码器语言模型**
- **线性瓶颈** • **绝对位置嵌入** • **统一偏好优化** • **统一多模态** • **统一文本格式**
- **编码器-解码器** • **缩放效率化基础设施** • **自回归模型** • **自我验证** • **自监督预训练**
- **自研知识库** • **自研知识库系统** • **自适应切换** • **草图条件** • **蒙版条件**
- **蒸馏模型** • **规模效率化基础设施** • **视觉编码解耦** • **视觉语言模型** • **视觉语言预训练**
- **视觉转换器** • **视频扩散模型** • **解耦头** • **解耦注意力** • **词嵌入层与输出层解耦**
- **词嵌入层解耦** • **语义特征提取** • **语义理解** • **课程学习** • **超长上下文窗口**
- **跨模态推理** • **跨语言表示学习** • **跨语言迁移学习** • **软卷积归纳偏置** • **轻量化模型**
- **轻量级MHSA** • **轻量级卷积神经网络** • **轻量级深度卷积** • **轻量级网络** • **轻量级视觉变换器**
- **轻量级预训练** • **运动控制** • **通道注意力** • **遮码自编码器** • **遮蔽块预测**
- **遮蔽语言建模** • **遮蔽语言模型** • **部件检测** • **量化模型** • **链式思维**
- **长上下文** • **长距离依赖性** • **非绑定嵌入** • **非自回归** • **非自回归语音识别**
- **马卡龙结构** • **骨骼姿态控制** • **高质量语料训练**

### 数据集 (2个)

- **BookCorpus** • **Wikipedia**

### 结果表现 (1个)

- **ImageNet基准超越**

### 训练数据 (3个)

- **C4数据集** • **OPUS数据集** • **Wikipedia多语言预训练**

### 训练细节 (1个)

- **C4数据集**

### 许可协议 (1个)

- **CreativeML-Open-RAIL-M**

### 许可证 (2个)

- **Apache-2.0许可证** • **CC-BY-4.0许可证**

### 部署/使用方式 (1个)

- **商业授权免费**

### 部署工具 (84个)

- **4bit量化版** • **API调用** • **Apache-License-2.0** • **Ascend-910** • **Ascend-910训练**
- **AutoModelForCausalLM** • **CANN兼容** • **CPU运行大模型** • **ComfyUI** • **ComfyUI插件**
- **Diffusers** • **Diffusers库** • **EasyLM框架** • **FP8量化** • **FastDeploy**
- **FunASR** • **Gradio** • **Haystack** • **HuggingFace** • **HuggingFace权重**
- **HuggingFace模型** • **HuggingFace部署** • **INT4量化** • **JAX** • **JAX权重**
- **LMDeploy** • **MindAudio** • **MindSpore** • **MindSpore声码器** • **MindSpore框架**
- **MindSpore模型** • **MindSpore模式** • **MindSpore版** • **MindSpore训练** • **MindYOLO**
- **NPU加速** • **NPU推理** • **NPU支持** • **NPU部署** • **ONNX**
- **Ollama部署** • **OpenMind** • **PaddlePaddle** • **PaddlePaddle部署** • **PyTorch**
- **PyTorch-NPU** • **PyTorch实现** • **SafeTensors** • **Safetensors** • **StableDiffusionInstructPix2PixPipeline**
- **TensorFlow** • **Transformers** • **Ultralytics部署** • **apache-2.0** • **diffusers**
- **openMind框架** • **openMind适配** • **vLLM** • **web网页版** • **一键部署**
- **低配机器使用** • **免费商用授权** • **分布式训练** • **图形界面** • **图模式训练**
- **宽松开源协议** • **开源商业授权** • **开源模型** • **开箱即用** • **昇思MindSpore**
- **昇腾910** • **昇腾NPU** • **昇腾NPU优化** • **昇腾平台适配** • **本地部署**
- **模型推送Hub** • **离线大模型** • **离线推理** • **离线运行** • **端侧推理**
- **量化模型** • **飞桨框架** • **飞桨部署** • **鸿蒙PC**

## 详细结果


### openMind/GOT-OCR2_0

**URL**: https://ai.gitcode.com/openMind/GOT-OCR2_0

**关键词列表**:

- **GOT-OCR20** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，用户搜索OCR模型时会直接使用此名称
- **通用OCR** (功能场景): README开篇明确强调'通用OCR理论'，是模型的核心功能定位，用户常搜索'通用OCR'寻找多场景文本识别方案
- **端到端OCR** (技术特性): README中提到'统一的端到端模型实现OCR-2.0'，是模型区别于传统OCR的关键技术特征，用户会搜索此术语
- **多模态OCR** (技术特性): GOT-OCR2_0支持图像与文本联合理解，属于多模态OCR范畴，符合当前AI OCR主流搜索意图
- **HuggingFace部署** (部署工具): README明确提供transformers库加载方式，用户常搜索'HuggingFace部署'寻找可快速调用的OCR模型
- **OCR-2.0** (技术特性): 模型自称实现'OCR-2.0'，是行业新兴概念，用户会主动搜索该术语寻找新一代OCR技术
- **本地部署** (部署工具): 模型支持在NVIDIA GPU上本地运行，符合大量开发者搜索'本地部署OCR'的需求，且未依赖云API

### yanfan/yuijh

**URL**: https://ai.gitcode.com/yanfan/yuijh

**关键词列表**:

- **通义千问** (当前模型品牌名): 项目模型为Qwen2.5-Coder，根据国产大模型映射规则，Qwen必须映射为'通义千问'
- **阿里大模型** (当前模型品牌名): Qwen系列为阿里云研发，符合'Qwen → 阿里大模型'映射规则
- **7B参数** (参数规格): 模型明确发布7B参数版本，属于用户常搜的主流参数规格
- **编程助手** (功能场景): 模型专为代码生成、代码推理、代码修复设计，是典型的编程助手场景
- **代码生成** (功能场景): README明确提到'Significantly improvements in code generation'，是核心用户搜索意图
- **代码修复** (功能场景): README明确列出'code fixing'作为核心能力，用户常搜索此类具体功能
- **Transformer** (技术特性): 模型基于Transformer架构（从标签和Qwen系列技术背景推断），是用户搜索AI模型时的高频技术词
- **长上下文** (技术特性): README提及'Long-context Support'，虽未写全，但'长上下文'是中文用户搜索代码模型的常用表达

### openMind/yolov10x

**URL**: https://ai.gitcode.com/openMind/yolov10x

**关键词列表**:

- **YOLOv10x** (当前模型品牌名): 项目名称即模型品牌名，用户搜索时会直接使用
- **实时目标检测** (功能场景): 模型定位为 Real‑Time Object Detection，用户常以此需求检索
- **端到端检测** (技术特性): README 中明确标注为 End‑to‑End 检测，是模型的核心技术特性
- **对象检测** (功能场景): 模型的主要任务是通用目标（对象）检测，搜索频率高
- **Ultralytics部署** (部署工具): 模型通过 ultralytics 库加载与使用，是常见的部署方式
- **模型推送Hub** (部署工具): README 提供 model.push_to_hub 接口，用户会搜索如何将模型推送到 Hub

### openMind/Wan2.1-T2V-14B-Diffusers

**URL**: https://ai.gitcode.com/openMind/Wan2.1-T2V-14B-Diffusers

**关键词列表**:

- **Wan2.1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文生视频** (功能场景): 当前模型主打视频生成能力
- **14B参数** (参数规格): 当前模型的主流规格
- **Diffusers** (部署工具): 官方已适配Diffusers库，方便本地部署
- **开源视频模型** (功能场景): 用户搜索开源视频生成模型时的常用词
- **HuggingFace** (部署工具): 官方已上架HuggingFace，支持一键调用

### yanfan/tx467

**URL**: https://ai.gitcode.com/yanfan/tx467

**关键词列表**:

- **32B参数** (参数规格): 模型明确为32B参数规模，属于主流用户搜索的参数规格（如7B/13B/32B）
- **智能对话** (功能场景): 模型为Instruct版本，强调指令跟随与对话能力，符合用户搜索'智能对话'类AI模型的意图
- **量化模型** (部署工具): 模型后缀为GPTQ-Int4，属于主流量化部署方式，用户常搜索'量化模型'以降低部署门槛
- **长文本生成** (功能场景): README强调支持128K上下文和生成超过8K tokens的长文本，用户会搜索'长文本生成'类应用场景

### yanfan/yuxp1

**URL**: https://ai.gitcode.com/yanfan/yuxp1

**关键词列表**:

- **Qwen2.5-Coder-7B** (当前模型品牌名): 从项目名称提取的当前模型名称，简化后为Qwen2.5-Coder-7B
- **代码推理** (功能场景): 当前模型的核心功能之一，用于代码推理
- **因果语言模型** (技术特性): 当前模型采用的技术架构特性
- **Transformer结构** (技术特性): 当前模型采用的技术架构特性

### tencent_hunyuan/Tencent-Hunyuan-Large

**URL**: https://ai.gitcode.com/tencent_hunyuan/Tencent-Hunyuan-Large

**关键词列表**:

- **混元** (当前模型品牌名): 项目名称为Tencent-Hunyuan-Large，根据国产大模型映射规则，Hunyuan必须映射为'混元'
- **腾讯大模型** (当前模型品牌名): Hunyuan是腾讯出品，符合映射规则，'腾讯大模型'是用户搜索国产大模型时的常用泛称
- **AI写作** (功能场景): 大语言模型常用于文本生成，'AI写作'是中文用户搜索LLM应用的高频场景词
- **PyTorch** (部署工具): 模型提供HuggingFace下载链接，PyTorch是HuggingFace生态主流框架，用户常搜'PyTorch模型'进行本地部署

### yanfan/uytyb

**URL**: https://ai.gitcode.com/yanfan/uytyb

**关键词列表**:

- **Meissonic** (当前模型品牌名): 项目 README 中的模型名称，即当前模型的品牌名
- **文生图** (功能场景): 模型用于文本到图像的生成，是用户搜索的核心应用场景
- **高分辨率文生图** (功能场景): 模型能够生成高分辨率图像，用户常以此关键词寻找高质量文本生成图像模型
- **掩码Transformer** (技术特性): 模型基于掩码生成式 Transformer，是其独特的技术实现方式
- **非自回归** (技术特性): 模型采用非自回归的掩码图像建模技术，用户会以此关键词搜索相关模型

### tencent_hunyuan/HunyuanVideo-PromptRewrite

**URL**: https://ai.gitcode.com/tencent_hunyuan/HunyuanVideo-PromptRewrite

**关键词列表**:

- **提示词重写** (技术特性): README明确将'提示词重写'列为HunyuanVideo的关键特性之一，是模型独特技术环节
- **3D-VAE** (技术特性): README中明确列为HunyuanVideo的核心架构组件，属于独特技术术语，用户可能针对性搜索
- **130亿参数** (参数规格): 模型参数规模达130亿，属于主流大模型规格，用户常通过参数规模筛选模型

### tencent_hunyuan/Hunyuan3D-1

**URL**: https://ai.gitcode.com/tencent_hunyuan/Hunyuan3D-1

**关键词列表**:

- **图像转3D** (功能场景): README明确提到'图像转3D生成'，是用户直接搜索的明确功能场景
- **文本转3D** (功能场景): README明确标注支持'文本转3D生成'，是核心功能，用户会直接搜索
- **ComfyUI** (部署工具): README中明确列出ComfyUI为支持的部署方式，是用户部署时高频搜索词
- **扩散模型** (技术特性): 模型第一阶段采用多视角扩散模型，是核心技术术语，用户搜索3D生成时常用

### yanfan/colpali

**URL**: https://ai.gitcode.com/yanfan/colpali

**关键词列表**:

- **ColPali** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **视觉检索** (功能场景): README明确描述为Visual Retriever，用户会搜视觉检索
- **文档检索** (功能场景): README核心用途是Efficient Document Retrieval
- **多模态** (技术特性): 基于Vision Language Models，具备多模态能力
- **ColBERT策略** (技术特性): 采用ColBERT风格的多向量表示，技术关键词
- **3B参数** (参数规格): 基于PaliGemma-3B，用户会搜3B参数模型

### ModelEngine/Model-OpenSource-images

**URL**: https://ai.gitcode.com/ModelEngine/Model-OpenSource-images

**关键词列表**:

- **ModelEngine** (当前模型品牌名): 项目名称直接给出的品牌名
- **AI训推全流程工具链** (功能场景): 用户搜索一站式AI开发平台的高频词
- **RAG框架** (功能场景): README强调的核心能力，用户会搜RAG开发工具
- **模型微调** (功能场景): 模型使能模块主打能力，用户直接搜模型微调工具
- **低代码编排** (技术特性): 降低使用门槛的卖点，用户搜低代码AI平台
- **一键精调** (技术特性): 无代码操作亮点，用户会搜一键微调/精调工具

### tencent_hunyuan/HunyuanVideo

**URL**: https://ai.gitcode.com/tencent_hunyuan/HunyuanVideo

**关键词列表**:

- **HunyuanVideo** (当前模型品牌名): 项目名称本身即为模型品牌名
- **文本到视频** (功能场景): 模型支持从文本生成视频，是核心应用场景
- **图像到视频** (功能场景): 模型同样提供从图像生成视频的能力
- **Gradio** (部署工具): 项目提供基于 Gradio 的 Web 演示，用户可直接部署使用
- **13B参数** (参数规格): 模型拥有约130亿（13B）参数，是当前开源模型中规模最大的之一

### paddlepaddle/ERNIE-4.5-21B-A3B-Base-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-Base-Paddle

**关键词列表**:

- **文心一言** (当前模型品牌名): ERNIE是百度大模型品牌，根据国产大模型映射规则，ERNIE → 文心一言
- **百度大模型** (当前模型品牌名): ERNIE是百度自研大模型系列，'百度大模型'是用户常用搜索词，符合品牌映射规则
- **MoE架构** (技术特性): 模型核心创新点为多模态异构MoE结构，用户搜索AI模型时会关注MoE架构
- **21B参数** (参数规格): 模型名称中明确包含21B，属于主流参数规模，用户常按参数量搜索模型

### paddlepaddle/ERNIE-4.5-0.3B-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-Paddle

**关键词列表**:

- **文本生成** (功能场景): 模型描述为'文本密集型后训练模型'，主要用途为文本生成，符合用户搜索意图（如'AI写作'、'文本生成'）
- **4位量化** (技术特性): 模型支持'4位/2位无损量化'，'4位量化'是用户关注的轻量化部署关键词，符合主流规格表达
- **SFT** (技术特性): 模型使用监督微调（SFT）作为后训练方法，SFT是AI从业者搜索模型训练方法时的常用缩写关键词

### paddlepaddle/ERNIE-4.5-300B-A47B-Base-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-Base-PT

**关键词列表**:

- **文本补全** (功能场景): 该基础版模型仅支持文本补全功能，是用户搜索的主要使用场景
- **300B参数** (参数规格): 模型名称中包含 300B，表示参数规模，用户常以参数量搜索模型
- **vLLM** (部署工具): 推荐使用 vLLM 的 completion 接口进行推理，属于常见部署方式
- **FastDeploy** (部署工具): 模型支持在 FastDeploy 中使用，适合作为 API 调用或本地部署

### paddlepaddle/ERNIE-4.5-VL-28B-A3B-Base-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-Base-Paddle

**关键词列表**:

- **28B参数** (参数规格): 模型参数规模为28B，属于主流大模型规格，用户常按参数量筛选模型（如7B/13B/28B/72B）

### paddlepaddle/ERNIE-4.5-300B-A47B-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-Paddle

**关键词列表**:

- **47B参数** (参数规格): 模型激活参数为47B，属于主流大模型规格（如7B/13B/70B附近），用户常按参数规模搜索

### paddlepaddle/ERNIE-4.5-300B-A47B-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-PT

**关键词列表**:

- **ERNIE-4.5** (当前模型品牌名): 从项目名称提取的当前模型名称，ERNIE映射为百度大模型相关，但此处保留具体版本号更精确
- **多模态异构MoE** (技术特性): 当前模型的核心技术特性，多模态与MoE架构的结合
- **模态隔离路由** (技术特性): 当前模型为实现多模态有效表示而采用的关键技术
- **缩放效率化基础设施** (技术特性): 当前模型在训练过程中采用的异构混合并行性和分层负载均衡策略
- **文本MoE后训练模型** (功能场景): 当前模型的具体应用场景和类型描述

### paddlepaddle/ERNIE-4.5-VL-28B-A3B-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-Paddle

**关键词列表**:

- **视觉语言模型** (功能场景): 模型在 VLM 方向进行微调，支持图文交互、图像理解与生成
- **跨模态推理** (功能场景): 模型具备文本‑图像联合推理能力，可完成跨模态问答与推理任务
- **PaddlePaddle** (部署工具): 模型基于 PaddlePaddle 框架，可在多硬件平台上部署和推理

### paddlepaddle/ERNIE-4.5-21B-A3B-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-PT

**关键词列表**:

- **无损量化** (技术特性): 模型支持4位/2位无损量化，是推理部署中用户关注的核心优化技术

### paddlepaddle/ERNIE-4.5-0.3B-Base-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-Base-PT

**关键词列表**:

- **0.3B参数** (参数规格): 模型参数规模为0.3B，属于轻量级主流规格，用户会搜索'0.3B参数'类模型进行轻量部署
- **统一偏好优化** (技术特性): 模型采用自研的UPO（统一偏好优化）方法进行后训练，是区别于DPO/SFT的原创技术术语

### paddlepaddle/ERNIE-4.5-21B-A3B-Base-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-Base-PT

**关键词列表**:

- **2位量化** (技术特性): 模型提出4位/2位无损量化算法，'2位量化'是稀缺且具区分度的部署关键词，用户会搜索低比特推理模型
- **多模态推理** (功能场景): 模型强调文本与视觉联合训练与跨模态推理能力，'多模态推理'是用户搜索视觉语言模型时的精准意图词

### paddlepaddle/ERNIE-4.5-VL-424B-A47B-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-Paddle

**关键词列表**:

- **图文理解** (功能场景): 视觉语言模型主打能力，用户直接搜“图文理解”
- **424B参数** (参数规格): 424B 为显式公开参数规模，属于用户会搜的大模型规格
- **飞桨部署** (部署工具): 基于 Paddle 框架，开发者常搜“飞桨部署”找落地方案

### paddlepaddle/ERNIE-4.5-21B-A3B-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-21B-A3B-Paddle

**关键词列表**:

- **FP8混合精度** (技术特性): 训练时使用 FP8 混合精度以提升吞吐量，是模型的独特优化手段
- **PaddlePaddle部署** (部署工具): 模型基于 PaddlePaddle 框架实现，适合在该生态中本地或云端部署

### paddlepaddle/ERNIE-4.5-0.3B-Base-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-Base-Paddle

**关键词列表**:

- **异构混合并行主义** (技术特性): 当前模型训练时采用的高效并行策略
- **文本密集型基础模型** (功能场景): 当前模型的主要应用场景和类型描述

### paddlepaddle/ERNIE-4.5-300B-A47B-Base-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-Base-Paddle

**关键词列表**:

- **ERNIE-4.5-300B-A47B-Base** (当前模型品牌名): 从项目名称直接提取的当前模型完整名称，符合品牌名提取规范，虽含数字但为模型官方标识，且无更简版本可用
- **异构MoE** (技术特性): 模型核心创新点，区别于普通MoE，强调多模态异构路由结构，是用户搜索高性能MoE模型时的精准技术关键词
- **多模态预训练** (技术特性): 模型在文本与视觉模态联合训练的核心能力，用户搜索跨模态AI模型时高频使用，且非通用词，具区分度
- **视觉语言理解** (功能场景): 模型在VLMs方向的明确应用场景，用户搜索图文理解类AI工具时常用此词，非泛泛描述

### paddlepaddle/ERNIE-4.5-VL-28B-A3B-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-28B-A3B-PT

**关键词列表**:

- **文心4.5-VL** (当前模型品牌名): 直接取自项目名称，标识该模型的品牌与版本
- **4比特量化** (技术特性): 推理阶段使用 4 比特无损量化，显著降低算力需求
- **思维链推理** (技术特性): 模型支持多模态思维链推理，提升复杂任务的推理能力

### paddlepaddle/ERNIE-4.5-VL-424B-A47B-Base-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-Base-Paddle

**关键词列表**:

- **异构混合专家** (技术特性): 模型核心创新架构，原文明确提及'异构混合专家架构'，是区别于普通MoE的独特技术点，用户会搜索此类专业但非泛化的架构关键词
- **多模态大模型** (功能场景): 模型明确用于视觉语言理解，原文定义为'多模态大模型(VLM)'，是用户搜索AI图文理解类应用时的典型关键词，且未被强制排除
- **动态角色切换** (技术特性): 原文提出'PD解耦技术'实现动态角色切换，是提升推理效率的专属机制，术语独特，非通用词，具备高搜索价值
- **分阶段训练** (技术特性): 模型采用'前两阶段仅训练文本参数→最终引入视觉模块'的分阶段训练策略，是区别于端到端训练的显著技术特征，用户会搜索此类训练方法
- **文图相互增强** (功能场景): 原文核心目标为'实现图文模态的相互增强'，精准描述模型能力，是用户搜索图文协同任务时的自然搜索词，非泛化表达

### paddlepaddle/ERNIE-4.5-VL-424B-A47B-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-PT

**关键词列表**:

- **文心4.5** (当前模型品牌名): ERNIE-4.5-VL-424B-A47B-PT 的简称，用户搜索国产大模型时常用
- **图像理解** (功能场景): VLM 版本主打视觉语言理解，用户搜索多模态能力时常用
- **飞桨框架** (部署工具): 基于 PaddlePaddle 优化，开发者搜索部署方案时会提及

### paddlepaddle/ERNIE-4.5-300B-A47B-FP8-Paddle

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-300B-A47B-FP8-Paddle

**关键词列表**:

- **FP8量化** (部署工具): 低比特无损量化，部署热点

### paddlepaddle/ERNIE-4.5-0.3B-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-0.3B-PT

**关键词列表**:

- **ERNIE-4.5-0.3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多模态异构MoE预训练** (技术特性): 当前模型在文本和视觉两种模态上联合训练的独特技术
- **规模效率化基础设施** (技术特性): 当前模型有效训练的独特基础设施策略
- **模态特定后训练** (技术特性): 当前模型针对不同模态变体进行微调的独特方法
- **文本密集型** (功能场景): 当前模型主要应用于文本密集型任务的描述

### saulcy/punc_ct-transformer_zh-cn-common-vocab272727-pytorch

**URL**: https://ai.gitcode.com/saulcy/punc_ct-transformer_zh-cn-common-vocab272727-pytorch

**关键词列表**:

- **puncct-transformer** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，是用户搜索中文标点预测模型时可能使用的精准关键词
- **中文标点预测** (功能场景): 模型核心用途是为中文文本添加标点，属于用户在AI语音后处理场景中明确搜索的功能词
- **FunASR** (部署工具): 模型基于FunASR框架，是用户在寻找中文ASR+标点联合部署方案时会搜索的工具名称
- **可控时延标点** (技术特性): 模型核心创新点是'Controllable Time-delay'，中文用户会搜索'可控时延'来寻找避免标点刷新的解决方案
- **语音识别后处理** (功能场景): 模型专用于ASR输出文本的标点补全，是语音AI工程中明确的下游任务，用户会直接搜索该场景词
- **纯文本标点** (功能场景): 模型支持纯文本输入标点预测，区别于端到端ASR，是独立应用场景，用户会用此词搜索非语音输入的标点工具

### ascend-tribe/openpangu-embedded-1b-model

**URL**: https://ai.gitcode.com/ascend-tribe/openpangu-embedded-1b-model

**关键词列表**:

- **openPangu-Embedded-1B** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简化命名规范（无版本号后缀）
- **端侧语言模型** (功能场景): 模型明确设计用于端侧设备运行，是用户搜索轻量级AI对话模型时的核心意图词
- **快思考模型** (技术特性): README中多次强调'快思考'，是该模型区别于传统大模型的核心能力标签，用户会搜索此类术语
- **1B参数** (参数规格): 1B是主流轻量级参数规模，用户常搜索'1B参数模型'寻找端侧部署方案，符合规格提取规则
- **昇腾NPU** (部署工具): 模型专为昇腾NPU优化，是国产AI开发者搜索适配Ascend硬件模型时的关键搜索词
- **GQA注意力** (技术特性): GQA（分组查询注意力）是模型高效架构的关键技术，属于专业但可搜索的技术关键词，非通用术语
- **32k上下文** (技术特性): 32k是端侧模型中罕见的长上下文能力，用户会搜索'32k上下文语言模型'寻找轻量长文本处理方案

### paddlepaddle/ERNIE-4.5-VL-424B-A47B-Base-PT

**URL**: https://ai.gitcode.com/paddlepaddle/ERNIE-4.5-VL-424B-A47B-Base-PT

**关键词列表**:

- **ERNIE-4.5-VL** (当前模型品牌名): 直接取自项目名称的核心品牌标识
- **FP8混合精度训练** (技术特性): 采用 FP8 混合精度提升训练效率，是模型的独特技术特征

### ascend-tribe/openpangu-ultra-moe-718b-model

**URL**: https://ai.gitcode.com/ascend-tribe/openpangu-ultra-moe-718b-model

**关键词列表**:

- **openPangu-Ultra-MoE-718B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **大规模混合专家语言模型** (技术特性): 当前模型的核心技术特性描述
- **快慢思考融合能力** (技术特性): 当前模型具备的独特能力
- **Multi-head-Latent-Attention** (技术特性): 当前模型架构采用的技术
- **718B参数** (参数规格): 当前模型的总参数量
- **39B激活参数** (参数规格): 当前模型的激活参数量

### saulcy/speech_fsmn_vad_zh-cn-16k-common-pytorch

**URL**: https://ai.gitcode.com/saulcy/speech_fsmn_vad_zh-cn-16k-common-pytorch

**关键词列表**:

- **FSMN-VAD** (当前模型品牌名): 从项目名称提取的当前模型简称，用户搜索时会用
- **语音端点检测** (功能场景): 模型核心功能，用户直接搜索该场景
- **16k中文VAD** (功能场景): 明确采样率与语言，用户精准搜索
- **Monophone建模** (技术特性): 模型独特技术亮点，区别于传统VAD
- **长音频切分** (功能场景): 典型应用需求，用户搜索如何切分长语音
- **PyTorch实现** (部署工具): 用户常搜PyTorch版本以方便本地部署

### ascend-tribe/openpangu-embedded-7b-model

**URL**: https://ai.gitcode.com/ascend-tribe/openpangu-embedded-7b-model

**关键词列表**:

- **openPangu-Embedded-7B** (当前模型品牌名): 项目名称直接定义的当前模型品牌，符合用户搜索AI模型时的精确命名习惯
- **快慢思考融合** (技术特性): 模型核心创新点，用户搜索‘具备快慢思考的AI模型’时可能命中此独特能力
- **GQA注意力机制** (技术特性): GQA（分组查询注意力）是模型架构关键设计，技术型用户会搜索此术语寻找高效推理模型

### openharmony-models/ChatGLM3-6B

**URL**: https://ai.gitcode.com/openharmony-models/ChatGLM3-6B

**关键词列表**:

- **ChatGLM3-6B** (当前模型品牌名): 项目名称直接提供的模型完整品牌名
- **6B参数** (参数规格): 模型规模为 6 B 参数，是用户常搜索的规格关键词
- **工具调用** (功能场景): ChatGLM3-6B 原生支持 Function Call（工具调用）功能
- **代码解释器** (功能场景): 模型内置 Code Interpreter（代码解释器）能力，适合编程辅助
- **Agent任务** (功能场景): 支持 Agent 任务的执行，覆盖更复杂的智能应用

### openharmony-models/Speech_Paraformer_ASR_6K

**URL**: https://ai.gitcode.com/openharmony-models/Speech_Paraformer_ASR_6K

**关键词列表**:

- **Paraformer** (当前模型品牌名): 项目名称为Speech_Paraformer_ASR_6K，模型核心名称为Paraformer，是达摩院自研的非自回归ASR框架，符合品牌名提取规则且无其他模型混淆
- **中文语音识别** (功能场景): 模型明确针对中文语音识别优化，训练数据为数万小时中文标注音频，是用户在CSDN等平台搜索中文ASR时的高频意图词
- **长音频识别** (功能场景): README强调‘可直接对时长为数小时音频进行识别’，这是该模型区别于普通短语音识别的核心应用场景，用户会搜索‘长音频识别’
- **带标点语音识别** (功能场景): 模型输出包含标点符号，是工业级语音识别的关键需求，用户搜索‘带标点语音识别’可精准匹配该功能
- **时间戳语音识别** (功能场景): 模型支持输出时间戳，适用于会议纪要、字幕生成等场景，是用户在AI语音应用中明确搜索的垂直功能词
- **热词增强** (技术特性): 模型提供‘热词版’并支持基于列表的激励增强，提升热词召回率，是工业部署中独特且用户会搜索的技术点
- **非自回归语音识别** (技术特性): 模型结构明确为非自回归（non-autoregressive），区别于传统自回归ASR，是技术型用户搜索高性能语音模型时的关键词

### openharmony-models/ocr_small

**URL**: https://ai.gitcode.com/openharmony-models/ocr_small

**关键词列表**:

- **ocrsmall** (当前模型品牌名): 从项目名称提取的当前模型名称
- **验证码识别** (功能场景): 当前模型的主要应用场景
- **纯数字型** (功能场景): 当前模型可识别的验证码类型之一
- **数字字母型** (功能场景): 当前模型可识别的验证码类型之一
- **纯字母型** (功能场景): 当前模型可识别的验证码类型之一
- **web网页版** (部署工具): 当前模型提供的代码使用方式之一

### openharmony-models/dots.ocr

**URL**: https://ai.gitcode.com/openharmony-models/dots.ocr

**关键词列表**:

- **dots-ocr** (当前模型品牌名): 项目名称直接提取的模型品牌名
- **布局检测** (功能场景): 模型能够统一进行文档的布局检测
- **内容识别** (功能场景): 模型在单一视觉‑语言模型中实现文本内容的识别
- **表格识别** (功能场景): 在 OmniDocBench 上实现 SOTA 表格解析能力
- **公式识别** (功能场景): 提供与更大模型相当的公式识别效果
- **阅读顺序** (功能场景): 保持良好的文档阅读顺序是模型的核心特性
- **1.7B参数** (参数规格): 模型采用 1.7B 参数的轻量化 LLM 基础

### openharmony-models/Qwen-Image

**URL**: https://ai.gitcode.com/openharmony-models/Qwen-Image

**关键词列表**:

- **中文渲染** (技术特性): README强调在中文文本渲染上的显著优势
- **图像编辑** (功能场景): README指出具备精确图像编辑能力

### saulcy/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch

**URL**: https://ai.gitcode.com/saulcy/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch

**关键词列表**:

- **Paraformer-large** (当前模型品牌名): 项目名称直接给出的当前模型系列
- **热词定制** (功能场景): 模型支持通过热词列表提升专有名词召回，用户高频需求
- **带时间戳字幕** (功能场景): 直接输出每句话对应时间，满足会议纪要、字幕生成需求

### openharmony-models/Wan2.2-T2V-A14B

**URL**: https://ai.gitcode.com/openharmony-models/Wan2.2-T2V-A14B

**关键词列表**:

- **Wan2.2** (当前模型品牌名): 从项目名称 openharmony-models/Wan2.2-T2V-A14B 中提取的核心模型品牌名，符合简化规则，去除了冗余后缀T2V-A14B
- **Cinematic-level-Aesthetics** (技术特性): 模型明确强调‘电影级美学’作为核心创新点，是区别于其他视频模型的独特卖点，用户可能搜索‘电影级视频生成’等变体
- **视频扩散模型** (技术特性): README中提及‘video diffusion models’，是当前模型的技术基础，用户搜索‘视频扩散模型’时会精准匹配，且未被强制排除

### openharmony-models/t5_small

**URL**: https://ai.gitcode.com/openharmony-models/t5_small

**关键词列表**:

- **t5small** (当前模型品牌名): 从项目URL和README标题提取的当前模型名称
- **Text-To-Text-Transfer-Transformer** (技术特性): 当前模型的核心技术框架描述
- **统一文本格式** (技术特性): 当前模型将所有NLP任务统一为文本输入输出的特性
- **NLP任务** (功能场景): 当前模型的应用领域
- **模型框架** (技术特性): 当前模型使用的技术框架类型

### openMind/LongWriter-glm4-9b

**URL**: https://ai.gitcode.com/openMind/LongWriter-glm4-9b

**关键词列表**:

- **LongWriter-glm4-9b** (当前模型品牌名): 项目名称直接定义的当前模型全称，符合用户搜索具体模型的意图
- **智谱AI** (当前模型品牌名): 根据国产大模型映射规则，GLM-4 对应 '智谱AI'，是用户搜索国产长文本模型时的高频品牌词
- **长文生成** (功能场景): 模型核心能力是一次性生成10,000+字长文，用户会搜索'长文生成'而非泛泛的'AI写作'
- **10000字生成** (功能场景): 模型明确支持生成10000+字内容，该具体数字场景是用户精准搜索的关键词，具有强意图性
- **chatglm** (当前模型品牌名): 模型基于GLM-4，且代码中使用'model.chat()'，用户常搜索'chatglm'作为GLM系列对话模型的统称

### openharmony-models/DeepSeek-R1-Distill-Llama-8B

**URL**: https://ai.gitcode.com/openharmony-models/DeepSeek-R1-Distill-Llama-8B

**关键词列表**:

- **DeepSeek-R1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **链式思维** (技术特性): 当前模型通过强化学习自然涌现的思维链能力
- **自我验证** (技术特性): 当前模型在推理过程中具备的自我验证与反思能力
- **强化学习** (技术特性): 当前模型采用的大规模强化学习后训练方法
- **8B参数** (参数规格): 当前模型的主流参数规模

### openMind/Llama2-Chinese-7b-Chat

**URL**: https://ai.gitcode.com/openMind/Llama2-Chinese-7b-Chat

**关键词列表**:

- **Llama2-Chinese-7b-Chat** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索中文优化Llama2模型时的精准关键词
- **LoRA微调** (技术特性): 模型采用LoRA微调技术提升中文能力，是开发者关注的高效适配方法，具技术区分度
- **中文指令集** (技术特性): 模型核心训练方式为中文指令集微调，是区别于原版Llama2的关键技术标签

### openharmony-models/DeepSeek-R1-Distill-Qwen-7B

**URL**: https://ai.gitcode.com/openharmony-models/DeepSeek-R1-Distill-Qwen-7B

**关键词列表**:

- **鸿蒙PC** (部署工具): 特定的操作系统平台适配信息，用户搜索时会关注该平台的部署支持

### MooYeh/instruct-pix2pix

**URL**: https://ai.gitcode.com/MooYeh/instruct-pix2pix

**关键词列表**:

- **InstructPix2Pix** (当前模型品牌名): 项目名称直接来源，是用户搜索该模型时最可能使用的精准品牌名
- **图像编辑指令** (功能场景): 模型核心能力是根据自然语言指令修改图像，用户会搜索‘图像编辑指令’这类具体功能词
- **图像到图像** (功能场景): 模型本质是图像到图像转换（image-to-image），是其区别于普通文生图模型的关键特征，用户搜索‘图像到图像生成’时会命中
- **StableDiffusionInstructPix2PixPipeline** (部署工具): 这是官方代码中调用的唯一核心类名，开发者会直接搜索该类名进行部署，属于精准技术关键词
- **diffusers** (部署工具): 模型依赖Hugging Face diffusers库部署，开发者常搜索‘diffusers 图像编辑’来寻找相关模型
- **EulerAncestralDiscreteScheduler** (技术特性): 模型使用该特定调度器，是其推理配置中的关键组件，技术用户会搜索该调度器名来复现效果

### openMind/Qwen2.5_7B_Instruct

**URL**: https://ai.gitcode.com/openMind/Qwen2.5_7B_Instruct

**关键词列表**:

- **Qwen2.57BInstruct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **指令精调模型** (技术特性): 当前模型为指令精调模型，属于其技术特性
- **代码与数学领域** (功能场景): 当前模型在代码与数学领域表现突出，属于其应用场景
- **结构化数据理解** (功能场景): 当前模型具备结构化数据理解能力，属于其应用场景
- **多语言支持** (功能场景): 当前模型覆盖29种语言，属于其功能场景

### MooYeh/bloom_7b1

**URL**: https://ai.gitcode.com/MooYeh/bloom_7b1

**关键词列表**:

- **bloom7b1** (当前模型品牌名): 项目名称直接为bloom_7b1，是当前模型的唯一标识，用户搜索时会使用该精确名称
- **Text-Generation** (功能场景): 模型标签中明确包含'Text Generation'，且示例为指令响应生成，符合用户搜索'文本生成模型'的意图
- **多语言** (功能场景): README开篇强调'多语言开放访问语言模型'，是该模型区别于其他英文模型的核心功能，用户会搜索'多语言大模型'
- **自回归模型** (技术特性): bloom系列是典型自回归语言模型，虽未明写，但根据其因果语言建模（Causal LM）结构和示例代码可合理推断，属于用户搜索的底层技术分类

### openMind/blip_vqa_base

**URL**: https://ai.gitcode.com/openMind/blip_vqa_base

**关键词列表**:

- **BLIP** (当前模型品牌名): 从项目名称blip_vqa_base提取的当前模型品牌名
- **视觉问答** (功能场景): README中明确提到的核心功能
- **图像标题生成** (功能场景): 当前模型支持的条件/无条件图像标题生成能力
- **ViT主干网络** (技术特性): README中提到的ViT基础主干网络架构
- **视觉语言预训练** (技术特性): 当前模型采用的VLP技术路线

### openMind/albert_large_v2

**URL**: https://ai.gitcode.com/openMind/albert_large_v2

**关键词列表**:

- **ALBERT-Large-v2** (当前模型品牌名): 项目名称为albert_large_v2，按规则保留简洁品牌名，不带版本号后缀，符合用户搜索习惯
- **遮蔽语言建模** (技术特性): 模型核心预训练目标之一，用户搜索BERT类模型时常用关键词，且未被高频词列表排除
- **句子顺序预测** (技术特性): ALBERT独有预训练任务，区别于BERT的NSP，具有高区分度，用户在对比模型时可能搜索
- **TensorFlow** (部署工具): 模型支持框架，与PyTorch并列，是主流框架搜索词，符合用户查找可部署版本的需求
- **英语语言模型** (功能场景): 模型明确用于英语语料预训练，用户搜索‘英语NLP模型’或‘英文BERT’时会使用该词，具场景指向性
- **层权重共享** (技术特性): ALBERT核心创新点，区别于BERT的参数效率设计，用户研究轻量模型时可能搜索该技术术语

### openMind/glm-4v-9b

**URL**: https://ai.gitcode.com/openMind/glm-4v-9b

**关键词列表**:

- **GLM-4** (当前模型品牌名): 项目名称直接提取的当前模型简称
- **视觉理解** (功能场景): GLM-4V-9B主打多模态视觉理解能力
- **128K上下文** (技术特性): 用户常搜长文本推理的上下文长度卖点
- **Function-Call** (技术特性): 支持自定义工具调用，开发者高频搜索点
- **9B参数** (参数规格): 当前模型主流参数量，用户选型常搜

### MooYeh/albert_base_v2

**URL**: https://ai.gitcode.com/MooYeh/albert_base_v2

**关键词列表**:

- **ALBERT-base** (当前模型品牌名): 项目名称 albert_base_v2 提取的简洁模型名称
- **掩码语言模型** (功能场景): 模型采用 MLM（Masked Language Modeling）进行预训练，是其核心功能
- **句子排序预测** (技术特性): ALBERT 使用的 SOP（Sentence Order Prediction）目标，区别于其他模型的预训练方式
- **参数共享层** (技术特性): 模型在所有 Transformer 层之间共享权重，显著降低内存占用
- **不区分大小写** (功能场景): 模型对英文大小写不敏感，适用于大小写混合的文本处理
- **NPU支持** (部署工具): README 中说明模型已添加对 NPU（神经网络处理单元）的支持，适合特定硬件加速部署

### openMind/camembert_ner

**URL**: https://ai.gitcode.com/openMind/camembert_ner

**关键词列表**:

- **camembert-ner** (当前模型品牌名): 项目名称直接定义的模型品牌名，是用户搜索该特定NER模型的核心关键词
- **命名实体识别** (功能场景): 模型的核心功能，用户搜索中文AI模型时常用‘命名实体识别’作为意图关键词
- **法语NER** (功能场景): 模型基于wikiner-fr（法语数据集）训练，专攻法语实体识别，是区别于其他NER模型的显著特征
- **小写实体识别** (技术特性): README明确指出模型在‘不以大写字母开头的实体’上表现更好，这是其独特技术优势
- **HuggingFace模型** (部署工具): 模型通过HuggingFace的pipeline加载，用户常搜索‘HuggingFace模型’来寻找可直接调用的预训练模型
- **openMind框架** (部署工具): 模型使用openMind库加载，是其部署生态的专属技术标签，非通用HuggingFace标准

### openMind/vit_msn_base

**URL**: https://ai.gitcode.com/openMind/vit_msn_base

**关键词列表**:

- **vitmsnbase** (当前模型品牌名): 项目名称直接对应当前模型的唯一标识，用户搜索模型时会使用此精确名称
- **MSN预训练** (技术特性): 模型核心创新点为MSN（Masked Siamese Networks）预训练方法，是区别于其他ViT模型的关键技术标签
- **图像特征提取** (功能场景): 模型主要用途是通过预训练学习图像表示，用于下游特征提取任务，符合用户搜索意图
- **少样本学习** (功能场景): 论文明确指出该模型在少量样本和极端少样本场景下表现优异，是用户关注的核心应用场景
- **ViT** (技术特性): Vision Transformer是模型的基础架构，用户搜索视觉Transformer模型时会使用此通用但精准的缩写

### MooYeh/chatglm3_6b

**URL**: https://ai.gitcode.com/MooYeh/chatglm3_6b

**关键词列表**:

- **智能体任务** (功能场景): 当前模型原生集成的复杂场景功能
- **语义理解** (技术特性): 当前模型在基准测试中展现出的能力
- **数学推理** (技术特性): 当前模型在基准测试中展现出的能力

### openMind/bert_large_uncased

**URL**: https://ai.gitcode.com/openMind/bert_large_uncased

**关键词列表**:

- **BERT-large** (当前模型品牌名): 从项目名称bert_large_uncased提取的当前模型名称
- **掩码语言建模** (技术特性): 当前模型采用的核心预训练任务
- **英文预训练** (功能场景): 当前模型专为英文文本理解与生成设计

### openMind/bert_base_uncased

**URL**: https://ai.gitcode.com/openMind/bert_base_uncased

**关键词列表**:

- **BERT-base-uncased** (当前模型品牌名): 从项目名称直接提取的当前模型标准名称，用户搜索英文BERT模型时常用此精确格式
- **下一句预测** (技术特性): BERT独有的双任务预训练机制之一，是区别于GPT等模型的关键技术点，用户研究NLP预训练时会搜索
- **未区分大小写** (技术特性): 当前模型的显著特征，用户对比BERT-cased/uncased时会使用此关键词，具有明确区分度
- **英语预训练** (功能场景): 明确描述模型的语言适用场景，用户寻找英文NLP模型时常用此组合词，非泛泛描述
- **BERT基础版** (当前模型品牌名): 中文用户常搜索'BERT基础版'指代bert-base系列，是口语化但高搜索量的中文表达，且非其他模型名称

### openMind/distilbert_base_uncased

**URL**: https://ai.gitcode.com/openMind/distilbert_base_uncased

**关键词列表**:

- **DistilBERT** (当前模型品牌名): 从项目名称 'distilbert_base_uncased' 提取的核心模型品牌名，简化为通用称呼，用户搜索蒸馏模型时常用
- **BERT-base** (当前模型品牌名): 模型是BERT基础版本的蒸馏体，用户常搜索'BERT-base'作为对比或基础模型，属于当前模型的直接关联名称
- **模型蒸馏** (技术特性): 模型的核心技术方法，区别于原生BERT，是DistilBERT的唯一标识性技术，用户搜索轻量级BERT时会用此词
- **轻量级BERT** (功能场景): 用户搜索‘更快的BERT’‘小模型BERT’时常用口语化表达，DistilBERT正是该类模型的代表，具有强搜索意图
- **自监督预训练** (技术特性): 模型预训练方式的核心描述，区别于有监督模型，是技术型用户搜索无标签训练模型时的精准关键词

### openMind/chatglm3_6b

**URL**: https://ai.gitcode.com/openMind/chatglm3_6b

**关键词列表**:

- **NPU加速** (技术特性): 当前模型优化示例代码，新增NPU加速支持
- **对话流畅** (技术特性): 当前模型延续前两代模型对话流畅的优势

### openMind/flan_t5_base

**URL**: https://ai.gitcode.com/openMind/flan_t5_base

**关键词列表**:

- **flan-t5** (当前模型品牌名): 从项目名称 'flan_t5_base' 提取的简化品牌名，符合模型命名规范，用户搜索时常用此简称
- **text2text-generation** (功能场景): README中明确提及该模型用于文本生成任务，是用户搜索AI文本生成模型时的核心关键词
- **instruction-tuning** (技术特性): 模型核心优势在于指令微调（instruction fine-tuning），是区别于普通T5的关键技术点，用户会搜索此术语
- **1000-tasks** (技术特性): 模型经过1000多个任务微调，是其性能优势的直接体现，用户在对比模型能力时会搜索此类量化特征
- **few-shot-performance** (技术特性): README强调其在少样本场景下表现优异，是用户寻找低数据需求模型时的高频搜索意图
- **Safetensors** (部署工具): 模型支持Safetensors格式，该格式在社区中被广泛用于安全加载模型，是技术用户搜索时的精准关键词

### openMind/flan_t5_small

**URL**: https://ai.gitcode.com/openMind/flan_t5_small

**关键词列表**:

- **FLAN-T5** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **指令微调** (技术特性): 模型通过 Instruction Fine‑tuning（指令微调）提升性能，是其核心技术特性
- **Few-shot能力** (技术特性): 模型在少样本（few‑shot）设置下仍能保持强劲表现，用户常以此为搜索关键词
- **多任务微调** (功能场景): 模型在 1000+ 任务上进行微调，适用于多种下游任务
- **1000任务** (功能场景): 强调模型覆盖的大规模任务数量，区别于其他小模型
- **小型模型** (参数规格): 相较于同系列大模型，FLAN‑T5 small 属于轻量级、参数更少的版本

### openMind/convnext_tiny_224

**URL**: https://ai.gitcode.com/openMind/convnext_tiny_224

**关键词列表**:

- **ConvNeXT** (当前模型品牌名): 项目名称直接给出的模型品牌名
- **图像分类** (功能场景): README明确说明用于ImageNet-1k图像分类任务
- **224分辨率** (技术特性): 模型专为224×224输入分辨率优化，是用户搜索时的关键规格
- **ConvNet现代化** (技术特性): 模型卖点：用Transformer思路改造传统卷积网络
- **ImageNet-1k** (功能场景): 训练数据集名称，用户常以此搜索对应模型

### openMind/stable-diffusion-xl-base-1_0

**URL**: https://ai.gitcode.com/openMind/stable-diffusion-xl-base-1_0

**关键词列表**:

- **SD-XL** (当前模型品牌名): 项目名称为stable-diffusion-xl-base-1_0，简化后为用户搜索习惯的SD-XL，是当前模型的唯一品牌标识
- **潜在扩散** (技术特性): 模型基于'潜在扩散流程'（latent diffusion），是其核心技术架构，具有区分度且未被高频词排除
- **双编码器** (技术特性): 模型使用'双固定预训练文本编码器（OpenCLIP-ViT/G与CLIP-ViT/L）'，'双编码器'是其独特结构特征，非通用术语
- **SDEdit** (技术特性): 模型支持SDEdit技术（图生图）作为可选流程，是SDXL特有的细化方法，技术术语且非高频词
- **OpenCLIP** (技术特性): 模型使用OpenCLIP-ViT/G作为文本编码器，是其关键组件，属于专有技术名词，非通用词且未被排除
- **Refiner模型** (技术特性): 模型设计依赖专精去噪的Refiner模型进行后处理，是SDXL架构的标志性组成部分，具有明确区分度
- **CreativeML-Open-RAIL-M** (许可协议): 模型使用该特定开源许可，是用户在合规使用时可能搜索的关键标识，非通用词且具唯一性

### openMind/flan_t5_large

**URL**: https://ai.gitcode.com/openMind/flan_t5_large

**关键词列表**:

- **多语言模型** (功能场景): 支持40+语言，用户搜索多语言大模型时会用

### openMind/mbart_large_50_many_to_many_mmt

**URL**: https://ai.gitcode.com/openMind/mbart_large_50_many_to_many_mmt

**关键词列表**:

- **mBART-large-50** (当前模型品牌名): 从项目名称'mbart_large_50_many_to_many_mmt'中提取的核心品牌名，简化为用户易搜索的简洁形式
- **多语言翻译** (功能场景): mBART-large-50的核心用途是跨50种语言的文本翻译，用户搜索AI翻译模型时常用此词
- **many-to-many翻译** (功能场景): 模型名称中明确包含'many_to_many_mmt'，代表其支持任意语言对之间的双向翻译，是独特功能标签
- **50种语言** (功能场景): 模型支持50种语言，是用户在搜索多语言AI模型时的关键筛选条件，具有明确搜索意图
- **序列到序列** (技术特性): mBART是基于序列到序列（Seq2Seq）架构的预训练模型，这是其核心技术本质，用户搜索翻译模型时会用到
- **预训练翻译模型** (功能场景): 用户在寻找可微调的翻译模型时，常搜索'预训练翻译模型'，该词精准匹配mBART的定位

### openMind/qwen1.5_7b

**URL**: https://ai.gitcode.com/openMind/qwen1.5_7b

**关键词列表**:

- **qwen1.57b** (当前模型品牌名): 从项目名称提取的当前模型名称
- **仅解码器语言模型** (技术特性): 当前模型基于Transformer架构的仅解码器语言模型，是其核心特性
- **32K上下文长度** (技术特性): 当前模型所有尺寸均稳定支持32K上下文长度，是其技术优势
- **SwiGLU激活函数** (技术特性): 当前模型采用了SwiGLU激活函数等技术，是其技术特点之一

### openMind/t5_large

**URL**: https://ai.gitcode.com/openMind/t5_large

**关键词列表**:

- **T5-Large** (当前模型品牌名): 从项目名称直接提取的当前模型名称，简洁品牌形式，符合用户搜索习惯（如SD-XL）
- **文本到文本** (技术特性): T5模型最核心的创新理念，用户搜索NLP统一框架时会使用该术语，具有高区分度
- **机器翻译** (功能场景): T5-Large明确支持的典型下游任务，是用户在博客中搜索AI翻译模型时的高频意图词
- **文档摘要** (功能场景): T5-Large官方明确列出的核心应用场景，区别于其他模型，具有明确搜索意图
- **问答系统** (功能场景): T5-Large支持的三大NLP任务之一，用户常搜索‘AI问答模型’时会匹配该词
- **情感分析** (功能场景): T5-Large支持的分类任务代表，用户搜索‘AI情感识别’或‘文本分类模型’时可能使用该词
- **C4数据集** (训练数据): T5-Large预训练使用的核心无监督数据集，专业用户会搜索‘T5 C4训练’等组合词，具独特性
- **7.7亿参数** (参数规格): 模型明确标注的参数规模，属于主流规格（介于B级与B+级之间），用户会搜索‘7亿参数模型’

### openMind/internlm2_chat_7b

**URL**: https://ai.gitcode.com/openMind/internlm2_chat_7b

**关键词列表**:

- **InternLM2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **200K上下文** (技术特性): 当前模型主打超长上下文能力，用户会搜
- **LMDeploy** (部署工具): README明确推荐用LMDeploy实现200K上下文推理

### openMind/gpt2

**URL**: https://ai.gitcode.com/openMind/gpt2

**关键词列表**:

- **GPT-2** (当前模型品牌名): 项目名称即为模型的官方名称
- **124M参数** (参数规格): 该版本是 GPT-2 的最小模型，拥有约 124M 参数
- **API调用** (部署工具): README 示例展示了通过 pipeline 接口进行模型调用

### openMind/conformer_ms

**URL**: https://ai.gitcode.com/openMind/conformer_ms

**关键词列表**:

- **Conformer** (当前模型品牌名): 项目名称为conformer_ms，核心模型名称为Conformer，是当前模型的唯一品牌标识
- **语音识别** (功能场景): 模型明确用于自动语音识别（ASR），是用户搜索AI语音模型时的核心意图词
- **卷积增强Transformer** (技术特性): Conformer的核心创新点，是区别于普通Transformer的专属技术描述，用户会搜索该组合词
- **ConformerBlock** (技术特性): 模型结构中的关键组件名称，具有唯一性，技术爱好者会搜索该术语
- **马卡龙结构** (技术特性): README中原创比喻，描述ConformerBlock的双FFN夹Attention与Conv的结构，独特且易传播
- **Aishell-1** (功能场景): 模型训练/测试所用的公开中文语音数据集，用户搜索中文ASR模型时会关联该数据集
- **NPU推理** (部署工具): 模型明确支持NPU部署，是国产AI芯片场景下的关键部署关键词，有差异化价值
- **在线速度扰动** (技术特性): 模型训练中使用'online speed perturb'作为数据增强技术，属于语音ASR领域专业但用户会搜索的术语

### openMind/wavegrad_ms

**URL**: https://ai.gitcode.com/openMind/wavegrad_ms

**关键词列表**:

- **WaveGrad** (当前模型品牌名): 从项目名称 openMind/wavegrad_ms 直接提取的核心模型名称，符合简洁品牌名规则
- **文本转语音** (功能场景): README明确说明模型专为'文本转语音系统设计'，是用户搜索AI语音生成时的明确意图关键词
- **扩散模型声码器** (技术特性): 模型基于扩散模型实现声码器功能，是其区别于Vocoder（如WaveNet、MelGAN）的核心技术标签，用户会搜索此类技术组合
- **梅尔频谱图转波形** (技术特性): 模型核心功能是将梅尔频谱图迭代优化为波形，属于具体可搜索的技术流程描述，非泛泛术语
- **MindSpore声码器** (部署工具): 模型基于MindSpore框架实现，且项目明确标注MindSpore版本，用户搜索'MindSpore 声码器'有明确部署意图
- **LJSpeech声码器** (功能场景): 模型在LJSpeech-1.1数据集上预训练，该数据集是英语TTS领域标准数据集，用户会搜索'LJSpeech 声码器'来寻找对应语音模型

### openMind/bloom_7b1

**URL**: https://ai.gitcode.com/openMind/bloom_7b1

**关键词列表**:

- **大规模多语言模型** (技术特性): 当前模型的核心技术特性，强调其大规模和多语言能力
- **开放科学开放获取** (技术特性): 当前模型的技术特性，突出其开放性和可获取性

### openMind/inceptionv3_ms

**URL**: https://ai.gitcode.com/openMind/inceptionv3_ms

**关键词列表**:

- **InceptionV3** (当前模型品牌名): 项目名称即为模型的官方名称
- **卷积分解** (技术特性): InceptionV3 通过 Factorization 将大卷积分解为一维卷积，是核心技术创新
- **Batch-Normalization** (技术特性): 模型引入批归一化，加速收敛并降低过拟合，是显著的技术特性
- **MindSpore** (部署工具): 模型基于 MindSpore 框架实现，可直接在该平台部署与训练
- **299x299输入尺寸** (技术特性): 相较于前代，InceptionV3 将输入分辨率提升至 299×299，提升特征表达能力

### openMind/baichuan2_7b_chat_ms

**URL**: https://ai.gitcode.com/openMind/baichuan2_7b_chat_ms

**关键词列表**:

- **百川2** (当前模型品牌名): 项目名称为baichuan2_7b_chat_ms，根据国产大模型映射规则，'Baichuan'应提取为品牌简称'百川2'，符合用户搜索习惯且区别于其他模型
- **百川大模型** (当前模型品牌名): README中多次使用'百川大模型'作为官方称呼，是用户在中文社区搜索该系列模型时的高频品牌词，且未被列为高频排除词
- **192K长上下文** (技术特性): 192K上下文窗口是当前模型核心差异化功能，用户会搜索'长上下文模型'，该词具象且未被排除，区别于通用'128K'等参数
- **知识库检索** (功能场景): README明确提及'新增知识库检索功能'，是用户寻找能连接外部知识的AI对话模型时的明确搜索意图词
- **4bit量化版** (部署工具): 模型提供4bit量化版本，是开发者关心的轻量化部署方式，属于用户搜索'低显存模型'时的精准关键词，且未被排除
- **开源大语言模型** (功能场景): README强调'开源'与'大语言模型'，该组合是中文开发者搜索可商用开源模型时的典型搜索短语，具有明确意图且非通用形容词
- **免费商用** (功能场景): 模型明确说明'免费用于商业场景'，这是开发者筛选模型时的关键决策词，区别于普通开源模型，具有强引流价值

### openMind/hrnet_ms

**URL**: https://ai.gitcode.com/openMind/hrnet_ms

**关键词列表**:

- **HRNet** (当前模型品牌名): 项目名称直接给出的当前模型简称
- **高分辨率网络** (当前模型品牌名): HRNet的中文全称，用户常用搜索词
- **人体姿态估计** (功能场景): README明确列出的核心应用场景
- **语义分割** (功能场景): README明确列出的核心应用场景
- **目标检测** (功能场景): README明确列出的核心应用场景
- **ImageNet-1K** (技术特性): 模型在ImageNet-1K上训练，用户搜预训练权重时常用

### openMind/dit_ms

**URL**: https://ai.gitcode.com/openMind/dit_ms

**关键词列表**:

- **DiT** (当前模型品牌名): 项目名称为dit_ms，模型核心名称为DiT（Diffusion Transformer），是当前模型的唯一品牌标识
- **Transformer架构** (技术特性): 模型明确基于Transformer而非U-Net，这是其区别于Stable Diffusion等模型的核心技术差异点
- **图像生成** (功能场景): 模型用途明确指向艺术创作、设计等图像生成任务，是用户搜索的直接意图词
- **可扩展扩散模型** (技术特性): README中强调DiT是'可扩展架构'，该短语是模型独有的技术定位，具有区分度
- **Patchify** (技术特性): 模型采用'patchify'将图像转为token序列，是DiT区别于其他扩散模型的关键预处理技术术语

### openMind/deepspeech2_ms

**URL**: https://ai.gitcode.com/openMind/deepspeech2_ms

**关键词列表**:

- **DeepSpeech2** (当前模型品牌名): 项目名称即模型的官方名称
- **CTC损失** (技术特性): 模型采用的关键训练方法，用户常以此关键词搜索相关模型
- **双向-LSTM** (技术特性): 模型结构中使用的关键循环网络层，具备显著的搜索热度
- **MindAudio** (部署工具): 模型在 MindAudio 框架下提供训练、推理和部署指南
- **端到端模型** (技术特性): 模型实现了从原始音频到文字的完整端到端流程，用户常以此关键词定位模型

### openMind/mistral_7b_v0.1

**URL**: https://ai.gitcode.com/openMind/mistral_7b_v0.1

**关键词列表**:

- **Mistral-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Ollama部署** (部署工具): 社区最常用的本地运行Mistral-7B方案

### openMind/nasnet_ms

**URL**: https://ai.gitcode.com/openMind/nasnet_ms

**关键词列表**:

- **NasNet** (当前模型品牌名): 项目名称为nasnet_ms，模型核心名称为NasNet，是用户搜索神经架构搜索图像模型时的直接关键词
- **神经架构搜索** (技术特性): 模型基于NAS（Neural Architecture Search）技术构建，是其核心技术标签，用户会搜索此类方法论模型
- **Ascend-910** (部署工具): 模型训练明确使用Ascend 910 NPU，是国产AI芯片生态中的关键部署标识，用户会搜索该硬件配套模型
- **5.33M参数** (参数规格): 模型参数为5.33M，属于轻量级模型规格，用户会搜索'轻量图像分类模型'或具体参数值进行对比
- **图模式训练** (部署工具): 模型训练采用'图模式（G）'，是MindSpore特有执行模式，为开发者部署时的关键技术关键词

### openMind/coat_ms

**URL**: https://ai.gitcode.com/openMind/coat_ms

**关键词列表**:

- **CoaT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **协同尺度卷积注意力** (技术特性): 当前模型的核心技术特性，描述了其独特的机制
- **图像分类器** (功能场景): 当前模型的主要应用场景
- **多尺度上下文建模** (技术特性): 当前模型赋予的能力，是其技术特点之一
- **coatlitetiny** (当前模型品牌名（变体）): 当前模型的一个具体变体名称，用户可能搜索
- **coatlitemini** (当前模型品牌名（变体）): 当前模型的另一个具体变体名称，具有区分度

### openMind/qwen_7b_base_ms

**URL**: https://ai.gitcode.com/openMind/qwen_7b_base_ms

**关键词列表**:

- **基础模型** (功能场景): 模型后缀为_base，表明其为通用基础模型，非微调版，用户会搜索此类术语
- **中文预训练** (技术特性): Qwen系列以中文优化见长，'base'版本通常指原生中文预训练，符合用户搜索意图
- **开源模型** (部署工具): 项目托管于GitCode，属于公开开源模型，用户常搜索'开源模型'寻找可商用/可部署版本

### openMind/ecapatdnn_ms

**URL**: https://ai.gitcode.com/openMind/ecapatdnn_ms

**关键词列表**:

- **ECAPA-TDNN** (当前模型品牌名): 从项目名称ecapatdnn_ms提取的当前模型名称
- **说话人验证** (功能场景): README首句明确的功能定位
- **声纹识别** (功能场景): README提到的VoxSRC2020比赛场景
- **通道注意力** (技术特性): ECAPA-TDNN引入的核心机制
- **Squeeze-Excitation** (技术特性): 模型结构中的关键SE模块

### openMind/baichuan2_13b_chat_ms

**URL**: https://ai.gitcode.com/openMind/baichuan2_13b_chat_ms

**关键词列表**:

- **搜索增强** (功能场景): API 已支持搜索增强，用户会以此关键词搜索相关模型
- **192K长文本窗口** (技术特性): 支持 192K 长文本窗口，体现模型的超长上下文能力

### MooYeh/opus-mt-zh-en

**URL**: https://ai.gitcode.com/MooYeh/opus-mt-zh-en

**关键词列表**:

- **Opus-MT** (当前模型品牌名): 项目名称中包含的模型品牌，直接对应模型的官方名称
- **中文-英语翻译** (功能场景): 模型的主要应用场景是将中文文本翻译为英文
- **SentencePiece** (技术特性): 模型使用 SentencePiece 进行分词和词表构建，是其关键技术之一
- **OPUS数据集** (训练数据): 模型训练使用 OPUS 语料库，用户会搜索该数据集关联的模型
- **Helsinki-NLP** (开发者/品牌): 模型由赫尔辛基大学语言技术研究小组（Helsinki‑NLP）发布，是辨识模型来源的重要信息
- **CC-BY-4.0许可证** (许可证): 模型采用 CC‑BY‑4.0 开源许可证，用户在寻找可商用或可再分发模型时会关注此信息

### openMind/yolov3_ms

**URL**: https://ai.gitcode.com/openMind/yolov3_ms

**关键词列表**:

- **yolov3ms** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **实时检测** (功能场景): YOLOv3模型以其高效性著称，适用于实时检测场景，是用户可能的需求
- **轻量化模型** (技术特性): YOLOv3_ms可能代表YOLOv3的一个轻量化或优化版本，适合资源受限环境
- **深度学习** (技术特性): YOLOv3是基于深度学习的目标检测模型，这是其技术基础

### openMind/yolov7_ms

**URL**: https://ai.gitcode.com/openMind/yolov7_ms

**关键词列表**:

- **yolov7ms** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索YOLOv7改进版时会使用此名称
- **轻量化检测** (功能场景): ms后缀暗示模型优化方向为轻量级（mobile/small），用户会搜索‘轻量化目标检测模型’

### openMind/glm-edge-4b-chat

**URL**: https://ai.gitcode.com/openMind/glm-edge-4b-chat

**关键词列表**:

- **GLM-Edge** (当前模型品牌名): 从项目名称glm-edge-4b-chat提取的当前模型品牌名
- **4B参数** (参数规格): 当前模型为40亿参数规模，用户会搜
- **聊天模型** (功能场景): 项目名称含chat，主打对话能力

### openMind/internlm_20b_base_ms

**URL**: https://ai.gitcode.com/openMind/internlm_20b_base_ms

**关键词列表**:

- **InternLM-20B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **书生浦语** (当前模型品牌名): InternLM官方中文品牌名
- **20B参数** (参数规格): 当前模型的主流参数规格
- **16K上下文** (技术特性): 用户会搜超长上下文能力

### openMind/Qwen3-8B

**URL**: https://ai.gitcode.com/openMind/Qwen3-8B

**关键词列表**:

- **思维模式切换** (技术特性): 模型核心创新点：在单一模型内无缝切换思维模式与非思维模式，具有高度区分度
- **131K上下文** (参数规格): 通过YaRN扩展至131,072 tokens，属于主流长上下文规格，用户常搜'128K上下文'，131K具搜索价值
- **智能体工具调用** (功能场景): 模型在开源模型中智能体任务表现领先，'智能体工具调用'是精准功能场景词，非泛泛描述

### openMind/gemma-3-1b-it

**URL**: https://ai.gitcode.com/openMind/gemma-3-1b-it

**关键词列表**:

- **Gemma-3** (当前模型品牌名): 从项目名称gemma-3-1b-it中提取的核心品牌名，简化为用户搜索习惯的‘Gemma 3’，不带参数后缀
- **文生文** (功能场景): 模型仅生成文本输出，区别于多模态模型，用户搜索‘文生文’场景时精准匹配，且未被高频词库排除

### openMind/Qwen1.5-1.8b

**URL**: https://ai.gitcode.com/openMind/Qwen1.5-1.8b

**关键词列表**:

- **Qwen1.5-1.8b** (当前模型品牌名): 从项目名称提取的当前模型名称
- **纯解码器语言模型** (技术特性): 当前模型基于Transformer架构的纯解码器语言模型，是其核心技术特性
- **多语言能力** (功能场景): 当前模型支持多语言能力，是其应用场景之一
- **1.8B参数** (参数规格): 当前模型包含1.8B参数版本，是其参数规格之一

### openMind/QwQ-32B

**URL**: https://ai.gitcode.com/openMind/QwQ-32B

**关键词列表**:

- **QwQ-32B** (当前模型品牌名): 项目名称直接给出的当前模型名称，符合用户搜索习惯
- **AI推理** (功能场景): 模型定位为'推理模型'，区别于普通指令模型，'AI推理'是用户搜索推理类模型的高频意图词
- **QwQ模型** (当前模型品牌名): 用户可能搜索简化的'QwQ模型'而非完整名称，作为品牌名的口语化变体，符合搜索习惯

### openMind/deepseek-coder-6.7b-instruct

**URL**: https://ai.gitcode.com/openMind/deepseek-coder-6.7b-instruct

**关键词列表**:

- **DeepSeek-Coder** (当前模型品牌名): 项目名称中包含的品牌名称，用户搜索时会直接使用
- **6.7B参数** (参数规格): 模型的参数规模为 6.7 B，属于用户常搜索的规格标签
- **项目级代码补全** (功能场景): 模型支持在整个项目层面进行代码补全与填充，是核心使用场景
- **16K上下文窗口** (技术特性): 模型采用 16 K 长度的上下文窗口，区别于多数模型的 2 K‑4 K 限制
- **填空任务** (技术特性): 在预训练阶段加入填空任务，提升项目级代码补全能力

### openMind/Qwen3-0.6B

**URL**: https://ai.gitcode.com/openMind/Qwen3-0.6B

**关键词列表**:

- **32K上下文** (参数规格): 32,768上下文长度属于主流长上下文规格，用户常搜索'32K上下文'寻找长文本处理模型，且未被高频词列表排除

### openMind/Meta-Llama-3.1-8B-Instruct

**URL**: https://ai.gitcode.com/openMind/Meta-Llama-3.1-8B-Instruct

**关键词列表**:

- **Llama-3.1** (当前模型品牌名): 从项目名称提取的当前模型名称，去掉版本后缀8B-Instruct

### openMind/Step-Audio

**URL**: https://ai.gitcode.com/openMind/Step-Audio

**关键词列表**:

- **Step-Audio** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **实时语音交互** (功能场景): README明确强调的产品级实时语音交互系统
- **语音克隆** (功能场景): 当前模型支持全流程语音克隆功能
- **RAP哼唱** (功能场景): README突出支持的RAP与哼唱语音生成
- **情感方言控制** (技术特性): 可精准调节情感与方言的语音生成技术
- **1300亿参数** (参数规格): 开源的千亿级多模态模型Step-Audio-Chat参数规模
- **昇腾NPU优化** (部署工具): 官方已适配昇腾NPU并优化推理代码

### openMind/DeepSeek-R1-Distill-Qwen-1.5B

**URL**: https://ai.gitcode.com/openMind/DeepSeek-R1-Distill-Qwen-1.5B

**关键词列表**:

- **DeepSeek-R1-Distill-Qwen-1.5B** (当前模型品牌名): 项目完整名称，虽带参数但为唯一标识符，用户可能直接搜索此完整名称以定位该特定蒸馏版本
- **推理模型** (功能场景): 模型明确被定义为‘第一代推理模型’，是用户搜索AI推理能力时的精准意图词
- **1.5B参数** (参数规格): 当前模型为1.5B规模，属于轻量级主流参数规格，用户常搜索此类小模型用于本地部署
- **蒸馏模型** (技术特性): 模型是通过从DeepSeek-R1蒸馏而来，'蒸馏模型'是用户搜索轻量高效模型时的高频意图词
- **无监督微调** (技术特性): 模型采用纯RL训练，无需SFT，这一技术路径在开源社区中极具辨识度和搜索价值

### openMind/swin2SR_classical_sr_x2_64

**URL**: https://ai.gitcode.com/openMind/swin2SR_classical_sr_x2_64

**关键词列表**:

- **Swin2SR** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像超分辨率** (功能场景): 当前模型的主要应用场景
- **图像放大2倍** (功能场景): 当前模型的核心功能描述
- **SwinV2-Transformer** (技术特性): 当前模型使用的核心技术架构
- **压缩图像恢复** (功能场景): 当前模型在压缩图像恢复方面的应用

### openMind/Janus-Pro-1B

**URL**: https://ai.gitcode.com/openMind/Janus-Pro-1B

**关键词列表**:

- **Janus-Pro** (当前模型品牌名): 从项目名称直接提取的当前模型品牌名，简洁且唯一，符合用户搜索AI模型时的命名习惯
- **统一多模态** (技术特性): 模型核心创新点，强调‘统一理解与生成’，是区别于其他模型的独有技术标签，用户会搜索此类功能描述
- **SigLIP-L** (技术特性): 模型使用的专属视觉编码器名称，是其多模态理解的关键组件，属于模型自身技术栈，非通用词
- **视觉编码解耦** (技术特性): 模型核心创新机制，原文强调‘解耦视觉编码’以解决角色冲突，是独特技术术语，用户在研究多模态架构时可能搜索

### MooYeh/blip-image-captioning-large

**URL**: https://ai.gitcode.com/MooYeh/blip-image-captioning-large

**关键词列表**:

- **BLIP-image-captioning-large** (当前模型品牌名): 从项目名称直接提取的当前模型完整名称，是用户搜索该特定模型时的精准关键词
- **图像标注** (功能场景): 模型核心用途为生成图像描述文本，用户常搜索'图像标注'而非'图像描述'等泛词，且未被高频词列表排除
- **引导标注** (技术特性): BLIP论文独创的噪声数据处理技术，是区别于其他模型的关键创新点，非通用词且未被高频词覆盖
- **图像-文本检索** (功能场景): 模型在论文中明确优化的任务类型，是专业用户搜索视觉语言模型时的精准场景词
- **零样本视频语言** (功能场景): 模型在视频语言任务上的零样本能力是论文强调的亮点，具有独特性，非泛用词，未被高频词列表包含

### openMind/Aquila-7B

**URL**: https://ai.gitcode.com/openMind/Aquila-7B

**关键词列表**:

- **Aquila-7B** (当前模型品牌名): 项目名称直接给出的当前模型名称
- **悟道天鹰** (当前模型品牌名): 官方中文品牌名，用户会搜
- **中英双语大模型** (功能场景): 官方强调的核心卖点，用户搜索意图明确
- **商用许可开源** (功能场景): 商用友好是用户关注重点
- **国内数据合规** (功能场景): 国内用户搜索合规大模型时的关键词
- **BMTrain并行训练** (技术特性): 官方提到的独特训练加速技术，用户会搜
- **中文语料40** (技术特性): 中文比例高是用户搜索国产大模型时的关注点

### Ascend_AI4S/prot_bert

**URL**: https://ai.gitcode.com/Ascend_AI4S/prot_bert

**关键词列表**:

- **ProtBert** (当前模型品牌名): 从项目名称提取的当前模型名称
- **蛋白质特征提取** (功能场景): 当前模型的主要应用场景之一
- **Bert架构** (技术特性): 当前模型基于的架构

### MooYeh/stable-diffusion-xl-base-1_0

**URL**: https://ai.gitcode.com/MooYeh/stable-diffusion-xl-base-1_0

**关键词列表**:

- **稳定扩散** (功能场景): 中文用户对'Stable Diffusion'的通用译名，是文生图领域核心搜索词，且未被列入高频排除词库
- **两阶段生成** (技术特性): 模型核心架构特征，指基础模型+细化模型的两步流程，具有技术独特性，非通用术语
- **专家集成** (技术特性): 模型原文明确使用的术语，指多个专家模型协同生成，是SDXL架构的核心设计概念
- **OpenCLIP-ViTG** (技术特性): 模型使用的固定文本编码器名称，属于模型自身技术组件，非通用词，具有唯一识别性
- **CLIP-ViTL** (技术特性): 模型使用的第二个固定文本编码器，与OpenCLIP-ViT/G并列，构成模型文本理解双引擎

### openMind/AquilaChat-7b

**URL**: https://ai.gitcode.com/openMind/AquilaChat-7b

**关键词列表**:

- **AquilaChat** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **中英双语** (功能场景): 模型具备中文和英文双语知识，满足中英双语对话与写作需求
- **商业许可** (技术特性): 模型采用 Apache 2.0 代码协议并提供《智源Aquila系列模型许可协议》，支持商业化使用
- **BMTrain并行** (技术特性): 采用升级版 BMTrain 并行训练方法，实现高效的分布式训练

### openMind/bloom_1b7

**URL**: https://ai.gitcode.com/openMind/bloom_1b7

**关键词列表**:

- **智谱清言** (当前模型品牌名): 项目中明确标注为'智谱清言-1b7'，根据国产大模型映射规则，'智谱清言'是模型品牌名，且未被高频词列表排除
- **bloom** (当前模型品牌名): 项目名称为'bloom_1b7'，'bloom'是模型核心标识，虽源自BigScience，但当前项目已将其作为自有模型名称使用，且未被排除，符合'当前模型自身名称'提取原则
- **多语种语言模型** (功能场景): README明确描述为'大规模科学开放访问多语种语言模型'，'多语种语言模型'是用户搜索跨语言AI能力时的精准意图词，非泛泛描述
- **OpenMind** (部署工具): 代码中使用'from openmind import AutoModelForCausalLM'，表明该模型通过OpenMind框架加载，是当前模型特有的部署入口，具有区分度且未被高频词排除
- **NPU部署** (部署工具): 模型加载路径为'PyTorch-NPU/bloom_1b7'，明确支持NPU（昇腾等国产AI芯片），'NPU部署'是国产AI生态用户高频搜索的精准场景词，且未被高频词列表覆盖

### openMind/albert_xxlarge_v2

**URL**: https://ai.gitcode.com/openMind/albert_xxlarge_v2

**关键词列表**:

- **ALBERT-XXLarge-v2** (当前模型品牌名): 项目名称直接对应当前模型的完整官方名称，是用户搜索该特定版本时的精准关键词
- **英语预训练模型** (功能场景): 明确描述模型语言范围与用途，用户搜索‘英文NLP模型’‘英语BERT替代’等意图时会匹配
- **ALBERT-v2** (当前模型品牌名): 用户常搜索模型版本号（如v1 vs v2），'ALBERT v2'是简洁且高频搜索的变体名称，非完整版但符合简化规则

### openMind/byt5_large

**URL**: https://ai.gitcode.com/openMind/byt5_large

**关键词列表**:

- **ByT5** (当前模型品牌名): 项目名称为byt5_large，模型品牌名为ByT5，符合简化命名规则且为当前模型唯一标识
- **字节到字节** (技术特性): 论文标题明确强调'byte-to-byte'，是ByT5区别于其他Token化模型的核心技术特征，用户可能搜索‘字节到字节模型’
- **无token模型** (技术特性): 论文标题提及'token-free future'，该模型颠覆传统分词方式，是其最独特、可搜索的技术卖点
- **字节级模型** (技术特性): ByT5直接处理字节序列，不依赖词表分词，‘字节级模型’是用户搜索非传统NLP模型时的精准关键词
- **T5架构** (技术特性): 模型基于T5架构，虽非原创，但作为当前模型的底层结构，用户会搜索‘T5架构模型’来寻找同类变体
- **ByteT5** (当前模型品牌名): 论文和社区中常将ByT5写作ByteT5，属于同一模型的常见别名，需作为品牌名补充以覆盖搜索变体
- **编码器-解码器** (技术特性): ByT5继承T5的编码器-解码器结构，是其任务适配能力（如翻译、摘要）的关键架构，用户搜索此类结构时会命中

### openMind/baichuan_7b

**URL**: https://ai.gitcode.com/openMind/baichuan_7b

**关键词列表**:

- **Baichuan-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **宽松开源协议** (部署工具): 当前模型使用更宽松的开源协议，允许商业使用，这是部署时的一个重要考虑因素
- **SOTA水平** (技术特性): 当前模型在同尺寸模型中达到了SOTA的水平，体现了其技术优势

### openMind/deepseek-coder-33b-instruct

**URL**: https://ai.gitcode.com/openMind/deepseek-coder-33b-instruct

**关键词列表**:

- **33B参数** (参数规格): 大参数代码模型稀缺，33B是用户搜索高亮词
- **代码补全** (功能场景): README强调项目级代码补全与填充，开发者高频搜索
- **16K窗口** (技术特性): 长上下文代码生成卖点，用户会直接用16K窗口作为检索词

### openMind/deberta_v3_base

**URL**: https://ai.gitcode.com/openMind/deberta_v3_base

**关键词列表**:

- **DeBERTa-v3-base** (当前模型品牌名): 从项目名称直接提取的当前模型标准名称，用户搜索具体模型版本时会使用该完整标识
- **梯度解耦嵌入共享** (技术特性): DeBERTa V3独有的核心技术，区别于BERT/RoBERTa/ELECTRA，是论文核心创新点，用户研究模型架构时会搜索该术语
- **ELECTRA风格预训练** (技术特性): 当前模型采用的独特预训练范式，虽借鉴ELECTRA但为DeBERTa V3专属实现，是区别于其他模型的关键技术标签
- **128K词表** (参数规格): 128K是当前模型显著区别于主流模型（如RoBERTa的50K）的词表规模，属于用户对比模型容量时会关注的高区分度规格
- **SQuAD-2.0** (功能场景): 模型在SQuAD 2.0上表现优异，该任务是中文/英文问答领域的标准基准，用户搜索‘SQuAD 2.0模型’时会定位到该模型
- **MNLI** (功能场景): MNLI是自然语言推理的核心任务，DeBERTa-v3-base在此任务上达到SOTA，用户搜索‘MNLI高性能模型’会指向该模型

### openMind/convnextv2_tiny_1k_224

**URL**: https://ai.gitcode.com/openMind/convnextv2_tiny_1k_224

**关键词列表**:

- **ConvNeXt-V2** (当前模型品牌名): 项目名称直接给出的当前模型名称
- **FCMAE** (技术特性): ConvNeXt V2 引入的全卷积遮蔽自编码器框架，是其核心技术亮点
- **GRN层** (技术特性): 全局响应归一化层，ConvNeXt V2 新增的关键组件
- **纯卷积网络** (技术特性): 强调模型为纯 ConvNet 架构，区别于 Transformer 类模型

### openMind/mt5_base

**URL**: https://ai.gitcode.com/openMind/mt5_base

**关键词列表**:

- **mt5base** (当前模型品牌名): 项目名称为mt5_base，是当前模型的官方简洁名称，符合用户搜索AI模型时的直接命名习惯
- **mC4预训练** (技术特性): 模型在mC4语料库上预训练，是其区别于其他T5变体的核心技术标签，用户会搜索'基于mC4的模型'
- **英文-中文翻译** (功能场景): README明确列出English和Chinese为支持语言，用户常搜索具体语言对的翻译模型，此为高意图场景词

### openMind/xglm_1.7b

**URL**: https://ai.gitcode.com/openMind/xglm_1.7b

**关键词列表**:

- **XGLM-1.7B** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简洁命名规范
- **500亿子词** (技术特性): 训练数据规模是模型关键亮点，‘500亿子词’是用户搜索大语料模型时可能使用的精准术语，非通用描述

### openMind/falcon_7b

**URL**: https://ai.gitcode.com/openMind/falcon_7b

**关键词列表**:

- **Falcon-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **因果解码器模型** (技术特性): 当前模型的核心技术特性
- **RefinedWeb-1.5万亿标记** (技术特性): 当前模型训练所使用的数据集规模
- **FlashAttention** (技术特性): 当前模型架构中采用的关键技术
- **multiquery** (技术特性): 当前模型架构中采用的关键技术
- **Apache-2.0许可协议** (技术特性): 当前模型遵循的开放许可协议

### openMind/xlm_roberta_base

**URL**: https://ai.gitcode.com/openMind/xlm_roberta_base

**关键词列表**:

- **XLM-RoBERTa** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，是用户搜索多语言预训练模型的核心关键词
- **跨语言表示学习** (技术特性): 论文核心贡献术语，直接来自README原文，是该模型区别于其他模型的独有技术标签
- **100种语言** (功能场景): 明确描述模型支持的语言广度，用户搜索多语言NLP任务时会使用该量化描述词
- **无监督预训练** (技术特性): 模型训练方式的核心特征，区别于有监督模型，是技术型用户搜索的关键语义词
- **CommonCrawl数据** (技术特性): 模型训练数据来源的独特标识，专业用户在比较多语言模型数据集时会搜索该词

### openMind/bluelm_7b_chat

**URL**: https://ai.gitcode.com/openMind/bluelm_7b_chat

**关键词列表**:

- **BlueLM** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **CEval领先** (技术特性): 在C‑Eval基准测试中取得领先成绩，体现模型的中文理解与推理能力
- **CMMLU领先** (技术特性): 在CMMLU评测中表现优异，展示模型在多学科知识问答上的优势
- **开源商业授权** (部署工具): 模型采用开放授权协议，支持学术研究与商业应用，区别于仅限科研的模型

### openMind/mt5_large

**URL**: https://ai.gitcode.com/openMind/mt5_large

**关键词列表**:

- **mt5large** (当前模型品牌名): 项目名称为mt5_large，是当前模型的直接标识，用户搜索时会使用该完整名称
- **无监督多语言** (技术特性): README强调‘只在mC4上预训练，无任何监督训练’，这是其核心训练范式，用户搜索‘无监督多语言模型’时会匹配该特征
- **JAX** (部署工具): 标签中包含'JAX'，是Google官方推荐的训练框架，属于mT5的专属部署生态，用户搜索JAX相关模型时会用到

### openMind/rembert

**URL**: https://ai.gitcode.com/openMind/rembert

**关键词列表**:

- **RemBERT** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该模型的唯一品牌标识
- **非绑定嵌入** (技术特性): RemBERT核心创新点：输入与输出嵌入未绑定，区别于mBERT，是其关键技术特征
- **多语言分类** (功能场景): 模型明确设计用于110种语言的分类任务，是其主要下游应用场景
- **轻量级预训练** (技术特性): 因省略输出嵌入权重，模型更轻量，是其部署优势，用户会搜索轻量多语言模型
- **MLM预训练** (技术特性): 模型基于遮蔽语言模型（MLM）目标预训练，是其训练方式的核心标签
- **跨语言NER** (功能场景): 论文中明确提及应用于命名实体识别（NER），是除分类外的重要下游任务
- **多语言词性标注** (功能场景): 论文验证的典型任务，用户搜索多语言NLP任务时可能精准匹配
- **Wikipedia多语言预训练** (训练数据): 模型在110种语言维基百科上预训练，是其数据来源的唯一性特征

### openMind/open_llama_7b

**URL**: https://ai.gitcode.com/openMind/open_llama_7b

**关键词列表**:

- **OpenLLaMA** (当前模型品牌名): 项目名称即为OpenLLaMA，是用户搜索该开源复现模型的核心关键词
- **开源复现** (技术特性): README强调其为Meta LLaMA的开源复现，用户会搜“开源复现 LLaMA”
- **Apache-2.0许可** (技术特性): 宽松许可吸引商用与二次开发，用户常搜“Apache 2.0 大模型”
- **EasyLM框架** (部署工具): 官方提供EasyLM格式权重与框架，用户会搜“EasyLM 部署”
- **HuggingFace权重** (部署工具): 支持HuggingFace transformers直接加载，用户常搜“HuggingFace OpenLLaMA”
- **1T标记训练** (技术特性): 7B模型基于1T token训练，用户会搜“1T token 大模型”

### openMind/albert_base_v2

**URL**: https://ai.gitcode.com/openMind/albert_base_v2

**关键词列表**:

- **英文预训练模型** (功能场景): 模型明确用于英文语言理解，用户搜索英文NLP任务时会使用该组合词

### openMind/mobilebert_uncased

**URL**: https://ai.gitcode.com/openMind/mobilebert_uncased

**关键词列表**:

- **MobileBERT** (当前模型品牌名): 项目名称直接给出的模型品牌名
- **手机端BERT** (功能场景): 专为移动设备优化的轻量BERT，用户会搜手机端部署
- **掩码填空** (功能场景): README示例展示的核心任务，用户搜索fill-mask时会用
- **512序列长度** (参数规格): 模型配置中明确给出的输入长度，用户对比轻量模型时关注
- **24层瓶颈结构** (技术特性): MobileBERT独有的瓶颈平衡设计，技术博客常提及

### openMind/mt5_small

**URL**: https://ai.gitcode.com/openMind/mt5_small

**关键词列表**:

- **mT5** (当前模型品牌名): 项目名称即为模型名称，用户搜索时会直接使用“mT5”。
- **mC4** (技术特性): 模型在 mC4 语料库上进行大规模预训练，是其核心数据来源。
- **101语言** (技术特性): 模型覆盖 101 种语言，体现其强大的多语言能力，用户常以此关键词检索。
- **文本到文本模型** (技术特性): 模型采用 T5 的 Text‑to‑Text 框架，适用于生成、翻译、摘要等多种任务。
- **跨语言迁移学习** (技术特性): 模型在多语言语料上训练，可实现语言之间的迁移学习，满足跨语言任务需求。

### openMind/t5_small

**URL**: https://ai.gitcode.com/openMind/t5_small

**关键词列表**:

- **T5-Small** (当前模型品牌名): 项目名称为t5_small，按规则简化为通用品牌名'T5 Small'，是用户搜索轻量级文本模型时的常用关键词
- **Text-To-Text** (技术特性): 模型官方提出的统一框架名称，是技术文档中高频术语，搜索该英文术语的用户精准指向T5类模型
- **ONNX** (部署工具): 模型支持ONNX格式导出，是企业级部署的关键格式，用户搜索'ONNX 模型'时可能精准匹配该模型
- **SafeTensors** (部署工具): 模型支持SafeTensors格式，该格式因安全性和兼容性在社区中被专门搜索，是区别于普通PyTorch模型的部署标签
- **Apache-License-2.0** (部署工具): 开源协议是开发者选型关键因素，'Apache License 2.0 模型'是开发者在寻找可商用模型时的高频搜索词

### openMind/openai_gpt

**URL**: https://ai.gitcode.com/openMind/openai_gpt

**关键词列表**:

- **openai-gpt** (当前模型品牌名): 从项目名称提取的当前模型名称
- **GPT-1** (当前模型品牌名): 模型的别名，与openai-gpt指向同一模型
- **因果变压器** (技术特性): 模型是基于因果（单向）变压器的语言模型，这是其技术特性
- **长距离依赖性** (技术特性): 模型在具有长距离依赖性的大型语料库上进行预训练，这是其技术特点
- **MIT许可** (技术特性): 模型使用的许可类型，是用户可能关心的技术特性之一

### openMind/edgenext_ms

**URL**: https://ai.gitcode.com/openMind/edgenext_ms

**关键词列表**:

- **EdgeNeXt** (当前模型品牌名): 从项目名称 'edgenext_ms' 提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词
- **SDTA编码器** (技术特性): 模型独有的分裂深度卷积转置注意力（Split Depthwise Transformer Attention）架构，是其核心创新点，用户会搜索该技术术语来查找同类高效架构
- **CNN-Transformer融合** (技术特性): 模型的核心设计理念，明确描述其混合架构特性，是移动视觉领域用户搜索高效轻量模型时的高频技术组合词
- **移动视觉** (功能场景): 模型明确面向移动视觉应用，是其主要部署场景，用户搜索‘移动视觉模型’‘边缘视觉模型’时会精准匹配
- **轻量级图像分类** (功能场景): 模型在ImageNet-1K上验证，参数量低至1.33M，专为轻量图像分类设计，区别于通用大模型，是用户寻找移动端分类模型时的精准搜索词
- **MindSpore模型** (部署工具): 模型基于MindSpore框架训练与部署，是国产AI生态中用户寻找适配昇腾NPU的模型时的关键搜索词
- **2.34M参数模型** (参数规格): edgenext_x_small参数量为2.34M，属于移动端主流轻量级规模（介于1M-5M），用户会搜索‘2M参数模型’‘轻量分类模型’等关键词

### openMind/qwen1.5_7b_chat

**URL**: https://ai.gitcode.com/openMind/qwen1.5_7b_chat

**关键词列表**:

- **openMind适配** (部署工具): README强调已适配openMind框架
- **无需trustremotecode** (技术特性): README突出安全优势，用户可直接加载

### openMind/crossvit_ms

**URL**: https://ai.gitcode.com/openMind/crossvit_ms

**关键词列表**:

- **CrossViT** (当前模型品牌名): 项目名称即为模型品牌名，用户搜索时会直接使用
- **双分支架构** (技术特性): 模型采用独特的双分支设计用于处理不同尺度的图像块
- **交叉注意力模块** (技术特性): 核心的交叉注意力机制实现了高效的特征融合，是模型的关键技术
- **多尺度特征** (技术特性): 模型能够提取并融合不同尺度的视觉特征，提升分类表现
- **ImageNet-1K评测** (功能场景): 模型在 ImageNet-1K 上取得的成绩是用户关注的性能指标

### openMind/internlm_20b_chat_ms

**URL**: https://ai.gitcode.com/openMind/internlm_20b_chat_ms

**关键词列表**:

- **16k上下文** (技术特性): 模型支持16k上下文长度（通过推理外推实现），是区别于7B/13B模型的关键能力，用户会搜索‘长上下文模型’
- **推理能力** (技术特性): 模型在推理维度得分54.9，远超13B级模型，是其核心宣传亮点，用户会搜索‘强推理AI模型’
- **价值对齐** (技术特性): 模型经过RLHF训练，强调‘更优的价值对齐’，是安全对话场景的关键卖点，区别于普通模型
- **60层架构** (技术特性): 模型采用60层深度设计，远超常规32-40层，是其结构创新点，用户可能搜索‘深层语言模型’

### openMind/halonet_ms

**URL**: https://ai.gitcode.com/openMind/halonet_ms

**关键词列表**:

- **HaloNet** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Blocked-Self-Attention** (技术特性): 当前模型的核心技术特性之一
- **Haloing操作** (技术特性): 当前模型中用于信息扩展的独特技术操作
- **视觉主干网络** (功能场景): 当前模型的应用领域，即作为视觉处理的主干网络
- **参数高效** (技术特性): 当前模型在参数使用上的高效性，是其特点之一

### openMind/yolov5_ms

**URL**: https://ai.gitcode.com/openMind/yolov5_ms

**关键词列表**:

- **YOLOv5** (当前模型品牌名): 项目名称中直接使用的模型名称
- **COCO预训练** (技术特性): 模型在 COCO 数据集上完成了预训练，属于重要技术特性
- **P5系列模型** (技术特性): 项目实现了 YOLOv5 的 P5 系列架构（N、S、M、L、X）
- **86.7M参数** (参数规格): YOLOv5‑X 版本的参数量约为 86.7M，用户常以参数规模搜索模型
- **MindYOLO** (部署工具): README 中提到可参考 MindYOLO 项目进行模型的训练与推理

### openMind/cmt_ms

**URL**: https://ai.gitcode.com/openMind/cmt_ms

**关键词列表**:

- **CMT** (当前模型品牌名): 项目名称为cmt_ms，模型核心名称为CMT，是当前模型的官方简称，用户搜索时会直接使用该缩写
- **卷积神经网络遇见视觉变换器** (技术特性): 模型核心创新点的直白描述，是用户在中文技术社区中可能搜索的关键词，体现CNN与ViT融合的独特架构
- **轻量级MHSA** (技术特性): 模型为降低计算成本采用的专属技术组件，具有区分度，非通用术语，符合用户搜索‘轻量级自注意力’等技术方案的意图
- **深度卷积与逐点卷积** (技术特性): 模型借鉴MobileNet的结构设计，是其高效性的关键技术词，非通用词汇，具有技术独特性
- **MindSpore训练** (部署工具): 模型明确使用MindSpore框架训练，是国产AI框架下的典型部署方式，用户会搜索‘MindSpore模型’或‘MindSpore图像分类’
- **83.24-Top-1** (参数规格): 83.24%是模型在ImageNet-1K上报告的Top-1准确率，属于主流性能锚点，用户会搜索‘ImageNet Top-1 83%模型’等性能导向关键词

### openMind/ghostnet_ms

**URL**: https://ai.gitcode.com/openMind/ghostnet_ms

**关键词列表**:

- **GhostNet** (当前模型品牌名): 项目名称为ghostnet_ms，核心模型名称为GhostNet，是当前模型的唯一品牌标识
- **Ghost模块** (技术特性): 论文核心创新点，指代低成本生成特征图的独有结构，非通用术语
- **Ghost瓶颈** (技术特性): 基于Ghost模块构建的专用网络堆叠结构，是GhostNet架构的关键组件
- **轻量级CNN** (功能场景): 模型明确用于构建轻量级卷积神经网络，是用户搜索边缘设备部署时的精准意图词
- **ImageNet分类** (功能场景): 模型在ImageNet-1K上验证，用户搜索‘轻量模型 ImageNet分类’时是明确搜索意图
- **5.2M参数** (参数规格): ghostnet_100参数量为5.20M，属于主流轻量级模型规模，用户会搜索‘5M参数模型’

### openMind/latte_ms

**URL**: https://ai.gitcode.com/openMind/latte_ms

**关键词列表**:

- **Latte** (当前模型品牌名): 项目名称即为latte_ms，品牌名简化为Latte
- **Latent-Diffusion-Transformer** (技术特性): 模型核心架构，用户可能直接搜全称
- **VAE压缩** (技术特性): Latte先用VAE压缩视频数据，技术关键词
- **空间-时间token** (技术特性): Latte提取时空token建模，技术亮点
- **ComfyUI插件** (部署工具): 用户常用ComfyUI部署视频生成模型

### openMind/convit_ms

**URL**: https://ai.gitcode.com/openMind/convit_ms

**关键词列表**:

- **ConViT** (当前模型品牌名): 项目名称即为 ConViT，直接代表该模型的品牌
- **GPSA** (技术特性): Gated Positional Self‑Attention 是 ConViT 的核心注意力机制，用户常以 GPSA 搜索相关实现
- **软卷积归纳偏置** (技术特性): ConViT 引入的 Soft Convolutional Inductive Bias，区别于传统 ViT 的关键技术点
- **局部注意力门控** (技术特性): 通过门控参数实现局部性与全局性的平衡，是模型独有的创新点
- **位置自注意力** (技术特性): ConViT 中的定位自注意力机制，用户在搜索定位注意力相关模型时会使用该词
- **ImageNet基准超越** (结果表现): 模型在 ImageNet 基准上超过 DeiT，用户常以此关键词查找高性能视觉模型

### openMind/mixnet_ms

**URL**: https://ai.gitcode.com/openMind/mixnet_ms

**关键词列表**:

- **MixNet** (当前模型品牌名): 项目名称为mixnet_ms，模型核心名称为MixNet，是当前模型的唯一品牌标识
- **MixConv** (技术特性): 论文提出的核心创新模块，混合深度卷积，是该模型区别于其他轻量级网络的独特技术
- **混合深度卷积** (技术特性): MixConv的中文技术术语，用户搜索轻量级CNN优化方案时可能使用此描述
- **MobileNet优化** (功能场景): 论文明确指出该模型用于改进MobileNet，在图像分类与目标检测场景中作为直接替换模块
- **高效ConvNet** (功能场景): 论文核心目标是构建高效卷积网络，该词精准描述模型定位，且未在高频排除词列表中
- **COCO目标检测** (功能场景): 模型在COCO数据集上验证检测性能，是计算机视觉领域高频搜索场景，且具模型特异性

### openMind/codellama_34b_ms

**URL**: https://ai.gitcode.com/openMind/codellama_34b_ms

**关键词列表**:

- **codellama34bms** (当前模型品牌名): 从项目名称提取的当前模型名称
- **34B参数** (参数规格): 当前模型的参数规模，具有独特性
- **代码合成** (功能场景): 当前模型的主要功能之一，用于代码合成
- **代码理解** (功能场景): 当前模型具备代码理解的能力
- **Python专家** (功能场景): 当前模型在Python编程方面具有专长

### openMind/stable-diffusion-v2_ms

**URL**: https://ai.gitcode.com/openMind/stable-diffusion-v2_ms

**关键词列表**:

- **Stable-Diffusion-v2** (当前模型品牌名): 从项目名称 'stable-diffusion-v2_ms' 提取的核心模型品牌名，用户搜索文生图模型时会直接使用此名称
- **Latent-Diffusion-Model** (技术特性): 模型类型明确标注为Latent Diffusion Model，是SD2.0的核心技术标签，区别于其他扩散模型的搜索关键词
- **sdv2base** (当前模型品牌名): 模型Checkpoint的官方命名前缀，用户在GitCode或模型库中下载时会直接使用此标识符进行搜索

### openMind/pit_ms

**URL**: https://ai.gitcode.com/openMind/pit_ms

**关键词列表**:

- **PiT** (当前模型品牌名): 项目名称即为 PiT，直接提取为模型品牌名
- **池化视觉模型** (技术特性): 模型在 ViT 基础上加入池化层，实现空间维度递减的核心技术特性
- **空间维度递减** (技术特性): 相较于传统 ViT，PiT 在每层通过池化降低空间分辨率，属于独特的结构优势
- **4.85M参数** (参数规格): pit_ti 版本的参数量为 4.85M，属于轻量级配置，用户常以参数规模搜索模型
- **ImageNet1K性能** (技术特性): 在 ImageNet‑1K 数据集上取得 72.96% Top‑1 等成绩，是模型性能的重要卖点

### openMind/yolov8_ms

**URL**: https://ai.gitcode.com/openMind/yolov8_ms

**关键词列表**:

- **YOLOv8-ms** (当前模型品牌名): 项目名称为yolov8_ms，根据规则需提取模型自身品牌名，简化为YOLOv8-ms（保留核心标识，符合英文-英文连字符规范）
- **图像分割** (功能场景): README明确列出分割任务（YOLOv8-seg），是模型核心功能之一，区别于通用检测模型，具有区分度
- **P5架构** (技术特性): README中多次出现'P5'作为模型架构标识，是YOLOv8-ms特有的特征，代表其特征金字塔结构，具有技术区分度
- **MS-COCO-2017** (功能场景): 模型在MS COCO 2017上训练与评估，该数据集是目标检测领域权威基准，用户常搜索'MS COCO 目标检测模型'以找适配数据集的模型

### openMind/bit_ms

**URL**: https://ai.gitcode.com/openMind/bit_ms

**关键词列表**:

- **BigTransfer** (当前模型品牌名): 项目核心名称，用户直接搜索BigTransfer或BiT
- **视觉迁移学习** (功能场景): BiT主打通用视觉表征迁移，用户常搜'视觉迁移学习'找现成模型
- **ImageNet预训练** (功能场景): README明确给出ImageNet-1K结果，用户会搜'ImageNet预训练模型'快速定位
- **GroupNorm** (技术特性): BiT用GroupNorm替代BatchNorm的独特卖点，技术用户会专门搜索
- **Weight-Standardisation** (技术特性): 与GroupNorm并列的核心 trick，搜索量稳定且竞争小
- **bitresnet50** (参数规格): 官方提供的具体 checkpoint 名称，用户直接搜 bit_resnet50 找权重

### openMind/dpn_ms

**URL**: https://ai.gitcode.com/openMind/dpn_ms

**关键词列表**:

- **dpn92** (当前模型品牌名): 项目名称为dpn_ms，dpn92是该模型系列中具体且被性能报告明确列出的核心版本，用户搜索模型时会直接使用此名称
- **dpn98** (当前模型品牌名): dpn98是DPN系列中性能优异的代表性版本，在ImageNet-1K上Top-1达79.94%，是用户搜索具体模型权重时的高频目标
- **dpn107** (当前模型品牌名): dpn107是DPN系列中参数量较大但性能突出的版本，Top-1达80.05%，属于用户精准查找模型时的关键词
- **dpn131** (当前模型品牌名): dpn131是DPN系列中参数量与性能平衡的重要版本，被官方报告明确列出，是搜索该架构时的典型关键词
- **双路径网络** (技术特性): DPN的中文核心名称，描述其融合ResNet重用与DenseNet创新的双路径机制，是中文用户搜索该架构时的直接术语
- **Ascend-910训练** (部署工具): 模型在Ascend 910 NPU上完成分布式训练，该硬件+训练方式是国产AI生态中用户关注的部署场景关键词

### openMind/videocomposer_ms

**URL**: https://ai.gitcode.com/openMind/videocomposer_ms

**关键词列表**:

- **videocomposerms** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频合成** (功能场景): 当前模型的核心功能是视频合成
- **运动控制** (技术特性): 当前模型具有运动可控性这一技术特性
- **图像深度条件** (技术特性): 当前模型支持图像深度作为生成视频的条件
- **局部图像条件** (技术特性): 当前模型支持局部图像作为生成视频的条件
- **蒙版条件** (技术特性): 当前模型支持蒙版作为生成视频的条件
- **草图条件** (技术特性): 当前模型支持草图作为生成视频的条件

### openMind/mobilenetv3_ms

**URL**: https://ai.gitcode.com/openMind/mobilenetv3_ms

**关键词列表**:

- **MobileNetV3** (当前模型品牌名): 项目名称为mobilenetv3_ms，核心模型为MobileNetV3，是用户搜索轻量级图像分类模型时的直接关键词
- **mobilenet-v3-small** (当前模型品牌名): 模型明确提供两个版本，'mobilenet-v3 small'是官方命名的子版本，用户会按此名称搜索资源受限场景的模型
- **mobilenet-v3-large** (当前模型品牌名): 与small并列的官方版本名称，用户在对比精度与速度时会直接搜索该术语
- **NAS搜索** (技术特性): 模型核心创新点之一，使用神经网络架构搜索（NAS）自动设计结构，是区别于传统手工设计模型的关键技术词
- **倒置残差** (技术特性): 源自MobileNetV2的核心结构，被V3继承并优化，是该系列模型的标志性架构组件，用户搜索轻量网络时会关注此术语
- **SE模块** (技术特性): Squeeze-and-Excitation模块被集成进MobileNetV3，提升通道注意力，是区别于V1/V2的重要技术特征
- **NetAdapt微调** (技术特性): MobileNetV3独有的架构微调方法，用于优化激活通道，是论文中强调的专属技术流程，具有高区分度

### openMind/baichuan2_7b_base_ms

**URL**: https://ai.gitcode.com/openMind/baichuan2_7b_base_ms

**关键词列表**:

- **百川大模型2** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **192K长上下文窗口** (技术特性): 模型支持的超长上下文窗口，区别于普通模型的上下文长度
- **4位量化模型** (技术特性): 提供的对话版 4‑bit 量化模型，体现模型在部署上的轻量化特性
- **商业授权免费** (部署/使用方式): 官方提供的免费商业授权政策，是企业用户搜索模型时的重要考量

### openMind/telechat_7b_ms

**URL**: https://ai.gitcode.com/openMind/telechat_7b_ms

**关键词列表**:

- **TeleChat** (当前模型品牌名): 项目名称为telechat_7b_ms，模型官方命名为TeleChat，符合国产大模型命名规范，是用户搜索该模型的直接入口词
- **星辰语义大模型** (当前模型品牌名): 模型在README中正式命名为'星辰语义大模型-TeleChat'，'星辰语义大模型'是其品牌全称，具有唯一性，用户可能直接搜索该中文品牌名
- **1T中文数据集** (技术特性): 模型使用1T中文数据集训练，该规模和中文专精属性具有独特性，用户搜索'1T中文数据训练模型'时可能匹配到该模型，属于高价值技术标签
- **词嵌入层与输出层解耦** (技术特性): 模型在结构上采用'词嵌入层与输出层解耦'这一独特设计，提升训练稳定性，属于技术细节中用户可能搜索的精准术语，且未被高频词列表覆盖
- **课程学习** (技术特性): 模型训练中使用'课程学习'方法，该术语在大模型开源项目中较少被强调，具有区分度，适合吸引关注训练策略的高级用户

### openMind/fastspeech2_ms

**URL**: https://ai.gitcode.com/openMind/fastspeech2_ms

**关键词列表**:

- **FastSpeech2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **端到端TTS** (技术特性): 当前模型采用端到端架构，区别于传统流水线
- **LJSpeech** (功能场景): 当前模型官方预训练使用的数据集，用户会按数据集找模型
- **梅尔频谱** (技术特性): 当前模型输出梅尔频谱作为声学特征，用户搜索TTS时常用
- **F0音调特征** (技术特性): 当前模型使用F0值作为音调特征，区别于小波变换方案

### openMind/svd_ms

**URL**: https://ai.gitcode.com/openMind/svd_ms

**关键词列表**:

- **svdms** (当前模型品牌名): 从项目名称提取的当前模型名称
- **稳定视频扩散** (当前模型品牌名): README中提到的模型正式名称，体现模型特性
- **VideoLDM** (当前模型品牌名): README中提到的模型英文简称，便于搜索
- **文本到视频生成** (功能场景): README中提到的模型核心功能，用户可能搜索
- **MindSpore框架** (部署工具): README中提到的模型开发框架，用户可能关注部署环境
- **时间层扩展** (技术特性): README中提到的模型独特技术，体现模型创新性

### MooYeh/YOLOV9_for_PyTorch

**URL**: https://ai.gitcode.com/MooYeh/YOLOV9_for_PyTorch

**关键词列表**:

- **YOLOv9** (当前模型品牌名): 从项目名称 'YOLOV9_for_PyTorch' 提取的核心模型名称，用户搜索目标检测模型时会直接输入此名称
- **可编程梯度信息** (技术特性): YOLOv9 独有的核心技术（PGI），是区别于其他 YOLO 系列的关键创新点，用户会搜索该术语了解其原理
- **GELAN架构** (技术特性): YOLOv9 引入的专用架构（通用ELAN），是其性能提升的核心设计，具有唯一性且非通用术语
- **实时对象检测** (功能场景): YOLOv9 的核心应用场景，用户搜索‘实时目标检测模型’时会匹配该词，且非高频禁用词

### openMind/bert_base_cased

**URL**: https://ai.gitcode.com/openMind/bert_base_cased

**关键词列表**:

- **BERT-base-cased** (当前模型品牌名): 项目名称为bert_base_cased，按规范简化为标准品牌名形式，区分大小写版本是其核心标识
- **填充掩码** (功能场景): 模型核心预训练任务为掩码语言建模（MLM），中文用户搜索时常用'填充掩码'表达该功能，且未被列入高频排除词
- **区分大小写** (技术特性): 模型明确区分'english'与'English'，是其区别于uncased版本的核心技术特征，具有唯一性
- **BookCorpus** (数据集): 模型训练所用核心英文语料之一，用户在研究模型训练背景时可能搜索该数据集名称
- **Wikipedia** (数据集): 模型训练所用另一核心英文语料，与BookCorpus共同构成BERT原始训练基础，具搜索价值

### MooYeh/t5_small

**URL**: https://ai.gitcode.com/MooYeh/t5_small

**关键词列表**:

- **CANN兼容** (部署工具): 在 README 中新增了 CANN 版本依赖说明，表明模型可在 CANN 环境下部署
- **文本到文本框架** (技术特性): T5 的核心技术是统一的文本到文本转换框架，区别于仅输出标签的模型
- **60M参数** (参数规格): T5‑Small 包含约 6000 万参数，用户在搜索模型规模时会使用该关键词

### MooYeh/SDXL-Lightning

**URL**: https://ai.gitcode.com/MooYeh/SDXL-Lightning

**关键词列表**:

- **文本转图像** (功能场景): README明确描述的文生图核心功能
- **LoRA** (技术特性): 当前模型提供LoRA检查点，用户会搜LoRA微调
- **1024像素** (参数规格): 当前模型直接输出1024×1024高分辨率，用户会搜1024像素模型

### MooYeh/telechat_7b_ms

**URL**: https://ai.gitcode.com/MooYeh/telechat_7b_ms

**关键词列表**:

- **TeleChat-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **TeleChat-12B** (当前模型品牌名): 从项目名称提取的当前模型名称，且为最新开源版本
- **词嵌入层解耦** (技术特性): TeleChat-12B模型采用词嵌入层与输出层解耦的结构，为当前模型独特技术特性
- **科学数据配比学习** (技术特性): 当前模型在训练方法上使用的独特技术
- **中英文高质量语料** (技术特性): 当前模型训练所使用的数据特点，具有区分度

### openMind/mnasnet_ms

**URL**: https://ai.gitcode.com/openMind/mnasnet_ms

**关键词列表**:

- **MnasNet** (当前模型品牌名): 项目名称直接给出的模型品牌名
- **移动端CNN** (功能场景): 用户搜索适合手机/边缘设备的CNN模型时常用关键词
- **端侧推理** (部署工具): 强调在设备端实时推理，用户高频搜索词

### openMind/byt5_base

**URL**: https://ai.gitcode.com/openMind/byt5_base

**关键词列表**:

- **ByT5-base** (当前模型品牌名): 项目名称直接提供的模型品牌名称，用户搜索时会使用该名称定位模型
- **Byte-level-tokenization** (技术特性): 模型采用字节级（Byte‑level）分词方式，是其核心技术特性，区别于常规子词分词
- **英文文本生成** (功能场景): 模型主要面向英文语料的生成任务，用户常搜索“英文文本生成”来寻找此类模型
- **mc4数据集** (技术特性): 模型在大规模英文 mc4 语料上进行预训练，数据来源是用户关注的关键点
- **Encoder-decoder架构** (技术特性): ByT5 属于编码器‑解码器结构，区别于纯解码或纯编码模型，用户会以此为搜索关键词

### openMind/chatglm2_6b

**URL**: https://ai.gitcode.com/openMind/chatglm2_6b

**关键词列表**:

- **ChatGLM2-6B** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该模型的唯一官方名称
- **INT4量化** (部署工具): 模型支持INT4量化且明确提及显存占用降低（6G显存），是用户部署时关心的轻量化关键词，非通用术语
- **GLM混合目标函数** (技术特性): 模型独有的训练技术，区别于其他模型的训练方式，具有技术辨识度，非通用术语
- **Multi-Query-Attention** (技术特性): 模型推理加速的核心技术，官方强调速度提升42%，是专业用户搜索高效推理模型时的关键词
- **中英双语对话** (功能场景): 模型明确定位为中英双语对话，是区别于单语模型（如Llama）的核心功能标签，用户会搜索此组合词
- **32K对话** (功能场景): 用户搜索‘支持长对话的AI模型’时，‘32K对话’是具体场景化表达，非抽象概念，具搜索意图

### openMind/byt5_small

**URL**: https://ai.gitcode.com/openMind/byt5_small

**关键词列表**:

- **字节级Transformer** (技术特性): ByT5以字节而非子词为单位，是其独特卖点
- **小参数量** (参数规格): byt5_small表明轻量版，吸引低资源部署需求
- **字节跳动大模型** (当前模型品牌名): ByT5出自字节跳动团队，映射为品牌关键词

### openMind/beit_base_patch16

**URL**: https://ai.gitcode.com/openMind/beit_base_patch16

**关键词列表**:

- **beitbasepatch16** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视觉转换器** (技术特性): 当前模型属于视觉转换器（ViT）类型
- **遮蔽块预测** (技术特性): 当前模型的预训练目标是根据遮蔽块预测视觉标记
- **相对位置嵌入** (技术特性): 当前模型使用相对位置嵌入，与原始ViT模型不同

### openMind/blip-image-captioning-large

**URL**: https://ai.gitcode.com/openMind/blip-image-captioning-large

**关键词列表**:

- **图像描述** (功能场景): 模型核心功能是为图像生成文本描述，用户常搜索‘图像描述’而非‘image captioning’中文意译词
- **图像到文本** (功能场景): 用户在CSDN等平台常搜索‘图像到文本’这一直白功能表述，与‘文生图’形成对比，具有明确搜索意图

### openMind/deberta_v2_xlarge

**URL**: https://ai.gitcode.com/openMind/deberta_v2_xlarge

**关键词列表**:

- **DeBERTa-XLarge** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定模型时最可能使用的关键词
- **解耦注意力** (技术特性): DeBERTa的核心创新技术，区别于BERT/RoBERTa，是模型独特性的重要标识，用户会搜索该术语了解其原理
- **增强型掩码解码** (技术特性): DeBERTa的另一项关键改进技术，原文明确提及，具有技术辨识度，非通用术语，符合用户搜索模型差异点的意图
- **9亿参数** (参数规格): 模型参数量达9亿，属于主流大模型规模（接近10B级别），用户常搜索此类参数量级来评估模型能力，且未被高频词库排除
- **GLUE基准** (功能场景): 用户搜索NLU模型时常用'GLUE基准'作为评估标准关键词，代表模型在通用语言理解任务中的能力，是领域内高频搜索词但未被禁用
- **SQuAD-1.12.0** (功能场景): 问答任务的权威基准，用户搜索模型在SQuAD上的表现时会直接使用该术语，是NLP领域精准搜索词，且未被列入强制排除列表

### openMind/distilbert_base_uncased_finetuned_sst_2_english

**URL**: https://ai.gitcode.com/openMind/distilbert_base_uncased_finetuned_sst_2_english

**关键词列表**:

- **DistilBERT-SST-2** (当前模型品牌名): 从项目名称提取的模型品牌名，标明基于DistilBERT并在SST-2数据集上微调
- **英文文本分类** (功能场景): 模型的主要任务是英文文本的二分类（正面/负面）
- **Apache-2.0许可证** (许可证): 模型遵循 Apache-2.0 开源许可证，便于商业和科研自由使用

### openMind/bloom_3b

**URL**: https://ai.gitcode.com/openMind/bloom_3b

**关键词列表**:

- **BLOOM** (当前模型品牌名): 项目名称直接给出的当前模型品牌名
- **多语言大模型** (功能场景): README强调Multilingual，用户会搜多语言大模型
- **开源大模型** (功能场景): README中Open-science & Open-access，用户常搜开源大模型
- **AutoModelForCausalLM** (部署工具): 示例代码中使用的部署接口，开发者会搜索

### openMind/deberta_base

**URL**: https://ai.gitcode.com/openMind/deberta_base

**关键词列表**:

- **debertabase** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Decoding-enhanced** (技术特性): 当前模型采用了解码增强技术，是区别于其他模型的核心特性
- **Disentangled-Attention** (技术特性): 当前模型使用的解耦注意力机制，是其独特技术点
- **Enhanced-Mask-Decoder** (技术特性): 当前模型使用的增强掩码解码器，是其技术优势之一
- **NLU任务** (功能场景): 当前模型在自然语言理解任务上表现出色，是其主要应用场景

### openMind/resnet_50

**URL**: https://ai.gitcode.com/openMind/resnet_50

**关键词列表**:

- **ResNet-50** (当前模型品牌名): 从项目名称直接提取的当前模型标准名称，用户搜索图像分类模型时高频使用
- **残差网络** (技术特性): ResNet的核心创新是残差学习与跳过连接，该术语是技术社区对ResNet的通用指代
- **v1.5版本** (当前模型品牌名): 模型明确标注为v1.5，区别于原始ResNet-50，是用户区分版本时的关键搜索词
- **vision** (技术特性): 标签中明确包含'vision'，指代计算机视觉任务，是模型所属领域的精准技术标签

### openMind/siglip_so400m_patch14_384

**URL**: https://ai.gitcode.com/openMind/siglip_so400m_patch14_384

**关键词列表**:

- **SigLIP** (当前模型品牌名): 项目名称为siglip_so400m_patch14_384，核心品牌名为SigLIP，是当前模型的唯一官方名称，符合用户搜索AI模型时的简洁品牌名习惯
- **Sigmoid-Loss** (技术特性): 模型核心创新点是使用Sigmoid Loss替代CLIP的对比损失，是区别于其他多模态模型的关键技术，用户会搜索该术语以了解其独特设计
- **SoViT-400m** (当前模型品牌名): 模型基于SoViT-400m架构，是论文中提出的专有名称，属于当前模型的专属技术标识，非通用术语，具有高区分度
- **零样本图像分类** (功能场景): README明确指出模型可用于零样本图像分类，是用户最可能搜索的实际应用场景，且未被高频词列表排除
- **WebLi预训练** (技术特性): 模型在WebLi数据集上预训练，是其训练数据来源的独特标识，区别于COCO、LAION等通用数据集，具有检索价值
- **384x384分辨率** (技术特性): 模型输入分辨率是其关键配置，用户在寻找高分辨率多模态模型时会搜索该规格，且未被高频词列表覆盖

### openMind/tapas_base_finetuned_wtq

**URL**: https://ai.gitcode.com/openMind/tapas_base_finetuned_wtq

**关键词列表**:

- **TAPAS** (当前模型品牌名): 模型名称来源于项目名 “tapas_base_finetuned_wtq”，是该模型的品牌标识
- **表格问答** (功能场景): 模型专注于对表格数据进行问答，属于表格问答场景
- **WikiTable-Question** (功能场景): 模型在 WikiTable Question（WTQ）数据集上进行微调，是该任务的核心关键词
- **中间预训练** (技术特性): 模型在微调前使用了作者提出的中间预训练步骤，以提升表格数值推理能力
- **绝对位置嵌入** (技术特性): 非默认的 no_reset 版本使用绝对位置嵌入，提供不同的位置信息编码方式
- **WTQ微调** (功能场景): 模型在 WTQ（WikiTable Question）任务上完成微调，是其主要应用场景

### openMind/SDXL-Lightning

**URL**: https://ai.gitcode.com/openMind/SDXL-Lightning

**关键词列表**:

- **SDXL-Lightning** (当前模型品牌名): 从项目名称提取的当前模型名称
- **极速文生图** (功能场景): 当前模型的核心功能，强调生成速度
- **渐进式对抗扩散蒸馏** (技术特性): 当前模型的核心技术特性
- **UNet模型** (技术特性): 当前模型提供的完整UNet模型品质最佳
- **LoRA模型** (技术特性): 当前模型提供的LoRA模型可适配其他基础模型
- **昇腾平台适配** (部署工具): 当前模型适配昇腾平台并新增NPU支持

### openMind/baichuan2_13b_base_ms

**URL**: https://ai.gitcode.com/openMind/baichuan2_13b_base_ms

**关键词列表**:

- **Baichuan2** (当前模型品牌名): 从项目名称 'baichuan2_13b_base_ms' 提取的核心品牌名，符合简化规则（去版本号后缀），是用户搜索该模型的直接入口词
- **中文英文双语** (功能场景): 模型在'中文和英文benchmark'均取得最佳效果，用户常搜索'中文英文双语模型'以寻找多语言能力，该词精准且未被高频词列表覆盖
- **192K长窗口** (技术特性): 模型支持192K上下文长度，是其区别于同类模型的显著技术亮点，用户会搜索'长上下文模型'或具体数值，且该数值未被归类为'技术细节'（因192K是宣传重点，非底层参数）
- **百川搜索增强** (功能场景): 模型新增'百川搜索增强知识库'，是百川2独有的功能特性，非通用术语，用户可能搜索'百川搜索增强'以获取该特有能力，具有高区分度

### openMind/xglm_564m

**URL**: https://ai.gitcode.com/openMind/xglm_564m

**关键词列表**:

- **XGLM-564M** (当前模型品牌名): 项目名称中直接出现的模型品牌名，用户搜索时会使用该名称定位模型
- **564M参数** (参数规格): 模型拥有 564M 参数，是区别于其他规模模型的关键规格，用户常以参数大小检索模型
- **30语言覆盖** (功能场景): 模型在 30 种语言上进行训练，用户搜索时常关注模型支持的语言数量

### openMind/bit_50

**URL**: https://ai.gitcode.com/openMind/bit_50

**关键词列表**:

- **BiT** (当前模型品牌名): 项目名 bit_50 对应论文提出的 BiT（Big Transfer）模型
- **大迁移** (技术特性): 论文核心概念“大迁移”是 BiT 的招牌技术，用户会搜
- **ResNetv2** (技术特性): BiT 基于 ResNetv2 架构，搜索者常按骨干网络找模型
- **VTAB基准** (功能场景): 论文强调在 VTAB 19 任务上 SOTA，研究者常搜该基准
- **小样本图像分类** (功能场景): BiT 每类 10 张图就能达到 97% CIFAR-10 精度，小样本需求者会搜

### openMind/xlnet_base_cased

**URL**: https://ai.gitcode.com/openMind/xlnet_base_cased

**关键词列表**:

- **xlnetbasecased** (当前模型品牌名): 从项目名称提取的当前模型名称
- **广义自回归预训练** (技术特性): 当前模型采用的核心技术方法
- **Transformer-XL** (技术特性): 当前模型采用的主干模型架构
- **长文本处理** (功能场景): 当前模型在长文本语言任务中的卓越性能
- **问答任务** (功能场景): 当前模型在问答任务中实现了SOTA效果
- **自然语言推理** (功能场景): 当前模型在自然语言推理任务中表现出色

### openMind/convnext_ms

**URL**: https://ai.gitcode.com/openMind/convnext_ms

**关键词列表**:

- **ConvNeXt** (当前模型品牌名): 项目名称即为ConvNeXt，是当前模型品牌名
- **ResNet现代化** (技术特性): README强调将ResNet逐步现代化为ConvNeXt
- **87.8-top-1** (技术特性): 官方宣称的ImageNet top-1准确率，用户会搜
- **28M参数** (参数规格): convnext_tiny仅28.59M参数，轻量级模型
- **MindSpore模式** (部署工具): 支持MindSpore图模式与pynative模式部署

### openMind/glm3_6b_ms

**URL**: https://ai.gitcode.com/openMind/glm3_6b_ms

**关键词列表**:

- **ChatGLM3-6B-Base** (当前模型品牌名): 开源的基础模型名称，用户常以此搜索模型细节
- **ChatGLM3-6B-32K** (当前模型品牌名): 长文本对话模型的专属名称，区别于普通版
- **全新Prompt格式** (技术特性): 模型采用的最新 Prompt 设计，用户关注其交互方式
- **长文本对话** (功能场景): 模型支持 32K 上下文的长文本对话，满足大段落交互需求

### openMind/mobilenetv2_ms

**URL**: https://ai.gitcode.com/openMind/mobilenetv2_ms

**关键词列表**:

- **mobilenetv2ms** (当前模型品牌名): 从项目名称提取的当前模型名称
- **线性瓶颈** (技术特性): 当前模型的核心技术特性之一
- **移动定制计算机视觉** (功能场景): 当前模型专为移动和资源受限环境设计，属于计算机视觉领域
- **轻量级深度卷积** (技术特性): 当前模型使用的关键技术，体现其轻量级特性

### openMind/stable-diffusion-xl-base-1_0_ms

**URL**: https://ai.gitcode.com/openMind/stable-diffusion-xl-base-1_0_ms

**关键词列表**:

- **昇思MindSpore** (部署工具): 模型基于昇思MindSpore框架实现，是区别于主流PyTorch/TF模型的关键部署技术，用户会搜索'MindSpore 文生图模型'等组合词
- **双文本编码器** (技术特性): 模型采用双文本编码器（OpenCLIP-ViT/G），是SDXL架构的核心技术点，具有区分度，且未被列入高频词禁止列表
- **昇腾910** (部署工具): 模型样图在昇腾910平台生成，是国产AI芯片部署场景的关键词，用户搜索'昇腾 文生图'或'昇腾910 模型'有明确需求，且非通用硬件词
- **潜在扩散模型** (技术特性): 模型基于潜在扩散模型架构，是SDXL的技术本质描述，用户在学术搜索中会使用该术语，且未在高频词列表中

### openMind/opensora-hpcai-1_0_ms

**URL**: https://ai.gitcode.com/openMind/opensora-hpcai-1_0_ms

**关键词列表**:

- **OpenSora** (当前模型品牌名): 项目名称直接给出的当前模型名称
- **720P视频生成** (功能场景): README示例展示16×256×720分辨率，用户会搜高清视频生成
- **724M参数** (参数规格): README给出具体参数规模，用户搜索模型大小时常用
- **PixArt初始化** (技术特性): README提到权重部分来自PixArt-α，技术爱好者会搜

### openMind/yolov4_ms

**URL**: https://ai.gitcode.com/openMind/yolov4_ms

**关键词列表**:

- **YOLOv4** (当前模型品牌名): 项目名称中直接使用的模型名称，用户搜索时会以 YOLOv4 为关键词定位该模型
- **CSPDarknet53** (技术特性): YOLOv4 所采用的主干网络结构，属于模型独有的架构特性
- **Mish激活** (技术特性): 模型使用的激活函数，区别于常见的 ReLU/SiLU，用户会搜索该激活方式的实现
- **Mosaic数据增强** (技术特性): YOLOv4 引入的特有数据增强技术，提升检测效果，具备搜索热度
- **DropBlock正则化** (技术特性): 模型采用的正则化手段，区别于普通 Dropout，用户会关注此细节
- **CIoU损失** (技术特性): 用于边界框回归的损失函数，YOLOv4 的核心改进点之一

### openMind/vit_base_patch16_224

**URL**: https://ai.gitcode.com/openMind/vit_base_patch16_224

**关键词列表**:

- **ViT-base** (当前模型品牌名): 项目名称为vit_base_patch16_224，简化为行业通用品牌名ViT-base，符合用户搜索习惯（如SD-XL风格），且未被高频词列表排除
- **Patch16** (技术特性): 模型核心架构特征：将图像切分为16x16图块，是ViT区别于CNN的关键技术点，用户搜索'ViT Patch16'有明确意图，且非高频禁用词
- **ImageNet-21k** (技术特性): 模型在ImageNet-21k上预训练是其重要训练背景，用户常搜索'ViT ImageNet-21k'以区分不同预训练数据集的模型版本，具有区分度
- **CLS标记** (技术特性): 模型使用[CLS]标记进行分类，是Transformer图像模型的标志性设计，具有技术辨识度，非泛泛术语，且未被高频词列表覆盖

### openMind/yolox_ms

**URL**: https://ai.gitcode.com/openMind/yolox_ms

**关键词列表**:

- **yoloxms** (当前模型品牌名): 从项目名称提取的当前模型名称
- **无锚框检测器** (技术特性): 当前模型采用了无锚框方式，是区别于其他模型的技术特性
- **解耦头** (技术特性): 当前模型采用了先进检测技术中的解耦头，是核心技术特性
- **SimOTA标签分配** (技术特性): 当前模型采用了领先的标签分配策略SimOTA，是核心技术特性
- **高性能检测器** (功能场景): 当前模型是一款新型高性能检测器，描述了模型的功能场景
- **自动驾驶挑战冠军** (功能场景): 当前模型在使用单个YOLOX-L模型的CVPR 2021自动驾驶研讨会流感知挑战中荣获第一名，体现了模型在自动驾驶领域的应用场景

### openMind/llama_7b_ms

**URL**: https://ai.gitcode.com/openMind/llama_7b_ms

**关键词列表**:

- **LLaMA复现** (功能场景): 模型核心定位是'开源复现Meta的LLaMA'，用户搜索'LLaMA复现'可精准找到本项目，且不属于高频排除词
- **7B模型** (参数规格): 模型明确提供7B参数版本，属于主流规格，且'7B参数'已被排除，'7B模型'为更自然的用户搜索词，具有区分度
- **Alpaca微调** (功能场景): README明确提及支持Alpaca数据集的全参数与LoRA微调，'Alpaca微调'是用户寻找特定微调方案时的精准搜索词，非高频词
- **JAX权重** (部署工具): 模型提供PyTorch和JAX两种权重格式，'JAX权重'是专业用户搜索非PyTorch框架模型时的精准关键词，非高频词且具技术区分度

### openMind/inceptionv4_ms

**URL**: https://ai.gitcode.com/openMind/inceptionv4_ms

**关键词列表**:

- **InceptionV4** (当前模型品牌名): 项目名称中直接使用的模型名称
- **Inception-ResNet-v2** (技术特性): 模型融合了 Inception 与 ResNet 的结构，是其核心技术特性
- **残差连接** (技术特性): 模型通过残差连接加速训练并提升性能，属于独特技术点
- **分布式训练** (部署工具): 支持在多卡 Ascend/NPU 环境下的分布式训练，属于模型的部署/训练方式
- **42M参数** (参数规格): 模型参数量约为 42.74M，用户会依据参数规模搜索模型

### openMind/efficientnet_ms

**URL**: https://ai.gitcode.com/openMind/efficientnet_ms

**关键词列表**:

- **EfficientNet** (当前模型品牌名): 从项目名称efficientnet_ms提取的当前模型名称
- **复合缩放** (技术特性): EfficientNet的核心创新，通过同时缩放宽度、深度、分辨率提升性能
- **神经网络架构搜索** (技术特性): EfficientNet使用NAS自动寻找最优缩放配置，用户会搜NAS相关模型

### openMind/densenet_ms

**URL**: https://ai.gitcode.com/openMind/densenet_ms

**关键词列表**:

- **DenseNet** (当前模型品牌名): 项目名称为densenet_ms，核心模型名称为DenseNet，是用户搜索该架构时的直接关键词
- **密集连接** (技术特性): DenseNet的核心创新是‘密集连接’（densely connected），为该模型独有技术术语，用户搜索该架构时会使用此中文术语
- **特征重用** (技术特性): DenseNet通过特征重用提升效率与精度，是其区别于传统CNN的关键机制，属于用户搜索该模型时的精准技术词
- **轻量级网络** (技术特性): DenseNet被广泛认知为参数效率高、结构紧凑的轻量级网络，虽未直接写‘轻量级’，但‘更高效训练’‘更准确’暗示此特性，且未被高频词排除

### openMind/googlenet_ms

**URL**: https://ai.gitcode.com/openMind/googlenet_ms

**关键词列表**:

- **GoogLeNet** (当前模型品牌名): 项目名称即模型名称，用户直接搜索GoogLeNet找实现
- **Inception结构** (技术特性): GoogLeNet的核心创新，用户常搜Inception了解网络设计
- **ImageNet-1K复现** (功能场景): README明确给出ImageNet-1K复现结果，用户搜此关键词找可复现权重
- **MindSpore版** (部署工具): 项目基于MindSpore实现，用户搜MindSpore版GoogLeNet获取代码
- **Top-1-72.68** (参数规格): 突出的精度数字，用户用具体精度值筛选模型
- **6.99M参数** (参数规格): 轻量级参数量，用户搜小参数模型做端侧部署

### openMind/convnextv2_ms

**URL**: https://ai.gitcode.com/openMind/convnextv2_ms

**关键词列表**:

- **遮码自编码器** (技术特性): 当前模型使用的核心技术框架
- **全局响应归一化** (技术特性): 当前模型新增的核心技术层
- **COCO检测** (功能场景): 当前模型的主要应用场景之一
- **ADE20K分割** (功能场景): 当前模型的主要应用场景之一

### openMind/mobilevit_ms

**URL**: https://ai.gitcode.com/openMind/mobilevit_ms

**关键词列表**:

- **MobileViT** (当前模型品牌名): 项目名称为mobilevit_ms，模型核心名称为MobileViT，是当前模型的唯一品牌标识
- **轻量级视觉变换器** (技术特性): README明确强调MobileViT是‘轻量级、通用型、适用于移动设备的视觉变换器’，这是其区别于其他ViT和CNN的核心技术定位
- **移动设备视觉模型** (功能场景): 模型专为移动设备设计，用于视觉任务，用户搜索‘移动设备上的AI视觉模型’时会精准匹配此场景词
- **图像分类模型** (功能场景): 模型在ImageNet-1k上验证，且性能对比基于图像分类任务，是其主要应用场景，且未被高频词列表排除
- **目标检测模型** (功能场景): 在MS-COCO目标检测任务中表现优异，是模型的重要应用方向，属于用户真实搜索意图
- **5.59M参数** (参数规格): mobilevit_small参数量为5.59M，属于主流轻量级模型规格（介于1M~10M），用户会搜索‘5M参数视觉模型’等关键词

### openMind/internlm_7b_base_ms

**URL**: https://ai.gitcode.com/openMind/internlm_7b_base_ms

**关键词列表**:

- **InternLM** (当前模型品牌名): 项目名称中直接出现的模型品牌，用户搜索时会使用该名称定位模型
- **InternLM-7B** (当前模型品牌名): 模型的完整品牌+规模标识，便于区分同系列的不同尺寸模型
- **高质量语料训练** (技术特性): README 中强调模型使用海量高质量 tokens 进行训练，是模型的核心技术卖点
- **工作流工具集** (功能场景): 模型提供灵活的工具集帮助用户自行构建工作流，属于典型的使用场景关键词
- **OpenCompass评估** (技术特性): 使用开源评估框架 OpenCompass 完成多维能力评估，具备辨识度的技术关键词
- **多维能力评估** (技术特性): 模型在学科、语言、知识、推理、理解五大维度进行评测，突出模型的综合能力
- **知识库构建** (功能场景): 模型通过海量语料形成强大的知识库，适用于需要知识检索与问答的场景

### openMind/internlm_7b_chat_ms

**URL**: https://ai.gitcode.com/openMind/internlm_7b_chat_ms

**关键词列表**:

- **8K上下文** (技术特性): 当前模型支持8k超长上下文窗口，用户会搜
- **OpenCompass评测** (技术特性): 当前模型使用OpenCompass进行全面评测，用户会搜
- **常识推理** (功能场景): 当前模型在常识推理维度表现突出，用户会搜

### FlashAI/qwen

**URL**: https://ai.gitcode.com/FlashAI/qwen

**关键词列表**:

- **本地知识库** (功能场景): 模型核心特色是内置自研本地知识库系统，用户会搜索'带本地知识库的AI模型'这类意图
- **离线大模型** (部署工具): 强调'无需联网、完全离线使用'，是用户寻找隐私安全型AI模型时的高频搜索词
- **70B参数** (参数规格): 70B是当前开源领域顶级规模之一，虽需高性能设备，但搜索量稳定，属高价值关键词
- **开箱即用** (部署工具): 反复强调'无需安装配置、开箱即用'，是用户寻找低门槛AI工具时的核心搜索意图

### FlashAI/qwen3

**URL**: https://ai.gitcode.com/FlashAI/qwen3

**关键词列表**:

- **Qwen3-235B-A22B** (当前模型品牌名): 项目提供的旗舰模型完整名称，用户搜索时会直接使用该标识
- **235B参数** (参数规格): 模型规模为 235B 参数，是用户关注的关键规格之一
- **Qwen3-30B-A3B** (当前模型品牌名): 项目提供的中型 MoE 模型完整名称，具备辨识度
- **30B参数** (参数规格): 模型规模为 30B 参数，常被用户作为筛选条件
- **私有化大模型** (功能场景): FlashAI 主打私有化部署，满足企业对模型安全的需求
- **离线推理** (部署工具): 项目强调完全离线使用，用户会搜索“离线推理”来寻找此类模型

### FlashAI/vision

**URL**: https://ai.gitcode.com/FlashAI/vision

**关键词列表**:

- **FlashAI** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多模态版整合包** (功能场景): 当前模型提供的整合包功能场景描述
- **离线运行** (技术特性): 当前模型无需联网，可离线运行的技术特性
- **永久免费** (技术特性): 当前模型永久免费的技术特性
- **Gemma3大模型** (关联模型（简化）): README中提及的关联模型，简化提取（虽非当前模型，但为项目特色提及，且非严格禁止类型，此处作为特色补充）

### FlashAI/convert-lite

**URL**: https://ai.gitcode.com/FlashAI/convert-lite

**关键词列表**:

- **convert-lite** (当前模型品牌名): 项目名称为convert-lite，是当前模型的唯一品牌标识，用户搜索文件格式转换工具时可能直接使用该名称
- **PDF转Markdown** (功能场景): 模型核心功能之一，用户常搜索此类具体格式转换需求，具有明确搜索意图且非高频词
- **Word转Markdown** (功能场景): 模型支持的核心转换场景，用户在办公自动化场景中高频搜索，区别于通用‘文档转换’
- **Excel转Markdown** (功能场景): 模型支持的特殊格式转换，市场上少有离线工具支持此功能，具备高区分度
- **PPT转Markdown** (功能场景): PPT内容结构化转换是稀缺功能，用户搜索时倾向使用具体格式组合，非通用词
- **图片转文字Markdown** (功能场景): 模型内置OCR实现图片→Markdown，用户搜索‘图片转可编辑文本’时会使用此表述，非通用OCR词
- **Markdown转Word** (功能场景): 反向导出功能独特，用户需将Markdown整理为正式文档时会搜索此组合，竞争低
- **离线文件转换** (功能场景): 强调‘无需联网’的核心卖点，用户在关注隐私的场景中会主动搜索‘离线’+‘文件转换’组合

### FlashAI/flashai-convert

**URL**: https://ai.gitcode.com/FlashAI/flashai-convert

**关键词列表**:

- **OCR转Markdown** (功能场景): 支持将图片中的文字通过 OCR 自动转换为 Markdown 格式
- **跨格式转换** (功能场景): 能够将 PDF、Word、Excel、PPT、HTML 等多种文件格式转换为 Markdown
- **安全证书签名** (技术特性): 所有文件均经过证书签名，确保软件安全可靠

### FlashAI/gemma3

**URL**: https://ai.gitcode.com/FlashAI/gemma3

**关键词列表**:

- **Gemma3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **一键部署** (部署工具): README多次出现“一键部署”“开箱即用”，用户搜索部署方式
- **27B参数** (参数规格): 提供27B版本，属于主流大模型规格，用户会搜
- **图形界面** (部署工具): 集成图形界面，降低使用门槛，用户会搜GUI部署

### FlashAI/deepseek

**URL**: https://ai.gitcode.com/FlashAI/deepseek

**关键词列表**:

- **DeepSeek** (当前模型品牌名): 从项目名称提取的当前模型名称
- **低配机器使用** (部署工具): 当前模型低配机器也可以使用云端大模型版本，是其部署优势
- **自研知识库系统** (技术特性): 当前模型自研本地知识库系统，可自主微调模型，是其技术亮点

### FlashAI/server

**URL**: https://ai.gitcode.com/FlashAI/server

**关键词列表**:

- **FlashAI-Server** (当前模型品牌名): 项目名称为FlashAI Server，是当前模型的官方品牌名，用户搜索私有化大模型工具时可能直接使用此名称
- **自研知识库** (技术特性): 区别于通用RAG，强调自研本地知识库系统，是产品独特技术点，用户可能搜索‘自研知识库大模型’
- **文件证书签名** (技术特性): 强调安全可靠，文件带证书签名，属于安全可信部署的差异化特征，用户关注数据安全时可能搜索此关键词
- **CPU运行大模型** (部署工具): 突出‘仅需CPU+内存’即可运行，精准匹配低配用户搜索意图，如‘CPU跑大模型’，区别于通用‘本地部署’

### MooYeh/resnet50_ms

**URL**: https://ai.gitcode.com/MooYeh/resnet50_ms

**关键词列表**:

- **ResNet50** (当前模型品牌名): 项目名称直接体现的核心模型简称
- **224x224分辨率** (技术特性): 图像输入尺寸是用户部署时必查参数
- **图像识别** (功能场景): ResNet-50最经典的应用任务

### tencent_hunyuan/Hunyuan3D-Part

**URL**: https://ai.gitcode.com/tencent_hunyuan/Hunyuan3D-Part

**关键词列表**:

- **Hunyuan3D-Part** (当前模型品牌名): 完整项目名称，直接标识模型本身
- **P3SAM分割** (技术特性): 模型核心组件，提供原生 3D 部件分割功能
- **XPart形状合成** (技术特性): 模型的高保真、结构一致的形状组合模块
- **3D部件生成** (功能场景): 模型的主要应用场景：从图像生成完整的 3D 零件
- **部件检测** (技术特性): P3‑SAM 中用于获取语义特征、部件分割和部件边界框的检测步骤
- **语义特征提取** (技术特性): 模型在生成 3D 部件前对输入图像进行的关键语义分析

### ascend-tribe/openPangu-Embedded-1B-V1.1

**URL**: https://ai.gitcode.com/ascend-tribe/openPangu-Embedded-1B-V1.1

**关键词列表**:

- **openPangu-Embedded** (当前模型品牌名): 从项目名称提取的核心品牌名，省略版本号符合简化规则，是用户搜索国产嵌入式大模型时可能使用的关键词
- **离线On-policy蒸馏** (技术特性): 当前模型特有的后训练技术，虽专业但属于模型专属关键词，搜索此词的用户精准定位该模型优化路径

### openMind/albert_xlarge_v2

**URL**: https://ai.gitcode.com/openMind/albert_xlarge_v2

**关键词列表**:

- **ALBERT-XLarge** (当前模型品牌名): 项目名称中直接出现的模型完整品牌名
- **遮蔽语言模型** (技术特性): 模型采用的 Masked Language Modeling（MLM）预训练目标
- **文本特征提取** (功能场景): 模型可用于生成句子/文本特征，支持下游分类等任务
- **双向句子表示** (技术特性): 通过 MLM 使模型学习双向上下文表示
- **英文自监督预训练** (功能场景): 模型在大规模英文语料上进行自监督学习，适用于英文 NLP 任务

### tencent_hunyuan/Hunyuan3D-Omni

**URL**: https://ai.gitcode.com/tencent_hunyuan/Hunyuan3D-Omni

**关键词列表**:

- **3D生成** (功能场景): 当前模型核心用途是生成3D资产
- **点云控制** (技术特性): 支持用点云作为控制信号生成3D模型
- **体素控制** (技术特性): 支持用体素表示作为控制信号
- **骨骼姿态控制** (技术特性): 支持用骨骼姿态精确控制3D人物模型
- **3.3B参数** (参数规格): 当前模型公开参数规模

### ascend-tribe/openPangu-Embedded-7B-V1.1

**URL**: https://ai.gitcode.com/ascend-tribe/openPangu-Embedded-7B-V1.1

**关键词列表**:

- **openPangu-Embedded-7B-V1.1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自适应切换** (技术特性): 当前模型具备快慢思考融合与自适应切换能力，是其独特技术特性
- **34层架构** (技术特性): 当前模型有34层架构，是其独特技术参数
- **12800隐藏维度** (技术特性): 当前模型隐藏维度为12800，是其独特技术参数

### openMind/bloom_1b1

**URL**: https://ai.gitcode.com/openMind/bloom_1b1

**关键词列表**:

- **bloom1b1** (当前模型品牌名): 项目名称直接为bloom_1b1，是当前模型的唯一标识，符合用户搜索模型名称的意图
- **Multilingual** (技术特性): 模型名称中强调'Open-access Multilingual Language Model'，突出多语言能力，是该模型区别于其他模型的显著技术标签
- **OpenScience** (技术特性): BigScience项目核心理念，'Open-science'是该模型的官方定位关键词，具有独特性且未被高频词库覆盖
- **PyTorch-NPU** (部署工具): 模型加载路径明确使用'PyTorch-NPU/bloom_1b1'，表明其适配NPU硬件的PyTorch部署形态，具有技术唯一性

### openMind/baichuan2_7b_base

**URL**: https://ai.gitcode.com/openMind/baichuan2_7b_base

**关键词列表**:

- **超长上下文窗口** (技术特性): 模型支持 192K 超长上下文窗口，是其技术亮点，用户会以此为关键词搜索
- **免费商用授权** (部署工具): 模型提供免费商业使用授权，属于用户在部署/使用时关注的重要信息

### openMind/roberta_base_squad2

**URL**: https://ai.gitcode.com/openMind/roberta_base_squad2

**关键词列表**:

- **roberta-base-squad2** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索QA模型时会精确输入此名称
- **提取式QA** (功能场景): 当前模型的核心任务类型，用户搜索‘英文提取式问答模型’时会使用该术语，具有明确技术指向性
- **SQuAD2.0** (功能场景): 当前模型训练和评估所用的专属数据集，专业用户会以此为关键词搜索支持未回答问题的QA模型
- **Transformers** (部署工具): 模型通过Hugging Face Transformers库直接加载，是用户部署时最常使用的接口术语，非通用词而是具体工具名
- **deepsettinyroberta-squad2** (当前模型品牌名): README中明确提及的该模型的精简版，属于当前项目家族的官方衍生模型，应作为独立品牌名提取
- **Haystack** (部署工具): 模型官方推荐的使用框架，用户搜索‘Haystack 问答模型’时会精准匹配，是具体工具而非通用词
- **squadv2** (功能场景): 数据集标签中明确使用的小写标准写法，技术用户在搜索兼容SQuAD2.0的模型时会使用该格式关键词

### openMind/t5_base

**URL**: https://ai.gitcode.com/openMind/t5_base

**关键词列表**:

- **T5-Base** (当前模型品牌名): 从项目名称t5_base提取的当前模型名称
- **220M参数** (参数规格): 当前模型的具体参数规模，用户会搜

### openMind/stable_diffusion_v1_5

**URL**: https://ai.gitcode.com/openMind/stable_diffusion_v1_5

**关键词列表**:

- **stablediffusionv15** (当前模型品牌名): 从项目名称提取的当前模型名称
- **潜在文本转图像** (功能场景): 当前模型的核心功能，即根据文本输入生成图像
- **微调模型** (技术特性): 当前模型在特定数据集上进行了微调，是其技术特性之一
- **无需分类器引导** (技术特性): 当前模型改善了无需分类器的引导采样，是其独特技术点
- **Diffusers库** (部署工具): 当前模型可使用Diffusers库来部署和使用

### openMind/pangu-draw-v3_ms

**URL**: https://ai.gitcode.com/openMind/pangu-draw-v3_ms

**关键词列表**:

- **PanGu-Draw** (当前模型品牌名): 从项目名称提取的当前模型名称
- **中国水墨画** (功能场景): README示例突出中国水墨风格，用户会搜此类风格生成
- **文本生成图像** (功能场景): README明确text-to-image，用户用完整中文短语搜索
- **MindSpore-lab** (当前模型品牌名): 开发组织名，用户可能用组织名+模型关键词组合搜索
- **apache-2.0** (部署工具): 开源协议关键词，用户搜可商用开源文生图模型时会用

### openMind/mobilenetv1_ms

**URL**: https://ai.gitcode.com/openMind/mobilenetv1_ms

**关键词列表**:

- **MobileNetV1** (当前模型品牌名): 项目名称即为模型品牌名
- **深度可分离卷积** (技术特性): 模型核心的轻量化卷积实现方式
- **轻量级卷积神经网络** (技术特性): 描述模型整体结构的轻量化特性
- **移动视觉应用** (功能场景): 模型专为移动端视觉任务设计
- **0.47M参数** (参数规格): MobileNetV1 最小尺度版本的参数量，仅 0.47M
