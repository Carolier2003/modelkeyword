# 模型关键词提取分析报告

## 概览统计

- 📊 **CSV读取模型数**: 2
- ✅ **成功提取模型数**: 2
- ❌ **失败模型数**: 0
- 📈 **成功率**: 100.0%
- 🔍 **原始关键词总数**: 14
- ✂️ **去重后关键词总数**: 14
- 📉 **去重率**: 0.0%
- 📊 **平均每模型关键词数**: 7.0
- 🕐 **生成时间**: 2025-10-10 09:36:40

## 维度分布

| 维度 | 关键词数量 | 占比 |
|------|------------|------|
| 核心技术架构 | 4 | 28.6% |
| 热门模型品牌 | 3 | 21.4% |
| 部署集成 | 3 | 21.4% |
| 性能规格 | 2 | 14.3% |
| 专业领域 | 1 | 7.1% |
| 应用场景 | 1 | 7.1% |

## 原始数据高频关键词分析

> 基于去重前的原始提取数据，展示整个数据集中最常见的关键词

| 排名 | 关键词 | 原始出现次数 | 最终保留次数 |
|------|--------|-------------|-------------|
| 1 | InternLM大模型 | 1 | 1 |
| 2 | 235B-MoE架构 | 1 | 1 |
| 3 | FP8量化 | 1 | 1 |
| 4 | 科学计算大模型 | 1 | 1 |
| 5 | 多模态推理 | 1 | 1 |
| 6 | Ollama部署 | 1 | 1 |
| 7 | 5T-token预训练 | 1 | 1 |
| 8 | FLUX.1大模型 | 1 | 1 |
| 9 | SVDQuant量化 | 1 | 1 |
| 10 | 文本生成图像 | 1 | 1 |
| 11 | ComfyUI集成 | 1 | 1 |
| 12 | Diffusers兼容 | 1 | 1 |
| 13 | INT4量化模型 | 1 | 1 |
| 14 | NVIDIA大模型 | 1 | 1 |

## 所有关键词列表


### 专业领域 (1个)

- **科学计算大模型**

### 应用场景 (1个)

- **文本生成图像**

### 性能规格 (2个)

- **5T-token预训练** • **INT4量化模型**

### 核心技术架构 (4个)

- **235B-MoE架构** • **FP8量化** • **SVDQuant量化** • **多模态推理**

### 热门模型品牌 (3个)

- **FLUX.1大模型** • **InternLM大模型** • **NVIDIA大模型**

### 部署集成 (3个)

- **ComfyUI集成** • **Diffusers兼容** • **Ollama部署**

## 详细结果


### internlm/Intern-S1-FP8

**URL**: https://gitcode.com/hf_mirrors/internlm/Intern-S1-FP8

**关键词列表**:

- **InternLM大模型** (热门模型品牌): 官方品牌+大模型后缀，CSDN搜索量高
- **235B-MoE架构** (核心技术架构): 超大参数+MoE热点，技术圈热搜
- **FP8量化** (核心技术架构): 低精度训练推理新趋势，性能优化必搜
- **科学计算大模型** (专业领域): 化学、生物、地震等科研场景刚需关键词
- **多模态推理** (核心技术架构): 图文混合推理技术风口，开发者高度关注
- **Ollama部署** (部署集成): 本地一键运行热门方案，教程搜索量大
- **5T-token预训练** (性能规格): 超大规模数据量吸睛，彰显模型实力

### nunchaku-tech/nunchaku-flux.1-krea-dev

**URL**: https://gitcode.com/hf_mirrors/nunchaku-tech/nunchaku-flux.1-krea-dev

**关键词列表**:

- **FLUX.1大模型** (热门模型品牌): 项目核心基础模型，具备高关注度和社区热度
- **SVDQuant量化** (核心技术架构): 采用前沿的4-bit扩散模型量化技术，论文发表于ICLR2025，技术辨识度高
- **文本生成图像** (应用场景): 模型核心功能，契合AIGC热门应用方向，搜索需求旺盛
- **ComfyUI集成** (部署集成): 提供官方ComfyUI工作流支持，吸引大量本地AI绘画用户
- **Diffusers兼容** (部署集成): 支持Hugging Face Diffusers生态，便于开发者快速部署和调用
- **INT4量化模型** (性能规格): 强调4-bit低精度高效推理，满足轻量化部署需求，关键词搜索量高
- **NVIDIA大模型** (热门模型品牌): 模型针对NVIDIA GPU（含Blackwell架构）优化，关联硬件生态引流
