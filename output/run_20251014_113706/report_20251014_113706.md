# 模型关键词提取分析报告

## 概览统计

- 📊 **CSV读取模型数**: 702
- ✅ **成功提取模型数**: 699
- ❌ **失败模型数**: 3
- 📈 **成功率**: 99.6%
- 🔍 **原始关键词总数**: 4644
- ✂️ **去重后关键词总数**: 3068
- 📉 **去重率**: 33.9%
- 📊 **平均每模型关键词数**: 4.4
- 🕐 **生成时间**: 2025-10-14 11:56:07

## 维度分布

| 维度 | 关键词数量 | 占比 |
|------|------------|------|
| 技术特性 | 1159 | 37.8% |
| 功能场景 | 891 | 29.0% |
| 当前模型品牌名 | 663 | 21.6% |
| 部署工具 | 179 | 5.8% |
| 参数规格 | 124 | 4.0% |
| 数据集 | 8 | 0.3% |
| 部署方式 | 6 | 0.2% |
| 训练数据 | 6 | 0.2% |
| 评估指标 | 5 | 0.2% |
| 数据来源 | 3 | 0.1% |
| 模型规格 | 2 | 0.1% |
| 训练数据集 | 2 | 0.1% |
| 评测数据集 | 2 | 0.1% |
| 技术参数 | 1 | 0.0% |
| 标签体系 | 1 | 0.0% |
| 使用工具 | 1 | 0.0% |
| 任务类型 | 1 | 0.0% |
| 语言支持 | 1 | 0.0% |
| 模型组件 | 1 | 0.0% |
| 评估数据 | 1 | 0.0% |
| 下游用途 | 1 | 0.0% |
| 输入规格 | 1 | 0.0% |
| 提供方 | 1 | 0.0% |
| 应用领域 | 1 | 0.0% |
| 当前模型品牌名相关 | 1 | 0.0% |
| 评测基准 | 1 | 0.0% |
| 数据特性 | 1 | 0.0% |
| 使用场景 | 1 | 0.0% |
| 模型特性 | 1 | 0.0% |
| 应用场景 | 1 | 0.0% |
| 许可协议 | 1 | 0.0% |

## 原始数据高频关键词分析

> 基于去重前的原始提取数据，展示整个数据集中最常见的关键词

| 排名 | 关键词 | 原始出现次数 | 最终保留次数 |
|------|--------|-------------|-------------|
| 1 | 数学推理 | 15 | 1 |
| 2 | PyTorch | 14 | 1 |
| 3 | 文心一言 | 14 | 1 |
| 4 | 32B参数 | 13 | 1 |
| 5 | 阿里大模型 | 13 | 1 |
| 6 | 视觉语言模型 | 13 | 1 |
| 7 | 思维模式切换 | 13 | 1 |
| 8 | 代码生成 | 13 | 1 |
| 9 | Transformer | 12 | 1 |
| 10 | 多模态 | 12 | 1 |
| 11 | 7B参数 | 12 | 1 |
| 12 | Safetensors | 12 | 1 |
| 13 | 14B参数 | 12 | 1 |
| 14 | 文生视频 | 12 | 1 |
| 15 | MoE架构 | 12 | 1 |
| 16 | 百度大模型 | 12 | 1 |
| 17 | 编程助手 | 11 | 1 |
| 18 | 本地部署 | 11 | 1 |
| 19 | 文生图 | 11 | 1 |
| 20 | 自回归模型 | 11 | 1 |

## 所有关键词列表


### 下游用途 (2个)

- **图像生成引导** • **线性探针图像分类**

### 任务类型 (1个)

- **情感分类**

### 使用场景 (1个)

- **非商业许可**

### 使用工具 (1个)

- **pysentimiento工具包**

### 功能场景 (928个)

- **100-语言支持** • **100米风场** • **10分钟音频输入** • **10秒视频生成** • **16种语言**
- **1M上下文** • **200种语言翻译** • **22kHz高保真音频** • **256K长上下文** • **256x256图像合成**
- **256种语言** • **26种语言** • **338种编程语言** • **3D点轨迹** • **3D生成模型**
- **3D视觉感知** • **44-kHz音频** • **52关键点检测** • **53种语言** • **720P24fps**
- **720P视频生成** • **8语言** • **8语言支持** • **93-languages** • **94种语言**
- **AI作曲** • **AI写作** • **AI控制框架** • **ASR** • **Android任务自动化**
- **Android应用任务执行** • **Android应用控制** • **Any-to-Any** • **Any2Any检索** • **AutoGluon分类器**
- **Bedroom256** • **Blender** • **CAD** • **CIFAR-10** • **CIFAR-10-数据集**
- **COCO2017数据集** • **COCO全景分割** • **CelebA-HQ** • **CelebAMask-HQ** • **Cityscapes**
- **Code-Agent** • **Common-Voice数据集** • **DNA序列优化** • **DepthFusion** • **DevOps-Chat模型**
- **DevOpsEval** • **DevOps生命周期问答** • **DevOps领域大模型** • **DocVQA微调** • **Edge-AI**
- **English** • **EnglishGerman-translation** • **Extractive-QA** • **Feature-Extraction** • **Function-Call**
- **GUI交互** • **GUI任务** • **GUI智能体** • **Gemma3文本生成** • **Google-Colab微调**
- **Graph-Machine-Learning** • **HTML代码生成** • **HiDream-I1文生图** • **I2V** • **Image-Text-to-Text**
- **Image-to-3D** • **Image-to-Image** • **ImageNet-1k-预训练** • **Indonesian** • **JEE数学**
- **JSON提取** • **JSON模式** • **JSON输出** • **Keypoint-Detection** • **KorQuAD**
- **LIBERO-Spatial** • **LIBERO任务套件** • **LSUN** • **LaTeX公式识别** • **Layout-model**
- **Lean-4-形式化定理证明** • **Lean-4形式化语句** • **Lean-4证明** • **MLP手写数字** • **MP-DocVQA**
- **MS-MARCO段落排序** • **Mask-Generation** • **NLI俄语** • **NLI模型** • **NLP模型**
- **Next-Edit模型** • **OCR推理** • **OSworld基准** • **Open-World-Localization** • **OpenCapBench**
- **PDF解析** • **PDF转Markdown** • **POS标注** • **Prompt摄像机** • **PubTables1M**
- **Push-in-camera** • **PushT** • **PushT-环境** • **RTL-Coder** • **RTL推理**
- **SA-1B数据集** • **SD-XL** • **SEO写作** • **SQA** • **SQuAD**
- **SQuAD微调** • **SQuAD问答微调** • **SROIE微调** • **SWE-Bench-Verified** • **ScreenSpot-Pro**
- **Search-Agent** • **Something-Something-V2** • **Spanish** • **Stable-Diffusion-VAE改进** • **Stable-Diffusion-控制**
- **Swift应用开发** • **TI2V** • **Tabular-Classification** • **Tabular-Regression** • **Tailwind-CSS生成**
- **Text-Generation** • **Text-to-3D** • **Text-to-RGBD** • **Text-to-Video** • **Token-Classification**
- **UI生成** • **US-Housing-Prices-数据集** • **Unsloth微调** • **VQA任务** • **Verilog**
- **Verilog-AI** • **ViT特征提取** • **WikiTable问答** • **XML转换** • **XSum**
- **YAML生成** • **YAML结构化** • **Zero-Shot-Image-Classification** • **Zero-Shot-Object-Detection** • **Zero-shot-classification**
- **ai-safety** • **anime** • **audio** • **audio-classification** • **audio-text-to-text**
- **background-removal** • **biology** • **chat** • **chemistry** • **conll03-english**
- **denoising** • **depth** • **depth-estimation** • **digits分类** • **emotion-recognition**
- **feature-extraction** • **fill-mask** • **generation** • **gym-hopper** • **gympusht**
- **image** • **image-analysis** • **image-text-to-text** • **image-to-3d** • **image-to-image**
- **image-to-video** • **img2vid** • **inpainting** • **librispeechasr** • **make-this-person-look-real**
- **medical** • **mesh-generation** • **mikrotik** • **model** • **normals-estimation**
- **object-detection** • **overlapped-speech-detection** • **question-answering** • **regression** • **relative-depth**
- **remove-background** • **roleplay** • **sentence-similarity** • **speech** • **speech-enhancement**
- **summarization** • **table-question-answering** • **tabular** • **tabular-regression** • **text-classification**
- **text-to-image** • **text-to-video** • **tokenizer** • **unconditional-image-generation** • **video-classification**
- **video-to-video** • **wikisql** • **wikitablequestions** • **zero-shot-object-detection** • **一步式视频修复**
- **一步生成** • **三维图像匹配定位** • **上下文压缩模型** • **上下文图像编辑** • **上下文文档**
- **下游任务** • **不良药物反应监测** • **中文关系抽取** • **中文写作** • **中文搜索**
- **中文文本生成** • **中文语音预训练** • **中文预训练** • **中短文本翻译** • **中英双语交互**
- **中英双语多轮对话** • **中英双语文本生成** • **中英双语视频生成** • **中英混合发音** • **主体驱动生成**
- **主题分类** • **事件捕捉** • **二次创作音乐** • **二氧化碳排放量预测** • **交互式图像编辑**
- **人体姿态估计** • **人像编辑一致性** • **人工智能预报系统** • **人脸年龄分类** • **代理能力**
- **代理能力集成** • **代码基准测试** • **代码嵌入** • **代码执行** • **代码推理**
- **代码搜索** • **代码检索** • **代码生成** • **代码编辑预测** • **代码能力**
- **代码语言模型** • **任务抓取** • **任务适配器** • **任意分辨率修复** • **任意分辨率视频**
- **位姿估计** • **低延迟TTS** • **低延迟响应** • **低资源语言研究** • **俄英翻译**
- **俄语NLI模型** • **俄语文本蕴含** • **俄语自然语言推理** • **俄语语音识别** • **俄语零样本分类**
- **信息抽取** • **信息检索** • **像素级生成** • **光学字符识别** • **免OCR文档理解**
- **全域行动学习** • **全景分割** • **全端到端音频交互** • **公式识别** • **关键点匹配**
- **兴趣点匹配** • **内容安全审计** • **内容审核模型** • **函数调用** • **函数调用增强**
- **分子建模** • **分钟级预测** • **创意写作** • **前端Web开发** • **前端代码生成**
- **动作片段生成** • **动作选择** • **化学实体识别** • **单列回归** • **单图多图支持**
- **单应性估计** • **单样本图像分割** • **单样本推理** • **单步生成** • **单步视频修复**
- **单目度量深度估计** • **单目法向量估计** • **单目深度估计** • **单行文本识别** • **印刷体OCR**
- **印地语TTS** • **印地语语音理解** • **印尼语NER** • **印度教育AI** • **参考图像编辑**
- **双语GUI助手** • **双语图像理解** • **发票识别** • **口语音频分析** • **句子嵌入**
- **句子文本相似度** • **句子相似度** • **句子语义映射** • **可提示视觉分割** • **合同文本分析**
- **合成地震速度模型** • **合成生物学** • **命名实体识别** • **哼唱检测** • **因果语言模型**
- **图像-文本对话** • **图像上色** • **图像交互** • **图像任意分割** • **图像修复**
- **图像偏好预测** • **图像分割** • **图像分类** • **图像分类微调** • **图像分类生成**
- **图像分类骨干网络** • **图像到3D** • **图像到图像** • **图像到文本** • **图像匹配**
- **图像字幕** • **图像字幕生成** • **图像定位** • **图像年龄检测** • **图像排序**
- **图像推理** • **图像描述** • **图像描述生成** • **图像文本分析** • **图像条件3D生成**
- **图像查询** • **图像特征提取** • **图像特征提取器** • **图像特征模型** • **图像理解**
- **图像生成** • **图像生成与编辑** • **图像生成引导** • **图像生成视频** • **图像精炼**
- **图像组合生成** • **图像编辑** • **图像解码优化** • **图像识别** • **图像超分辨率**
- **图像转3D** • **图像转Markdown** • **图像转文本** • **图像转视频** • **图像问答**
- **图分类** • **图形界面任务处理** • **图文对话** • **图文检索** • **图生3D**
- **图生图模型** • **图生视频** • **图表到文本** • **图表识别** • **图表问答**
- **土壤湿度预报** • **声音事件分类** • **复杂任务处理** • **复杂检索任务** • **复杂表格提取**
- **复杂逻辑推理** • **复选框识别** • **多向量检索** • **多图像交互** • **多图像理解**
- **多图像生成** • **多图理解** • **多图编辑** • **多对多机器翻译** • **多提示生成**
- **多格式视觉定位** • **多模态RAG** • **多模态文档转换** • **多模态理解** • **多模态直播**
- **多视图立体匹配** • **多语言** • **多语言NER** • **多语言VAD** • **多语言与方言支持**
- **多语言原生支持** • **多语言句子检索** • **多语言安全审查** • **多语言嵌入模型** • **多语言指令遵循**
- **多语言支持** • **多语言文本到语音** • **多语言标点恢复** • **多语言模型** • **多语言能力**
- **多语言语音语义** • **多语言重新排序器** • **多语言长尾知识** • **多语言音频** • **多说话人情绪识别**
- **多轮图像编辑** • **多轮对话** • **多轮音频对话** • **多页文档理解** • **多页文档问答**
- **大型推理模型** • **大规模指令数据** • **大规模自回归图像生成** • **学术评测** • **安全审核模型**
- **安全无害** • **定理证明** • **定量推理** • **实体三元组抽取** • **实体识别**
- **实例分割** • **实时安全审核** • **实时流式文本转语音** • **实时深度图生成** • **实时目标检测器**
- **实时视频理解** • **实时视频生成** • **实时语音对话** • **实时音视频交互** • **实时音视频对话**
- **密码子优化** • **密集检索** • **对话场景** • **对话式AI** • **对话式指向**
- **小参数推理模型** • **小型表格数据集** • **小学数学** • **小模型** • **小说文本生成**
- **少步采样** • **居家预训练模型** • **屏幕截图交互** • **工业图像分析** • **工具使用**
- **工具使用能力** • **工具调用** • **工具调用优化** • **工程代码** • **巴西葡萄牙语预训练**
- **带标点和大小写** • **年龄组分类** • **序列分类** • **度量深度估计** • **开放目标检测**
- **开源代码模型** • **开源聊天机器人** • **开源视频生成** • **强化学习微调** • **形式化推理**
- **形式定理证明** • **微调** • **思维推理** • **思维链** • **总降水量预报**
- **情感分析** • **情感识别** • **情感语音合成** • **情感语音控制** • **意大利语支持**
- **房价预测** • **手写体OCR** • **报告生成** • **抽取式问答** • **拒绝率降低**
- **指令微调** • **指令调优** • **指令跟随** • **指令遵循** • **推理**
- **推理任务优化** • **推理模型** • **推理能力** • **推理轨迹生成** • **推荐系统**
- **推荐系统大语言模型** • **推镜式运镜** • **掩码生成** • **掩码语言建模** • **摄像机运动控制**
- **摘要** • **数学推理** • **数学推理模型** • **数学竞赛问题证明** • **数学能力提升**
- **数学计算** • **数据提取** • **文本-视频对齐** • **文本到图像** • **文本到图像生成**
- **文本到语音** • **文本到音频** • **文本到音频检索** • **文本向量化** • **文本向量表示**
- **文本图像理解** • **文本填充** • **文本嵌入** • **文本引导图像编辑** • **文本排序**
- **文本推理** • **文本提示生成音乐** • **文本摘要** • **文本理解** • **文本理解与生成**
- **文本生成** • **文本生成视频** • **文本相似度评分** • **文本蕴含识别** • **文本补全**
- **文本转图像** • **文本转语音** • **文本转音乐** • **文本重排序** • **文本驱动图像生成**
- **文本驱动视频扩展** • **文档OCR** • **文档VQA** • **文档信息抽取** • **文档元素问答**
- **文档摘要** • **文档理解** • **文档索引** • **文档表格检测** • **文档视觉特征索引**
- **文档视觉问答** • **文档解析** • **文档问答** • **文档问答模型** • **文生3D**
- **文生图** • **文生图评分** • **文生视频** • **文生音乐** • **新闻摘要**
- **无审查大模型** • **无条件图像生成** • **无监督目标检测** • **无边框表格检测** • **无需手动标注交互数据**
- **日语命名实体识别** • **日语英语双向翻译** • **日语语音识别** • **时间序列预测** • **智能代理**
- **智能代理能力** • **智能体** • **智能体任务** • **智能体功能** • **智能体工具**
- **智能体工具对接** • **智能体工具集成** • **智能体搜索** • **智能体智能** • **智能体框架**
- **智能体浏览器使用** • **智能体编码** • **智能体能力** • **智能体集成** • **智能对话**
- **智能设备控制** • **最小化通用控制** • **有边框表格检测** • **机器人强化学习** • **机器人控制**
- **机器人推箱子** • **机器人操作** • **机器人规划** • **机器翻译** • **标点预测**
- **标记分类** • **检索增强生成** • **概率预报** • **概率预测** • **歌词生成**
- **气象预报** • **水印提取** • **汉英翻译** • **沉浸式翻译** • **法律文本预训练**
- **法律自然语言处理** • **法英翻译** • **法语TTS** • **法语词性标注** • **流式语音生成**
- **测试用例生成** • **深度估计** • **深度推理模型** • **深度补全** • **混合专家视觉语言模型**
- **混合检索** • **游戏操作智能体** • **激发度-支配度-效价** • **点云图** • **热带气旋路径预报**
- **物体任务** • **物理常识推理** • **特征主干网络** • **特征提取** • **环境声音与音乐辨识**
- **生成式安全模型** • **生成模型** • **生物信息学工具** • **生物医学知识图谱构建** • **生物医学视觉语言模型**
- **用户-物品交互** • **用户-物品理解** • **用户偏好建模** • **用户物品交互** • **电影感运动**
- **电话ASR** • **目标任务** • **目标检测** • **相对深度** • **相机位姿估计**
- **相机内参** • **相机外参** • **相机运动分类** • **真实世界迁移** • **知识图谱SEO**
- **知识图谱填充** • **知识图谱推理** • **知识图谱补全** • **短视频理解** • **研究型写作**
- **硬件编程AI** • **神经声码器** • **科学推理** • **科学问题求解** • **稀疏检索**
- **空间任务** • **空间智能** • **立体声音乐生成** • **端到端GUI自动化** • **端到端三维重建**
- **端到端任务自动化** • **端到端目标检测** • **端到端语音指令跟随** • **策略微调** • **签名检测**
- **简洁连贯摘要** • **精细化音频描述生成** • **线性探测** • **结构化数据分类** • **结构化数据理解**
- **结构化输出** • **结构化输出生成** • **绝对深度估计** • **统一偏好优化** • **编码能力**
- **编程助手** • **网络导航** • **网页浏览** • **聊天对话** • **聚类任务**
- **自动形式化** • **自动标点** • **自动语音识别** • **自回归图像生成** • **自定义工具调用**
- **自然语言推理** • **自然语言理解** • **艺术创作** • **英文检索** • **英文语义匹配**
- **英文语音识别** • **英文问答** • **英文预训练** • **英法翻译** • **英语TTS**
- **英语语音识别** • **英语预训练** • **药物相互作用检测** • **荷兰语英语翻译** • **葡萄牙语语音识别**
- **虚拟试穿** • **虚拟试衣间** • **蛋白质序列建模** • **蛋白质序列转化** • **蛋白质预训练模型**
- **表格事实验证** • **表格分类** • **表格回归** • **表格基础模型** • **表格推理**
- **表格机器学习** • **表格结构识别** • **表格解析** • **表格问答** • **表格问答模型**
- **西班牙语-英语翻译** • **西班牙语NER** • **西班牙语情感分析** • **视觉-语言推理** • **视觉-语言理解**
- **视觉与多模态AI模型** • **视觉代理推理** • **视觉动作策略** • **视觉基础模型** • **视觉多轮对话**
- **视觉定位** • **视觉嵌入模型** • **视觉感知与理解** • **视觉推理** • **视觉文本交互**
- **视觉文档检索** • **视觉智能体** • **视觉检索** • **视觉检索模型** • **视觉模型**
- **视觉空间智能** • **视觉编码器** • **视觉语言推理** • **视觉语言模型** • **视觉问答**
- **视频-文本检索** • **视频交互** • **视频任意分割** • **视频修复** • **视频偏好预测**
- **视频分割** • **视频分类** • **视频分类头** • **视频基准测试** • **视频多模态大模型**
- **视频字幕生成** • **视频控制** • **视频推理** • **视频文本检索** • **视频文本理解**
- **视频文本转文本** • **视频检索** • **视频特征提取** • **视频理解** • **视频理解基准测试**
- **视频生成** • **视频生成模型** • **视频编码器** • **视频编辑** • **视频质量提升**
- **视频质量评估** • **视频超分** • **视频运镜控制** • **视频重光照** • **视频问答**
- **角色扮演** • **角色扮演写作** • **计算机使用代理** • **计算生物学** • **记忆增强**
- **设备端嵌入** • **设备端部署** • **词性标注** • **词级时间戳** • **语义分割**
- **语义搜索** • **语义搜索任务** • **语义检索** • **语义相似度搜索** • **语义相似度评分**
- **语码混合TTS** • **语种识别** • **语音令牌化器** • **语音克隆** • **语音分割**
- **语音到文本** • **语音合成** • **语音增强** • **语音大语言模型** • **语音情感识别**
- **语音活动检测** • **语音理解** • **语音直接触发** • **语音续写** • **语音编辑**
- **语音翻译** • **语音聊天** • **语音触发API** • **语音识别** • **语音语言识别**
- **语音转录** • **语音转换** • **语音转文本** • **语音转语音翻译** • **语音重建**
- **语音问答** • **说话人分割** • **说话人识别** • **财务文档分析** • **资源受限环境适配**
- **超分辨率** • **跨具身视频学习** • **跨模态对话** • **跨模态推理** • **跨模态检索**
- **跨语言任务** • **跨语言检索** • **转录后处理** • **软件工程任务** • **软件工程助手**
- **轻量AI模型** • **轻量型句子嵌入模型** • **轻量级NER** • **轻量级摘要模型** • **轻量级文本分类**
- **轻量级语音模型** • **边缘AI** • **边缘人工智能** • **运动学分析** • **近实时翻译**
- **连续图像编辑** • **连续控制** • **通用命名实体识别** • **通用逻辑推理** • **逻辑推理**
- **逻辑推理增强** • **重排序模型** • **金融分析** • **金融推理** • **钢琴踏板检测**
- **钢琴转录** • **链接预测** • **长上下文** • **长上下文处理** • **长上下文推理**
- **长上下文检索** • **长上下文理解** • **长上下文音频理解** • **长文本处理** • **长文本推理**
- **长文本生成** • **长时序视频理解** • **长时视频理解** • **长期记忆** • **长视频理解**
- **长音频单次转录** • **长音频转录** • **问答** • **问答任务** • **问答系统**
- **问题回答** • **随机数据处理** • **零样本分类** • **零样本单目深度估计** • **零样本图像分割**
- **零样本图像分类** • **零样本文本分类** • **零样本文本条件目标检测** • **零样本泛化** • **零样本深度估计**
- **零样本目标检测** • **零样本知识图谱** • **零样本编辑** • **零样本视频-语言** • **零样本视频分类**
- **零样本视频语言** • **零样本音频分类** • **零样本预测** • **非官方实时演示** • **非推理模式**
- **非结构化文档提取** • **非语言音效生成** • **非语音信息理解** • **面部解析** • **韩国语-英语语言模型**
- **韩国语OCR优化** • **韩文多模态** • **韩语大模型** • **韩语问答** • **音乐分析**
- **音乐理解** • **音乐生成** • **音乐生成模型** • **音乐预训练** • **音符识别**
- **音色克隆** • **音视频流式生成** • **音频-文本转文本** • **音频内容理解** • **音频分析**
- **音频分类** • **音频描述** • **音频文本转文本** • **音频查询-音频应答** • **音频理解**
- **音频生成** • **音频示例生成音乐** • **音频细粒度描述** • **音频翻译** • **音频语言模型**
- **音频转乐谱** • **音频转录** • **音频问答** • **音频问答与推理** • **音频预训练**
- **预训练模型** • **额外upscale模型** • **首尾帧生成视频** • **高保真图像合成** • **高分辨率感知**
- **高分辨率视觉理解** • **高分辨率视频修复** • **高动态视觉效果** • **高动态视频处理** • **高层大气变量预报**
- **高帧率视频理解** • **高空气象变量预报** • **高速生成**

### 功能特性 (1个)

- **Any-to-Any**

### 参数规格 (128个)

- **0.3B参数** • **0.6B-参数** • **0.6B参数** • **1.24亿参数** • **1.2B参数**
- **1.3B参数** • **1.5B参数** • **1.6B参数** • **1.7B参数** • **1024维嵌入**
- **1060亿参数** • **109B-MoE** • **10B参数** • **10亿参数** • **110B参数**
- **11B参数** • **120亿参数** • **128K上下文** • **128k上下文窗口** • **12B参数**
- **130亿参数** • **131K上下文** • **13B参数** • **14.7B参数** • **140亿参数**
- **14B** • **14B参数** • **15B参数** • **15参数** • **16B参数**
- **17亿参数量** • **1B参数** • **1万亿参数** • **1万亿总参数** • **2.21B参数**
- **2.2亿参数** • **2.4B激活参数** • **2.5M参数** • **2.6B参数** • **2.7B参数**
- **2000标记窗口** • **203亿参数** • **209M参数** • **20亿参数** • **210亿参数**
- **21B参数** • **224x224** • **22B参数** • **22kHz采样率** • **2350亿参数**
- **235B参数** • **236B参数** • **240亿参数** • **24B-Instruct** • **24B参数**
- **256分辨率** • **258M参数** • **270M** • **270M参数** • **270m指令微调**
- **27B参数** • **288x288** • **28B参数** • **2B参数** • **300B参数**
- **300M参数** • **30B参数** • **30亿参数** • **32.8B参数** • **320亿激活参数**
- **3210亿参数** • **321B参数** • **32B参数** • **330M参数** • **34B参数**
- **350M参数** • **3550B参数** • **3550亿参数** • **36B参数** • **36亿活跃参数**
- **3700万参数** • **38B激活参数** • **3B参数** • **3亿参数** • **3亿参数嵌入**
- **40B参数** • **40亿参数** • **424B参数** • **434M参数** • **44kHz采样率**
- **450M参数** • **480B参数** • **4B参数** • **50亿参数** • **512倍上采样**
- **512分辨率** • **550M-参数** • **5B参数** • **6.5亿参数** • **600M变体**
- **64帧采样** • **6710亿参数** • **671B参数** • **7.7B参数** • **700M参数**
- **70B参数** • **70亿参数** • **7200万参数** • **72B参数** • **74M参数**
- **7B参数** • **7B推理模型** • **86M参数** • **8B参数** • **91.5K参数**
- **95M参数** • **9B参数** • **A47B** • **HiDream-I1-7B参数** • **ViT-B16**
- **bf16-精度** • **marhuge** • **patch14-224** • **small参数** • **tiny模型**
- **万亿参数** • **每帧16令牌** • **激活22B**

### 应用场景 (1个)

- **原神音乐生成**

### 应用领域 (1个)

- **地球物理勘探**

### 当前模型品牌名 (669个)

- **2DseisvelGenerator** • **32B-VL-Instruct模型** • **A.X-3.1** • **A35B-Instruct** • **A3B-Base**
- **A3B-Thinking** • **A3B系列** • **A47B系列** • **AIFS** • **AIFS-ENS**
- **AIFS-Single** • **ALPDeepScaleR** • **AndroidGen** • **AnimateDiff-Lightning** • **Apriel-1.5**
- **Aryabhata-1.0** • **Audio-Flamingo** • **AutoTrain** • **AutoTrain-US-Housing-Prices** • **BAAIbge-small-en-v1.5**
- **BCCard-VL模型** • **BERT-base** • **BERT-large** • **BERTimbau-Base** • **BGE**
- **BGE-Large-En** • **BGE-M3** • **BGE-base** • **BLIP** • **BLIP-2**
- **BM-Model** • **BRIA-AI** • **BetaCeti-Beta** • **BigVGAN** • **BigVGANv2**
- **BioBERT-large** • **BiomedCLIP** • **BlenderLLM** • **Bllossom-AICA-5B** • **CIDASclipseg-rd64-refined**
- **CLAP** • **CLIP** • **CLIP-ViT-B-32** • **CLIP-ViT-H-14** • **CLIP-ViT-L-14**
- **CLIPSeg** • **CamMotion-Preview** • **Canary-Qwen-2.5B** • **Chinese-Hubert** • **Chronos-Bolt**
- **Chronos-Bolt-Tiny** • **Chronos-T5** • **Chronos-T5-Small** • **CodeFuse-DevOps-Model-7B-Chat** • **CodonTransformer**
- **CogAgent** • **CogVideoX** • **CogVideoX-5b** • **CogVideoX-LoRa** • **CogVideoX1.5**
- **Cogito** • **ColPali** • **ColQwen2** • **Consistency-Decoder** • **ControlNet**
- **ControlNet-v1-1** • **Cosmos-Reason1** • **D-FINE** • **DDPM** • **DDPMChurch256**
- **DETR-ResNet-101** • **DETR-ResNet-50** • **DINOv2** • **DINOv2-giant** • **DINOv2-small**
- **DISK** • **DPT-Hybrid** • **DPT-Large** • **DeBERTa-v3-large** • **DePlot**
- **Decision-Transformer** • **DeepSeek-Coder-V2** • **DeepSeek-Coder-V2-Lite** • **DeepSeek-Prover** • **DeepSeek-Prover-V1**
- **DeepSeek-Prover-V1.5** • **DeepSeek-Prover-V2** • **DeepSeek-R1** • **DeepSeek-R1-Zero** • **DeepSeek-V2**
- **DeepSeek-V2-Chat** • **DeepSeek-V2-Lite** • **DeepSeek-V2.5** • **DeepSeek-V3** • **DeepSeek-V3.1**
- **DeepSeek-V3.1-Terminus** • **DeepSeek-V3.2-Exp-Base** • **DeepSeek-VL2** • **DeepSeek-VL2-Small** • **DeepSeek-VL2-Tiny**
- **Depth-Anything-V2** • **Depth-Anything-V2-Large** • **DepthAnythingV2** • **DevOps-Model-14B-Base** • **DevOps-Model-14B-Chat**
- **DevOps-Model-7B-Base** • **DevOps-Model-7B-Chat** • **Dia** • **Diffusion-Policy** • **DistilBARTCNN**
- **DistilBERT** • **DistilBERT-base** • **DistilRoBERTa-base** • **DobbE** • **DocOwl2**
- **Dolphin** • **E2-TTS** • **ECMWF-AI模型** • **ERNIE-4.5** • **ERNIE-4.5-0.3B-Base-PT**
- **ERNIE-4.5-21B** • **ERNIE-4.5-21B-A3B-Thinking** • **ERNIE-4.5-300B-A47B** • **ERNIE-4.5-300B-A47B-Base** • **ERNIE-4.5-VL**
- **ERNIE4.5** • **ESM-2** • **ESM2t33650MUR50D** • **ETH-CVGlightgluesuperpoint** • **EXAONE-4.0**
- **EdgeNeXt** • **ElsaV2** • **EmbeddingGemma** • **Emu3** • **Exp-Base**
- **F5-TTS** • **FLUX.1-Kontext** • **FLUX.1-Kontext-dev** • **FLUX.1-dev** • **FLUX.1Kreadev**
- **Falconsaitextsummarization** • **Florence-2** • **Florence-2-base** • **Frame-VAD** • **French-Camembert**
- **FusionX** • **GCIRS-Reasoning** • **GIT** • **GLM-4** • **GLM-4-9B**
- **GLM-4-9B-Chat** • **GLM-4-9B-Chat-1M** • **GLM-4.1V** • **GLM-4.1V-9B-Base** • **GLM-4.5**
- **GLM-4.5-Air** • **GLM-4.5V** • **GLM-4.6** • **GLM-4V-9B** • **GLM-4VQ**
- **GLM-Edge-4B-Chat** • **GLM-Edge-V-2B** • **GLM-Edge-V-5B** • **GLM-Z1-Rumination** • **GLiNER-multi**
- **GME-Qwen2-VL-2B** • **GPT-2** • **Gemma-3** • **Gemma-3-270M** • **Gemma-3-270m**
- **GenerativeImage2Text** • **Genmo** • **Granite-Docling-258M** • **Granite-TTM** • **Granite-TimeSeries-TTM**
- **Graphormer** • **GraphsGPT** • **GraspMolmo** • **Grok-2** • **HF模型**
- **HelsinkiNLP** • **Hermes-4** • **HiDream-E1** • **HiDream-I1** • **HiPO**
- **Holo1.5** • **HumAware-VAD** • **HunyuanVideo** • **I2V-A14B** • **IDM-VTON**
- **ITDR** • **ITDR-LLaMA3.2-3B** • **ITDR-Qwen2.5** • **ImageGPT** • **ImageGPT-small**
- **Intern-S1** • **InternLM-XComposer2.5** • **InternVL2-2B** • **InternVL2.5HiCoR16** • **InternVL3-78B**
- **InternVideo2.5** • **Isaac** • **Janus-Pro** • **JanusFlow** • **Jina-Embeddings**
- **Jukebox-5B-lyrics** • **K2** • **KAT-Coder** • **KAT-Dev** • **KAT-V1-40B**
- **KDD-CUP-2021** • **Kakao多模态** • **Kanana-1.5** • **KaniTTS** • **Keras**
- **Keye-VL** • **Keye-VL-1.5** • **Kimi** • **Kimi-Audio** • **Kimi-K2**
- **Kimi-VL** • **Kimi-VL-A3B** • **Kimi-VL-A3B-Thinking** • **Kimi-VL-A3B-Thinking-2506** • **Kimi-VL-Thinking**
- **Kontext-lora** • **Kosmos-2** • **KwaiCoder** • **LDM3D** • **LFM2**
- **LFM2-1.2B** • **LFM2-350M** • **LFM2-350M-ENJP-MT** • **LFM2-350M-Extract** • **LLMDet**
- **LLMDet-Large** • **LLaMA-Mesh** • **LLaSA** • **LLaVA** • **LLaVA-NeXT-Video**
- **LLaVA-Video** • **LTX-Video** • **LayoutLM** • **LayoutLMv3** • **Legal-BERT**
- **LightGlue** • **Ling-1T** • **Liquid-AI** • **LiquidAI** • **LiquidAI-LFM2-1.2B-Tool**
- **Llasa-1B** • **LongCat** • **LongCat-Flash-Thinking** • **Lumina-DiMOO** • **M3-Agent**
- **M3-Agent-Control** • **MAR** • **MASt3RViTLarge** • **MERT** • **MERT-v1-95M**
- **MM-Grounding-DINO** • **MMS-LID** • **MMaDA** • **MP-SENet-DNS** • **MachineLearningLM**
- **Magenta-RT** • **MagicQuill** • **Magistral-1.2** • **Magistral-Small** • **MapAnything**
- **Marigold-Normals** • **Marvis-AI** • **Mask2Former** • **MaskFormer** • **MeloTTS**
- **Meta-FAIR-研发** • **MetricGAN-plus** • **MiDaS-3.0** • **MiMo-Audio-7B-Base** • **MiMo-Audio-7B-Instruct**
- **Mikrotik-7** • **MinerU2.5** • **Ming-Lite-Omni** • **MiniCPM** • **MiniCPM-V**
- **MiniCPM-o** • **MiniCPM4.1** • **MiniLM** • **Mistral-Small-3.2** • **Mitra-Regressor**
- **MobileNetV3** • **MobileViT** • **Mochi-1** • **Molmo** • **Moonlight**
- **Motion-Lora** • **MusicGen** • **MusicGen-stereo-small** • **MusicGen小型** • **NAFlex**
- **NLLB-200** • **NVIDIA** • **Nanonets-OCR-s** • **NemotronNano** • **NextStep-1**
- **Nunchaku** • **NusaBert** • **OASIS** • **OCRFlux** • **OWL-ViT**
- **OWLv2** • **OminiControl** • **Omni-30B-Captioner** • **Omni-7B** • **OmniGen2**
- **OmniTab** • **OpenGVLab** • **OpenMed-NER** • **OpenReasoning-Nemotron** • **OpenReasoning-Nemotron-14B**
- **OpenVLA-OFT** • **Orsta-7B-i1-GGUF** • **PCQM4M-LSC** • **PCQM4M-LSCv2** • **Parakeet-TDT**
- **Patch16** • **Phi-4-mini-flash** • **PhysicsWallahAI** • **Pi0** • **Pick-a-Pic**
- **PickScorev1** • **Prior-Labs** • **Qianfan-VL-8B** • **QwQ-32B** • **Qwen**
- **Qwen-Image-Edit** • **Qwen2-Audio** • **Qwen2-Audio-7B-Instruct** • **Qwen2-VL** • **Qwen2.5-14B-Instruct-1M**
- **Qwen2.5-7B-Instruct** • **Qwen2.5-Omni** • **Qwen2.5-VL** • **Qwen2.5-VL-3B-Instruct** • **Qwen2.5-VL-7B**
- **Qwen3** • **Qwen3-1.7B** • **Qwen3-1.7B-FP8** • **Qwen3-14B** • **Qwen3-14B-MLX-6bit**
- **Qwen3-14B-MLX-8bit** • **Qwen3-235B** • **Qwen3-235B-A22B** • **Qwen3-235B-A22B-Instruct-2507** • **Qwen3-235B-A22B-Instruct-2507-FP8**
- **Qwen3-235B-A22B-Thinking-2507** • **Qwen3-30B-A3B** • **Qwen3-32B** • **Qwen3-32B-AWQ** • **Qwen3-32B-MLX-4bit**
- **Qwen3-32B-MLX-8bit** • **Qwen3-4B** • **Qwen3-4B-Base** • **Qwen3-4B-MLX-4bit** • **Qwen3-4B-Thinking-2507**
- **Qwen3-8B** • **Qwen3-Coder** • **Qwen3-Coder-480B** • **Qwen3-Coder-480B-A35B-Instruct** • **Qwen3-Embedding**
- **Qwen3-Next-80B-A3B** • **Qwen3-Omni** • **Qwen3-Omni-30B-A3B-Thinking** • **Qwen3Guard** • **Qwen3Guard-Gen**
- **QwenLong-CPRS-7B** • **RMBG-1.4** • **RT-DETR** • **Realistic-Vision** • **ResNet18**
- **Ring-mini** • **RoBERTa-base-bne** • **RolmOCR** • **RuBERT** • **SAM-2**
- **SAM-ViT** • **SAM-ViT-Huge** • **SD-XL** • **SDXL-Turbo** • **SEOcrate-4B**
- **SRPO** • **SWE-Dev** • **SWE-Dev-9B** • **Seed-OSS** • **SeedVR**
- **SeedVR2** • **SegFormer-b4** • **SegFormerb0** • **SigLIP** • **SigLIP-2**
- **Silero-VAD-CoreML** • **SlimSAM** • **SmolLM3** • **So400m** • **SoViT-400m**
- **Spatial-MLLM** • **SpeechT5** • **Stable-Diffusion-2** • **Stable-Video-Diffusion** • **StableDiffusion2-1**
- **Step-Audio-2** • **Step-Audio-AQAA** • **Step3** • **StepFun-Formalizer** • **SynthPose**
- **T-one** • **T-pro-it** • **T-tech** • **T2V-14B** • **T5-11B**
- **T5-Base** • **T5-Large** • **TAPAS** • **TAPAS-large** • **TAPEX**
- **TATR** • **TC-Light** • **TFDecisionTrees** • **TRELLIS** • **TRELLIS-text-large**
- **TTM** • **TabPFN-v2** • **TabPFN-v2-clf** • **TabPFNMix** • **Table-Transformer**
- **Tapas** • **Tar-1.5B** • **Tar-7B** • **TencentARCInstantMesh** • **TensorFlow**
- **Tifa-DeepSexV2** • **Tifa-Deepsex** • **Tifa-Deepsex-14b-CoT** • **Tifa-DeepsexV2** • **TimeSformer**
- **TinyTimeMixers** • **Tongyi-DeepResearch** • **TrOCR** • **TrOCR-base** • **UI-TARS**
- **UI-TARS-1.5** • **UI-TARS-72B-DPO** • **UI-TARS-7B-SFT** • **UIGENT3** • **ULTRA**
- **Ultravox** • **UniVLA** • **Unsloth** • **V-JEPA-2** • **VACE**
- **VGGT** • **VINCIE** • **VITL-FPC64-256** • **VJEPA-2** • **VL2-Tiny**
- **VLAC** • **VLAC-2B** • **VQBeT** • **Veena** • **Venice-Uncensored**
- **VeriReason** • **ViLT** • **ViT-Base-DINOv2** • **ViT-Large-Patch14** • **ViViT**
- **Video-R1** • **Video-R1-7B** • **VideoLLaMA3-7B** • **VideoMAE-V2** • **VideoMAE-v2**
- **VideoMAEv2-Base** • **VideoMAEv2-Large** • **VideoScore** • **VideoScore-v1.1** • **VisionReward-Image**
- **VitPose-Huge** • **VoxCPM** • **Voxtral** • **Voxtral-Mini** • **Voxtral-Mini-3B**
- **Voxtral-Small** • **Wan2.1** • **Wan2.1-Fun** • **Wan2.1-I2V-14B-480P** • **Wan2.1-T2V-14B**
- **Wan2.1I2V14BFusionX** • **Wan2.2** • **Wan2.2-T2V-A14B** • **WanVideo** • **WebSailor**
- **Whisper** • **Whisper-large-v3-turbo** • **Whisper-tiny.en** • **WikiTableQuestions** • **Wolf-Rayet-2B-Prime3**
- **WorldPM** • **X-CLIP** • **XCodec2** • **XLM-RoBERTa** • **XLM-RoBERTa-large**
- **YOLOS** • **YOLOS-tiny** • **ZoeDepth** • **ZoeDepth-nyu** • **arxiv2106.05234**
- **audeeringwav2vec2-large-robust-12-ft-emotion-msp-dim** • **autogluon-mitra** • **autotrain** • **autotrain-hmaet** • **autotrain-us-housing-prices**
- **bagel** • **bart-large-cnn-samsum** • **bart-large-mnli-yahoo-answers** • **beaver-7b-v1.0-cost** • **bert-base-cased-squad2**
- **bert-base-chinese** • **bert-base-portuguese-cased** • **bert-large-cased** • **bert-large-uncased-whole-word-masking-squad2** • **bge-reranker-v2-m3**
- **bge-small-zh** • **cdimagenet64l2** • **chinese-hubert-large** • **colSmol-256M** • **continuedevinstinct**
- **convnextv2** • **convnextv2nano** • **ctcat256** • **ddpm-cat-256** • **ddpm-ema-church-256**
- **deberta-v3** • **deberta-v3-large** • **detr-doc-table-detection** • **diffusers-cdcat256l2** • **diffusers-ctimagenet64**
- **dino** • **dino-vits8** • **dinov2-base** • **discogs-maest-30s-pw-73e-ts** • **distilbart-cnn**
- **distilbart-mnli** • **distilbart-xsum-12-6** • **ditr-e15** • **dmis-lab** • **dreamshaper-7**
- **dreamshaper-8** • **edgenextsmall.usiin1k** • **emotion-recognition-wav2vec2-IEMOCAP** • **face-parsing** • **facebookbart-base**
- **facebooksam-vit-base** • **facebooksam-vit-large** • **facebooksam2-hiera-large** • **facebookwav2vec2-base-960h** • **fairfaceageimagedetection**
- **flux** • **fofrkontext-make-person-real** • **gemma-3-12b-it-qat-4bit** • **gemma3** • **genomics-tf-prediction**
- **goldg** • **google-t5t5-3b** • **googleddpm-celebahq-256** • **googletapas-base-finetuned-wtq** • **gpt-oss**
- **gpt-oss-120b** • **gpt-oss-20b** • **gte-large-en** • **gte-reranker-modernbert-base** • **hiera-large**
- **hoyoMusic** • **indonesian-roberta-base-posp-tagger** • **intfloatmultilingual-e5-large-instruct** • **jina-embeddings-v3** • **koelectra-small-v2**
- **layoutlm-document-qa** • **layoutlmv3-finetuneddocvqa** • **llava-hf** • **ltx-video** • **mDeBERTa-v3-base**
- **marvis-tts** • **mbart-large-50** • **microsofttable-transformer-structure-recognition** • **mitra分类器** • **mobilenetv3small100**
- **ms-marco-MiniLM-L6-v2** • **multi-qa-MiniLM** • **mxbai-embed** • **mxbai-embed-large-v1** • **naverDUSt3RViTLargeBaseDecoder512dpt**
- **ner-english-fast** • **nli-deberta-v3-large** • **nomic-embed-text-v1.5** • **nomic-embed-vision** • **nvidia**
- **o365v2** • **oiv6** • **opus-mt-en-de** • **opus-mt-en-fr** • **opus-mt-es-en**
- **opus-mt-fr-en** • **opus-mt-nl-en** • **opus-mt-ru-en** • **opus-mt-zh-en** • **palmyra-mini**
- **paraphrase-MiniLM-L6-v2** • **paraphrase-multilingual-MiniLM** • **pcolocautotrain-600-dragino** • **pcolocautotrain-dragino-7-7** • **pcolocautotrain-dragino-7-7-max495m**
- **pcolocautotrain-only-rssi** • **pegasus** • **pegasus-large** • **pianotrans** • **punctuate-all**
- **pyannote-audio-model** • **pyannote-segmentation** • **pydevmini1** • **robertuito** • **rubert-base-cased-nli-threeway**
- **sam2** • **samvitbase** • **skops** • **smol-vision** • **stable-diffusion-xl-diffusers**
- **stable-video-diffusion** • **suryalayout3** • **tapas-small** • **tapex** • **tapex-base**
- **tiny-tapas-random-sqa** • **ultra3g** • **unsloth** • **vit-age-classifier** • **vitbasepatch16224.dino**
- **wav2vec2-large-xlsr-53-japanese** • **wav2vec2-large-xlsr-53-portuguese** • **wav2vec2-large-xlsr-53-russian** • **whisper-base.en** • **xlm-roberta-large-xnli**
- **xlm-roberta-ner-japanese** • **xt-1-1** • **万2.1** • **关系抽取模型** • **决策Transformer**
- **字节大模型** • **快手Keye** • **文心一言** • **智谱AI** • **月之暗面**
- **混元** • **百度大模型** • **腾讯大模型** • **豆包** • **赫尔辛基大学翻译模型**
- **通义千问** • **阿里大模型** • **阿里大模型-Qwen2.5-VL-32B-Instruct** • **阿里大模型系列**

### 当前模型品牌名相关 (1个)

- **LLMDet资源集合**

### 技术参数 (1个)

- **32x32分辨率**

### 技术特性 (1218个)

- **1000万长上下文** • **100段影像训练** • **1024x1024分辨率** • **10秒生成** • **11201120高分辨率**
- **119种语言覆盖** • **12-1蒸馏** • **128K上下文** • **128K上下文长度** • **128K扩展上下文窗口**
- **128K长上下文** • **128k上下文** • **128专家** • **12层Transformer** • **131072-tokens**
- **131072上下文** • **131K上下文** • **131K长上下文** • **131k上下文** • **1360768分辨率**
- **14帧短视频** • **16-bit格式** • **16kHz采样率** • **16kHz音频** • **19类实体**
- **1M上下文** • **1x1-卷积捷径** • **1步推理** • **200K上下文** • **2048维稠密嵌入**
- **20ms帧** • **20万实例数据集** • **24kHz音频** • **256K-长上下文** • **256K上下文**
- **256K长上下文** • **256K长文本理解** • **262k上下文** • **26种语言** • **27-languages**
- **2Bits** • **2比特量化** • **3232图像生成** • **324标记编码** • **32768上下文**
- **32768序列长度** • **32K-原生上下文** • **32K上下文** • **32k-token上下文** • **32kHz-EnCodec**
- **32k上下文** • **32x32分辨率** • **32像素块分辨率** • **32帧视频采样** • **36万亿tokens预训练**
- **36层模型** • **384维向量** • **3D-Resampler** • **3D-VAE** • **3D变分自编码器**
- **4-bit格式** • **4-bit量化模型** • **4096标记词汇表** • **48层网络** • **48帧推理**
- **4K分辨率** • **4bit量化** • **4bit量化模型** • **4位2位无损量化** • **4位无损量化**
- **4位量化** • **4比特2比特无损量化** • **4比特无损量化** • **4比特量化** • **4码本生成**
- **50-tokenss** • **512倍上采样** • **570GB清洗语料** • **576x1024-分辨率** • **5T数据预训练**
- **64K上下文** • **64K输出标记** • **64k上下文** • **64帧采样** • **6B视觉编码器**
- **6bit量化** • **768维嵌入** • **7B级多模态** • **7x7-卷积** • **8192上下文**
- **8x8补丁嵌入** • **8帧视频输入** • **92.20准确率** • **94层** • **96K长上下文**
- **97-languages** • **A22B-模型架构** • **A35B-Instruct** • **A3B系列** • **A47B**
- **A47B架构** • **AF-Whisper编码器** • **ANLI** • **ANLI基准** • **APO对齐**
- **ASR模型** • **ASR模式** • **AWQ量化** • **AWQ量化模型** • **Action-Operation-Sensitive格式**
- **Adam优化器** • **Agent能力** • **Agent记忆机制** • **AnglE损失函数** • **Any-to-Any**
- **Apache-2.0许可** • **Apache-2.0许可证** • **Apache-License-2.0** • **Audio-to-Audio** • **AutoModel**
- **AutoThink** • **AutoThink范式** • **AutoTrain-训练** • **AutoTrain回归** • **AutoVideoProcessor**
- **BART架构** • **BCE-损失函数** • **BERT-Base架构** • **BERT-base** • **BEiT编码器**
- **BLEU-24.9** • **BLEU评分** • **BNE语料** • **BaseDecoder512** • **BiPali**
- **BiSigLIP** • **BrowseComp** • **CAPITEL数据集** • **CC-BY-4.0翻译模型** • **CCBY4.0-license**
- **CLIP-H微调** • **CLIP-tokens** • **CLIP主干网络** • **CLIP多模态** • **CLIP视觉backbone**
- **CLIP骨干网络** • **CLS标记** • **CLS标记特征** • **CNN-Transformer** • **COCO数据集**
- **CPU实时推理** • **CRPS优化** • **CSS10数据集** • **CTC束搜索** • **CVPR-2025**
- **CVPR2023** • **CVPR23** • **CVPR23视频模型** • **CfgDistill** • **ChatML模板**
- **CityScapes微调** • **Codec-Does-Matter** • **ColBERT** • **ColBERT策略** • **ColBERT风格**
- **Common-Voice数据集** • **Conformer** • **ControlNet原生支持** • **Creative-Commons-Attribution-4.0** • **CreativeML**
- **Cross-Encoder** • **DALL-E-3技术** • **DDIM** • **DDIM调度器** • **DDPM**
- **DDPM模型** • **DEISMultistepScheduler** • **DEMAND** • **DETR** • **DETR损失函数**
- **DETR架构** • **DINOv2** • **DINOv2预训练** • **DINOv2骨干网络** • **DORA系统**
- **DPO微调** • **DPT架构** • **DPT框架** • **DPT框架扩展** • **DataComp.XL**
- **DeepSeekMoE** • **DiT架构** • **Diffusers** • **Diffusion-Transformer** • **Diffusion概率模型**
- **Dual-Masking** • **EMA权重平均** • **Eagle-解码** • **Embedding模型** • **EnCodec令牌器**
- **EnCodec标记器** • **Euclideanizing-Graph** • **EvoCoT** • **FLD-5B数据集** • **FP16混合精度**
- **FP16版本** • **FP8** • **FP8-scaled** • **FP8-版本** • **FP8混合精度**
- **FP8混合精度训练** • **FP8训练** • **FP8量化** • **FP8量化推理** • **FP8量化模型**
- **Fairseq** • **FastConformer** • **Five-shot-DevOps推理** • **Flair** • **Flash-Attention**
- **Flash-Attention-2** • **FlashAttention2** • **Foundation-Model** • **GGUF** • **GGUF-Q8量化**
- **GGUF格式** • **GGUF量化** • **GGUF量化模型** • **GLU激活** • **GPTQInt4**
- **GQA注意力** • **GRPO微调** • **Gemma3指令微调** • **GenSelect生成式选择** • **Graph-Machine-Learning**
- **Group-Relative-Policy-Optimization** • **HPR** • **HTS-AT融合** • **Heterogeneous-MoE-Structure** • **HiCo时空压缩**
- **HoNY数据集** • **HubertModel** • **Hubert模型** • **Hugging-Face兼容** • **Hybrid-model**
- **I2V** • **IAM数据集** • **ICDAR2019训练** • **ICML-2024** • **IDA训练**
- **IEMOCAP** • **INT4-量化** • **IQ1S** • **IQ1量化** • **IQ2IQ3量化**
- **IQ2XS** • **IQ3S** • **IQ4XS** • **IQ量化** • **Image-Segmentation**
- **Image-Text-to-Text** • **Image-to-Image** • **ImageNet-1k** • **Inception-Score** • **Interleaved图文训练**
- **IterResearch** • **JAX** • **JSUT数据集** • **Joblib** • **K2**
- **KC-MMBench** • **Keras** • **Kinetics-400** • **LAION-2B** • **LAION-Audio-630K**
- **LAMB-优化器** • **LAMB优化器** • **LLM模式** • **LLM语音合成** • **LLaVA-NeXT架构**
- **LPIPS优化** • **LSTM-CRF架构** • **LSUN数据集** • **Langevin-动力学** • **LibriTTS**
- **LiveCodeBench** • **Llasa微调** • **LoRA** • **LoRA微调** • **LoRA秩16**
- **LoRa适配器** • **LongCoT** • **MAE77.527** • **MAE权重初始化** • **MGRPO**
- **MGRPO算法** • **MIT** • **MIT许可** • **MLA** • **MLA注意力**
- **MLM** • **MLM范式** • **MLX格式** • **MMBench评测** • **MNLI**
- **MTEB** • **MTEB-en** • **MXFP4量化** • **Mamba2混合架构** • **MarbleNet**
- **Mask-Generation** • **Matryoshka-Representation-Learning** • **Matryoshka嵌入** • **Matryoshka表示** • **Matryoshka表示学习**
- **MegatronLM训练** • **Mixture-of-Experts** • **MoE架构** • **Mobile-Vision** • **MobileNetV2风格**
- **Modality-Isolated-Routing** • **Modeling-World-Preference** • **ModernBERT** • **MoonViT** • **Motion-LoRAs**
- **Multilingual** • **Muon-optimizer** • **MuonClip优化器** • **Muon优化器** • **MusicCoCa**
- **NBFNet** • **NVFP4-量化** • **NanoCodec** • **OASIS-instruct-数据合成算法** • **OCRfree-处理**
- **OCR增强** • **ONNX** • **OPUS-dataset** • **OPUS数据集** • **OS-agent-grounding**
- **Objects365预训练** • **OmniBench** • **OmniContext** • **OpenCLIP** • **OpenRAIL-M**
- **PD解耦技术** • **PEFT** • **PKU-SafeRLHF** • **PMC预训练** • **PMP**
- **PNDM** • **PaliGemma-3B** • **PaliGemma-3B扩展** • **Patch嵌入** • **Phantom**
- **Pile-NER** • **PixMo** • **Prior-data-based-learning** • **PromptRewrite** • **PubMedBERT编码器**
- **PubMed预训练** • **PubTables1M** • **PyTorch** • **Q2K** • **Q40格式**
- **Q6KL量化** • **Q80** • **Q80量化** • **R1写作风格** • **R2-0.632**
- **R20.502** • **R2决定系数0.922** • **RAG** • **RLHFlow** • **RLHF优化**
- **RMSProp优化器** • **RMSProp模拟** • **RMS归一化** • **RVC** • **RandAugment**
- **ReAct推理** • **Registers** • **Replicate训练** • **ResNet34** • **RoBERTa解码器**
- **RoPE位置编码** • **Robotics** • **Rust** • **SA-1B数据集** • **SA-1B预训练**
- **SAT权重** • **SDEdit技术** • **SFT** • **SNAC神经编解码器** • **SQuAD**
- **SQuAD2-微调** • **SVDQuant** • **SWE-Verified** • **SWE-bench-Multilingual** • **Safetensors**
- **Safetensors格式** • **SailorFog-QA** • **Segformer** • **Sentence-Similarity** • **SentencePiece**
- **SentencePiece-tokenizer** • **SentencePiece分词** • **SentencePiece预处理** • **Seq2SeqLM** • **Sigmoid-Loss**
- **Space-Time-Attention** • **SpectroStream** • **SpeechBrain** • **Step-SRPO** • **StepDistill**
- **Stockmark数据集微调** • **Structured-3D-Latents** • **SwiGLU优化** • **Swin** • **Swin-Large**
- **T5-Small** • **T5架构** • **TDT-解码器** • **TMRoPE** • **TMRoPE-位置编码**
- **TMRoPE技术** • **Tabular-Regression** • **TensorFlow** • **Terminal-bench** • **Text-to-Audio**
- **Think-off模式** • **Think-on模式** • **Thinker-Talker架构** • **ThinkerTalker-架构** • **ThinkerTalker架构**
- **ThinkerTalker设计** • **Transformer** • **Transformer-align** • **Transformer-based** • **Transformers**
- **Transformers.js** • **Tunesformer** • **UE8M0-FP8** • **UI定位** • **UniGRPO**
- **UnlabeledHybrid-1M** • **Unsloth-Dynamic-2.0** • **VACE** • **VAD** • **VQAScore**
- **VQBeT-policy** • **ViT** • **ViT-B** • **ViT-B16** • **ViT-H14**
- **ViT-Large** • **ViT-base** • **ViT-g-384** • **ViT-like-Transformer** • **ViT图像编码器**
- **ViT大型骨干** • **Video-Text-to-Text** • **VideoMME基准** • **Vision-Transformer** • **Vision-Transformer编码器**
- **Vision2Seq** • **VisionTokenizer** • **VitPose-Base** • **Voicebank** • **Wan-VAE**
- **Wav2Vec2** • **Wav2Vec2FeatureExtractor** • **Wav2Vec2特征提取器** • **WenetSpeech预训练** • **WenetsSpeech-L子集**
- **Whole-Word-Masking** • **WikiTableQuestions微调** • **XLM-RoBERTa微调** • **XLSR微调** • **XNLI**
- **XNLI数据集** • **YaRN扩展** • **YaRN扩展上下文** • **YaRN技术** • **YaRN长上下文**
- **Yahoo-Answers** • **Yarn技术** • **ZeRO-1分布式** • **Zero-shot-DevOps推理** • **abc-乐谱切片**
- **absolute-depth-estimation** • **adam优化** • **agent-capabilities** • **artistic** • **arxiv1912.0877**
- **arxiv2103.15691** • **arxiv2104.14294** • **arxiv2106.00666** • **arxiv2107.07653** • **arxiv2311.16098**
- **audio** • **audio-to-audio** • **averagepool** • **bfloat16推理** • **binary-quantization**
- **bipartite-matching-loss** • **catmlpdpt** • **chain-case微调** • **chr-F评分** • **cnndailymail**
- **computer-vision** • **conll2003** • **consistency-model** • **cot** • **distilled模型**
- **exam-centric** • **f8-decoder-微调** • **fcmae** • **feature-extraction** • **forcedbostokenid参数**
- **fp16变体** • **fp8** • **fp8量化蒸馏模型** • **generative-model** • **getdetailedinstruct**
- **grit-id数据集** • **harmony响应格式** • **hypothesistemplate** • **i1-IQ系列** • **i1-IQ量化**
- **imagenet-1k预训练** • **in-the-wild** • **incremental-pretraining** • **indonlu数据集** • **inpainting**
- **int8量化蒸馏模型** • **latent-actions** • **latent-扩散模型** • **llamacpp-imatrix-量化** • **metric-depth-estimation**
- **miniF2F测试** • **mmproj文件** • **msp-podcast** • **mteb** • **multilingual**
- **multinli** • **neural-SQL-executor** • **nli** • **no-VAE** • **non-thinking-mode**
- **normalize-before** • **olmo** • **preference-model** • **qk层归一化** • **quantized**
- **realistic** • **reasoning** • **reinforcement-learning** • **resegmentation** • **reward-model**
- **schedulingddim** • **schedulingddpm** • **schedulingpndm** • **scikit-learn** • **sentence-transformers**
- **seq2seq** • **sequence-tagger-model** • **sft** • **spa-eng** • **speech**
- **stable-diffusion-inpainting** • **stable-diffusion-xl** • **t5-efficient-tiny** • **tabular** • **text-classification**
- **text-generation-inference** • **thinking-mode** • **timm** • **token-classification** • **transformer-align**
- **transformers实现** • **transformers模型** • **uncased** • **uncased模型** • **vision**
- **wav2vec2** • **whole-word-masking** • **wmteuroparl** • **xDiT并行推理** • **xlm-roberta-base微调**
- **xsum** • **zero-shot** • **zero-shot-classification** • **一致性RMS更新** • **一致性模型**
- **一致性蒸馏** • **一致性训练** • **万-VAE** • **三级严重程度分类** • **三级安全分类**
- **三级风险分类** • **三级风险等级分类** • **上下文学习** • **上下文学习范式** • **上下文感知语音生成**
- **下一个视觉-token-预测** • **下一句预测** • **不确定性最小化查询** • **两阶段TTS** • **两阶段历史重采样策略优化**
- **两阶段流水线** • **两阶段生成** • **中文RoBERTawwm-ext** • **中期训练** • **中等轨迹**
- **中英文混合** • **中间预训练** • **主权AI** • **乘法门控** • **二分匹配损失**
- **二次开发** • **人机任务联觉** • **人类偏好对齐** • **仓库级程序分析** • **代理强化学习**
- **代理能力** • **代码定位** • **任务中心化潜在动作** • **任务定制化嵌入** • **任务泛化能力**
- **任意宽高比图像** • **企鹅视频基准** • **优化微调** • **优化微调技术** • **位置重置**
- **低幻觉率** • **低幻觉音频描述** • **低延迟ASR** • **低维稠密向量** • **余弦学习率调度**
- **修正流** • **先验数据学习** • **全局批负载均衡** • **全局最优定位自蒸馏** • **全模态**
- **全模态模型** • **全自动数据合成** • **共享嵌入空间** • **具身推理** • **决策森林模型**
- **冷启动推理数据** • **冷启动数据** • **冷启动数据混合** • **冷启动自动思考** • **减少重复错误**
- **函数调用** • **分位数预测** • **分割一切视觉Transformer** • **分数蒸馏** • **分步序列强化学习**
- **剪枝优化模型** • **加权变分界** • **加权矩阵量化版本** • **加权量化** • **动作扩散**
- **动作空间建模** • **动态2.0** • **动态FPS采样** • **动态分辨率** • **动态分辨率训练**
- **动态图像分辨率** • **动态推理** • **动态特征分析** • **动态角色切换** • **动态计算机制**
- **动态静态视觉场景推理** • **匈牙利匹配** • **单列回归** • **单样本生成** • **单样本解决方案**
- **单模型多模式** • **单轮对话** • **单轮音频输入模型** • **卷积码量化** • **卷积码量化算法**
- **历史重采样** • **原生MXFP4量化** • **原生分辨率视觉编码器MoonViT** • **原生智能体** • **原生端到端**
- **原生长上下文** • **去噪分数匹配** • **去噪扩散概率模型** • **双向扩散** • **双向编码器**
- **双向表征** • **双模式** • **双模式推理** • **双码本音频分词器** • **双采样策略优化**
- **双重掩码策略** • **反刍能力** • **反思模型** • **反思能力** • **句子嵌入**
- **可变形注意力** • **可引导模型** • **可微分等值面提取** • **可提示视觉分割** • **可调解码层**
- **可配置推理力度** • **可配置推理强度** • **右填充方式** • **合成SQL语料库** • **合成数据微调**
- **合成数据集** • **合成数据预训练** • **合成标注图像** • **合成表格数据** • **向量自定义维度**
- **噪声数据过滤** • **噪声过滤** • **噪声鲁棒训练** • **噪声鲁棒语音** • **回归模型**
- **回归版本模型** • **因果语言模型** • **固定预训练文本编码器** • **图-Transformer** • **图Transformer**
- **图像拼接训练** • **图像补丁** • **图像补丁嵌入** • **图像视频统一生成** • **图神经网络**
- **块因果扩散** • **基于MM-Grounding-DINO改进** • **基于Transformer** • **基于UI的问答** • **基础模型**
- **填充掩码** • **增量训练** • **增量预训练** • **复杂卷积优化** • **复杂推理**
- **复杂运动生成** • **外部工具集成** • **外部知识选择性推理** • **多token预测** • **多分辨率**
- **多分辨率图像** • **多功能检索** • **多向量表示** • **多头潜伏注意力** • **多尺度子带CQT判别器**
- **多尺度梅尔频谱图损失** • **多控制条件** • **多智能体协同** • **多智能体协同工作** • **多标记预测**
- **多格式视觉定位** • **多模态** • **多模态RAG** • **多模态大语言模型** • **多模态异构MoE**
- **多模态异构MoE预训练** • **多模态异构混合专家预训练** • **多模态感知** • **多模态指令跟随** • **多模态推理**
- **多模态模型** • **多模态补充文件** • **多模态评估** • **多模态语音** • **多模态预训练**
- **多步决策** • **多步推理** • **多矩阵分解注意力** • **多粒度嵌入** • **多级并行计算**
- **多视觉输入** • **多语言支持** • **多语言支持模型** • **多语言模型** • **多语言长尾知识**
- **多轮上下文学习** • **多轮交互微调** • **多轮交互改写** • **大型模型** • **大型语言模型协同训练**
- **大小写敏感** • **大规模上下文** • **大规模视觉编码器** • **大规模视频预训练** • **大规模预训练**
- **大语言模型协同训练** • **子目标分解** • **完整思维链** • **实时处理** • **实时安全监控**
- **密集视觉标注** • **密集预测Transformer** • **对抗后训练** • **对抗扩散蒸馏** • **对比学习**
- **对象查询** • **对象查询机制** • **小尺寸模型** • **小样本学习** • **少样本学习**
- **少样本预测** • **嵌套式嵌入** • **工具调用** • **工具调用优化** • **工具调用推理**
- **差分注意力** • **布局感知问答** • **布局语言模型** • **并行生成头** • **广义IoU损失**
- **序列到序列模型** • **序列视频数据洞察提取** • **延迟交错处理** • **开放词汇** • **开放词汇表分类**
- **开源指令微调数据集** • **开源智能体** • **异构MoE** • **异构MoE架构** • **异构MoE结构**
- **异构MoE预训练** • **异构混合并行** • **引导蒸馏** • **弱监督训练** • **强化学习**
- **强化学习对齐** • **强化学习推理** • **强化学习训练** • **强化学习赋能** • **强化微调**
- **归一化系数** • **归一化预处理** • **形式化数学语言** • **微调模型** • **微调版**
- **微调训练** • **快慢思考模式** • **快速推理** • **思维推演** • **思维推演能力**
- **思维推理** • **思维模式** • **思维模式与非思维模式** • **思维模式切换** • **思维深度增强**
- **思维能力增强** • **思维范式** • **思维链** • **思维链推理** • **思维链融合**
- **思考模式** • **思考模式切换** • **思考范式** • **思考长度提升** • **性能优化**
- **感知语言模型** • **感知重采样器** • **慢-快视频编码** • **成对评论家** • **扩散先验**
- **扩散变换器** • **扩散大型语言模型** • **扩散大模型** • **扩散对抗后训练** • **扩散技术**
- **扩散损失函数** • **扩散概率模型** • **扩散模型** • **扩散视频模型** • **批次大小256**
- **技能整合** • **抗混叠激活** • **抗混叠激活CUDA内核** • **拒绝采样** • **拒绝采样微调**
- **持续预训练** • **指令微调** • **指令微调数据集** • **指令微调模型** • **指令微调语言模型**
- **指令跟随** • **指令跟随任务** • **指令遵循** • **指令遵循任务** • **指令遵循优化**
- **指令遵循训练** • **推理优化** • **推理效率提升** • **推理能力** • **推理规模扩展**
- **推理轨迹优化** • **推荐指令微调** • **掩码语言建模** • **掩码语言模型** • **掩码预测**
- **提炼模型** • **提示词拼接技术** • **提示词改写** • **提示词视觉任务** • **支持微调**
- **数值建模稳健性** • **数据自控** • **文本-视觉信息融合** • **文本MoE模型** • **文本到文本**
- **文本到文本框架** • **文本到文本迁移转换器** • **文本对齐表征** • **文本提示遵循** • **文档结构理解**
- **旋转增强** • **无G2P多语言TTS** • **无位置嵌入** • **无分类器指导采样** • **无分词器TTS系统**
- **无分词器模型** • **无微调头** • **无损量化** • **无条件生成** • **无标注交互学习**
- **无监督微调** • **无监督深度估计** • **无监督视觉模型** • **无辅助损失负载均衡** • **无辅助损失负载平衡**
- **无需矢量量化** • **日语维基百科数据** • **时间一致性** • **时间一致性生成** • **时间序列基础模型**
- **显存优化** • **智能体功能** • **智能体强化学习** • **智能体数据生成** • **智能体数据预训练**
- **智能体智能** • **智能体能力** • **更高思考效率** • **朗之万动力学** • **权重衰减**
- **条件生成** • **样本效率** • **案例法预训练** • **梯度解耦嵌入共享** • **检索增强**
- **模型压缩** • **模型融合** • **模态专项后训练** • **模态转换模块** • **模态隔离路由**
- **注意力-前馈网络解耦** • **注意力前馈网络解耦** • **注意力统计池化** • **流匹配头** • **流式TTS模块**
- **流式合成** • **流式检测** • **流式语音识别** • **流式音频生成** • **测试用例生成**
- **深度图** • **深度思考能力** • **深度推理** • **混合专家** • **混合专家架构**
- **混合专家模型** • **混合奖励系统** • **混合思考模式** • **混合推理** • **混合推理模型**
- **混合推理模式** • **混合检查点** • **混合注意力** • **混合注意力机制** • **混合液态模型**
- **混合长链思维** • **混合音频输入** • **渐进式有损解压缩** • **渐进式有损解压缩方案** • **滑动窗口变换**
- **滑动窗口变换处理器** • **潜在扩散** • **潜在扩散模型** • **灵活控制思考预算** • **物理AI**
- **特定模态后训练** • **特征匹配损失** • **特征骨干网络** • **生成式人工智能** • **生成式安全模型**
- **生成式解决方案** • **生成式解决方案选择** • **用户-物品交互** • **用户-物品理解** • **用户偏好建模**
- **电影级美学** • **百万字上下文** • **监督微调** • **目标检测** • **直接多步预测**
- **相对位置嵌入** • **真实世界代码编辑数据集微调** • **真实无标注图像** • **知识推理融合** • **知识蒸馏**
- **矩阵量化** • **短卷积** • **神经SQL执行器** • **神经声码器** • **离散扩散**
- **离散文本令牌和连续图像令牌训练** • **离散空间-token-化** • **稀疏注意力** • **稀疏视角重建** • **稠密向量空间**
- **稠密模型与混合专家模型** • **稳健函数调用** • **稳定性优化** • **稳定抓取方式** • **空间时间理解**
- **端到端任务自动化** • **端到端扩散自回归架构** • **端到端语音指令跟随** • **算法优化机制** • **系统提示格式化**
- **线性学习率调度器** • **细粒度分布精化** • **细粒度多维度评分** • **细粒度音色控制** • **结构优化模型**
- **结构化3D潜变量** • **结构化响应** • **结构化模板** • **结构化输出** • **统一偏好优化**
- **统一偏好优化UPO** • **统一分割范式** • **统一变换器架构** • **统一扩散架构** • **统一模态**
- **编码器-解码器** • **编码器-解码器架构** • **编码器-解码器模型** • **翻译质量媲美大模型** • **聊天模板**
- **自举式生成** • **自举式训练** • **自举标注** • **自动思考** • **自动遮罩生成**
- **自回归Transformer** • **自回归变换器** • **自回归文本生成** • **自回归时间序列** • **自回归框架**
- **自回归模型** • **自回归生成** • **自回归语言模型** • **自回归采样** • **自回归预测**
- **自定义工具调用** • **自我改进** • **自我验证** • **自然音频流** • **自监督**
- **自监督DINO方法** • **自监督图像预训练** • **自监督学习** • **自监督视觉特征** • **自监督视觉训练**
- **自监督视频学习** • **自监督预训练** • **自适应分层令牌压缩** • **自适应推理** • **自适应窗口注意力**
- **草稿模型** • **蒙特卡洛树搜索** • **蒸馏** • **蒸馏模型** • **蒸馏版**
- **融合CUDA内核** • **融合损失函数** • **补丁反扁平化** • **表格推理能力** • **表格预训练**
- **规范视频表示** • **视觉-语言-动作** • **视觉-语言-动作模型** • **视觉-语言双向模型** • **视觉-语言预训练**
- **视觉Transformer** • **视觉ViT** • **视觉几何** • **视觉模态理解** • **视觉环境交互**
- **视觉编码器** • **视觉编码解耦** • **视觉语言动作模型** • **视觉语言动作流** • **视觉语言对齐**
- **视觉语言推理** • **视觉语言智能体** • **视觉语言模型** • **视觉语言模型微调** • **视觉语言模型编码器**
- **视觉语言理解** • **视频Transformer** • **视频VAE** • **视频token压缩** • **视频多模态大语言模型**
- **视频掩码自编码器** • **视频文本匹配** • **视频理解** • **视频生成技术** • **视频视觉变换器**
- **视频驱动图像编辑** • **解码层优化** • **解耦式图像分词器** • **解耦式模型** • **解耦注意力机制**
- **证明搜索合成** • **语义分割** • **语音触发功能调用** • **贪婪解码** • **超长上下文**
- **超长序列支持** • **跨任务微调** • **跨场景视觉内容处理** • **跨平台识别** • **跨模态向量量化**
- **跨模态性能** • **跨模态推理** • **跨编码器** • **跨语言抽取** • **跨页表格合并**
- **轨迹控制** • **轨迹质量筛选** • **轻量化** • **轻量化SAM** • **轻量化模型**
- **轻量化深度模型** • **轻量模型** • **轻量级BERT** • **轻量级MLP解码头** • **轻量级匹配**
- **轻量级模型** • **轻量级特征匹配** • **轻量级视觉Transformer** • **连续令牌生成** • **连续值空间**
- **逐帧解码器** • **递归定理证明流程** • **通用多模态嵌入** • **通用策略构建** • **逻辑推理**
- **遮蔽注意力** • **采样效率** • **量化感知训练** • **量化模型** • **链式微调**
- **链式思维** • **链式思维微调** • **链式思维推理** • **长CoT** • **长上下文**
- **长上下文优化** • **长上下文扩展** • **长上下文支持** • **长度外推** • **长思维变体**
- **长文本推理** • **长文本理解** • **长时依赖建模** • **长视频理解** • **长链式思维**
- **长链思维链冷启动训练** • **长链推理** • **阶梯式学习率** • **降维64** • **随机检查点**
- **零样本实体识别** • **零样本性能** • **零样本迁移** • **零样本预测** • **静态量化**
- **静态量化版本** • **非共享参数** • **非形式化与形式化推理整合** • **非思维模式** • **非思考模式**
- **非结构化文档处理** • **韩语BERT** • **音频-文本对比学习** • **音频伪标记** • **音频条件控制**
- **音频预训练** • **预训练时间序列模型** • **预训练模型** • **预转换CoreML模型** • **领域并行训练**
- **高分辨率文档压缩器** • **高分辨率转录** • **高效扩展基础设施** • **高效深度估计** • **高效混合编码器**
- **高稀疏混合专家模型** • **高级空间感知** • **高质数据混合**

### 授权协议 (1个)

- **Apache-License-2.0**

### 提供方 (1个)

- **NVIDIA模型**

### 数据来源 (3个)

- **TASS-2020语料库** • **欧盟立法语料** • **相机运动数据集**

### 数据特性 (1个)

- **高质量-DevOps-语料**

### 数据集 (9个)

- **ADE20K** • **COCO数据集** • **ImageNet-1k** • **ImageNet-21k** • **LVD-142M**
- **LVD-142M数据集** • **imagenet-1k** • **samsum数据集** • **米哈游音乐二创数据集**

### 标签体系 (1个)

- **POSNEGNEU标签**

### 模型特性 (1个)

- **Uncased**

### 模型组件 (1个)

- **Pi0Policy**

### 模型规格 (2个)

- **518518输入** • **R101VD**

### 训练数据 (6个)

- **Kinetics-400全监督训练** • **OpenFWI数据集** • **SQuAD-v2** • **SQuAD2.0** • **STS-Benchmark**
- **duie数据集**

### 训练数据集 (2个)

- **ImageNet-1k** • **VideoChatGPT-Instruct**

### 许可协议 (1个)

- **Apache-2.0**

### 评估指标 (5个)

- **EmuEdit基准** • **GLUE基准测试** • **Inception-分数-9.46** • **ROGUE1指标** • **ReasonEdit基准**

### 评估数据 (1个)

- **Flores-200数据集**

### 评测基准 (1个)

- **DevOpsEval基准**

### 评测数据集 (2个)

- **CEval-DevOps测试** • **CMMLU-DevOps测试**

### 语言支持 (1个)

- **西班牙语**

### 输入规格 (1个)

- **512x512分辨率**

### 部署工具 (190个)

- **4比特量化优化** • **6bit量化** • **API调用** • **AWQ-4-bit** • **AWQ量化**
- **AWQ量化模型** • **AWS-SageMaker** • **Amazon-SageMaker** • **Apache-License-2.0** • **Apple平台优化**
- **AutoAWQ量化** • **AutoGluon** • **AutoModelForZeroShotObjectDetection** • **AutoProcessor** • **AutoTrain**
- **AutoVideoProcessor** • **CPU卸载** • **Colab** • **Colab-TPU部署** • **Colab体验**
- **ComfyUI** • **ComfyUI-GGUF** • **ComfyUI-深度图** • **ComfyUI插件** • **ComfyUI模型**
- **ComfyUI部署** • **ComfyUI集成** • **DDPMPipeline** • **Diffusers** • **Diffusion-Single-File**
- **DiffusionPipeline** • **DiffusionPipeline集成** • **Docker部署** • **Docling流水线** • **FLUX.1-Kontext-dev**
- **FastDeploy** • **FastDeploy部署** • **FriendliAI** • **FriendliAI平台** • **GGUF**
- **GGUF文件** • **GGUF格式** • **GGUF格式导出** • **GGUF量化** • **GGUF量化模型**
- **GPTQ量化** • **Git下载** • **Google-Colab微调** • **Gradio本地演示** • **Gradio演示**
- **Gradio界面** • **Haystack** • **HiDream-I1本地部署** • **Hugging-Face容器** • **Hugging-Face模型库**
- **HuggingFace** • **HuggingFace-Spaces** • **HuggingFace-pipeline** • **HuggingFace下载** • **HuggingFace推理**
- **HuggingFace模型** • **HuggingFace模型库** • **HuggingSound库** • **INT4量化** • **JAX**
- **JavaScript推理** • **Joblib** • **Joblib模型** • **LM-Studio运行** • **LeRobot**
- **LeRobot平台** • **MIT许可证** • **MLX** • **MLX-4bit** • **MLX框架**
- **MLX部署** • **MLX量化** • **MLX量化部署** • **ModelScope** • **ModelScope-SDK**
- **NeMo** • **Nexa-SDK** • **Nomic-Atlas** • **OCRFlux-API** • **ONNX**
- **ONNX导出** • **Ollama** • **Ollama部署** • **OpenAI兼容API** • **OpenHands**
- **OpenVINO** • **Paddle** • **PaddlePaddle** • **PaddlePaddle权重** • **PaddlePaddle部署**
- **Paddle模型** • **PyTorch** • **Q8量化** • **Rust** • **SGLang**
- **SWIFT微调** • **Safetensors** • **Sentence-Transformers** • **SentenceTransformers** • **SwissArmyTransformer-调用**
- **TaylorSeer** • **TeaCache** • **TensorFlow** • **TouchDesigner** • **Transformers**
- **Transformers.js** • **Unsloth微调** • **Unsloth部署** • **Unsloth量化** • **Unsloth量化模型**
- **WanVideoWrapper** • **WebUI在线试用** • **ZeroGPU-Space** • **ZeroGPU空间** • **autotrain**
- **bf16推理** • **bnb-4bit** • **deepcompressor** • **diffusers库** • **diffusers部署**
- **gguf-connector** • **gguf节点** • **i1-IQ1S量化** • **i1-IQ4XS量化** • **int4量化**
- **joblib** • **joblib模型** • **joblib模型下载** • **llama.cpp** • **llama.cpp运行**
- **llama.cpp部署** • **mlx-audio** • **mlx-vlm工具** • **mlxlm部署** • **nomic-Python客户端**
- **ollama部署** • **pipeline调用** • **q4KM** • **q4KM量化** • **q5KM**
- **q5KM量化** • **q6K** • **q80** • **rvc-runpod** • **schedulingddpm**
- **sentence-transformers** • **sentence-transformers嵌入** • **sglang部署** • **text-generation-inference** • **timm库**
- **timm模型** • **transformers.js** • **vLLM** • **vLLM定制部署** • **vLLM推理加速**
- **vLLM部署** • **vllm推理架构** • **zero-shot-classification管道** • **交互式本地演示** • **企业级部署**
- **单GPU部署** • **单卡4090** • **单机运行** • **向量数据库集成** • **多GPU运行**
- **完全离线运行** • **密集型架构** • **嵌入API** • **开源模型** • **张量并行**
- **微调** • **指令优化版** • **本地推理** • **本地部署** • **现场表演部署**
- **端侧部署** • **终端部署** • **网页端部署** • **设备端推理** • **设备端部署**
- **轻量级部署** • **边缘设备部署** • **边缘部署** • **量化模型** • **量化适配**

### 部署方式 (9个)

- **API调用** • **BF16推理** • **Google-Colab运行** • **Jupyter笔记本** • **ModelScope-在线体验**
- **pytorchmodelhubmixin** • **即插即用LLM** • **本地部署** • **边缘部署**

### 预训练数据集 (1个)

- **ImageNet-1k**

## 详细结果


### deepseek-ai/DeepSeek-Prover-V1

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V1

**关键词列表**:

- **DeepSeek-Prover** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **DeepSeek-Prover-V1** (当前模型品牌名): 当前模型的完整名称
- **定理证明** (功能场景): 当前模型的核心功能用途
- **Lean-4证明** (功能场景): 当前模型针对的特定证明助手场景
- **形式定理证明** (功能场景): 当前模型的技术应用领域
- **数学竞赛问题证明** (功能场景): 当前模型处理的具体任务类型
- **合成数据集** (技术特性): 当前模型训练使用的核心技术方案
- **miniF2F测试** (技术特性): 当前模型性能评估的关键基准

### deepseek-ai/DeepSeek-V2.5

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2.5

**关键词列表**:

- **DeepSeek-V2.5** (当前模型品牌名): 项目名称即模型的完整品牌名称
- **智能对话** (功能场景): 模型继承 DeepSeek-V2-Chat 的对话能力，适用于智能聊天
- **编程助手** (功能场景): 模型融合 DeepSeek-Coder-V2-Instruct，支持代码生成与编程帮助
- **AI写作** (功能场景): 模型在写作与指令遵循方面经过优化，可用于自动化写作
- **指令遵循** (功能场景): 模型在 HumanEval、ArenaHard 等评测中表现突出，说明对指令的高效遵循
- **Transformer** (技术特性): 模型基于 Transformer 架构，是主流大语言模型的核心技术
- **本地部署** (部署工具): DeepSeek 系列模型常以 safetensors 形式发布，便于用户在本地环境快速部署

### deepseek-ai/JanusFlow-1.3B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/JanusFlow-1.3B

**关键词列表**:

- **JanusFlow** (当前模型品牌名): 从项目名称直接提取的当前模型名称，简洁品牌名，用户搜索AI多模态模型时会直接使用
- **文生图** (功能场景): 模型支持使用修正流和SDXL-VAE生成384x384图像，核心功能为文本驱动图像生成，符合用户搜索意图
- **多模态** (技术特性): 模型明确设计为统一图像理解与生成的多模态语言模型，是核心架构特征，用户常搜此关键词
- **自回归模型** (技术特性): 模型将自回归语言模型与修正流结合，自回归是其关键技术组件，属于用户关注的模型架构术语
- **修正流** (技术特性): 模型创新点在于直接在LLM框架中训练修正流，是论文核心术语，技术型用户会搜索此专业词
- **1.3B参数** (参数规格): 模型规模为1.3B，属于主流轻量级参数规格，用户常按参数量筛选模型，符合提取规则

### deepseek-ai/Janus-Pro-1B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/Janus-Pro-1B

**关键词列表**:

- **Janus-Pro** (当前模型品牌名): 从项目名称提取的当前模型名称
- **7B参数** (参数规格): 当前模型基于DeepSeek-LLM-7b-base构建，7B参数是常见用户搜索的规格

### Kwaipilot/KwaiCoder-AutoThink-preview

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/KwaiCoder-AutoThink-preview

**关键词列表**:

- **KwaiCoder** (当前模型品牌名): 从项目名称提取的模型品牌名称
- **AutoThink** (技术特性): 模型核心的自动思考能力，用户常以此关键词搜索
- **分步序列强化学习** (技术特性): Step‑SRPO（分步序列强化学习）是模型独有的强化学习技术
- **智能体数据生成** (技术特性): Agentic Data（智能体数据生成）用于冷启动思维链数据
- **知识蒸馏** (技术特性): KD + MTP（知识蒸馏+多 token 预测）是模型的关键蒸馏方案
- **多语言模型** (功能场景): 模型支持多语言输入输出，适用于跨语言编程与对话

### QuantStack/Wan2.2-T2V-A14B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.2-T2V-A14B-GGUF

**关键词列表**:

- **Wan2.2-T2V-A14B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Text-to-Video** (功能场景): 当前模型的核心功能，即文本到视频的转换
- **ComfyUI** (部署工具): 当前模型可配合使用的部署工具
- **量化模型** (技术特性): 当前模型为量化模型，是其重要技术特性
- **GGUF** (技术特性): 当前模型的文件格式，属于技术特性

### microsoft/deberta-v3-large

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/deberta-v3-large

**关键词列表**:

- **deberta-v3** (当前模型品牌名): 从项目名称和标签提取的当前模型核心名称
- **deberta-v3-large** (当前模型品牌名): 项目完整名称，用户可能直接搜索
- **自然语言理解** (功能场景): 当前模型主要应用的任务场景
- **fill-mask** (功能场景): 标签中明确标注的模型功能
- **解耦注意力机制** (技术特性): 当前模型的核心技术改进点
- **梯度解耦嵌入共享** (技术特性): DeBERTa V3版本的关键技术创新
- **Transformers** (部署工具): 标签中明确标注的模型部署框架
- **PyTorch** (部署工具): 标签中明确标注的模型支持框架

### openai/whisper-tiny.en

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-tiny.en

**关键词列表**:

- **Whisper-tiny.en** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索小型英文语音识别模型时会使用此精确名称
- **语音识别** (功能场景): 模型核心用途，用户搜索英文语音转文字工具时高频使用此词
- **HuggingFace** (部署工具): 模型托管平台，用户常搜索'HuggingFace 语音模型'来查找和下载
- **英文语音识别** (功能场景): 模型专为英语设计，用户明确搜索英文语音转文本方案时会使用此组合词
- **轻量级语音模型** (功能场景): tiny规模模型的用户意图关键词，搜索低资源环境部署方案时高频出现
- **ASR模型** (技术特性): Automatic Speech Recognition的通用缩写，技术用户搜索语音识别模型时常用术语

### gilf/french-camembert-postag-model

**URL**: https://ai.gitcode.com/hf_mirrors/gilf/french-camembert-postag-model

**关键词列表**:

- **French-Camembert** (当前模型品牌名): 项目名称中包含 “french‑camembert”，提取为模型的品牌名称
- **法语词性标注** (功能场景): 模型的核心任务是对法语进行词性标注（POS tagging）
- **POS标注** (功能场景): 模型提供通用的词性标注功能，可用于语言学研究和下游 NLP 任务
- **Safetensors** (技术特性): 模型文件采用 safetensors 格式，便于高效加载

### dandelin/vilt-b32-finetuned-vqa

**URL**: https://ai.gitcode.com/hf_mirrors/dandelin/vilt-b32-finetuned-vqa

**关键词列表**:

- **ViLT** (当前模型品牌名): 项目名称核心词，用户直接搜ViLT找该模型
- **视觉问答** (功能场景): 模型专精VQA任务，用户搜视觉问答即可定位

### keras-io/TF_Decision_Trees

**URL**: https://ai.gitcode.com/hf_mirrors/keras-io/TF_Decision_Trees

**关键词列表**:

- **TFDecisionTrees** (当前模型品牌名): 从项目名称提取的当前模型名称
- **TensorFlow** (当前模型品牌名): 当前模型基于TensorFlow框架实现，是重要的相关品牌
- **Keras** (当前模型品牌名): 当前模型与Keras相关，是重要的相关品牌
- **结构化数据分类** (功能场景): 当前模型的主要功能是用于结构化数据的二分类任务
- **决策森林模型** (技术特性): 当前模型通过构建决策森林模型来实现功能，是其技术特性

### autogluon/tabpfn-mix-1.0-regressor

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/tabpfn-mix-1.0-regressor

**关键词列表**:

- **TabPFNMix** (当前模型品牌名): 从项目名称提取的当前模型名称
- **表格基础模型** (功能场景): 当前模型的核心功能定位
- **Tabular-Regression** (功能场景): 当前模型的具体应用场景
- **编码器-解码器架构** (技术特性): 当前模型的技术实现方式
- **AutoGluon** (部署工具): 当前模型的官方推荐部署框架
- **3700万参数** (参数规格): 当前模型的核心参数规模

### pcoloc/autotrain-dragino-7-7-max_495m-1860863627

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-dragino-7-7-max_495m-1860863627

**关键词列表**:

- **AutoTrain** (部署工具): 模型是通过AutoTrain平台训练的，这是用户搜索自动化训练工具时的高频关键词
- **tabular-regression** (功能场景): 模型明确用于表格数据回归任务，是用户在AI建模中搜索特定任务类型的核心关键词
- **tabular** (功能场景): 用户常搜索‘tabular数据建模’或‘表格预测模型’，该词精准匹配模型输入类型
- **regression** (功能场景): 回归任务是AI建模中的基础场景，用户会直接搜索‘回归模型’寻找类似项目
- **Joblib** (部署工具): 模型使用Joblib加载，是Python用户部署传统机器学习模型时的高频搜索词
- **pcolocautotrain-dragino-7-7-max495m** (当前模型品牌名): 从项目名称提取的完整模型标识，虽含下划线但为官方命名，用户可能直接搜索此唯一标识

### TIGER-Lab/VideoScore-v1.1

**URL**: https://ai.gitcode.com/hf_mirrors/TIGER-Lab/VideoScore-v1.1

**关键词列表**:

- **VideoScore** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **VideoScore-v1.1** (当前模型品牌名): 完整版本号的模型名称，用户常以此检索特定版本
- **视频质量评估** (功能场景): 模型的核心用途是对视频质量进行自动评估
- **文本-视频对齐** (功能场景): 模型在文本‑视频对齐子项得分上表现突出，属于重要功能关键词
- **多模态评估** (技术特性): 模型基于多模态大模型进行训练，具备多模态评估能力
- **48帧推理** (技术特性): 推理时支持一次处理48帧视频，是模型的显著技术特性
- **回归版本模型** (技术特性): VideoScore‑v1.1 为回归版本，适合对比和迁移学习的用户搜索

### openbmb/MiniCPM-V

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-V

**关键词列表**:

- **MiniCPM-V** (当前模型品牌名): 从项目名称提取的当前模型名称
- **终端部署** (部署工具): 当前模型支持手机等终端设备部署的特性
- **中英双语交互** (功能场景): 当前模型支持中英双语多模态交互的核心功能
- **3B参数** (参数规格): 当前模型的参数量级（基于OmniLMM-3B及对比模型参数推断）
- **实时视频理解** (功能场景): 当前模型支持iPad端实时视频理解的特性

### FreedomIntelligence/BlenderLLM

**URL**: https://ai.gitcode.com/hf_mirrors/FreedomIntelligence/BlenderLLM

**关键词列表**:

- **BlenderLLM** (当前模型品牌名): 从项目名称 FreedomIntelligence/BlenderLLM 直接提取的当前模型正式名称
- **CAD** (功能场景): 模型核心应用场景为计算机辅助设计，用户会搜索‘CAD AI模型’等关键词
- **Text-to-3D** (功能场景): 模型明确支持文本生成3D模型，是用户搜索AI建模工具时的高频意图词
- **自我改进** (技术特性): 模型采用‘自我改进训练’技术，是其区别于普通微调模型的核心创新点，用户可能搜索‘自我改进LLM’
- **Blender** (功能场景): 模型专为Blender软件设计，支持bpy脚本，用户在3D设计圈会直接搜索‘Blender AI’或‘Blender模型’

### city96/Wan2.1-I2V-14B-480P-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/city96/Wan2.1-I2V-14B-480P-gguf

**关键词列表**:

- **Wan2.1** (当前模型品牌名): 从项目名称提取的简化模型名称
- **14B参数** (参数规格): 模型规模为 14 B 参数，用户常以参数规模搜索模型
- **文生视频** (功能场景): 模型支持 Image‑to‑Video（图像生成视频）功能，属于文本/图像生成视频场景
- **GGUF量化模型** (技术特性): 模型以 GGUF 格式提供，属于量化模型，用户会搜索此类技术特性

### naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt

**URL**: https://ai.gitcode.com/hf_mirrors/naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt

**关键词列表**:

- **naverDUSt3RViTLargeBaseDecoder512dpt** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像转3D** (功能场景): 结合README中‘Geometric 3D Vision’及‘image - to - 3d’标签，可知该模型有将图像转换为3D的功能场景

### Falconsai/text_summarization

**URL**: https://ai.gitcode.com/hf_mirrors/Falconsai/text_summarization

**关键词列表**:

- **Falconsaitextsummarization** (当前模型品牌名): 从项目URL和模型卡片提取的当前模型名称
- **文本摘要** (功能场景): 当前模型的主要应用场景
- **T5-Small** (技术特性): 当前模型基于T5 Small架构进行微调
- **微调版** (技术特性): 当前模型是经过微调的版本，具有特定优化
- **简洁连贯摘要** (功能场景): 当前模型能够生成简洁连贯的文本摘要

### CuriousMonkey7/HumAware-VAD

**URL**: https://ai.gitcode.com/hf_mirrors/CuriousMonkey7/HumAware-VAD

**关键词列表**:

- **HumAware-VAD** (当前模型品牌名): 从项目名称提取的当前模型名称
- **语音活动检测** (功能场景): 当前模型的核心功能场景
- **哼唱检测** (功能场景): 当前模型专门针对哼唱场景的检测功能
- **语音分割** (功能场景): 当前模型提升语音分割精度的应用场景
- **实时处理** (技术特性): 当前模型推理速度的技术特性
- **VAD** (技术特性): 当前模型所属的语音活动检测技术领域

### BAAI/bge-reranker-v2-m3

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-reranker-v2-m3

**关键词列表**:

- **bge-reranker-v2-m3** (当前模型品牌名): 项目名称中直接出现的模型名称，用户搜索时会使用该简写
- **多语言重新排序器** (功能场景): 模型能够对查询和文档进行多语言相关性打分，是其核心使用场景
- **文本相似度评分** (功能场景): 模型输出直接的相似度分数，满足用户对文本相似度计算的需求
- **轻量级部署** (部署工具): 模型体积小、易于部署，符合用户寻找可快速上线的模型的搜索意图
- **快速推理** (技术特性): 模型推理速度快，是用户在搜索高效检索模型时关注的关键特性
- **跨语言检索** (功能场景): 支持多语言输入，适用于跨语言信息检索的应用场景

### ServiceNow-AI/Apriel-1.5-15b-Thinker

**URL**: https://ai.gitcode.com/hf_mirrors/ServiceNow-AI/Apriel-1.5-15b-Thinker

**关键词列表**:

- **Apriel-1.5** (当前模型品牌名): 从项目名称 'Apriel-1.5-15b-Thinker' 中提取的核心品牌名，符合简化规则（去掉参数与后缀）
- **15B参数** (参数规格): 模型参数为150亿，符合主流规格（15B），用户常搜索‘15B参数模型’寻找轻量高性能模型
- **文本推理** (功能场景): 模型重点增强文本推理能力，是其主要用途，用户会搜索‘文本推理AI’或‘强推理模型’
- **图像推理** (功能场景): 模型新增图像推理支持，是区别于纯文本模型的关键功能，用户会搜索‘图像推理模型’
- **SFT** (技术特性): 模型采用文本监督微调（SFT）作为核心训练方式，是技术圈高频术语，专业用户会搜索

### openbmb/MiniCPM-Llama3-V-2_5-int4

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-Llama3-V-2_5-int4

**关键词列表**:

- **MiniCPM** (当前模型品牌名): 项目名称直接给出的当前模型品牌
- **int4量化** (部署工具): 当前版本核心卖点，用户搜索低显存部署方案时的关键词

### Wan-AI/Wan2.2-TI2V-5B

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.2-TI2V-5B

**关键词列表**:

- **Wan2.2** (当前模型品牌名): 从项目名称提取的当前模型核心标识
- **图生视频** (功能场景): 模型另一核心功能，与文生视频并列展示
- **MoE架构** (技术特性): 模型采用的创新架构，具有技术独特性
- **5B参数** (参数规格): 模型参数量级，用户关注的重要指标

### nvidia/Cosmos-Reason1-7B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/Cosmos-Reason1-7B

**关键词列表**:

- **Cosmos-Reason1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **物理常识推理** (功能场景): 当前模型的核心功能场景
- **具身推理** (技术特性): 当前模型的核心技术特性
- **机器人规划** (功能场景): 当前模型的应用场景
- **空间时间理解** (技术特性): 当前模型的核心技术特性

### THUDM/SWE-Dev-9B

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/SWE-Dev-9B

**关键词列表**:

- **SWE-Dev-9B** (当前模型品牌名): 项目名称中直接出现的模型名称
- **智谱AI** (当前模型品牌名): GLM-4 系列模型对应的国产大模型品牌映射
- **软件工程助手** (功能场景): 模型定位于面向软件工程任务的开源智能体
- **测试用例生成** (功能场景): README 中提到模型能够自动生成测试用例
- **9B参数** (参数规格): 模型规模为 9B 参数
- **强化微调** (技术特性): 模型在训练阶段使用了强化微调（RFT）提升性能
- **OpenHands** (部署工具): 模型基于开源框架 OpenHands，可直接部署使用

### sshleifer/distilbart-xsum-12-6

**URL**: https://ai.gitcode.com/hf_mirrors/sshleifer/distilbart-xsum-12-6

**关键词列表**:

- **distilbart-xsum-12-6** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索特定轻量摘要模型时会使用此精确名称
- **轻量级摘要模型** (功能场景): 模型参数306M，显著小于基准模型（406M），用户会搜索'轻量级'+'摘要'组合词寻找高效方案
- **XSum** (功能场景): 模型在XSum数据集上训练，该数据集是新闻摘要领域知名基准，专业用户会直接搜索'XSum模型'
- **模型压缩** (技术特性): 该模型是BART的蒸馏版本，核心价值在于压缩后保持高ROUGE分数，符合'模型压缩'搜索意图

### BAAI/bge-base-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-base-en-v1.5

**关键词列表**:

- **BGE-base** (当前模型品牌名): 从项目名称提取的当前模型名称，简化自BAAI/bge-base-en-v1.5
- **英文检索** (功能场景): 当前模型为英文密集检索模型，属于核心功能场景
- **密集检索** (功能场景): README明确说明属于BGE系列的密集检索模型方向
- **Embedding模型** (技术特性): 项目属于FlagEmbedding系列，核心是Embedding技术

### lmms-lab/LLaVA-NeXT-Video-7B-DPO

**URL**: https://ai.gitcode.com/hf_mirrors/lmms-lab/LLaVA-NeXT-Video-7B-DPO

**关键词列表**:

- **LLaVA-NeXT-Video** (当前模型品牌名): 从项目名称和模型详情中提取的当前模型名称
- **多模态指令跟随** (技术特性): 当前模型的核心技术特性
- **视频文本理解** (功能场景): 当前模型处理视频与文本的核心功能
- **开源聊天机器人** (功能场景): 当前模型的主要用途描述
- **Video-Text-to-Text** (技术特性): 当前模型的标签，体现其视频文本转换能力
- **VQA任务** (功能场景): 当前模型在视觉问答领域的应用场景

### reducto/RolmOCR

**URL**: https://ai.gitcode.com/hf_mirrors/reducto/RolmOCR

**关键词列表**:

- **RolmOCR** (当前模型品牌名): 项目名称即模型名称，直接提取为品牌名
- **文档OCR** (功能场景): 模型的核心功能是对文档进行光学字符识别
- **PDF解析** (功能场景): 模型专注于解析 PDF 及复杂文档，是用户常搜索的场景关键词
- **vLLM部署** (部署工具): README 中提供了通过 vLLM 部署模型的完整指令
- **OpenAI兼容API** (部署工具): 模型支持以 OpenAI 兼容方式调用，符合用户对 API 接口的搜索需求
- **旋转增强** (技术特性): 训练时对约 15% 数据进行旋转处理，提高对非标准角度文档的鲁棒性

### THUDM/GLM-4-32B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4-32B-0414

**关键词列表**:

- **32B参数** (参数规格): 模型参数规模为320亿，属于主流参数规格，用户常搜索'32B参数'类模型
- **深度推理** (技术特性): GLM-Z1-32B-0414和GLM-Z1-Rumination-32B-0414具备深度思考与反刍思考能力，是模型独特技术标签

### BAAI/bge-small-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-small-en-v1.5

**关键词列表**:

- **BAAIbge-small-en-v1.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **检索增强** (技术特性): 当前模型所属的FlagEmbedding专注于检索增强的大语言模型
- **重排序模型** (功能场景): 当前模型所属的FlagEmbedding包含重排序模型项目
- **sentence-similarity** (功能场景): 当前模型相关的功能标签，句子相似度
- **feature-extraction** (功能场景): 当前模型相关的功能标签，特征提取

### THUDM/GLM-Z1-32B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-Z1-32B-0414

**关键词列表**:

- **GLM-4** (当前模型品牌名): 从项目名称提取的当前模型核心品牌名
- **深度推理模型** (功能场景): 当前模型核心功能定位，用户搜索意图明确
- **反刍能力** (技术特性): 当前模型独特的技术特性，具备区分度
- **函数调用** (技术特性): 当前模型强化的核心技术能力
- **工程代码** (功能场景): 当前模型擅长的应用场景，用户需求明确

### diffusers/stable-diffusion-xl-1.0-inpainting-0.1

**URL**: https://ai.gitcode.com/hf_mirrors/diffusers/stable-diffusion-xl-1.0-inpainting-0.1

**关键词列表**:

- **SD-XL** (当前模型品牌名): 从项目名称 'stable-diffusion-xl-1.0-inpainting-0.1' 中提取的核心品牌简称，用户搜索AI图像生成模型时最常用关键词
- **图像修复** (功能场景): 模型核心能力为基于遮罩的图像修复（inpainting），是用户搜索该类AI工具时的明确意图词
- **Diffusers** (部署工具): 模型通过Hugging Face Diffusers库调用，是用户部署该模型时的关键技术入口词
- **stable-diffusion-xl-diffusers** (当前模型品牌名): 项目标签中明确标注的完整品牌标识，虽较长但为官方命名，用户在精准搜索时会使用该组合词
- **inpainting** (技术特性): 模型核心技术创新点，英文术语在AI开发者中广泛使用，且为当前模型区别于基础SD-XL的关键特征
- **无分类器指导采样** (技术特性): 模型训练中采用的关键技术优化，是专业用户搜索高质量图像修复模型时的精准技术关键词

### zai-org/GLM-4.5V

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5V

**关键词列表**:

- **GUI智能体** (功能场景): 官方强调可操控图形界面，开发者实测热点
- **API调用** (部署工具): README 明确提供智谱AI开放平台API，落地首选
- **1060亿参数** (参数规格): 旗舰规模，用户对比模型大小时常搜索
- **文档理解** (功能场景): 官方列出的核心能力，办公/教育场景刚需

### cross-encoder/nli-deberta-v3-large

**URL**: https://ai.gitcode.com/hf_mirrors/cross-encoder/nli-deberta-v3-large

**关键词列表**:

- **nli-deberta-v3-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自然语言推理** (功能场景): 该模型用于自然语言推理任务，是模型的应用场景
- **sentence-transformers** (部署工具): README中提及预训练模型可像sentence-transformers的使用方式使用，是部署相关工具
- **多模态推理** (技术特性): 模型进行自然语言推理，可看作一种多模态推理的应用，是模型的技术特性体现
- **92.20准确率** (技术特性): 模型在SNLI - test数据集上有92.20的准确率，是模型性能的技术特性体现

### hustvl/yolos-small

**URL**: https://ai.gitcode.com/hf_mirrors/hustvl/yolos-small

**关键词列表**:

- **YOLOS** (当前模型品牌名): 模型名称直接来源于项目名称
- **目标检测** (功能场景): 模型主要用于图像中的目标检测任务
- **COCO2017数据集** (功能场景): 模型在 COCO 2017 目标检测数据集上微调
- **二分匹配损失** (技术特性): 模型采用二分匹配（Hungarian）损失进行训练，是其核心技术特性
- **小尺寸模型** (技术特性): 该版本为 YOLOS 的 small（小尺寸）变体，适合轻量化部署
- **HuggingFace模型库** (部署工具): 模型通过 HuggingFace Transformers 库提供，便于快速调用和部署

### unsloth/gemma-3-270m-it-qat-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-qat-GGUF

**关键词列表**:

- **Gemma-3-270m** (当前模型品牌名): 从项目名称 unsloth/gemma-3-270m-it-qat-GGUF 中提取的核心模型名称，简洁无版本后缀，符合用户搜索习惯
- **Unsloth** (当前模型品牌名): Unsloth 是微调和优化该模型的官方技术品牌，用户搜索‘Unsloth Gemma’或‘Unsloth 量化’时会精准指向本项目
- **270M参数** (参数规格): 270M 属于轻量级主流参数规模，用户常搜索‘200M参数模型’‘300M模型’等寻找低资源部署方案

### openai/diffusers-ct_imagenet64

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-ct_imagenet64

**关键词列表**:

- **diffusers-ctimagenet64** (当前模型品牌名): 从项目名称提取的当前模型名称
- **consistency-model** (技术特性): 当前模型的核心技术类型，标签中明确标注
- **generative-model** (技术特性): 当前模型所属的生成模型类别，标签中明确标注
- **unconditional-image-generation** (功能场景): 当前模型的核心功能场景，标签中明确标注
- **图像超分辨率** (功能场景): 当前模型支持的零样本数据编辑功能之一

### unsloth/Qwen3-4B-Instruct-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-4B-Instruct-2507-GGUF

**关键词列表**:

- **通义千问** (当前模型品牌名): 项目名称中含 Qwen，按照映射规则提取的国产大模型品牌名
- **阿里大模型** (当前模型品牌名): Qwen 系列属于阿里巴巴的大模型系列，符合品牌映射要求
- **Qwen3-4B** (当前模型品牌名): 从项目全称 Qwen3-4B-Instruct-2507 提取的简洁模型名称
- **4B参数** (参数规格): 模型规模为 4 B（约 40 亿）参数，用户常以参数规模搜索模型
- **逻辑推理** (功能场景): README 中强调模型在逻辑推理上的突破，属于典型的使用场景关键词
- **长文本理解** (技术特性): 模型原生支持 256K 上下文，体现了长文本理解的技术优势

### Qwen/Qwen2.5-Omni-7B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B-AWQ

**关键词列表**:

- **流式语音生成** (功能场景): 模型突出能力为实时语音生成与响应，区别于普通TTS，是用户寻找实时交互AI时的精准搜索词
- **AWQ量化模型** (部署工具): 模型采用AWQ 4-bit量化技术，专为低显存设备优化，用户搜索'AWQ量化模型'时会精准定位此类轻量化部署方案
- **Any-to-Any** (功能场景): README明确标注标签为Any-to-Any，代表跨模态任意输入输出能力，是区别于普通多模态模型的独特功能表述，用户可能直接搜索该术语

### amazon/chronos-bolt-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-bolt-tiny

**关键词列表**:

- **Chronos-Bolt** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Chronos-Bolt-Tiny** (当前模型品牌名): 项目完整名称，用户可能直接搜索
- **时间序列预测** (功能场景): 当前模型的核心应用场景
- **零样本预测** (技术特性): 当前模型的关键技术特点
- **基础模型** (技术特性): 当前模型的技术定位，标签中明确提及
- **时间序列基础模型** (技术特性): 标签中明确的技术分类，具有搜索价值
- **预训练模型** (技术特性): 当前模型的核心属性，标签中包含
- **分位数预测** (技术特性): 当前模型的独特预测方法

### unsloth/GLM-4.5-Air

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/GLM-4.5-Air

**关键词列表**:

- **GLM-4.5-Air** (当前模型品牌名): 从项目名称提取的当前模型名称
- **混合推理模型** (技术特性): GLM-4.5和GLM-4.5-Air均为混合推理模型，是当前模型的技术特性

### facebook/dinov2-giant

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-giant

**关键词列表**:

- **DINOv2-giant** (当前模型品牌名): 项目名称即模型品牌名，用户搜索时会直接使用
- **ViT** (技术特性): 模型采用视觉变换器（Vision Transformer）架构，是其核心技术特征
- **自监督视觉特征** (技术特性): 模型通过 DINOv2 的自监督方式学习视觉特征，用户常以此关键词检索
- **图像特征提取** (功能场景): 模型主要用于从图像中提取特征，可直接用于下游任务
- **CLS标记** (技术特性): 模型在序列开头使用 CLS 标记进行全图表征，是其独特设计
- **大规模视觉编码器** (技术特性): 模型在大规模图像数据上预训练，强调其规模与编码能力
- **无微调头** (技术特性): 模型不包含任何微调头部，适合作为特征提取器使用

### lllyasviel/control_v11p_sd15_inpaint

**URL**: https://ai.gitcode.com/hf_mirrors/lllyasviel/control_v11p_sd15_inpaint

**关键词列表**:

- **ControlNet-v1-1** (当前模型品牌名): 从项目名称 lllyasviel/control_v11p_sd15_inpaint 提取的核心模型名称，是用户搜索该特定版本时的直接关键词
- **image-to-image** (功能场景): 模型基于修复图像作为条件输入，属于图像到图像的控制生成，是技术用户搜索的精准术语
- **ControlNet** (当前模型品牌名): 模型的通用品牌名称，用户在搜索控制扩散模型时会直接使用该术语，具有高搜索量和辨识度
- **Stable-Diffusion-控制** (功能场景): 模型专为与Stable Diffusion结合使用而设计，用户搜索‘Stable Diffusion如何控制生成’时会使用该组合词

### zai-org/GLM-4.5V-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5V-FP8

**关键词列表**:

- **GLM-4.5V** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视觉语言模型** (功能场景): 当前模型属于视觉语言模型，是智能系统的关键基石
- **多模态感知** (技术特性): 当前模型在基础多模态感知之外增强推理能力
- **视频理解** (功能场景): 当前模型具备视频理解能力，包括长视频分割与事件识别
- **GUI任务** (功能场景): 当前模型能够处理GUI任务，如屏幕内容读取等
- **思考模式** (技术特性): 当前模型引入了思考模式开关，允许用户在快速响应与深度推理之间灵活平衡

### unsloth/cogito-v2-preview-llama-109B-MoE

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/cogito-v2-preview-llama-109B-MoE

**关键词列表**:

- **Cogito** (当前模型品牌名): 从项目名称提取的当前模型品牌名
- **109B-MoE** (参数规格): 当前模型主打的109B参数MoE规格，用户会搜
- **IDA训练** (技术特性): 迭代蒸馏与放大技术，模型独特卖点
- **1000万长上下文** (技术特性): 超长上下文支持，用户会直接用数字搜索
- **Unsloth量化** (部署工具): 项目自带Unsloth动态量化方案，部署关键词

### speechbrain/metricgan-plus-voicebank

**URL**: https://ai.gitcode.com/hf_mirrors/speechbrain/metricgan-plus-voicebank

**关键词列表**:

- **MetricGAN-plus** (当前模型品牌名): 从项目名称'speechbrain/metricgan-plus-voicebank'提取的当前模型核心名称，简化后保留主体标识
- **语音增强** (功能场景): README明确描述为'基于MetricGAN训练的语音增强模型'，是当前模型的核心应用场景
- **Voicebank** (技术特性): 项目名称及标签中包含的关键技术标识，与模型训练数据或架构相关
- **DEMAND** (技术特性): 标签中明确列出的技术相关标识，属于模型的技术特性范畴
- **audio-to-audio** (技术特性): 标签中标识的模型处理类型，体现音频到音频的技术转换特性
- **SpeechBrain** (技术特性): README及标签中强调的框架依赖，是模型实现的核心技术框架

### unslothai/1

**URL**: https://ai.gitcode.com/hf_mirrors/unslothai/1

**关键词列表**:

- **文本生成** (功能场景): 模型基于 Transformer，可用于生成自然语言文本，是主要使用场景
- **4-bit量化模型** (技术特性): Unsloth 系列以 4‑bit 量化技术著称，可显著降低显存占用
- **Safetensors格式** (技术特性): 模型文件采用 Safetensors 存储，提供安全高效的加载方式
- **轻量化模型** (技术特性): 通过 4‑bit 量化和高效实现，使模型在资源受限环境下仍能流畅运行

### impira/layoutlm-document-qa

**URL**: https://ai.gitcode.com/hf_mirrors/impira/layoutlm-document-qa

**关键词列表**:

- **layoutlm-document-qa** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索文档问答模型时会使用此完整名称
- **文档问答** (功能场景): 模型核心用途为文档问答（document-question-answering），是用户在中文场景下搜索AI文档处理工具时的高频意图词
- **LayoutLM** (当前模型品牌名): 模型基于LayoutLM架构，该名称是行业公认的多模态文档理解模型系列，用户会直接搜索此架构名
- **发票识别** (功能场景): 示例中使用发票模板进行问答，'发票识别'是文档问答在财务场景下的典型应用，用户常以此类具体场景搜索
- **财务文档分析** (功能场景): 模型可处理发票、损益表等财务文档，'财务文档分析'是其精准应用场景，区别于通用文档处理

### vidore/colSmol-256M

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colSmol-256M

**关键词列表**:

- **colSmol-256M** (当前模型品牌名): 直接取自项目名称的核心标识符，代表当前模型唯一身份
- **视觉文档检索** (功能场景): README明确说明该模型的核心用途为通过视觉特征高效索引文档
- **ColBERT** (技术特性): 模型采用的核心策略，论文提出的创新架构，具有技术辨识度
- **LoRA** (技术特性): 模型训练采用的关键参数优化技术，属于当前热门PEFT方法

### cross-encoder/ms-marco-MiniLM-L6-v2

**URL**: https://ai.gitcode.com/hf_mirrors/cross-encoder/ms-marco-MiniLM-L6-v2

**关键词列表**:

- **ms-marco-MiniLM-L6-v2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **信息检索** (功能场景): 该模型可用于给定查询对段落进行编码并排序的信息检索场景
- **文本排序** (功能场景): 从标签可知该模型具备文本排序功能
- **SentenceTransformers** (部署工具): README中提及使用该模型在安装SentenceTransformers时使用方式简单，属于部署相关工具
- **跨编码器** (技术特性): 项目名称表明这是一个Cross - Encoder（跨编码器）模型，是其技术特性

### Qwen/Qwen3-1.7B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B-Base

**关键词列表**:

- **Qwen3** (当前模型品牌名): 从项目名称提取的当前模型系列名称
- **1.7B参数** (参数规格): 当前模型的参数规格

### Gen-Verse/MMaDA-8B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Gen-Verse/MMaDA-8B-Base

**关键词列表**:

- **MMaDA** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **8B参数** (参数规格): 模型规模为 8B 参数，用户常以参数规模搜索模型
- **多模态理解** (功能场景): 模型设计目标之一是提升多模态理解能力，用户会据此搜索
- **混合长链思维** (技术特性): 模型创新的跨模态 CoT 微调策略，属于独特技术特性
- **UniGRPO** (技术特性): 模型专用的统一强化学习算法名称，具备辨识度
- **统一扩散架构** (技术特性): 模型采用的共享概率建模与模态无关的扩散框架

### facebook/VGGT-1B

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/VGGT-1B

**关键词列表**:

- **VGGT** (当前模型品牌名): 从项目名称 'facebook/VGGT-1B' 中提取的核心模型名称，符合简化规则，去除了版本号'1B'，保留品牌标识
- **Image-to-3D** (功能场景): 模型核心功能是将图像直接转换为3D属性（相机参数、点云、深度图等），是用户搜索3D重建类模型时的明确意图关键词
- **视觉几何** (技术特性): 模型名称中核心术语，代表其基于视觉几何先验的Transformer架构，是区别于通用3D生成模型的独特技术标签
- **3D点轨迹** (功能场景): 模型能推断3D点轨迹，是其区别于普通NeRF或3D高斯溅射模型的专属能力，用户搜索动态3D重建时可能使用该词
- **相机外参** (功能场景): 模型直接输出相机外参（位姿），是其在视觉定位、AR/VR领域的重要应用场景，属于专业但搜索意图明确的关键词
- **相机内参** (功能场景): 与相机外参并列，是模型输出的关键3D属性之一，常被计算机视觉研究者用于相机标定相关搜索
- **点云图** (功能场景): 模型输出的核心3D表示之一，是3D感知领域高频搜索词，区别于普通图像生成模型
- **CVPR-2025** (技术特性): 模型发表于顶级会议CVPR 2025，代表前沿性，研究者常通过会议+年份搜索最新模型，具有强区分度且非通用词

### google/owlv2-base-patch16

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlv2-base-patch16

**关键词列表**:

- **OWLv2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **零样本文本条件目标检测** (功能场景): 当前模型的主要功能应用场景
- **Ollama部署** (部署工具): 当前模型可能的部署方式，用户会搜索相关内容
- **ViT-B16** (技术特性): 当前模型图像编码器采用的Transformer架构，具有区分度

### microsoft/tapex-large

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-large

**关键词列表**:

- **TAPEX** (当前模型品牌名): 从项目名称microsoft/tapex-large提取的当前模型名称
- **表格推理** (功能场景): 当前模型核心功能，赋予表格推理能力
- **神经SQL执行器** (技术特性): 当前模型通过学习神经SQL执行器实现预训练的独特技术
- **表格预训练** (技术特性): 当前模型基于Table Pre-training via Execution的核心技术
- **table-question-answering** (功能场景): 标签中明确的当前模型应用场景，表格问答任务
- **BART架构** (技术特性): 当前模型采用的基础架构，编码器-编码器变压器结构
- **微调** (部署工具): 当前模型明确支持的下游任务使用方式

### facebook/detr-resnet-50

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/detr-resnet-50

**关键词列表**:

- **DETR-ResNet-50** (当前模型品牌名): 从项目名称提取的当前模型名称
- **端到端目标检测** (功能场景): 当前模型的主要功能和应用场景
- **对象查询机制** (技术特性): 当前模型的核心技术特性之一
- **COCO数据集** (数据集): 当前模型训练使用的数据集
- **object-detection** (功能场景): 当前模型的功能场景英文描述

### microsoft/tapex-large-finetuned-wikisql

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-large-finetuned-wikisql

**关键词列表**:

- **wikisql** (功能场景): 模型在WikiSQL数据集上微调，该名称是领域内公认的基准数据集，用户会直接搜索 'wikisql 模型' 或 'wikisql 表格问答'
- **neural-SQL-executor** (技术特性): 模型核心创新点，用户搜索 '神经SQL执行器' 或 'AI执行SQL' 时可能使用该术语，具有技术独特性
- **arxiv2107.07653** (技术特性): 论文ID是学术用户精准查找该模型的唯一入口，常被用于文献检索，具有高搜索价值

### google/tapas-tiny-finetuned-sqa

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-tiny-finetuned-sqa

**关键词列表**:

- **TAPAS** (当前模型品牌名): 模型名称直接来源于项目名 google/tapas-tiny-finetuned-sqa
- **表格问答** (功能场景): 模型专注于表格（Table）上的序列问答（SQA）任务，属于表格问答场景
- **相对位置嵌入** (技术特性): 模型使用相对位置嵌入技术对表格单元格进行位置索引重置
- **位置重置** (技术特性): 默认版本在每个表格单元格上执行位置重置，是模型的核心特性之一
- **掩码语言建模** (技术特性): 模型在中间预训练阶段采用掩码语言建模（MLM）进行预训练
- **中间预训练** (技术特性): 在微调前模型经历了作者称为“中间预训练”的额外训练步骤
- **tiny模型** (参数规格): 模型体积极小，属于 TAPAS 系列的 tiny 规格，适合资源受限环境

### tencent/Hunyuan3D-1

**URL**: https://ai.gitcode.com/hf_mirrors/tencent/Hunyuan3D-1

**关键词列表**:

- **混元** (当前模型品牌名): 项目名称Hunyuan3D-1，按国产映射规则提取“混元”
- **腾讯大模型** (当前模型品牌名): Hunyuan系列归属腾讯，用户搜索“腾讯大模型”可直接定位
- **文生3D** (功能场景): README明确支持text-to-3D生成，用户高频搜索词
- **图生3D** (功能场景): README新增image_to_3d demo，用户会搜“图生3D”
- **两阶段生成** (技术特性): README核心卖点“two-stage approach”，用户搜技术方案时常用

### ibm-granite/granite-timeseries-ttm-r2

**URL**: https://ai.gitcode.com/hf_mirrors/ibm-granite/granite-timeseries-ttm-r2

**关键词列表**:

- **Granite-TimeSeries-TTM** (当前模型品牌名): 从项目名称提取的当前模型核心名称，简化自ibm-granite/granite-timeseries-ttm-r2
- **TTM** (当前模型品牌名): 模型名称TinyTimeMixers的缩写，README中高频使用的简称
- **少样本预测** (技术特性): 当前模型的关键技术特性，支持仅需5%训练数据进行微调
- **预训练时间序列模型** (技术特性): 当前模型的核心属性，基于公开时间序列数据预训练的模型

### THUDM/GLM-4-32B-Base-0414

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4-32B-Base-0414

**关键词列表**:

- **反思模型** (技术特性): GLM-Z1-Rumination-32B-0414 是具备'反思能力'的模型，对标OpenAI Deep Research，属于独特技术标签
- **报告生成** (功能场景): 模型在报告生成任务中表现良好，是明确的生产力应用场景，用户会针对性搜索

### Qwen/QwQ-32B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/QwQ-32B-AWQ

**关键词列表**:

- **QwQ-32B** (当前模型品牌名): 从项目名称提取的简化模型名称
- **因果语言模型** (技术特性): 模型属于因果（自回归）语言模型，适用于生成式任务
- **长上下文推理** (功能场景): 模型支持完整 131,072 token 上下文，适合长文档或对话推理

### openai/imagegpt-small

**URL**: https://ai.gitcode.com/hf_mirrors/openai/imagegpt-small

**关键词列表**:

- **ImageGPT-small** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像生成** (功能场景): 当前模型可用于执行（非）条件图像生成，是主要功能场景
- **特征提取** (功能场景): 当前模型能够提取下游任务所需的特征，属于功能场景
- **ImageNet-21k** (数据集): 当前模型在ImageNet-21k上进行预训练，是模型训练的重要数据集信息，用户可能会搜索
- **自监督学习** (技术特性): 该模型通过自监督方式在大量图像上进行预训练，是其技术特性
- **32x32分辨率** (技术参数): 模型在ImageNet ILSVRC 2012数据集上以32x32分辨率进行预训练，是模型训练的特定技术参数，有一定区分度

### Bllossom/llama-3.2-Korean-Bllossom-AICA-5B

**URL**: https://ai.gitcode.com/hf_mirrors/Bllossom/llama-3.2-Korean-Bllossom-AICA-5B

**关键词列表**:

- **Bllossom-AICA-5B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **韩国语-英语语言模型** (功能场景): 当前模型的语言处理能力描述
- **视觉-语言双向模型** (技术特性): 当前模型支持视觉和语言双向处理的技术特性
- **韩国语OCR优化** (功能场景): 当前模型在韩国语OCR方面的优化功能
- **外部知识选择性推理** (技术特性): 当前模型具备的外部知识选择性推理能力

### Qwen/Qwen3-235B-A22B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-GGUF

**关键词列表**:

- **思维模式切换** (技术特性): 模型独创支持单模型内无缝切换思维模式与非思维模式，为独家功能，高度差异化，符合用户搜索意图
- **235B参数** (参数规格): 2350亿参数属于超大规模主流规格，用户常搜索'XXXB参数'类关键词定位大模型，且未被高频词排除

### Qwen/Qwen3-8B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-8B-AWQ

**关键词列表**:

- **Qwen3-8B** (当前模型品牌名): 从项目名称提取的当前模型核心名称（简化版本号）
- **数学推理** (功能场景): 当前模型在思维模式下的核心应用场景之一
- **代码生成** (功能场景): 当前模型增强的核心能力之一
- **智能体功能** (技术特性): 当前模型具备的专业智能体能力，支持外部工具集成
- **AWQ量化** (部署工具): 当前模型采用的AWQ 4-bit量化方案，属于部署相关技术特性

### deepset/xlm-roberta-large-squad2

**URL**: https://ai.gitcode.com/hf_mirrors/deepset/xlm-roberta-large-squad2

**关键词列表**:

- **XLM-RoBERTa** (当前模型品牌名): 模型名称直接来源于项目名称 deepset/xlm-roberta-large-squad2
- **Extractive-QA** (功能场景): 模型用于抽取式问答（Extractive Question Answering）任务
- **Haystack** (部署工具): README 中明确说明模型可在 Haystack 框架中直接使用
- **Multilingual** (技术特性): 模型基于 XLM‑RoBERTa，具备多语言（跨语言）处理能力
- **SQuAD2-微调** (技术特性): 模型在 SQuAD 2.0 数据集上进行微调，提升了对不可回答问题的识别
- **550M-参数** (参数规格): XLM‑RoBERTa‑large 约拥有 550 百万参数，属于大规模语言模型

### pcoloc/autotrain-dragino-7-7-1860763606

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-dragino-7-7-1860763606

**关键词列表**:

- **pcolocautotrain-dragino-7-7** (当前模型品牌名): 从项目名称提取的当前模型名称
- **单列回归** (功能场景): 当前模型的功能/用途，从问题类型可知

### google/pegasus-xsum

**URL**: https://ai.gitcode.com/hf_mirrors/google/pegasus-xsum

**关键词列表**:

- **pegasus** (当前模型品牌名): 从项目名称google/pegasus-xsum提取的模型核心名称，符合模型名称简化规则（如SD-XL、DeepSeek-R1），避免冗余后缀
- **摘要** (功能场景): 任务明确标注为摘要，用户搜索AI模型时常用中文关键词'摘要'，指向文本摘要功能场景，符合'文生图'等示例格式
- **JAX** (技术特性): 标签中列出JAX，作为模型可能支持的框架，用户搜索时可能关联'JAX摘要模型'，符合技术特性维度（如规则示例中的'Transformer'）

### pengzhendong/chinese-hubert-large

**URL**: https://ai.gitcode.com/hf_mirrors/pengzhendong/chinese-hubert-large

**关键词列表**:

- **chinese-hubert-large** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **音频预训练** (技术特性): 当前模型仅通过音频数据进行预训练的技术特性
- **WenetsSpeech-L子集** (技术特性): 当前模型基于1万小时WenetsSpeech L子集预训练的技术特性
- **微调训练** (技术特性): 当前模型需使用带文本标注数据进行微调训练的技术特性
- **Wav2Vec2FeatureExtractor** (技术特性): 当前模型使用的特征提取工具
- **HubertModel** (技术特性): 当前模型的核心模型类

### IIC/DocOwl2

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/DocOwl2

**关键词列表**:

- **DocOwl2** (当前模型品牌名): 从项目名称'IIC/DocOwl2'直接提取的当前模型简称，符合品牌名简化规则（去前缀'IIC/'，保留核心名称）
- **免OCR文档理解** (功能场景): 模型核心功能是‘免OCR’的多页文档理解，这是区别于其他文档AI模型的独特卖点，用户会直接搜索‘免OCR 文档’类关键词
- **高分辨率文档压缩器** (技术特性): 模型独有的技术模块名称，具有高度区分性，是实现高效编码的核心创新，符合‘技术特性’维度且非通用术语
- **多页文档理解** (功能场景): 模型专为多页文档设计，这是其明确的应用场景，用户搜索‘多页文档 AI’‘文档理解模型’时会命中此词
- **324标记编码** (技术特性): 模型每页仅用324个标记编码，是其高效性的关键量化特征，属于用户可搜索的、具象的技术指标（非抽象参数）
- **图像-文本对话** (功能场景): 标签中‘Image-Text-to-Text’的自然中文表达，描述模型输入为图像+文本、输出为文本的对话能力，区别于纯文本或纯图像模型

### pengzhendong/chinese-hubert-base

**URL**: https://ai.gitcode.com/hf_mirrors/pengzhendong/chinese-hubert-base

**关键词列表**:

- **Chinese-Hubert** (当前模型品牌名): 项目名称中包含 chinese‑hubert‑base，提取为简洁的模型品牌名
- **WenetSpeech预训练** (技术特性): 模型基于 1 万小时 WenetSpeech L 子集进行预训练
- **Hubert模型** (技术特性): 模型实现为 HubertModel，属于 Hubert 系列的预训练语音模型
- **Wav2Vec2特征提取器** (技术特性): 示例代码使用 Wav2Vec2FeatureExtractor 进行音频特征提取
- **无分词器模型** (技术特性): README 明确说明模型未配备分词器，仅针对音频数据预训练
- **中文语音预训练** (功能场景): 模型针对中文语音数据进行大规模预训练，适用于中文语音任务

### Qwen/Qwen3-14B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-AWQ

**关键词列表**:

- **思维模式** (技术特性): Qwen3独家支持思维模式切换，用户会搜此功能
- **智能体** (功能场景): 官方强调专业级智能体能力，用户搜智能体找可调用工具的模型

### AI-ModelScope/TRELLIS-image-large

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/TRELLIS-image-large

**关键词列表**:

- **TRELLIS** (当前模型品牌名): 从项目名称AI-ModelScope/TRELLIS-image-large简化提取的当前模型名称
- **3D生成模型** (功能场景): README中描述的当前模型核心功能
- **结构化3D潜变量** (技术特性): 论文提出的当前模型核心技术特性

### IIC/QwenLong-CPRS-7B

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/QwenLong-CPRS-7B

**关键词列表**:

- **QwenLong-CPRS-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **长上下文处理** (功能场景): 该模型通过查询感知的多粒度压缩来优化长上下文处理
- **上下文压缩模型** (功能场景): 该模型是专为显式长上下文优化设计的上下文压缩模型

### Xenova/discogs-maest-30s-pw-73e-ts

**URL**: https://ai.gitcode.com/hf_mirrors/Xenova/discogs-maest-30s-pw-73e-ts

**关键词列表**:

- **discogs-maest-30s-pw-73e-ts** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，是用户搜索该特定音乐分析模型的精准关键词
- **ONNX** (部署工具): 模型提供ONNX权重版本，是网页端部署的核心技术路径，用户会搜索'ONNX模型'来寻找可浏览器运行的AI模型
- **Transformers.js** (部署工具): 模型明确兼容Transformers.js，是前端AI部署的关键框架，用户会搜索此组合词寻找可运行在浏览器的音乐分析模型
- **音乐分析** (功能场景): Discogs是音乐数据库，MAEST是音乐结构分析任务，该模型用于自动识别音乐结构（如段落、节拍），用户会搜索'音乐分析AI'等词
- **网页端部署** (部署工具): README强调适配网页端，这是模型的核心价值点，用户会搜索'网页端AI模型'或'浏览器运行音乐模型'等意图词

### PKU-Alignment/beaver-7b-v1.0-cost

**URL**: https://ai.gitcode.com/hf_mirrors/PKU-Alignment/beaver-7b-v1.0-cost

**关键词列表**:

- **beaver-7b-v1.0-cost** (当前模型品牌名): 从项目URL和名称中提取的当前模型名称
- **PKU-SafeRLHF** (技术特性): 当前模型基于PKU-SafeRLHF数据集训练，是其核心数据集特性
- **安全无害** (功能场景): 当前模型帮助Beaver模型变得更加安全无害，是其应用场景
- **自回归语言模型** (技术特性): 当前模型是基于Transformer架构的自回归语言模型
- **ai-safety** (功能场景): 当前模型与AI安全相关，是其应用场景之一

### openbmb/MiniCPM-V-4_5

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-V-4_5

**关键词列表**:

- **高帧率视频理解** (功能场景): 模型支持高帧率视频的理解与推理，是用户寻找视频理解模型时的关键需求
- **单图多图支持** (功能场景): 模型能够同时处理单张图片和多张图片，满足用户对图像理解多样性的搜索需求
- **视频token压缩** (技术特性): 采用 96 倍视频 token 压缩率的独特技术，用户会搜索此类高效视频处理特性
- **快慢思考模式** (技术特性): 模型提供可控的快速思考与深度思考两种模式，属于独特的推理控制特性
- **3D-Resampler** (技术特性): 全新的图像与视频统一 3D-Resampler 是模型的核心创新点，用户会以此关键词检索

### zai-org/CogVideoX1.5-5B-I2V

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B-I2V

**关键词列表**:

- **CogVideoX** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **I2V** (功能场景): 当前模型的核心功能（图像转视频）
- **视频生成模型** (功能场景): 当前模型的主要应用场景
- **diffusers部署** (部署工具): 当前模型使用的部署库
- **显存优化** (技术特性): 当前模型的技术特性
- **1360768分辨率** (技术特性): 当前模型支持的视频分辨率

### stepfun-ai/Step-Audio-2-mini

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/Step-Audio-2-mini

**关键词列表**:

- **Step-Audio-2** (当前模型品牌名): 从项目名称 stepfun-ai/Step-Audio-2-mini 提取的核心模型品牌名，符合简化规则（去掉'-mini'后缀，保留主品牌）
- **语音理解** (功能场景): README中'Advanced Speech and Audio Understanding'的精准中文提炼，区别于通用'语音识别'，更具模型特异性
- **工具调用** (技术特性): README提及'Tool Calling'，是当前模型区别于普通ASR模型的关键能力，用户搜索AI工具集成时会用此词
- **多模态RAG** (技术特性): README中'Multimodal RAG'是模型独特架构特性，非通用术语，具有高区分度，符合用户搜索AI知识增强场景
- **非语音信息理解** (功能场景): README中'para-linguistic and non-vocal information'的精准中文表达，属于模型专属能力，搜索者极少使用其他词描述

### stepfun-ai/StepFun-Formalizer-32B

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/StepFun-Formalizer-32B

**关键词列表**:

- **StepFun-Formalizer** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自动形式化** (功能场景): 当前模型的主要功能，即把自然语言数学问题转换为Lean 4形式化语句
- **Lean-4形式化语句** (功能场景): 当前模型转换的目标形式，体现了其特定的应用场景
- **HuggingFace下载** (部署工具): 当前模型可通过HuggingFace进行下载，是重要的获取途径
- **知识推理融合** (技术特性): 当前模型通过融合知识推理来释放自动形式化潜力，是其技术特点

### zai-org/CogVideoX1.5-5B

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B

**关键词列表**:

- **diffusers库** (部署工具): 当前模型明确提到的推理部署工具，用户可能搜索相关部署方案

### zai-org/glm-edge-4b-chat

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-edge-4b-chat

**关键词列表**:

- **GLM-Edge-4B-Chat** (当前模型品牌名): 从项目名称直接提取的当前模型全称，符合用户搜索AI模型时的精确命名习惯

### zai-org/cogagent-chat-hf

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/cogagent-chat-hf

**关键词列表**:

- **CogAgent** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **视觉多轮对话** (功能场景): 模型支持视觉多轮对话，属于典型使用场景
- **视觉定位** (功能场景): 模型具备视觉定位能力，用户常以此关键词寻找相应模型

### ByteDance-Seed/M3-Agent-Control

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/M3-Agent-Control

**关键词列表**:

- **豆包** (当前模型品牌名): 项目名称为ByteDance-Seed，根据国产大模型映射规则，应提取为'豆包'
- **字节大模型** (当前模型品牌名): ByteDance-Seed属于字节跳动大模型系列，'字节大模型'是用户搜索的通用品牌词
- **M3-Agent-Control** (当前模型品牌名): 项目名称核心部分，是该模型的唯一标识符，用户可能直接搜索此完整名称
- **智能代理** (功能场景): 模型名称含'Agent-Control'，表明其用于构建智能代理系统，符合用户搜索意图
- **多步决策** (技术特性): M3-Agent-Control的核心能力是支持复杂任务的多步推理与控制，属于独特技术特征
- **AI控制框架** (功能场景): 模型用于控制AI代理行为，'AI控制框架'是用户在寻找代理系统架构时的高频搜索词

### ByteDance-Seed/M3-Agent-Memorization

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/M3-Agent-Memorization

**关键词列表**:

- **M3-Agent** (当前模型品牌名): 从项目名称提取的简化模型名称
- **长期记忆** (功能场景): 模型聚焦于提升智能体的长期记忆能力
- **记忆增强** (功能场景): 模型的核心目标是对智能体记忆进行增强
- **Agent记忆机制** (技术特性): 模型采用专门的 Agent 记忆机制实现信息存取
- **长时依赖建模** (技术特性): 模型能够有效捕获并建模长时依赖关系

### zai-org/glm-4-9b-chat-1m

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-1m

**关键词列表**:

- **1M上下文** (技术特性): 支持百万级 token 长文本推理，极具区分度
- **长文本推理** (功能场景): 用户明确搜索超长文档理解与问答场景
- **Function-Call** (功能场景): 模型内置工具调用能力，开发者高频检索
- **HuggingFace推理** (部署工具): 官方示例基于 transformers 库，用户搜索部署方案

### zai-org/GLM-Z1-Rumination-32B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-Z1-Rumination-32B-0414

**关键词列表**:

- **GLM-Z1-Rumination** (当前模型品牌名): 从项目名称提取的当前模型名称
- **深度思考能力** (技术特性): 当前模型具备深度思考能力，是核心特性
- **研究型写作** (功能场景): 当前模型在研究型写作上表现出显著提升，是应用场景
- **复杂检索任务** (功能场景): 当前模型在复杂检索任务上表现出色，是应用场景

### unsloth/gpt-oss-120b-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gpt-oss-120b-bnb-4bit

**关键词列表**:

- **gpt-oss** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **gpt-oss-120b** (当前模型品牌名): 项目名称中的完整模型标识
- **unsloth** (当前模型品牌名): 项目归属的品牌标识，标签中明确提及
- **Text-Generation** (功能场景): 标签中明确标注的核心功能场景
- **Apache-License-2.0** (技术特性): 模型的核心许可特性，具有商业部署优势
- **完整思维链** (技术特性): README中强调的核心技术特性，可访问推理过程
- **可配置推理力度** (技术特性): 模型独特的技术优势，支持根据需求调整推理强度

### openai-community/gpt2

**URL**: https://ai.gitcode.com/hf_mirrors/openai-community/gpt2

**关键词列表**:

- **GPT-2** (当前模型品牌名): 项目名称直接为openai-community/gpt2，模型名称为GPT-2，是用户搜索该模型时最核心的关键词
- **1.24亿参数** (参数规格): README明确提及'这是GPT-2的最小版本，拥有1.24亿个参数'，属于主流小参数规模，用户会用于对比模型大小

### zai-org/glm-4-9b-chat-1m-hf

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-1m-hf

**关键词列表**:

- **代码执行** (功能场景): README中表明模型具备代码执行的高级功能，属于功能场景范畴
- **网页浏览** (功能场景): README中提到模型具备网页浏览的高级功能，是模型的功能应用场景

### sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

**URL**: https://ai.gitcode.com/hf_mirrors/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

**关键词列表**:

- **MiniLM** (当前模型品牌名): 模型名称中包含 MiniLM，简化后作为品牌名
- **paraphrase-multilingual-MiniLM** (当前模型品牌名): 完整模型标识，突出多语言改写能力
- **句子嵌入** (功能场景): 模型将句子映射为向量，可用于句子嵌入任务
- **语义搜索** (功能场景): 模型输出的向量可直接用于语义检索
- **句子相似度** (功能场景): 通过向量比较实现句子相似度计算
- **384维向量** (技术特性): 模型输出固定的 384 维稠密向量，具备明确的维度特征
- **多语言句子检索** (功能场景): 模型支持多语言，适用于跨语言句子检索场景

### google-t5/t5-base

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-base

**关键词列表**:

- **T5-Base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本到文本迁移转换器** (技术特性): 当前模型的核心技术架构描述
- **机器翻译** (功能场景): 当前模型的应用场景之一
- **文档摘要** (功能场景): 当前模型的应用场景之一
- **问答系统** (功能场景): 当前模型的应用场景之一
- **情感分析** (功能场景): 当前模型支持的分类任务场景
- **2.2亿参数** (参数规格): 当前模型的参数规格描述

### facebook/musicgen-small

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/musicgen-small

**关键词列表**:

- **MusicGen** (当前模型品牌名): 从项目名称 'facebook/musicgen-small' 提取的核心模型品牌名，用户搜索音乐生成模型时会直接使用此名称
- **文生音乐** (功能场景): 模型核心功能是根据文本描述生成音乐，符合用户搜索意图（如'文生音乐工具'），且为中文场景高频搜索词，区别于通用'文生图'
- **EnCodec标记器** (技术特性): 模型使用32kHz EnCodec标记器作为独特技术组件，是区别于MusicLM等模型的关键实现细节，用户可能搜索此术语研究技术方案
- **4码本生成** (技术特性): 模型一次性生成4个码本，是其并行预测架构的核心特征，技术文档中常被提及，具有明确指向性
- **300M参数** (参数规格): 模型明确标注为'小型 - 300M'，属于主流小参数规模（非极端细节），用户会搜索'300M音乐模型'进行轻量化部署对比
- **文本到音频** (功能场景): README中使用'Text-to-Audio (TTA)'作为核心流程，中文用户常搜索'文本到音频生成'，该词精准对应模型用途且非泛用词
- **MusicGen小型** (当前模型品牌名): 项目明确区分'小型'检查点，用户在搜索时会使用'MusicGen小型'来区别于中型/大型版本，是实际使用中的精准搜索词

### deepseek-ai/DeepSeek-R1-Distill-Qwen-14B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B

**关键词列表**:

- **DeepSeek-R1** (当前模型品牌名): 从项目全称 DeepSeek-R1-Distill-Qwen-14B 中提取的核心模型名称
- **链式思维** (技术特性): README 中强调模型具备链式思维（CoT）能力，是核心推理技术
- **自我验证** (技术特性): 模型能够进行自我验证与反思，这是其独特的推理特性
- **代码推理** (功能场景): 模型在代码理解与生成方面表现优秀，适用于代码推理使用
- **蒸馏模型** (技术特性): 项目公开了基于蒸馏的模型版本，这是模型的核心技术手段

### deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

**关键词列表**:

- **反思能力** (技术特性): 当前模型通过RL训练获得的核心推理能力
- **强化学习训练** (技术特性): 当前模型无需SFT预处理的核心训练方式
- **推理模型** (功能场景): 当前模型的核心功能定位
- **提炼模型** (技术特性): 当前模型的官方分类属性

### openai/whisper-medium.en

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-medium.en

**关键词列表**:

- **Whisper** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自动语音识别** (功能场景): 当前模型的主要功能场景
- **语音翻译** (功能场景): 当前模型的功能场景之一
- **ASR** (功能场景): 自动语音识别的英文缩写，也是当前模型功能体现

### deepseek-ai/DeepSeek-V3

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3

**关键词列表**:

- **DeepSeek-V3** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，用户搜索AI模型时会直接输入此名称
- **671B参数** (参数规格): 6710亿参数属于超大规模主流规格，用户常搜索‘600B以上模型’或‘671B参数’来定位顶级开源模型
- **多标记预测** (技术特性): 模型独创的多标记预测（MTP）训练目标，是提升性能与推理加速的核心创新，具有唯一性且用户会搜索该术语研究训练方法
- **无辅助损失负载平衡** (技术特性): DeepSeek-V3首创的负载平衡策略，无辅助损失设计是其训练稳定性和效率的关键，属于高区分度技术术语
- **FP8训练** (技术特性): 模型首次在超大规模MoE上验证FP8混合精度训练可行性，是训练效率突破的标志性技术，用户会搜索‘FP8大模型训练’
- **DeepSeekMoE** (技术特性): 模型专用的MoE模块名称，是DeepSeek系列自研架构的标识，具有品牌技术辨识度，用户会搜索该术语了解其设计
- **MLA注意力** (技术特性): 多头潜在注意力（MLA）是DeepSeek-V3采用的高效注意力机制，区别于标准Attention，是其推理效率的核心支撑技术

### unsloth/embeddinggemma-300m-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-GGUF

**关键词列表**:

- **EmbeddingGemma** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本嵌入** (功能场景): 用户搜索生成文本向量的核心需求
- **GGUF量化** (部署工具): 项目自带GGUF格式，方便本地轻量部署
- **Matryoshka表示** (技术特性): 支持768/512/256/128维灵活截断的独特技术
- **Sentence-Transformers** (部署工具): 官方推荐搭配使用的流行嵌入框架

### mixedbread-ai/mxbai-embed-large-v1

**URL**: https://ai.gitcode.com/hf_mirrors/mixedbread-ai/mxbai-embed-large-v1

**关键词列表**:

- **mxbai-embed-large-v1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **轻量型句子嵌入模型** (功能场景): 当前模型的功能描述，用户可能搜索此类模型
- **Matryoshka-Representation-Learning** (技术特性): 当前模型支持的技术，具有独特性，用户可能搜索
- **binary-quantization** (技术特性): 当前模型支持的技术特性，用户可能对此感兴趣

### deepseek-ai/DeepSeek-Coder-V2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Base

**关键词列表**:

- **DeepSeek-Coder-V2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **16B参数** (参数规格): 当前模型的总参数量规格
- **236B参数** (参数规格): 当前模型的总参数量规格

### deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

**关键词列表**:

- **DeepSeek-Coder-V2-Lite** (当前模型品牌名): 从项目名称直接提取的当前模型完整品牌名，符合简化规则（保留核心标识，去除非必要后缀）
- **128K上下文** (技术特性): 128K上下文长度是模型关键能力指标，开发者常搜索长上下文代码模型，且未被高频词列表禁止
- **338种编程语言** (功能场景): 支持338种语言是该模型在代码领域的独特优势，开发者会针对性搜索多语言支持的AI编码工具

### deepseek-ai/deepseek-vl2-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/deepseek-vl2-tiny

**关键词列表**:

- **DeepSeek-VL2** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **VL2-Tiny** (当前模型品牌名): 模型的具体变体名称，标识 Tiny 规格
- **光学字符识别** (功能场景): 模型能够进行 OCR（光学字符识别），是重要的应用场景
- **10B参数** (参数规格): 模型拥有约 10 B（10 亿）激活参数，是其规模标识

### deepseek-ai/deepseek-vl2

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/deepseek-vl2

**关键词列表**:

- **DeepSeek-VL2-Tiny** (当前模型品牌名): 当前模型系列的变体名称，是当前模型相关内容
- **DeepSeek-VL2-Small** (当前模型品牌名): 当前模型系列的变体名称，是当前模型相关内容

### nlpaueb/legal-bert-base-uncased

**URL**: https://ai.gitcode.com/hf_mirrors/nlpaueb/legal-bert-base-uncased

**关键词列表**:

- **Legal-BERT** (当前模型品牌名): 项目名称中直接包含的模型品牌名称
- **法律自然语言处理** (功能场景): 模型专注于法律领域的自然语言处理任务
- **合同文本分析** (功能场景): 模型提供针对合同（Contracts）子领域的专门变体
- **欧盟立法语料** (数据来源): 预训练语料中包含大量 EURLEX 欧盟立法文件
- **案例法预训练** (技术特性): 模型使用欧洲法院、欧洲人权法院等案例法进行预训练
- **轻量级BERT** (技术特性): 提供仅为 BERT‑BASE 大小 33% 的轻量级模型，适合资源受限环境
- **法律文本预训练** (功能场景): 模型专为法律文本（立法、判例、合同）进行大规模预训练

### jonathandinu/face-parsing

**URL**: https://ai.gitcode.com/hf_mirrors/jonathandinu/face-parsing

**关键词列表**:

- **face-parsing** (当前模型品牌名): 项目名称直接为jonathandinu/face-parsing，是当前模型的唯一标识名称，用户搜索面部解析模型时会直接使用该术语
- **图像分割** (功能场景): 模型用于语义分割面部区域，是用户在AI图像处理领域搜索此类任务时的核心关键词，且未被列入强制排除词
- **CelebAMask-HQ** (功能场景): 模型训练所用的专属数据集，是该模型区别于其他面部解析模型的关键标识，用户会搜索'CelebAMask-HQ 模型'来寻找高质量人脸分割方案
- **Segformer** (技术特性): 模型基于Segformer架构（nvidia/mit-b5是其变体），属于当前模型的核心技术骨架，且未被列为高频排除词（排除的是'Transformer'泛称）
- **语义分割** (技术特性): 模型执行的具体任务类型，是计算机视觉领域高频搜索词，但未被列为强制排除词，且精准描述模型能力
- **面部解析** (功能场景): 中文用户搜索该模型最可能使用的自然语言关键词，直接对应模型名称和功能，具有明确搜索意图

### audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim

**URL**: https://ai.gitcode.com/hf_mirrors/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim

**关键词列表**:

- **audeeringwav2vec2-large-robust-12-ft-emotion-msp-dim** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **语音情感识别** (功能场景): 当前模型的核心功能，用于识别语音中的情感
- **emotion-recognition** (功能场景): 当前模型的核心功能英文关键词，符合用户搜索习惯
- **wav2vec2** (技术特性): 当前模型基于wav2vec2架构，是其核心技术特性
- **speech** (技术特性): 当前模型处理语音数据的技术特性关键词
- **audio** (技术特性): 当前模型处理音频数据的技术特性关键词
- **msp-podcast** (技术特性): 当前模型训练所使用的数据集，是其独特技术标识
- **激发度-支配度-效价** (功能场景): 当前模型输出的情感维度指标，体现其功能特点

### deepseek-ai/DeepSeek-Prover-V1.5-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V1.5-Base

**关键词列表**:

- **DeepSeek-Prover-V1.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **强化学习** (技术特性): 当前模型通过从证明助手反馈中学习（RLPAF），强化学习是核心技术特性
- **蒙特卡洛树搜索** (技术特性): 当前模型提出了RMaxTS，一种蒙特卡洛树搜索的变种，是重要技术特性
- **形式化数学语言** (技术特性): 当前模型专注于形式化数学语言，是模型训练和推理的关键特性

### deepseek-ai/DeepSeek-R1-Distill-Llama-8B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Llama-8B

**关键词列表**:

- **强化学习推理** (技术特性): 模型核心训练方式为‘大规模强化学习（RL）直接应用于基础模型’，是区别于 SFT 模型的关键技术标签
- **无监督微调** (技术特性): 模型训练无需监督微调（SFT），这是 DeepSeek-R1-Zero 的突破性设计，用户会搜索‘无SFT模型’这类关键词
- **冷启动数据** (技术特性): DeepSeek-R1 引入冷启动数据解决 R1-Zero 的缺陷，是其架构创新点，具有独特性且未被高频词覆盖

### deepseek-ai/DeepSeek-V3-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3-Base

**关键词列表**:

- **多头潜伏注意力** (技术特性): 当前模型采用的创新注意力机制
- **无辅助损失负载均衡** (技术特性): 当前模型开创性的负载均衡策略

### deepseek-ai/DeepSeek-R1-Zero

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Zero

**关键词列表**:

- **DeepSeek-R1-Zero** (当前模型品牌名): 项目名称中直接出现的模型完整品牌名
- **长链式思维** (技术特性): 相较于普通 CoT，模型能够生成更长、更连贯的思考链

### ByteDance/AnimateDiff-Lightning

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance/AnimateDiff-Lightning

**关键词列表**:

- **AnimateDiff-Lightning** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本生成视频** (功能场景): 当前模型的主要功能应用场景
- **1步推理** (技术特性): 文档中提到的当前模型的一种推理方式，是较独特的技术特性体现
- **Motion-LoRAs** (技术特性): 文档中推荐使用且能使模型产生更强运动效果的技术特性

### deepseek-ai/DeepSeek-V2-Lite

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2-Lite

**关键词列表**:

- **DeepSeek-V2-Lite** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简化规则（无版本后缀）
- **MLA** (技术特性): 模型独有技术'多头潜在注意力（Multi-head Latent Attention）'的缩写，是区别于其他模型的关键技术标签，用户可能搜索该缩写
- **2.4B激活参数** (参数规格): 模型激活参数量为2.4B，属于主流稀疏MoE模型的典型规格，用户会搜索'X.B激活参数'来寻找轻量MoE模型，且未被高频词列表覆盖
- **单GPU部署** (部署工具): 原文强调'可在单个40G GPU上部署'，这是用户关心的低成本落地场景，'单GPU部署'是精准搜索词，非泛泛硬件词
- **DeepSeek-V2** (当前模型品牌名): DeepSeek-V2是当前模型的父系列名称，项目中明确区分V2-Lite与V2，用户常搜索父系列名来对比子模型，且为官方品牌名

### deepseek-ai/Janus-Pro-7B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/Janus-Pro-7B

**关键词列表**:

- **自回归框架** (技术特性): 当前模型的核心技术架构
- **视觉编码解耦** (技术特性): 当前模型解决多模态冲突的关键技术
- **统一变换器架构** (技术特性): 当前模型处理多模态任务的架构特点

### deepseek-ai/DeepSeek-R1-Distill-Qwen-7B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B

**关键词列表**:

- **长CoT** (技术特性): 指模型能够生成并处理较长的 Chain‑of‑Thought（思考链），提升复杂任务的解答质量

### ant-research/MagicQuill-models

**URL**: https://ai.gitcode.com/hf_mirrors/ant-research/MagicQuill-models

**关键词列表**:

- **MagicQuill** (当前模型品牌名): 项目名称为AntResearch/MagicQuill-models，模型官方名称为MagicQuill，是当前模型的唯一品牌标识
- **交互式图像编辑** (功能场景): 模型核心功能是通过极简交互（如插入、擦除、调色）实现图像编辑，用户会搜索此类具体场景
- **多模态大语言模型** (技术特性): 模型依赖MLLM实时预测编辑意图，是其核心技术机制，具有区分度且非高频词
- **扩散先验** (技术特性): 模型采用‘经过精心学习的双分支插件模块增强的强大扩散先验’，是其区别于普通扩散模型的关键技术点
- **Image-to-Image** (技术特性): 标签中明确标注，是AI图像生成/编辑领域的标准术语，用户在搜索图像编辑模型时常用

### dreamerwhite/surya_layout3

**URL**: https://ai.gitcode.com/hf_mirrors/dreamerwhite/surya_layout3

**关键词列表**:

- **suryalayout3** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **Layout-model** (功能场景): README中明确提到的模型功能定位
- **ModelScope-SDK** (部署工具): 当前模型提供的官方SDK下载方式
- **Git下载** (部署工具): 当前模型支持的Git克隆部署方式

### unsloth/gemma-3-270m

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m

**关键词列表**:

- **gemma3** (当前模型品牌名): 从项目名称unsloth/gemma-3-270m提取的核心模型标识，用户直接搜索目标模型时会使用的简称
- **Colab** (部署工具): 文档多次提及基于Google Colab的免费运行环境，是该模型重要的低门槛部署方式
- **270M** (参数规格): 项目名称中包含的270百万参数量级，属于轻量化模型的典型特征，用户常以此作为筛选条件
- **性能优化** (技术特性): README突出显示'快2倍/减少80%内存占用'等性能提升指标，体现模型的核心竞争优势
- **指令调优** (功能场景): 模型描述中提到提供指令调优变体的开放权重，满足特定场景下的精细化控制需求

### deepseek-ai/DeepSeek-Coder-V2-Instruct-0724

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Instruct-0724

**关键词列表**:

- **混合专家架构** (技术特性): 当前模型采用混合专家（MoE）架构，是核心特性
- **代码语言模型** (功能场景): 当前模型专注于代码特定任务，是主要应用场景
- **128K上下文长度** (技术特性): 当前模型将上下文长度延长到128K，是显著提升

### zai-org/glm-4v-9b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4v-9b

**关键词列表**:

- **GLM-4V-9B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **中英双语多轮对话** (功能场景): 体现了GLM-4V-9B具备的功能场景
- **高分辨率视觉理解** (功能场景): 表明模型在1120×1120高分辨率下具有视觉理解能力，属于功能场景
- **11201120高分辨率** (技术特性): 是该模型在视觉理解方面具有区分度的技术特性
- **MMBench评测** (技术特性): 模型在MMBench相关评测中有表现，是体现其技术特性的评测指标

### baidu/ERNIE-4.5-21B-A3B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-PT

**关键词列表**:

- **文心一言** (当前模型品牌名): ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'
- **百度大模型** (当前模型品牌名): ERNIE是百度自研大模型系列，'百度大模型'是用户搜索国产大模型时的常用泛称
- **多模态异构MoE** (技术特性): 模型独有的技术术语，指文本与视觉模态联合训练的异构MoE结构，非通用词，具高搜索价值
- **21B参数** (参数规格): 模型名称中明确标注21B，属于主流参数规模（介于7B与32B之间），用户常按参数量搜索模型
- **统一偏好优化** (技术特性): 模型独创的UPO（统一偏好优化）方法，是其强化学习微调的核心技术，具有唯一性和搜索价值
- **4位量化** (技术特性): 模型支持4位无损量化，是推理优化的关键特性，用户常搜索'4位量化模型'以降低部署成本

### moonshotai/Kimi-K2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-K2-Base

**关键词列表**:

- **Kimi** (当前模型品牌名): 项目名称中包含 MoonshotAI 的品牌标识 Kimi，用户搜索该品牌时会使用此词
- **K2** (当前模型品牌名): 模型系列名称 K2（Kimi‑K2‑Base），是模型的核心标识，用户常以 K2 为关键词检索
- **Muon优化器** (技术特性): 模型采用独创的 Muon 优化器进行大规模训练，是该模型的独特技术亮点
- **1万亿参数** (参数规格): 模型总参数量达到 1 万亿，是显著的规模特征，用户常以参数规模进行筛选
- **320亿激活参数** (参数规格): 激活参数量 320 亿是模型的关键规格之一，能够帮助用户辨别模型规模

### Qwen/Qwen3-235B-A22B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-4bit

**关键词列表**:

- **MLX部署** (部署工具): 当前模型支持mlx_lm部署的部署方式

### baidu/ERNIE-4.5-21B-A3B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Paddle

**关键词列表**:

- **异构MoE** (技术特性): 模型核心创新点为'多模态异构MoE架构'，'异构MoE'是区别于普通MoE的独特技术术语，用户会搜索该技术关键词
- **模态隔离路由** (技术特性): 模型独有的架构设计术语，用于解决多模态干扰，属于高区分度技术关键词，非通用词
- **2比特量化** (技术特性): 模型实现'4比特/2比特无损量化'，'2比特量化'是主流用户关注的高效推理参数，且未被高频词列表排除
- **PaddlePaddle** (部署工具): 模型明确使用PaddlePaddle权重格式，是用户寻找国产框架适配模型时的关键搜索词，且未在禁用列表中
- **动态角色切换** (技术特性): 模型独有推理优化技术'PD解耦+动态角色切换'，属于高技术差异点，非通用术语，用户可能搜索该特性

### m-a-p/MERT-v1-330M

**URL**: https://ai.gitcode.com/hf_mirrors/m-a-p/MERT-v1-330M

**关键词列表**:

- **MERT** (当前模型品牌名): 从项目名称m-a-p/MERT-v1-330M提取的当前模型核心品牌名，简化为MERT（避免版本号冗余，符合品牌名简化规则）
- **音乐理解** (功能场景): 模型核心功能描述，用户搜索AI模型时会直接使用'音乐理解'作为关键词（源自README中'音乐理解模型'的明确表述，区别于泛泛的'音频模型'）
- **MLM** (技术特性): 模型核心技术特征，用户搜索AI模型时常用缩写'MLM'（Masked Language Model）作为技术关键词（源自快速选型表'预训练范式：MLM'，符合技术特性维度要求）
- **330M参数** (参数规格): 模型关键参数规格，用户会搜索'330M参数'作为硬件适配关键词（源自快速选型表'模型参数量：3.3亿'，符合主流参数规格提取规则）
- **音频分类** (功能场景): 模型下游任务类型，用户搜索'音频分类'时会关联该模型（源自标签'Audio Classification'，作为具体功能场景词，避免泛泛描述）
- **Fairseq** (技术特性): 模型框架技术特征，用户会搜索'Fairseq'来查找相关实现（源自标签'Fairseq'，属于技术特性维度，非其他模型名称且未被强制排除）

### baidu/ERNIE-4.5-VL-28B-A3B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Base-Paddle

**关键词列表**:

- **28B参数** (参数规格): 模型名称中包含 “28B”，表明模型规模约为 280 亿参数，属于主流大模型规格
- **跨模态推理** (技术特性): 模型支持文本与图像之间的跨模态推理，是其核心能力之一
- **PaddlePaddle权重** (部署工具): 模型后缀 “-Paddle” 表明使用 PaddlePaddle 框架的权重文件，适配该平台部署
- **A3B系列** (技术特性): 模型属于 ERNIE‑4.5 的 A3B 系列，标识其特定的架构与训练方式

### Qwen/WorldPM-72B-RLHFLow

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/WorldPM-72B-RLHFLow

**关键词列表**:

- **WorldPM** (当前模型品牌名): 从项目名称及标签提取的当前模型核心名称
- **preference-model** (技术特性): 当前模型的核心技术定位（偏好模型）
- **reward-model** (技术特性): 当前模型作为奖励模型的功能属性
- **Modeling-World-Preference** (技术特性): 标签中明确标注的模型核心研究方向
- **PMP** (技术特性): 标签中提取的偏好模型预训练技术缩写（preference model pretraining）
- **RLHFlow** (技术特性): 项目名称及数据标签中包含的强化学习流程相关标识

### baidu/ERNIE-4.5-VL-28B-A3B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-PT

**关键词列表**:

- **图像理解** (功能场景): README中提到模型能提升图像理解任务性能，是该模型的功能场景
- **4比特量化** (技术特性): README中提到推理阶段采用4比特无损量化，是该模型独特的技术特性
- **ERNIE-4.5** (当前模型品牌名): 从项目名称中提取的当前模型具体名称

### baidu/ERNIE-4.5-300B-A47B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-PT

**关键词列表**:

- **ERNIE4.5** (当前模型品牌名): 项目名称中明确包含'ERNIE-4.5'，作为模型版本标识，用户可能直接搜索此简称
- **多模态预训练** (技术特性): 模型核心创新点为'textual and visual modalities joint training'，用户搜索多模态模型时会使用此完整术语
- **300B参数** (参数规格): 300B是当前模型的显著参数规模，属于主流超大规模级别，用户会搜索此类大模型规格

### baidu/ERNIE-4.5-300B-A47B-2Bits-TP2-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-TP2-Paddle

**关键词列表**:

- **多模态异构混合专家预训练** (技术特性): 当前模型的核心技术特性，突出多模态与MoE架构的结合
- **异构混合并行** (技术特性): 当前模型在训练时采用的高效基础架构策略
- **模态专项后训练** (技术特性): 当前模型针对不同模态进行的专项微调，提升实际应用能力
- **4比特2比特无损量化** (技术特性): 当前模型在推理阶段采用的量化技术，提升效率

### Qwen/Qwen3-32B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-6bit

**关键词列表**:

- **数学计算** (功能场景): 当前模型推理能力增强的核心应用场景
- **智能体能力** (技术特性): 当前模型专业的外部工具对接能力
- **mlxlm部署** (部署工具): 当前模型推荐的部署工具与库
- **6bit量化** (部署工具): 当前模型的量化规格（项目名称包含6bit）
- **131072上下文** (技术特性): 当前模型通过YaRN扩展的超长上下文长度

### Qwen/Qwen3-30B-A3B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-8bit

**关键词列表**:

- **30B参数** (参数规格): README明确给出30B级总参数量，用户常搜
- **MLX量化** (部署工具): 项目后缀带MLX-8bit，突出苹果MLX量化部署方案
- **智能体集成** (功能场景): 官方强调专业级智能体能力，支持工具调用

### Qwen/Qwen3-14B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-4bit

**关键词列表**:

- **Qwen3-14B** (当前模型品牌名): 项目名称中直接出现的模型标识，属于本模型的品牌名称
- **非思维模式** (技术特性): 模型提供的高效通用对话模式，与思维模式形成互补
- **4bit量化模型** (技术特性): 本仓库提供的模型已完成 4bit 量化，显著降低推理算力需求
- **MLX框架** (部署工具): 模型基于 Apple 的 MLX 框架实现，可直接在支持 MLX 的环境中部署运行
- **多语言支持** (功能场景): 模型支持 100+ 语言与方言，适用于跨语言指令遵循和翻译任务
- **长上下文支持** (技术特性): 原生支持 32k tokens，扩展至 131k tokens，适合需要大段文本处理的场景

### Qwen/Qwen3-235B-A22B-Instruct-2507-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8

**关键词列表**:

- **Qwen3-235B-A22B-Instruct-2507-FP8** (当前模型品牌名): 项目名称即为当前模型完整名称，虽含版本号，但因是FP8指令微调版且无通用简称，需保留完整标识以区分其他Qwen系列，符合‘模型自身名称’提取原则
- **256K长上下文** (功能场景): 模型明确强调‘增强256K长上下文理解’，是用户搜索长文本处理、文档分析、法律/科研摘要等场景时的高价值关键词，且非通用术语
- **FP8量化模型** (技术特性): FP8是当前前沿低精度量化格式，区别于常见的FP16/INT8，用户会主动搜索‘FP8模型’以获取高效推理方案，属独特技术标签
- **多语言长尾知识** (功能场景): 模型在‘多语言长尾知识覆盖’有显著提升，用户搜索‘多语言AI模型’‘小语种支持’‘冷门知识问答’时会匹配此精准场景词
- **指令微调** (技术特性): 模型名称含‘Instruct’，且README强调‘指令遵循能力显著提升’，‘指令微调’是用户区分通用模型与指令优化模型的核心搜索词

### THUDM/androidgen-glm-4-9b

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/androidgen-glm-4-9b

**关键词列表**:

- **AndroidGen** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Android应用任务执行** (功能场景): 当前模型支持基于LLM的智能体在各类Android应用中自主执行任务，这是其独特功能场景
- **无需手动标注交互数据** (功能场景): 是当前模型在执行任务时区别于其他模型的独特特性，可视为一种功能优势场景

### facebook/dinov2-base

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-base

**关键词列表**:

- **dinov2-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **DINOv2** (当前模型品牌名): 当前模型使用的核心方法名称，即模型技术标识
- **Vision-Transformer** (技术特性): 当前模型的基础架构类型，用户搜索视觉Transformer模型时会使用
- **视觉模型** (功能场景): 当前模型的应用领域，明确其视觉任务定位

### baidu/ERNIE-4.5-VL-424B-A47B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Paddle

**关键词列表**:

- **PaddlePaddle部署** (部署工具): 模型采用PaddlePaddle框架，区别于PyTorch版本
- **424B参数** (参数规格): 模型参数规模达424B，属超大规模模型特征

### nvidia/bigvgan_v2_44khz_128band_512x

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/bigvgan_v2_44khz_128band_512x

**关键词列表**:

- **BigVGANv2** (当前模型品牌名): 项目名称中直接出现的模型版本名称
- **神经声码器** (功能场景): 模型的核心功能是提供高质量的神经声码器
- **44kHz采样率** (参数规格): 模型支持最高 44 kHz 的音频采样率，用户常以此为搜索关键词
- **512倍上采样** (参数规格): 模型提供 512 倍的上采样倍率，是其显著的技术指标
- **抗混叠激活CUDA内核** (技术特性): 融合的抗混叠激活 CUDA 内核是模型加速推理的关键特性
- **多尺度子带CQT判别器** (技术特性): 采用多尺度子带 CQT 判别器提升生成音质，是模型独有的训练技术
- **多尺度梅尔频谱图损失** (技术特性): 使用多尺度梅尔频谱图损失函数进行训练，提升音频细节保真度
- **Gradio本地演示** (部署工具): 仓库提供基于 Gradio 的交互式本地演示，方便用户快速上手

### Helsinki-NLP/opus-mt-fr-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-fr-en

**关键词列表**:

- **opus-mt-fr-en** (当前模型品牌名): 项目名称直接对应当前模型的唯一标识，用户搜索法英翻译模型时会直接使用此名称
- **法英翻译** (功能场景): 用户搜索‘法语转英语’或‘法英翻译模型’时的自然搜索词，明确指向该模型的核心用途
- **SentencePiece** (技术特性): 模型预处理使用的核心子词技术，是区别于其他翻译模型的显著技术标签，用户会搜索该术语研究预处理方案
- **OPUS数据集** (技术特性): 模型训练基于OPUS语料库，该数据集在开源翻译领域具有高辨识度，用户常搜索‘OPUS翻译模型’
- **transformer-align** (技术特性): 模型架构明确标注为‘transformer-align’，是区别于标准Transformer的特定变体，技术用户会以此为关键词检索
- **归一化预处理** (技术特性): 模型预处理中明确提及的‘归一化’步骤，是其数据清洗的关键特征，专业用户会搜索该术语优化翻译质量

### unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF

**关键词列表**:

- **Qwen3-235B-A22B-Instruct-2507** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **Unsloth-Dynamic-2.0** (技术特性): 当前模型使用的Unsloth Dynamic 2.0技术实现卓越准确性

### THUDM/GLM-4.1V-9B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4.1V-9B-Thinking

**关键词列表**:

- **GLM-4.1V** (当前模型品牌名): 从项目名称提取的当前模型简化名称
- **思维范式** (技术特性): 当前模型引入的核心推理技术
- **64k上下文** (技术特性): 当前模型支持的超长上下文长度
- **4K分辨率** (技术特性): 当前模型处理图像的最高分辨率
- **Image-Text-to-Text** (功能场景): 当前模型的核心功能场景标签
- **推理优化** (技术特性): 当前模型作为系列首款专注推理优化的独特定位
- **任意宽高比图像** (技术特性): 当前模型处理图像的独特技术能力

### google/owlv2-base-patch16-ensemble

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlv2-base-patch16-ensemble

**关键词列表**:

- **CLIP骨干网络** (技术特性): 当前模型所采用的核心技术网络
- **开放词汇表分类** (技术特性): 当前模型实现的技术特性
- **bipartite-matching-loss** (技术特性): 当前模型微调过程中使用的损失函数，体现技术特性

### laion/CLIP-ViT-H-14-laion2B-s32B-b79K

**URL**: https://ai.gitcode.com/hf_mirrors/laion/CLIP-ViT-H-14-laion2B-s32B-b79K

**关键词列表**:

- **CLIP-ViT-H-14** (当前模型品牌名): 从项目名称直接提取的核心模型标识，是用户搜索CLIP视觉模型时的精准关键词，简洁且具唯一性
- **零样本图像分类** (功能场景): README明确列出的直接用途，是研究者和开发者搜索该类模型时的高频意图词，非通用术语
- **图文检索** (功能场景): README明确列出的直接用途，区别于通用图像分类，是CLIP模型的核心应用场景之一
- **OpenCLIP** (技术特性): 当前模型基于OpenCLIP框架训练，是区别于OpenAI官方CLIP的关键技术标签，用户会搜索该框架下的开源实现
- **LAION-2B** (技术特性): 模型训练所用的专属数据集名称，是该模型区别于其他CLIP变体的核心数据标识，研究者常以此为搜索条件
- **ViT-H14** (技术特性): 模型架构的精确描述，用户在比较不同视觉Transformer结构时会搜索该规格，具有技术区分度

### Intel/zoedepth-nyu-kitti

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/zoedepth-nyu-kitti

**关键词列表**:

- **ZoeDepth** (当前模型品牌名): 从项目名称提取的当前模型名称
- **深度估计** (功能场景): 当前模型的核心功能场景
- **单目深度估计** (功能场景): 当前模型支持的具体任务场景
- **metric-depth-estimation** (技术特性): 当前模型实现的技术功能
- **absolute-depth-estimation** (技术特性): 当前模型实现的技术功能
- **DPT框架** (技术特性): 当前模型扩展的基础技术架构
- **零样本迁移** (技术特性): 当前模型论文中提到的核心技术能力

### Alibaba-NLP/gte-large-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/gte-large-en-v1.5

**关键词列表**:

- **gte-large-en** (当前模型品牌名): 从项目名称提取的当前模型简洁品牌名
- **长上下文检索** (功能场景): 模型支持高达 8192 的上下文长度，适用于长文档检索
- **1024维嵌入** (参数规格): 模型输出的向量维度为 1024，属于主流嵌入规格
- **RoPE位置编码** (技术特性): 模型采用旋转位置编码（RoPE）提升长序列建模能力
- **GLU激活** (技术特性): 模型使用门控线性单元（GLU）作为激活函数，增强特征表达

### Intel/dpt-hybrid-midas

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/dpt-hybrid-midas

**关键词列表**:

- **MiDaS-3.0** (当前模型品牌名): 项目 README 明确标注的当前模型版本简称
- **DPT-Hybrid** (当前模型品牌名): 论文与仓库共同使用的官方模型名称
- **零样本深度估计** (功能场景): README 强调可直接推理，无需微调的使用场景
- **ComfyUI-深度图** (部署工具): 社区常用 ComfyUI 调用 MiDaS 生成深度图，搜索量大

### nvidia/OpenReasoning-Nemotron-14B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-14B

**关键词列表**:

- **OpenReasoning-Nemotron-14B** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定模型时的精准关键词
- **科学问题求解** (功能场景): 模型明确宣称的三大能力之一，具有高度专业性和搜索稀缺性，非通用词
- **生成式解决方案选择** (技术特性): 模型独有的多智能体协同技术术语，原文中专有描述，具有技术辨识度且未被高频词覆盖
- **64K输出标记** (技术特性): 模型支持超长输出的核心能力，虽为数值，但‘64K输出’是用户在搜索长文本推理模型时的精准搜索词

### sshleifer/distilbart-cnn-6-6

**URL**: https://ai.gitcode.com/hf_mirrors/sshleifer/distilbart-cnn-6-6

**关键词列表**:

- **DistilBARTCNN** (当前模型品牌名): 从项目名称提取的模型名称，标识该模型属于 DistilBART 系列并针对 CNN 数据集
- **新闻摘要** (功能场景): 模型在 CNN/DailyMail 新闻数据上评估，适用于新闻类文本的摘要需求

### tsmatz/xlm-roberta-ner-japanese

**URL**: https://ai.gitcode.com/hf_mirrors/tsmatz/xlm-roberta-ner-japanese

**关键词列表**:

- **xlm-roberta-ner-japanese** (当前模型品牌名): 从项目名称提取的当前模型名称
- **日语命名实体识别** (功能场景): 该模型专用于日语的命名实体识别任务，是核心功能
- **XLM-RoBERTa微调** (技术特性): 此模型是基于xlm - roberta - base进行微调得到的，是重要的技术特性
- **Stockmark数据集微调** (技术特性): 模型在Stockmark公司提供的NER数据集上进行了微调，是模型训练的关键信息
- **日语维基百科数据** (技术特性): 数据集收集自日语维基百科文章，体现了模型训练数据的来源

### QuantStack/FLUX.1-Kontext-dev-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/FLUX.1-Kontext-dev-GGUF

**关键词列表**:

- **FLUX.1-Kontext** (当前模型品牌名): 从项目名称提取的当前模型名称，简化后保留核心品牌标识
- **ComfyUI-GGUF** (部署工具): 当前模型专用的ComfyUI自定义节点，属于具体部署工具组件
- **flux** (当前模型品牌名): 项目标签中的模型核心品牌名，用户可能简化搜索该标识

### jinaai/jina-embeddings-v3

**URL**: https://ai.gitcode.com/hf_mirrors/jinaai/jina-embeddings-v3

**关键词列表**:

- **jina-embeddings-v3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多语言嵌入模型** (功能场景): 当前模型支持多语言，是其核心功能场景
- **超长序列支持** (技术特性): 当前模型支持最长8192个tokens的输入序列，是其独特技术特性
- **任务定制化嵌入** (技术特性): 当前模型可通过task参数定制嵌入向量，是其重要技术特性
- **嵌套式嵌入** (技术特性): 当前模型支持灵活的嵌入维度设置，是其独特技术特性
- **94种语言** (功能场景): 当前模型支持的语言数量多，是其功能场景的体现

### valhalla/distilbart-mnli-12-1

**URL**: https://ai.gitcode.com/hf_mirrors/valhalla/distilbart-mnli-12-1

**关键词列表**:

- **distilbart-mnli** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，是用户搜索该蒸馏模型的核心关键词
- **零样本分类** (功能场景): MNLI任务本质是零样本文本蕴含分类，用户搜索AI模型做文本推理时常用此术语，且非高频排除词
- **轻量级文本分类** (功能场景): distilbart-mnli是bart-large-mnli的压缩版，专为高效文本分类设计，用户会搜索‘轻量级’+‘文本分类’组合
- **HuggingFace模型** (部署工具): 虽HuggingFace是平台名，但用户常搜‘HuggingFace模型’作为模型来源关键词，且未在强制排除列表中被禁用（排除列表仅禁‘HuggingFace’单词）
- **12-1蒸馏** (技术特性): 模型名称中‘12-1’代表12层教师→1层学生，是该模型独特架构标识，用户可据此区分不同蒸馏版本

### ByteDance-Seed/SeedVR-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR-3B

**关键词列表**:

- **SeedVR** (当前模型品牌名): 项目名称中的核心模型品牌名
- **视频修复** (功能场景): 模型专注于通用视频修复任务
- **任意分辨率修复** (功能场景): 模型能够在不受固定分辨率限制的情况下进行修复
- **扩散模型** (技术特性): 模型基于扩散Transformer 的核心技术
- **视频生成技术** (技术特性): 模型融合了先进的视频生成训练流程以提升修复质量

### Diankun/Spatial-MLLM-subset-sft

**URL**: https://ai.gitcode.com/hf_mirrors/Diankun/Spatial-MLLM-subset-sft

**关键词列表**:

- **Spatial-MLLM** (当前模型品牌名): 从项目名称及论文标题提取的当前模型名称
- **视觉空间智能** (功能场景): 论文明确提及的模型核心应用场景

### Gen-Verse/MMaDA-8B-MixCoT

**URL**: https://ai.gitcode.com/hf_mirrors/Gen-Verse/MMaDA-8B-MixCoT

**关键词列表**:

- **扩散大模型** (技术特性): 区别于自回归，强调统一扩散架构
- **链式思维微调** (技术特性): MixCoT 策略是模型卖点

### google/ddpm-celebahq-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-celebahq-256

**关键词列表**:

- **googleddpm-celebahq-256** (当前模型品牌名): 从项目名称提取的当前模型名称
- **DDPM** (技术特性): 当前模型是基于去噪扩散概率模型（DDPM）实现的
- **无条件图像生成** (功能场景): 从标签中可知当前模型具有无条件图像生成功能
- **schedulingddpm** (部署工具): 是当前模型推理时可使用的离散噪声调度器，属于部署相关内容
- **256x256图像合成** (功能场景): 从内容可知模型在256x256 LSUN数据集上有相关合成表现，是具体的功能场景

### HiDream-ai/HiDream-E1-1

**URL**: https://ai.gitcode.com/hf_mirrors/HiDream-ai/HiDream-E1-1

**关键词列表**:

- **HiDream-E1** (当前模型品牌名): 项目名称中直接出现的模型名称
- **图像编辑** (功能场景): 模型定位为图像编辑模型，用户常搜索此功能
- **Gradio演示** (部署工具): 提供交互式 Gradio 界面，用户可直接体验模型
- **Flash-Attention** (技术特性): 模型依赖的高效注意力实现，提升推理速度
- **EmuEdit基准** (评估指标): 模型在 EmuEdit 基准测试中的表现，是用户关注的质量指标
- **ReasonEdit基准** (评估指标): 模型在 ReasonEdit 基准测试中的表现，体现编辑推理能力

### dbmdz/bert-large-cased-finetuned-conll03-english

**URL**: https://ai.gitcode.com/hf_mirrors/dbmdz/bert-large-cased-finetuned-conll03-english

**关键词列表**:

- **bert-large-cased** (当前模型品牌名): 从项目名称提取的当前模型核心名称，简化后保留主体标识
- **conll03-english** (功能场景): 模型针对CoNLL03英文数据集优化，用户搜索该数据集相关模型时会使用
- **Rust** (部署工具): 模型支持的开发语言之一，特定技术栈用户可能搜索该关键词

### PhysicsWallahAI/Aryabhata-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/PhysicsWallahAI/Aryabhata-1.0

**关键词列表**:

- **Aryabhata-1.0** (当前模型品牌名): 项目名称为PhysicsWallahAI/Aryabhata-1.0，是当前模型的唯一官方名称，符合品牌名提取规则且无其他模型混淆
- **JEE数学** (功能场景): 模型专为印度JEE主考试数学科目优化，是用户搜索竞赛数学AI模型时的核心意图词，具有明确场景指向性
- **exam-centric** (技术特性): README明确使用该术语描述模型特性，指代‘以考试为中心’的专用AI设计，是区别于通用模型的独特技术定位
- **模型融合** (技术特性): 模型通过加权平均融合Qwen 2.5 Math、Ace Math等多个模型构建，是Aryabhata 1.0的核心训练方法，非通用术语
- **拒绝采样** (技术特性): 模型训练流程中明确使用‘拒绝采样（rejection-sampling）’作为关键技术环节，是其高准确率的核心机制之一
- **2000标记窗口** (参数规格): 模型仅需约2000标记即可高效运行，该数值是其高效率的标志性参数，属于用户可搜索的典型效率指标（非技术细节）
- **PhysicsWallahAI** (当前模型品牌名): 模型由PhysicsWallah AI Research开发，品牌名直接关联印度教育AI生态，是用户搜索印度教育类AI模型时的精准入口词
- **印度教育AI** (功能场景): 模型专为印度JEE考试设计，属于‘印度教育场景’下的AI应用，是区域化教育AI搜索的高价值长尾词

### CIDAS/clipseg-rd64-refined

**URL**: https://ai.gitcode.com/hf_mirrors/CIDAS/clipseg-rd64-refined

**关键词列表**:

- **CIDASclipseg-rd64-refined** (当前模型品牌名): 从项目名称提取的当前模型名称
- **CLIPSeg** (当前模型品牌名): 模型的核心名称，用户可能直接搜索
- **降维64** (技术特性): 模型具有降维64的特性，是用户可能搜索的技术点
- **零样本图像分割** (功能场景): 模型适用于零样本图像分割，是用户可能搜索的应用场景
- **单样本图像分割** (功能场景): 模型也适用于单样本图像分割，是另一个用户可能搜索的应用场景
- **复杂卷积优化** (技术特性): 模型经过复杂卷积优化，是用户可能关注的技术改进点

### QuantStack/Wan2.1_14B_VACE-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.1_14B_VACE-GGUF

**关键词列表**:

- **VACE** (技术特性): 模型名称中包含的特有技术组件，具备辨识度
- **GGUF格式** (技术特性): 模型采用的 GGUF 文件格式，是该模型的独特格式特征
- **Q80量化** (技术特性): 模型提供的 Q8_0 低精度量化版本，提升推理效率

### moonshotai/Kimi-VL-A3B-Thinking-2506

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Thinking-2506

**关键词列表**:

- **视频推理** (功能场景): 模型在VideoMMMU等视频理解基准测试中设立SOTA，具备视频推理能力
- **高分辨率感知** (功能场景): 支持单图320万像素输入，显著提升高分辨率感知能力
- **视觉感知与理解** (功能场景): 在MMBench-EN-v1.1等通用视觉任务上超越非思考模型
- **OS-agent-grounding** (技术特性): 在高分辨率定位任务中取得显著提升，体现精准交互能力

### mradermacher/Wolf-Rayet-2B-Prime3-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Wolf-Rayet-2B-Prime3-i1-GGUF

**关键词列表**:

- **Wolf-Rayet-2B-Prime3** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简化规则（无版本后缀）
- **IQ1S** (技术特性): 模型提供IQ系列量化版本，IQ1_S是其独特量化技术标识，用户会搜索具体量化等级
- **IQ2XS** (技术特性): IQ2_XS是该模型特有的量化子版本，区别于通用Q2_K，具有区分度且非高频词
- **IQ3S** (技术特性): IQ3_S是模型推荐的中高质量化选项，为该模型专属量化标签，非通用术语
- **IQ4XS** (技术特性): 模型明确推荐IQ4_XS为优先选择，是其独特量化层级，用户会据此搜索优化版本

### mradermacher/VeriReason-Qwen2.5-7b-RTLCoder-Verilog-GRPO-reasoning-tb-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/VeriReason-Qwen2.5-7b-RTLCoder-Verilog-GRPO-reasoning-tb-i1-GGUF

**关键词列表**:

- **VeriReason** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **RTL-Coder** (功能场景): 当前模型的核心功能场景，对应RTL编码任务
- **Verilog** (功能场景): 当前模型针对Verilog语言的专用编程场景
- **reasoning** (技术特性): 当前模型的核心技术特性，强调推理能力
- **reinforcement-learning** (技术特性): 当前模型采用的核心训练技术，用户搜索技术实现时会使用

### jonatasgrosman/wav2vec2-large-xlsr-53-japanese

**URL**: https://ai.gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-japanese

**关键词列表**:

- **wav2vec2-large-xlsr-53-japanese** (当前模型品牌名): 从项目名称提取的当前模型名称
- **日语语音识别** (功能场景): 当前模型的应用场景，用于日语语音识别
- **Common-Voice数据集** (技术特性): 当前模型微调所使用的数据集之一，体现其技术特性
- **CSS10数据集** (技术特性): 当前模型微调所使用的数据集之一，体现其技术特性
- **JSUT数据集** (技术特性): 当前模型微调所使用的数据集之一，体现其技术特性
- **HuggingSound库** (部署工具): 可用于调用当前模型进行语音识别的工具

### pysentimiento/robertuito-sentiment-analysis

**URL**: https://ai.gitcode.com/hf_mirrors/pysentimiento/robertuito-sentiment-analysis

**关键词列表**:

- **robertuito** (当前模型品牌名): 模型名称直接来源于项目名称 robertuito‑sentiment‑analysis
- **西班牙语情感分析** (功能场景): 模型专注于西班牙语（Spanish）的情感（正面、负面、中性）分析
- **TASS-2020语料库** (数据来源): 模型基于 TASS 2020 推文语料库（约 5000 条）进行训练
- **POSNEGNEU标签** (标签体系): 模型输出的三类情感标签：POS（积极）、NEG（消极）、NEU（中性）
- **pysentimiento工具包** (使用工具): 可通过 pysentimiento Python 包直接调用进行情感预测
- **情感分类** (任务类型): 模型承担的核心任务是对文本进行情感（情绪）分类
- **西班牙语** (语言支持): 模型专为西班牙语（Spanish）设计，覆盖多种方言

### nvidia/canary-qwen-2.5b

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/canary-qwen-2.5b

**关键词列表**:

- **Canary-Qwen-2.5B** (当前模型品牌名): 项目名称直接定义的模型名称，符合用户搜索AI模型时的精确命名习惯
- **语音转文本** (功能场景): 模型核心功能是英语语音识别转文字，用户常搜索此中文意图词，且未被高频词库排除
- **ASR模式** (技术特性): 模型独有的双模式架构之一，用户在对比语音模型时可能搜索此专业术语
- **LLM模式** (技术特性): 模型另一独特模式，支持转录后处理，区别于普通ASR模型，具高区分度
- **FastConformer** (技术特性): 模型采用的核心架构名称，是技术文档中明确提及的专有术语，非通用词
- **带标点和大小写** (功能场景): 模型输出特性，用户在寻找高质量ASR结果时可能搜索此具体需求描述
- **转录后处理** (功能场景): 模型在LLM模式下的核心应用场景，区别于普通语音转文字工具，具商业价值指向

### maya-research/Veena

**URL**: https://ai.gitcode.com/hf_mirrors/maya-research/Veena

**关键词列表**:

- **Veena** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本转语音** (功能场景): 当前模型的核心功能场景
- **印地语TTS** (功能场景): 当前模型支持的特定语言TTS功能
- **语码混合TTS** (功能场景): 当前模型支持的多语言混合语音合成场景
- **自回归变换器** (技术特性): 当前模型的核心技术架构
- **SNAC神经编解码器** (技术特性): 当前模型使用的音频编解码技术
- **4比特量化优化** (部署工具): 当前模型支持的量化部署方式
- **24kHz音频** (技术特性): 当前模型输出的音频质量规格

### vidore/colpali-v1.2

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colpali-v1.2

**关键词列表**:

- **ColPali** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视觉检索** (功能场景): 当前模型的主要功能用途
- **ColBERT策略** (技术特性): 当前模型采用的策略，体现其技术特点
- **PaliGemma-3B** (技术特性): 当前模型基于此进行扩展，是其技术组成的一部分
- **BiSigLIP** (技术特性): 在模型构建过程中产生的中间成果，体现技术特性
- **BiPali** (技术特性): 在模型构建过程中产生的中间成果，体现技术特性

### facebook/timesformer-base-finetuned-k400

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/timesformer-base-finetuned-k400

**关键词列表**:

- **TimeSformer** (当前模型品牌名): 从项目名称提取的当前模型名称
- **video-classification** (功能场景): 当前模型的核心功能是视频分类
- **vision** (技术特性): 当前模型属于视觉领域模型
- **Kinetics-400** (技术特性): 当前模型在Kinetics-400数据集上微调，是其技术特性
- **Space-Time-Attention** (技术特性): 当前模型基于时空注意力机制，是其核心技术特性
- **视频分类** (功能场景): 当前模型的主要用途是视频分类

### mradermacher/Qwen2-Audio-7B-Instruct-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-Instruct-GGUF

**关键词列表**:

- **Qwen2-Audio-7B-Instruct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **静态量化版本** (技术特性): README中提到的当前模型版本特性
- **加权矩阵量化版本** (技术特性): README中提到的当前模型另一版本特性
- **音频-文本转文本** (功能场景): 从标签中提取的当前模型的功能场景
- **GGUF文件** (部署工具): README中提到的当前模型使用的文件类型
- **多模态补充文件** (技术特性): README中提到的当前模型补充文件特性

### google/ddpm-cifar10-32

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-cifar10-32

**关键词列表**:

- **CIFAR-10** (功能场景): 模型在无条件 CIFAR‑10 数据集上进行训练与评估，是用户搜索该数据集时常用的关键词
- **Diffusion概率模型** (技术特性): 模型基于扩散概率模型（Diffusion Probabilistic Model），是其核心技术特性
- **DDIM调度器** (技术特性): 提供的高效推理调度器之一，用户在搜索快速推理方案时会关注此关键词
- **渐进式有损解压缩方案** (技术特性): 模型自然支持的独特解压缩方案，区别于其他扩散模型的特性，具备搜索价值

### facebook/musicgen-medium

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/musicgen-medium

**关键词列表**:

- **1.5B参数** (参数规格): 当前medium版本的显式参数规模
- **自回归Transformer** (技术特性): 模型架构关键词，区别于扩散类音乐模型
- **32kHz-EnCodec** (技术特性): 高保真音频分词器，用户搜音质时常用
- **Colab体验** (部署工具): README强调一键Colab演示，引流常用词

### mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF

**关键词列表**:

- **SEOcrate-4B** (当前模型品牌名): 从项目名称 mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF 中提取的核心品牌名，去除了冗余后缀，符合简洁品牌名规范
- **SEO写作** (功能场景): 模型基于SEO相关数据集（seo-grpo-reasoning-dataset）微调，核心用途是生成优化搜索引擎的文本内容，用户会搜索'SEO写作'而非泛泛的'AI写作'
- **IQ2IQ3量化** (技术特性): 模型提供IQ2_XS、IQ3_S等独家量化等级，IQ系列是其技术亮点，区别于常规Q2/Q4，是用户对比量化质量时会搜索的精准术语
- **知识图谱SEO** (功能场景): 标签包含schema.org、knowledge-graph、ontology，表明模型专为结构化SEO与知识图谱内容生成优化，属于高度垂直的搜索意图
- **GRPO微调** (技术特性): 模型名称含'grpo'，源自'GRPO（Gradient-based Reinforcement Policy Optimization）'，是其微调技术核心，具有唯一性且未被高频词覆盖

### moojink/openvla-7b-oft-finetuned-libero-spatial-object-goal-10

**URL**: https://ai.gitcode.com/hf_mirrors/moojink/openvla-7b-oft-finetuned-libero-spatial-object-goal-10

**关键词列表**:

- **OpenVLA-OFT** (当前模型品牌名): 从项目名称和README中提取的当前模型名称
- **视觉-语言-动作模型** (技术特性): 当前模型的核心技术架构描述
- **优化微调** (技术特性): 当前模型采用的核心训练技术
- **LIBERO任务套件** (功能场景): 当前模型针对的特定任务场景
- **动作片段生成** (功能场景): 当前模型的核心功能应用
- **空间任务** (功能场景): 当前模型支持的LIBERO子任务类型
- **物体任务** (功能场景): 当前模型支持的LIBERO子任务类型
- **目标任务** (功能场景): 当前模型支持的LIBERO子任务类型

### mradermacher/BetaCeti-Beta-4B-Prime1-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/BetaCeti-Beta-4B-Prime1-i1-GGUF

**关键词列表**:

- **BetaCeti-Beta** (当前模型品牌名): 从项目名称提取的核心模型品牌名称
- **静态量化** (技术特性): README 中明确说明提供静态量化版本
- **IQ1量化** (技术特性): 模型文件列表中包含 i1‑IQ1_S、i1‑IQ1_M 等 IQ1 量化变体
- **强化学习微调** (功能场景): 标签中出现 reinforcement‑learning，说明模型支持强化学习微调

### ByteDance-Seed/SeedVR-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR-7B

**关键词列表**:

- **Diffusion-Transformer** (技术特性): README提到SeedVR采用扩散Transformer，是其技术特性

### baidu/ERNIE-4.5-VL-28B-A3B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Base-PT

**关键词列表**:

- **图像转文本** (功能场景): 从标签'Image-Text-to-Text'和README内容'显著提升...图像理解及跨模态推理任务的性能'提取，表示模型核心功能为图像到文本的转换，用户搜索AI模型时常用此场景描述词
- **思维链** (技术特性): 从README中'视觉语言模型（VLM）强化视觉-语言理解能力并支持思维链与非思维链双模式'提取，是模型独有的技术特性，用户搜索AI模型时会关注此具体能力

### am-infoweb/layoutlmv3-finetuned_docvqa

**URL**: https://ai.gitcode.com/hf_mirrors/am-infoweb/layoutlmv3-finetuned_docvqa

**关键词列表**:

- **layoutlmv3-finetuneddocvqa** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文档VQA** (功能场景): 当前模型针对文档视觉问答任务，是主要应用场景
- **Adam优化器** (技术特性): 当前模型训练过程中使用的优化器类型，体现技术细节
- **线性学习率调度器** (技术特性): 当前模型训练过程中采用的学习率调度器类型，体现技术细节
- **微调模型** (技术特性): 当前模型是基于microsoft/layoutlmv3-base微调得到的，体现技术特性

### mgalkin/ultra_3g

**URL**: https://ai.gitcode.com/hf_mirrors/mgalkin/ultra_3g

**关键词列表**:

- **ULTRA** (当前模型品牌名): 项目名称为mgalkin/ultra_3g，模型主品牌名为ULTRA，是用户搜索该模型时最直接的关键词
- **知识图谱推理** (功能场景): 模型核心用途是知识图谱上的链接预测与推理，属于用户明确搜索的AI应用场景，且非高频词
- **零样本知识图谱** (功能场景): 模型突出优势是零样本在任意知识图谱上执行推理，该组合词精准描述其独特能力，非通用表述
- **图神经网络** (技术特性): 模型核心技术基于图神经网络（GNN）与改进版NBFNet，是区别于文本大模型的关键技术标签
- **链接预测** (功能场景): 模型执行的核心任务是链接预测（知识图谱补全），是知识图谱领域标准术语，用户会直接搜索
- **ultra3g** (当前模型品牌名): 项目具体名称为ultra_3g，是HuggingFace上可下载的独立检查点，用户会用此精确名称搜索模型版本
- **NBFNet** (技术特性): 模型采用改进版NBFNet架构，是论文中提出的专有技术名称，具有唯一性且非高频词
- **知识图谱补全** (功能场景): 链接预测的同义术语，在学术与工业场景中广泛使用，用户搜索知识图谱任务时高频使用该词

### kredor/punctuate-all

**URL**: https://ai.gitcode.com/hf_mirrors/kredor/punctuate-all

**关键词列表**:

- **punctuate-all** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多语言标点恢复** (功能场景): 当前模型支持12种语言标点添加的核心功能
- **xlm-roberta-base微调** (技术特性): 当前模型基于xlm-roberta-base进行微调的技术特点
- **wmteuroparl** (技术特性): 模型关联的数据集标签，用户可能搜索相关领域模型
- **标点预测** (功能场景): 模型核心功能之一，用于预测文本中的标点符号

### nari-labs/Dia-1.6B-0626

**URL**: https://ai.gitcode.com/hf_mirrors/nari-labs/Dia-1.6B-0626

**关键词列表**:

- **Dia** (当前模型品牌名): 项目名称即为 Dia，直接提取模型品牌名
- **1.6B参数** (参数规格): 模型拥有约 1.6 B（16 亿）参数，是用户关注的规模信息
- **情感语音合成** (功能场景): 支持情感与语调的精准调节，满足情感化语音需求
- **音频条件控制** (技术特性): 通过音频提示控制输出效果，实现音色、情感等细粒度调节
- **非语言音效生成** (功能场景): 模型还能生成笑声、咳嗽、清嗓等非语言音效，扩展使用场景
- **Gradio界面** (部署工具): 提供交互式 Gradio UI，便于快速上手和在线体验
- **ZeroGPU空间** (部署工具): 模型已上线 ZeroGPU 环境，用户可免显卡直接使用

### mistralai/Magistral-Small-2507

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Magistral-Small-2507

**关键词列表**:

- **Magistral-Small** (当前模型品牌名): 从项目名称提取的当前模型名称
- **小参数推理模型** (功能场景): 当前模型是240亿参数的小型高效推理模型，体现其功能特点
- **量化适配** (部署工具): 当前模型量化后可适配单张RTX 4090或32GB内存的MacBook，属于部署相关特性
- **长链推理** (技术特性): 当前模型具有在给出答案前进行长链推理的能力，是其技术特性
- **128k上下文窗口** (参数规格): 当前模型拥有128k的上下文窗口，是重要的参数规格

### mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF

**关键词列表**:

- **GCIRS-Reasoning** (当前模型品牌名): 项目名称中唯一出现的模型品牌，用户会直接搜索
- **科学推理** (功能场景): 标签含science、math、reinforcement-learning，突出科研与推理能力
- **金融分析** (功能场景): 标签明确finance，吸引需要AI做量化或财报分析的用户

### LiquidAI/LFM2-1.2B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-GGUF

**关键词列表**:

- **LFM2** (当前模型品牌名): 项目名称为LFM2-1.2B-GGUF，核心品牌名为LFM2，符合模型名称简化规则，是用户搜索该模型的直接关键词
- **边缘AI** (功能场景): README明确指出模型'专为边缘AI和设备端部署而设计'，这是该模型的核心应用场景，用户会搜索'边缘AI模型'这类意图明确的词
- **设备端部署** (功能场景): 与'边缘AI'并列的核心部署目标，是用户在寻找可在手机、嵌入式设备运行的轻量模型时的高频搜索词
- **llama.cpp** (部署工具): README明确给出运行命令'llama-cli -hf ...'，表明该模型专为llama.cpp生态优化，用户会搜索'llama.cpp模型'来寻找兼容模型
- **8语言** (功能场景): README标注支持8种语言，用户在寻找多语言轻量模型时会搜索'8语言AI模型'，该词具独特区分度且未在排除列表中

### Kwai-Keye/Keye-VL-8B-Preview

**URL**: https://ai.gitcode.com/hf_mirrors/Kwai-Keye/Keye-VL-8B-Preview

**关键词列表**:

- **Keye-VL** (当前模型品牌名): 从项目名称Kwai-Keye/Keye-VL-8B-Preview提取的当前模型简化名称
- **短视频理解** (功能场景): 当前模型专为短视频理解领域设计的核心应用场景
- **视觉语言对齐** (技术特性): 当前模型四阶段预训练流程的核心技术特性
- **冷启动数据混合** (技术特性): 当前模型后训练第二阶段的创新数据策略
- **视频基准测试** (功能场景): 当前模型在公开视频基准测试中达到最先进水平的应用场景
- **KC-MMBench** (技术特性): 当前模型开发并发布的短视频场景定制新基准
- **强化学习对齐** (技术特性): 当前模型增强推理能力并修正异常行为的核心技术

### Robertooo/autotrain-hmaet-2037366891

**URL**: https://ai.gitcode.com/hf_mirrors/Robertooo/autotrain-hmaet-2037366891

**关键词列表**:

- **autotrain-hmaet** (当前模型品牌名): 项目名称中的简化模型标识，便于用户搜索特定模型
- **回归模型** (技术特性): 模型的核心技术特性是回归预测，属于回归模型类别

### MohamedRashad/Voxtral-Mini-3B-2507-transformers

**URL**: https://ai.gitcode.com/hf_mirrors/MohamedRashad/Voxtral-Mini-3B-2507-transformers

**关键词列表**:

- **Voxtral-Mini-3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音频转录** (功能场景): 当前模型的核心功能之一，用户可能搜索音频转录相关模型
- **语音直接触发** (功能场景): 当前模型独特的功能，用户可能搜索语音触发相关模型
- **32k-token上下文** (技术特性): 当前模型处理长文本上下文的能力，是用户可能关注的特性

### yuvalkirstain/PickScore_v1

**URL**: https://ai.gitcode.com/hf_mirrors/yuvalkirstain/PickScore_v1

**关键词列表**:

- **PickScorev1** (当前模型品牌名): 从项目名称 yuvalkirstain/PickScore_v1 直接提取的当前模型唯一品牌名，用户搜索该模型时会使用此精确名称
- **文生图评分** (功能场景): 模型核心功能是为文本生成图像进行评分，属于用户明确搜索的垂直场景词，区别于通用'文生图'，具有高区分度
- **图像偏好预测** (功能场景): README明确提及'人类偏好预测'，是该模型在AI图像评估领域的独特应用场景，非通用词，具搜索价值
- **Pick-a-Pic** (当前模型品牌名): 模型基于Pick-a-Pic数据集训练，该名称在论文和演示中作为核心标识，是模型的官方数据集品牌名，可视为模型代称
- **CLIP-H微调** (技术特性): 模型基于CLIP-H架构进行微调，'CLIP-H'是具体架构名称，'微调'是关键训练方式，组合词具技术搜索意图且非高频词
- **图像排序** (功能场景): README明确列出'图像排序'为应用场景之一，是AI图像评估中的具体任务，用户在研究模型评估时会搜索此关键词

### laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K

**URL**: https://ai.gitcode.com/hf_mirrors/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K

**关键词列表**:

- **CLIP-ViT-L-14** (当前模型品牌名): 从项目名称提取的当前模型核心名称，简洁且具有识别性
- **Zero-Shot-Image-Classification** (功能场景): README标签及用途中明确提到的核心功能，用户搜索意图明确
- **DataComp.XL** (技术特性): 项目名称中体现的数据集相关标识，反映模型训练数据特性
- **图像分类微调** (功能场景): 下游用途中明确提到的应用场景，用户可能搜索的具体使用方式
- **图像生成引导** (功能场景): 下游用途涉及的场景，具有明确的功能指向性

### mistralai/Voxtral-Mini-3B-2507

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Voxtral-Mini-3B-2507

**关键词列表**:

- **Voxtral-Mini** (当前模型品牌名): 从项目名称提取的当前模型核心品牌标识
- **语音转录** (功能场景): 模型核心功能之一，支持纯语音转录模式
- **音频翻译** (功能场景): 明确提及的跨语言音频处理能力
- **音频内容理解** (功能场景): 模型的核心应用场景描述
- **vLLM** (部署工具): 官方推荐的部署框架
- **语音触发功能调用** (技术特性): 独特的语音交互技术实现

### SWivid/F5-TTS

**URL**: https://ai.gitcode.com/hf_mirrors/SWivid/F5-TTS

**关键词列表**:

- **F5-TTS** (当前模型品牌名): 从项目名称提取的当前模型名称
- **E2-TTS** (当前模型品牌名): 项目相关的另一个TTS模型，与当前项目有紧密关联，也是文本转语音领域具体模型
- **12B参数** (参数规格): TTS模型可能存在的参数规格范围，是用户可能搜索的参数相关信息

### ChatDOC/OCRFlux-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ChatDOC/OCRFlux-3B

**关键词列表**:

- **OCRFlux** (当前模型品牌名): 项目名称中的品牌名，直接代表模型本身
- **PDF转Markdown** (功能场景): 模型的核心功能是将 PDF 文档转换为纯 Markdown 文本
- **跨页表格合并** (技术特性): 模型首创的跨页表格/段落合并能力，具备显著的差异化特征
- **OCRFlux-API** (部署工具): 提供直接调用的推理 API，便于在代码中集成模型功能
- **vllm推理架构** (部署工具): 使用 vllm 实现的高效推理架构，支持大规模文档处理

### ETH-CVG/lightglue_disk

**URL**: https://ai.gitcode.com/hf_mirrors/ETH-CVG/lightglue_disk

**关键词列表**:

- **LightGlue** (当前模型品牌名): 从项目名称 ETH-CVG/lightglue_disk 提取的核心模型品牌名，是论文提出的原创模型，具有唯一性
- **DISK** (当前模型品牌名): 模型基于DISK关键点检测器训练，是当前模型区别于其他LightGlue变体的核心训练数据源，属于模型自身组成部分
- **关键点匹配** (功能场景): 模型核心用途为图像间关键点匹配，是用户搜索图像配准、SFM、SLAM等场景时的直接搜索词，非通用词
- **轻量级特征匹配** (技术特性): 论文强调LightGlue是‘Light Speed’的局部特征匹配方案，‘轻量级特征匹配’是其区别于SuperGlue的核心技术标签
- **Hugging-Face模型库** (部署工具): 模型通过PytorchModelHubMixin集成到Hugging Face Hub，用户搜索‘Hugging Face模型库’时会寻找此类可直接加载的模型
- **图像匹配** (功能场景): 模型明确用于两幅图像的匹配任务，是计算机视觉领域高频搜索意图，且非通用词，具有明确应用场景
- **单应性估计** (功能场景): 论文明确指出模型适用于单应性估计，是专业用户搜索图像拼接、三维重建时的精准关键词，具有高意图指向性

### sentence-transformers/multi-qa-MiniLM-L6-cos-v1

**URL**: https://ai.gitcode.com/hf_mirrors/sentence-transformers/multi-qa-MiniLM-L6-cos-v1

**关键词列表**:

- **multi-qa-MiniLM** (当前模型品牌名): 从项目名称提取的当前模型简化名称
- **Sentence-Similarity** (技术特性): 模型标签中明确标注的核心功能
- **OpenVINO** (部署工具): 模型支持的部署框架

### ByteDance-Seed/BM-Model

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/BM-Model

**关键词列表**:

- **BM-Model** (当前模型品牌名): 项目仓库名称即为模型的官方品牌名称
- **图像到图像** (功能场景): 模型主要用于在已有图像上进行风格迁移、编辑等图像‑到‑图像任务
- **文本引导图像编辑** (功能场景): 支持通过自然语言描述对输入图像进行精准编辑，是模型的核心使用场景
- **ComfyUI插件** (部署工具): 模型提供了专门的 ComfyUI 插件，便于在本地工作流中快速集成使用
- **双向扩散** (技术特性): 采用双向扩散采样策略提升图像细节保留和编辑一致性，区别于传统单向扩散

### ByteDance-Seed/Tar-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Tar-7B

**关键词列表**:

- **Tar-7B** (当前模型品牌名): 从项目名称 ByteDance-Seed/Tar-7B 中提取的当前模型简称，符合简洁品牌名规则
- **文本对齐表征** (技术特性): README核心标题'通过文本对齐表征统一视觉理解与生成'，是模型独有的技术术语，用户可能搜索该表述

### LiquidAI/LFM2-350M

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M

**关键词列表**:

- **LFM2-350M** (当前模型品牌名): 从项目名称提取的当前模型名称
- **边缘人工智能** (功能场景): 当前模型专为边缘人工智能和设备端部署而设计
- **乘法门控** (技术特性): 当前模型具备乘法门控特性
- **短卷积** (技术特性): 当前模型具备短卷积特性
- **智能体任务** (功能场景): 当前模型特别适用于智能体任务
- **数据提取** (功能场景): 当前模型特别适用于数据提取
- **检索增强生成** (功能场景): 当前模型特别适用于检索增强生成（RAG）

### dphn/Dolphin-Mistral-24B-Venice-Edition

**URL**: https://ai.gitcode.com/hf_mirrors/dphn/Dolphin-Mistral-24B-Venice-Edition

**关键词列表**:

- **Dolphin** (当前模型品牌名): 项目核心品牌标识，用户会直接搜索'Dolphin模型'或'Dolphin AI'
- **Venice-Uncensored** (当前模型品牌名): 官方在Venice.ai上线的无审查版本名称，用户会搜'Venice Uncensored模型'
- **24B参数** (参数规格): README明确给出24B规模，用户会搜'24B大模型'或'Dolphin 24B'
- **无审查大模型** (功能场景): README多次强调'最无审查版本'，用户会搜'无审查AI'或'Uncensored LLM'
- **可引导模型** (技术特性): README突出'可引导性'，用户会搜'可引导大模型'或'Steerable AI'
- **数据自控** (技术特性): README强调'掌控自己的数据'，用户会搜'数据自控AI'或'Private LLM'

### ByteDance-Seed/Tar-1.5B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Tar-1.5B

**关键词列表**:

- **Tar-1.5B** (当前模型品牌名): 从项目名称中提取的当前模型具体名称，是该模型的标识

### zai-org/GLM-4.5-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5-FP8

**关键词列表**:

- **GLM-4.5** (当前模型品牌名): 从项目名称提取的当前模型核心名称，简洁且具有品牌识别度
- **fp8** (技术特性): 当前模型的量化技术特性，README标签中明确标注，用户可能搜索特定量化格式模型
- **混合专家** (技术特性): 当前模型采用的Mixture-of-Experts架构的中文表述，是其核心技术特性
- **推理能力** (功能场景): 当前模型整合的核心能力之一，用户搜索模型功能时的关键需求点
- **编码能力** (功能场景): 当前模型在ARC任务上表现优异的核心功能，针对编程相关用户的搜索需求
- **3550亿参数** (参数规格): 当前模型的总参数量，属于主流大模型参数规格，用户会搜索特定参数量级模型

### edbeeching/decision-transformer-gym-hopper-medium

**URL**: https://ai.gitcode.com/hf_mirrors/edbeeching/decision-transformer-gym-hopper-medium

**关键词列表**:

- **Decision-Transformer** (当前模型品牌名): 项目名称明确为Decision Transformer，是当前模型的唯一品牌名称，用户搜索强化学习序列决策模型时会直接使用该术语
- **gym-hopper** (功能场景): Gym Hopper是具体应用场景，用户搜索‘gym-hopper强化学习模型’或‘Hopper机器人控制AI’时会精准匹配，具有明确环境指向性
- **中等轨迹** (技术特性): 模型训练数据为‘中等轨迹’（medium trajectories），是区别于‘expert’或‘random’轨迹的核心数据特征，用户会搜索‘中等轨迹决策Transformer’来匹配特定性能层级
- **决策Transformer** (当前模型品牌名): ‘Decision Transformer’的中文标准译法，中文用户在CSDN等平台搜索时常用中文术语，需作为独立关键词覆盖中英文搜索习惯
- **连续控制** (功能场景): Gym Hopper属于连续控制环境，用户搜索‘连续控制强化学习模型’时会匹配该术语，且与离散控制模型形成明确区分
- **归一化系数** (技术特性): 模型需配合特定mean/std归一化参数使用，这是部署该模型的关键技术细节，用户搜索‘Decision Transformer 归一化参数’时会精准找到本项目

### ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8

**关键词列表**:

- **Tifa-DeepSexV2** (当前模型品牌名): 项目名称中直接出现的模型品牌名称，用户搜索时会使用该名称定位模型
- **角色扮演** (功能场景): 模型专注于角色扮演体验，是用户寻找角色扮演对话模型时的核心需求
- **MGRPO算法** (技术特性): 模型采用的创新型 MGRPO 算法，是区别于其他模型的独特技术亮点
- **WebUI在线试用** (部署工具): 提供基于 WebUI 的在线试用入口，用户常以此关键词搜索可直接体验模型
- **GGUF-Q8量化** (技术特性): 模型以 GGUF 格式提供 Q8 量化版本，满足对高效推理模型的搜索需求
- **百万字上下文** (技术特性): 模型支持约 100 万字的上下文长度，是长文本处理场景下的关键卖点

### jadechoghari/mar

**URL**: https://ai.gitcode.com/hf_mirrors/jadechoghari/mar

**关键词列表**:

- **MAR** (当前模型品牌名): 从项目名称jadechoghari/mar提取的当前模型名称
- **自回归图像生成** (功能场景): 当前模型的核心功能场景
- **无需矢量量化** (技术特性): 当前模型区别于传统方法的核心技术特性
- **连续值空间** (技术特性): 当前模型运作的技术空间特性
- **扩散损失函数** (技术特性): 当前模型实现高效生成的关键技术组件
- **DiffusionPipeline** (部署工具): 当前模型的官方加载部署工具
- **marhuge** (参数规格): 当前模型提供的高端参数规格选项

### Genereux-akotenou/genomics-tf-prediction

**URL**: https://ai.gitcode.com/hf_mirrors/Genereux-akotenou/genomics-tf-prediction

**关键词列表**:

- **genomics-tf-prediction** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Tabular-Classification** (功能场景): 当前模型的主要功能场景，即表格分类
- **biology** (功能场景): 当前模型应用的领域，即生物学，具有明确的应用场景

### city96/Wan2.1-T2V-14B-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/city96/Wan2.1-T2V-14B-gguf

**关键词列表**:

- **Wan2.1-T2V-14B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **FP16版本** (技术特性): 目前仅上传了FP16版本，是当前模型的一个技术版本特性

### PekingU/rtdetr_r101vd_coco_o365

**URL**: https://ai.gitcode.com/hf_mirrors/PekingU/rtdetr_r101vd_coco_o365

**关键词列表**:

- **RT-DETR** (当前模型品牌名): 项目名称中直接使用的模型名称
- **不确定性最小化查询** (技术特性): 模型提出的查询选择机制，用于提升解码器的初始查询质量
- **高效混合编码器** (技术特性): 通过解耦尺度内交互与跨尺度融合，实现多尺度特征的快速处理
- **可调解码层** (技术特性): 支持在不重新训练的情况下通过调节解码层数实现灵活的速度/精度平衡
- **Objects365预训练** (技术特性): 模型在 Objects365 数据集上进行预训练，显著提升 AP 表现
- **R101VD** (模型规格): 使用 R101VD 骨干网络的模型变体，代表模型的规模与结构

### joeddav/bart-large-mnli-yahoo-answers

**URL**: https://ai.gitcode.com/hf_mirrors/joeddav/bart-large-mnli-yahoo-answers

**关键词列表**:

- **bart-large-mnli-yahoo-answers** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **主题分类** (功能场景): 当前模型针对的具体任务场景
- **text-classification** (技术特性): 当前模型的技术标签类型
- **Yahoo-Answers** (技术特性): 当前模型微调使用的特定数据集
- **zero-shot-classification管道** (部署工具): 当前模型推荐的调用方式
- **hypothesistemplate** (技术特性): 当前模型使用时需指定的关键参数模板

### stanfordmimi/synthpose-vitpose-base-hf

**URL**: https://ai.gitcode.com/hf_mirrors/stanfordmimi/synthpose-vitpose-base-hf

**关键词列表**:

- **SynthPose** (当前模型品牌名): 项目名称为 stanfordmimi/synthpose-vitpose-base-hf，模型核心品牌名为 SynthPose，是当前模型唯一专属名称
- **VitPose-Base** (技术特性): 模型基于 VitPose Base 骨干网络，是其核心技术架构，且非通用术语，具有模型专属性
- **52关键点检测** (功能场景): 模型可预测52个密集人体关键点，区别于COCO的17点，是其核心应用场景和差异化功能
- **运动学分析** (功能场景): 模型专为运动学分析设计，用于生物力学与运动捕捉系统，是其明确的垂直应用方向
- **合成数据微调** (技术特性): 模型创新点在于使用合成数据对2D姿态模型进行微调，是其核心方法论，非通用术语
- **OpenCapBench** (功能场景): 模型是为OpenCapBench基准测试专门构建，该名称是其应用场景的专属标签，非通用词

### lerobot/pi0

**URL**: https://ai.gitcode.com/hf_mirrors/lerobot/pi0

**关键词列表**:

- **Pi0** (当前模型品牌名): 项目名称即为 Pi0，直接提取为模型的品牌名称
- **机器人控制** (功能场景): 模型用于通用机器人的控制任务，是核心应用场景
- **视觉语言动作流** (技术特性): 论文中描述的核心技术——将视觉、语言与动作统一建模的流式结构
- **LeRobot平台** (部署工具): 模型已在 LeRobot 框架中完成集成，可直接在该平台使用
- **策略微调** (功能场景): README 提供了在自有数据集上进行微调的完整示例
- **Pi0Policy** (模型组件): 模型提供的 Python 类名，用于加载和执行策略推理
- **动作选择** (功能场景): 模型的主要输出是机器人动作的选择，体现其决策能力

### Helsinki-NLP/opus-mt-nl-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-nl-en

**关键词列表**:

- **opus-mt-nl-en** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **荷兰语英语翻译** (功能场景): 当前模型的核心功能，源语言nl(荷兰语)到目标语言en(英语)的翻译
- **SentencePiece分词** (技术特性): 当前模型预处理阶段采用的关键技术，具有技术指向性

### clefourrier/graphormer-base-pcqm4mv1

**URL**: https://ai.gitcode.com/hf_mirrors/clefourrier/graphormer-base-pcqm4mv1

**关键词列表**:

- **Graphormer** (当前模型品牌名): 从项目名称 clefourrier/graphormer-base-pcqm4mv1 中提取的核心模型品牌名，是该模型的唯一标识，用户搜索图神经网络模型时会直接使用此名称
- **图分类** (功能场景): 模型明确用于图分类任务，是用户在AI领域搜索图神经网络应用场景时的核心关键词，具有明确搜索意图
- **分子建模** (功能场景): README明确指出该模型最可能应用于分子建模，是化学AI与药物发现领域的高价值垂直场景词，区别于通用图学习
- **PCQM4M-LSC** (当前模型品牌名): 模型在PCQM4M-LSC数据集上预训练并夺冠，该名称是模型训练基准的专有标识，专业用户会以此搜索特定性能模型
- **图Transformer** (技术特性): 模型本质是图结构上的Transformer架构，该术语是学术界和工业界对这类模型的通用技术命名，具有高搜索价值
- **KDD-CUP-2021** (当前模型品牌名): 模型在KDD CUP 2021量子预测赛道获得第一名，该竞赛名称是模型权威性的关键标签，专业用户会以此检索竞赛优胜模型
- **arxiv2106.05234** (当前模型品牌名): 论文ID是模型的唯一学术索引，研究者常直接搜索arxiv编号查找原始模型，具有极强的精准搜索属性

### OpenGVLab/InternVideo2_5_Chat_8B

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVideo2_5_Chat_8B

**关键词列表**:

- **InternVideo2.5** (当前模型品牌名): 项目标题中的核心模型名称，用户会直接搜索
- **视频多模态大模型** (功能场景): README明确给出的定位，用户搜索视频理解类模型常用词
- **长时序视频理解** (功能场景): 模型主打LRC能力，用户想找能处理长视频的大模型时会搜
- **INT4量化** (部署工具): 官方给出INT4速度数据，想低显存部署的用户会搜
- **HiCo时空压缩** (技术特性): 模型独有的层级token压缩技术，技术向用户会搜

### timm/vit_base_patch14_dinov2.lvd142m

**URL**: https://ai.gitcode.com/hf_mirrors/timm/vit_base_patch14_dinov2.lvd142m

**关键词列表**:

- **ViT-Base-DINOv2** (当前模型品牌名): 从项目名称提取的完整模型名称，包含ViT结构和DINOv2预训练信息
- **timm库** (部署工具): 模型通过timm库创建和加载，适合在Python环境中直接调用
- **DINOv2预训练** (技术特性): 使用最新的DINOv2自监督算法在大规模数据上预训练，保证鲁棒视觉特征
- **86M参数** (参数规格): 模型参数量约为86.6百万，属于轻量级视觉Transformer
- **LVD-142M数据集** (数据集): 模型在LVD-142M大规模图像数据集上进行预训练，覆盖丰富的视觉场景

### zai-org/GLM-4.5-Air-Base

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5-Air-Base

**关键词列表**:

- **混合推理** (技术特性): 模型核心架构特点，支持思维/非思维双模式切换
- **FP8量化** (技术特性): 模型发布的关键技术形态，提升部署效率

### DAMO-NLP-SG/VideoLLaMA3-7B

**URL**: https://ai.gitcode.com/hf_mirrors/DAMO-NLP-SG/VideoLLaMA3-7B

**关键词列表**:

- **VideoLLaMA3-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **跨场景视觉内容处理** (技术特性): 当前模型在跨场景视觉内容处理与解析方面展现出卓越能力
- **文本-视觉信息融合** (技术特性): 当前模型专门针对复杂多模态挑战设计，包括文本-视觉信息融合
- **序列视频数据洞察提取** (技术特性): 当前模型专门针对复杂多模态挑战设计，包括序列视频数据洞察提取
- **动态静态视觉场景推理** (技术特性): 当前模型专门针对复杂多模态挑战设计，包括对动态与静态视觉场景的高层次推理

### Qwen/Qwen2.5-VL-32B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-32B-Instruct

**关键词列表**:

- **阿里大模型-Qwen2.5-VL-32B-Instruct** (当前模型品牌名): 从项目名称提取的当前完整模型名称，体现品牌及具体型号
- **视觉代理推理** (功能场景): 当前模型具备直接作为视觉代理进行推理并动态调用工具的功能
- **长视频理解** (功能场景): 当前模型可解析超过1小时的视频内容，是重要的功能应用场景
- **结构化输出** (功能场景): 当前模型针对发票扫描件、表单、表格等数据支持内容结构化输出，属于特定功能场景
- **动态分辨率训练** (技术特性): 当前模型在视频理解上采用动态分辨率与帧率训练，是其独特的技术特性
- **数学能力提升** (功能场景): 当前模型通过强化学习提升了数学与解题能力，是突出的功能特性场景

### amazon/chronos-bolt-small

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-bolt-small

**关键词列表**:

- **直接多步预测** (技术特性): 模型独有的预测方法论，技术术语但具区分度，专业用户会用此词搜索特定架构

### microsoft/tapex-base-finetuned-wikisql

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-base-finetuned-wikisql

**关键词列表**:

- **tapex-base** (当前模型品牌名): 从项目名称提取的当前模型简化名称
- **表格推理能力** (技术特性): 模型的核心技术功能
- **seq2seq** (技术特性): 模型采用的序列转换技术框架

### BAAI/bge-m3

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-m3

**关键词列表**:

- **BGE-M3** (当前模型品牌名): 项目名称即为模型的品牌名称
- **多功能检索** (技术特性): 模型同时支持密集检索、稀疏检索和多向量检索，具备多功能性
- **多粒度嵌入** (技术特性): 模型可接受从短句到最长 8192 token 的长文档，具备多粒度处理能力
- **稀疏检索** (功能场景): 模型支持基于 token 权重的稀疏检索，类似 BM25
- **混合检索** (功能场景): 模型可在检索管道中结合密集检索与稀疏检索，实现更高准确性

### lmms-lab/LLaVA-Video-7B-Qwen2

**URL**: https://ai.gitcode.com/hf_mirrors/lmms-lab/LLaVA-Video-7B-Qwen2

**关键词列表**:

- **LLaVA-Video** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **视频交互** (功能场景): 当前模型支持的视频处理交互能力
- **图像交互** (功能场景): 当前模型支持的图像内容交互能力
- **多图像交互** (功能场景): 当前模型支持的多图像内容处理能力

### monologg/koelectra-small-v2-distilled-korquad-384

**URL**: https://ai.gitcode.com/hf_mirrors/monologg/koelectra-small-v2-distilled-korquad-384

**关键词列表**:

- **koelectra-small-v2** (当前模型品牌名): 从项目名称 monologg/koelectra-small-v2-distilled-korquad-384 中提取的核心模型品牌名，去除了冗余后缀，符合简洁品牌名规范
- **KorQuAD** (功能场景): KorQuAD 是当前模型训练所基于的韩语问答数据集，代表其核心应用场景为韩语阅读理解，是用户搜索韩语NLP模型时的明确意图词
- **韩语问答** (功能场景): KorQuAD 的实际用途是韩语机器阅读理解（Machine Reading Comprehension），用户搜索韩语AI模型时会直接使用‘韩语问答’这一中文意图词
- **轻量级模型** (技术特性): 模型名称含‘small’和‘distilled’，表明其为蒸馏轻量版本，符合‘轻量级模型’这一用户高频搜索词，且未被强制排除列表包含
- **韩语BERT** (技术特性): KoELECTRA 是韩语领域的BERT变体，用户常搜索‘韩语BERT’来寻找韩语预训练语言模型，该词具有明确搜索意图且未被禁用
- **distilled模型** (技术特性): 模型明确标注为‘distilled’，代表使用知识蒸馏技术压缩，是技术型用户搜索高效轻量模型时的精准关键词

### facebook/mbart-large-50-many-to-many-mmt

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/mbart-large-50-many-to-many-mmt

**关键词列表**:

- **mbart-large-50** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多对多机器翻译** (功能场景): 当前模型的主要功能应用场景
- **53种语言** (功能场景): 体现了该模型在语言翻译方面的覆盖范围这一独特特性
- **forcedbostokenid参数** (技术特性): 该模型在翻译时用于强制目标语言ID作为第一个生成标记的技术特性，具有区分度

### facebook/mms-lid-256

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/mms-lid-256

**关键词列表**:

- **MMS-LID** (当前模型品牌名): 从项目名称提取的当前模型简称，用户搜索时常用
- **语种识别** (功能场景): 模型核心能力，用户会直接搜索'语种识别模型'
- **256种语言** (功能场景): 支持语言数量是用户选型关键指标
- **Wav2Vec2** (技术特性): 底层架构名称，技术用户常用作搜索词
- **10亿参数** (参数规格): 主流大模型规格，用户对比时会搜索
- **语音语言识别** (功能场景): 完整任务名称，长尾搜索词

### nomic-ai/nomic-embed-text-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/nomic-ai/nomic-embed-text-v1.5

**关键词列表**:

- **nomic-embed-text-v1.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **MTEB** (技术特性): README中多次提及MTEB，是该模型的核心技术特性

### MohamedRashad/Voxtral-Small-24B-2507-transformers

**URL**: https://ai.gitcode.com/hf_mirrors/MohamedRashad/Voxtral-Small-24B-2507-transformers

**关键词列表**:

- **Voxtral** (当前模型品牌名): 从项目名称提取的当前模型核心品牌名，符合简化规则（去除版本号和后缀），是用户搜索该模型时最直接的关键词
- **音频理解** (功能场景): 模型核心功能，强调'音频理解'能力，用户常搜索此类专业场景词，且未被排除列表覆盖
- **语音问答** (功能场景): 基于'内置问答和摘要功能'及'通过音频直接提问'的描述，是用户搜索语音交互场景的精准关键词，符合功能场景维度

### autogluon/tabpfn-mix-1.0-classifier

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/tabpfn-mix-1.0-classifier

**关键词列表**:

- **上下文学习** (技术特性): 模型采用与TabPFN类似的上下文学习预训练策略，是区别于传统表格模型的核心技术亮点，用户会搜索此类方法
- **合成数据预训练** (技术特性): 模型在纯合成数据集上预训练，这一独特训练方式是其区别于其他表格模型的关键特征，具有搜索价值
- **AutoGluon分类器** (功能场景): 模型通过AutoGluon库调用，用户搜索'AutoGluon 分类器'时会精准定位此模型，是工具链+功能的组合关键词

### Qwen/Qwen2.5-VL-3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-3B-Instruct

**关键词列表**:

- **Qwen2.5-VL-3B-Instruct** (当前模型品牌名): 完整的模型名称，直接对应项目标题
- **视觉智能体** (功能场景): 模型可直接作为视觉智能体进行推理并动态调用工具
- **事件捕捉** (功能场景): 能够精准定位视频片段中的关键事件
- **多格式视觉定位** (技术特性): 生成边界框或坐标点并输出JSON格式的定位数据
- **动态FPS采样** (技术特性): 通过动态帧率采样实现视频分辨率的时序适配与精准时间定位

### ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q4

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q4

**关键词列表**:

- **Tifa-DeepsexV2** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **roleplay** (功能场景): 当前模型的核心功能场景，用户搜索角色扮演类AI模型时会使用
- **sft** (技术特性): 当前模型的训练方式，用户搜索模型训练方法时会使用
- **MGRPO** (技术特性): 当前模型创新的训练算法，具有独特性的技术关键词
- **incremental-pretraining** (技术特性): 当前模型的预训练方式，用户搜索相关技术时会使用
- **cot** (技术特性): 当前模型的技术标签，用户搜索思维链相关模型时会使用

### Prior-Labs/TabPFN-v2-reg

**URL**: https://ai.gitcode.com/hf_mirrors/Prior-Labs/TabPFN-v2-reg

**关键词列表**:

- **TabPFN-v2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Prior-Labs** (当前模型品牌名): 当前模型的开发者，可作为模型相关品牌标识
- **Foundation-Model** (技术特性): 表明该模型是基础模型，是模型的技术特性体现
- **Transformer-based** (技术特性): 说明模型基于Transformer架构，是技术特性
- **Prior-data-based-learning** (技术特性): 是该模型利用先验数据进行学习的技术特性

### clefourrier/graphormer-base-pcqm4mv2

**URL**: https://ai.gitcode.com/hf_mirrors/clefourrier/graphormer-base-pcqm4mv2

**关键词列表**:

- **图-Transformer** (技术特性): 模型类型为‘Graphormer’，其本质是基于Transformer的图神经网络，‘图 Transformer’是用户搜索图结构建模技术时的常用组合词，非通用词且未被排除
- **PCQM4M-LSCv2** (当前模型品牌名): 模型基于PCQM4M-LSCv2数据集预训练，该名称是模型训练背景的核心标识，属于当前模型专属的命名组成部分，用户在学术搜索中会精准使用
- **MIT许可** (技术特性): 模型采用MIT协议，是开发者关注开源可用性的关键筛选条件，虽非算法特性，但属于模型部署决策中的高价值标签，且未被高频词排除

### tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa

**URL**: https://ai.gitcode.com/hf_mirrors/tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa

**关键词列表**:

- **DocVQA微调** (功能场景): 模型在 DocVQA 数据集上进行微调，针对文档视觉问答任务
- **文档视觉问答** (功能场景): 模型用于对文档图片进行问答，满足文档视觉问答需求
- **文档问答模型** (功能场景): 该模型专注于文档内容的问答，属于文档问答模型类别
- **布局语言模型** (技术特性): 模型基于布局感知的语言模型（LayoutLM），具备文档布局理解能力
- **文档结构理解** (技术特性): 模型能够解析文档的结构信息，为后续问答提供支撑

### Qwen/Qwen2-VL-2B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2-VL-2B-Instruct

**关键词列表**:

- **Qwen2-VL** (当前模型品牌名): 从项目名称提取的当前模型核心名称（简化版本，符合名称简化规则）
- **视频问答** (功能场景): 当前模型支持20分钟以上视频理解的核心应用场景
- **智能设备控制** (功能场景): 当前模型可集成到手机、机器人等设备实现自动操作的应用场景
- **视觉环境交互** (技术特性): 当前模型基于视觉环境进行决策的核心技术特性
- **2B参数** (参数规格): 当前模型的参数规格（项目名称明确包含2B，且未在高频排除列表中）
- **多分辨率图像** (技术特性): 当前模型对不同分辨率和比例图像的SOTA理解能力

### naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric

**URL**: https://ai.gitcode.com/hf_mirrors/naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric

**关键词列表**:

- **MASt3RViTLarge** (当前模型品牌名): 从项目名称提取的当前模型名称
- **三维图像匹配定位** (功能场景): 当前模型的核心功能与应用场景
- **BaseDecoder512** (技术特性): 当前模型解码器部分的技术特性描述
- **catmlpdpt** (技术特性): 当前模型特有的技术标识或模块名称
- **image-to-3d** (功能场景): 当前模型实现图像到三维空间转换的功能描述

### internlm/internlm-xcomposer2d5-7b

**URL**: https://ai.gitcode.com/hf_mirrors/internlm/internlm-xcomposer2d5-7b

**关键词列表**:

- **InternLM-XComposer2.5** (当前模型品牌名): 从项目名称 internlm/internlm-xcomposer2d5-7b 提取的官方模型名称，符合品牌名简化规则（去版本号后为 XComposer2.5），是用户搜索该模型的直接关键词
- **文本图像理解** (功能场景): README 明确提到 'text-image comprehension'，中文对应 '文本图像理解'，是用户搜索多模态模型时的核心意图词，且未被高频词库覆盖
- **图像组合生成** (功能场景): README 中 'composition applications' 指代图像与文本的组合生成能力，中文表达为 '图像组合生成'，区别于通用 '文生图'，具有模型特异性
- **96K长上下文** (技术特性): 模型支持通过 RoPE 扩展至 96K 长上下文，是其核心差异化技术亮点，用户会搜索 '长上下文模型' 或 '96K上下文'，且 '96K' 为当前模型专属数值，非通用参数
- **7B级多模态** (技术特性): 模型以7B参数实现GPT-4V级能力，'7B级多模态' 是用户寻找轻量级高性能多模态模型时的典型搜索词，'级'字体现性能对标，非单纯参数描述，且避开高频词'7B参数'
- **Interleaved图文训练** (技术特性): 模型训练使用24K interleaved image-text contexts，中文术语 ' interleaved图文训练' 是其独特训练方式，专业用户会搜索该术语以区分普通多模态模型

### pcoloc/autotrain-mikrotik-7-7-1860563597

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-mikrotik-7-7-1860563597

**关键词列表**:

- **Mikrotik-7** (当前模型品牌名): 从项目名称提取的当前模型名称
- **AutoTrain回归** (技术特性): 模型由AutoTrain一键训练，主打零代码回归任务
- **joblib模型下载** (部署工具): 模型文件为joblib格式，用户常搜‘joblib模型下载’寻找现成文件
- **R2-0.632** (技术特性): 决定系数0.632是模型核心性能指标，用户搜‘R2 0.6 回归模型’可精准命中
- **表格回归** (功能场景): 标签明确tabular-regression，用户搜表格数据回归模型时会用

### zai-org/GLM-Z1-9B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-Z1-9B-0414

**关键词列表**:

- **指令跟随** (技术特性): 当前模型强化的核心技术能力
- **对话场景** (功能场景): 当前模型进行人类偏好对齐的应用场景

### BAAI/bge-large-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-large-en-v1.5

**关键词列表**:

- **BGE-Large-En** (当前模型品牌名): 从项目名称提取的当前模型名称
- **110B参数** (参数规格): 结合常见大模型参数规格情况，大模型通常有此类较大参数规格，且该模型作为大模型可能有类似量级参数，有一定区分度

### zai-org/glm-4-9b-chat-hf

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-hf

**关键词列表**:

- **多轮对话** (功能场景): 模型支持连续多轮交互，是核心对话能力

### unsloth/gemma-3-270m-it-unsloth-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-unsloth-bnb-4bit

**关键词列表**:

- **Gemma-3-270M** (当前模型品牌名): 从项目名称 unsloth/gemma-3-270m-it-unsloth-bnb-4bit 中提取的核心模型标识，简化去后缀，符合用户搜索习惯（如搜索 'Gemma-3-270M' 而非完整路径）
- **Unsloth量化模型** (部署工具): Unsloth是当前模型特有的高效量化框架，区别于常规4bit量化，用户会搜索'Unsloth量化'来寻找轻量高性能模型
- **Gemma3指令微调** (技术特性): 模型明确标注为'指令微调变体'，且Gemma3是Google最新系列，用户会搜索'Gemma3指令微调'来获取可直接对话的版本
- **32K上下文** (技术特性): 该模型（270M版本）支持32K上下文窗口，是其核心能力之一，且属于主流用户关注的上下文长度规格（非128K等大模型专属）
- **轻量AI模型** (功能场景): README强调'相对较小的尺寸'、'部署在笔记本电脑'，用户搜索'轻量AI模型'是为在本地或低资源环境部署，精准匹配使用场景
- **Gemma3文本生成** (功能场景): 模型明确用于文本生成、问答、摘要，'Gemma3'作为品牌前缀+文本生成是用户精准搜索意图，区别于通用'文本生成'高频词

### openai/diffusers-cd_cat256_l2

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-cd_cat256_l2

**关键词列表**:

- **diffusers-cdcat256l2** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **图像上色** (功能场景): 当前模型支持的零样本数据编辑功能之一
- **超分辨率** (功能场景): 当前模型支持的零样本数据编辑功能之一

### ByteDance-Seed/Seed-OSS-36B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Seed-OSS-36B-Base

**关键词列表**:

- **36B参数** (参数规格): 模型规模为 36 B 参数，是用户在挑选大模型时常用的搜索关键词
- **长上下文** (功能场景): Seed‑OSS‑36B‑Base 以强大的长上下文能力著称，满足需要处理长篇文本的用户需求
- **Agent能力** (技术特性): 模型支持 Agent 框架，可用于构建自主决策的智能系统，是其核心技术亮点
- **Apache-2.0许可** (技术特性): 采用 Apache‑2.0 开源许可证，吸引对许可证有要求的开发者和企业用户

### stepfun-ai/NextStep-1-Large-Pretrain

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large-Pretrain

**关键词列表**:

- **NextStep-1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **140亿参数** (参数规格): 当前模型的参数规模，具有独特性
- **流匹配头** (技术特性): 当前模型搭配流匹配头，是区别于其他模型的技术特性
- **高保真图像合成** (功能场景): 当前模型在图像生成任务中展现出的能力，是用户可能搜索的场景

### unsloth/gpt-oss-20b-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gpt-oss-20b-GGUF

**关键词列表**:

- **gpt-oss-20b** (当前模型品牌名): 从项目名称提取的当前模型名称
- **动态2.0** (技术特性): 提到了Unsloth Dynamic 2.0 GGUFs，动态2.0是该模型相关的技术特性
- **harmony响应格式** (技术特性): 当前模型采用harmony响应格式进行训练，是其独特的技术特性
- **Apache-2.0许可证** (技术特性): 该模型拥有宽松的Apache 2.0许可证，这是其区别于其他模型的一个特性

### Salesforce/blip-image-captioning-base

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip-image-captioning-base

**关键词列表**:

- **BLIP** (当前模型品牌名): 项目名称为Salesforce/blip-image-captioning-base，模型官方名称为BLIP，是当前模型的唯一品牌标识，符合简化命名规则
- **图像描述** (功能场景): 模型核心功能是为图像生成文本描述（image captioning），中文用户搜索‘图像描述’远高于‘图像字幕’等术语，且未在强制排除列表中
- **自举式训练** (技术特性): BLIP核心创新点为‘自举式caption’（bootstrapped captioning），是论文中明确提出的技术术语，具有唯一性且未被高频词覆盖
- **视觉-语言预训练** (技术特性): 模型属于VLP（Visual-Language Pretraining）框架，该术语在论文摘要中反复出现，是区别于纯文本或纯视觉模型的关键分类词
- **噪声数据过滤** (技术特性): BLIP通过‘过滤器去除噪声样本’处理网络爬取数据，这是其区别于其他VLP模型的关键数据处理机制，具独特性
- **ViT-base** (技术特性): 模型明确采用ViT base作为骨干网络，是技术实现的关键组件，用户搜索‘ViT base 图像描述’有明确意图，且未被高频词排除

### zai-org/CogVideoX1.5-5B-SAT

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B-SAT

**关键词列表**:

- **CogVideoX1.5** (当前模型品牌名): 当前模型的版本化名称
- **10秒视频生成** (功能场景): 当前模型的视频长度特性
- **任意分辨率视频** (功能场景): 当前模型的分辨率特性
- **SAT权重** (技术特性): 当前模型的权重版本特性

### inclusionAI/Ling-1T

**URL**: https://ai.gitcode.com/hf_mirrors/inclusionAI/Ling-1T

**关键词列表**:

- **Ling-1T** (当前模型品牌名): 模型名称直接来源于项目仓库名，唯一标识该模型
- **EvoCoT** (技术特性): 模型在中后期训练中采用的进化思维链（Evolutionary Chain‑of‑Thought）技术
- **视觉推理** (功能场景): 模型在视觉推理任务中取得领先成绩，属于独特的能力方向
- **前端代码生成** (功能场景): 模型能够生成符合前端语义与美学的代码，属于专属功能

### pyannote/segmentation

**URL**: https://ai.gitcode.com/hf_mirrors/pyannote/segmentation

**关键词列表**:

- **pyannote-segmentation** (当前模型品牌名): 从项目名称提取的当前模型名称，使用连字符连接英文品牌与功能
- **说话人分割** (功能场景): README中明确标注的核心功能场景，用户搜索意图明确
- **overlapped-speech-detection** (功能场景): 标签中明确标注的专业功能场景，英文术语符合用户搜索习惯
- **pyannote-audio-model** (当前模型品牌名): 标签中明确的模型归属标识，体现品牌与技术领域关联性
- **resegmentation** (技术特性): 标签中独特的技术特性描述，具有专业区分度

### stabilityai/stable-video-diffusion-img2vid-xt-1-1

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-video-diffusion-img2vid-xt-1-1

**关键词列表**:

- **stable-video-diffusion** (当前模型品牌名): 从项目名称 stabilityai/stable-video-diffusion-img2vid-xt-1-1 中提取的核心品牌名，是用户搜索该视频生成模型时最可能使用的关键词
- **图像转视频** (功能场景): README明确标注为'管道标签：图像转视频'，是用户寻找该模型的核心使用意图，精准匹配搜索词
- **img2vid** (功能场景): 模型名称中包含'img2vid'，是AI圈内广泛使用的缩写术语，用户在技术社区常直接搜索该词寻找图像转视频工具
- **Stable-Video-Diffusion** (当前模型品牌名): 模型官方全称，虽含空格但为用户在搜索引擎中可能输入的完整品牌名称，与'Stable Diffusion'系列形成认知关联，具有高搜索价值
- **视频生成** (功能场景): 图像转视频的上位词，用户在CSDN等平台搜索时更倾向使用'视频生成'这类通用但精准的场景词，区别于高频词'文生图'
- **xt-1-1** (当前模型品牌名): 模型版本后缀'xt-1-1'是该模型的唯一标识符，区别于其他Stable Video Diffusion版本，技术用户会精确搜索该版本

### facebook/wav2vec2-base-960h

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/wav2vec2-base-960h

**关键词列表**:

- **facebookwav2vec2-base-960h** (当前模型品牌名): 从项目名称提取的当前模型名称
- **16kHz音频** (技术特性): 模型所用音频样本率为16kHz，使用时语音输入也需采样于16kHz，是独特技术特性
- **librispeechasr** (功能场景): 标签中包含且模型基于Librispeech数据进行预训练，与语音识别场景相关

### facebook/mask2former-swin-large-cityscapes-semantic

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/mask2former-swin-large-cityscapes-semantic

**关键词列表**:

- **Mask2Former** (当前模型品牌名): 项目名称即为模型的官方名称
- **Swin** (技术特性): 模型使用 Swin 作为主干网络，属于关键的骨干架构
- **Cityscapes** (功能场景): 模型在 Cityscapes 数据集上进行语义分割训练，是该数据集的典型应用
- **全景分割** (功能场景): 模型支持全景（panoptic）分割任务，可同时输出实例与语义信息
- **实例分割** (功能场景): Mask2Former 将实例分割视为核心任务，能够分离图像中的独立对象
- **遮蔽注意力** (技术特性): 模型采用遮蔽注意力的 Transformer 解码器，提高分割精度且不增加计算量
- **可变形注意力** (技术特性): 使用多尺度可变形注意力机制取代传统像素解码器，提升模型的空间感知能力

### Qwen/Qwen3-1.7B-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B-FP8

**关键词列表**:

- **Qwen3-1.7B-FP8** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **稠密模型与混合专家模型** (技术特性): 当前模型提供的模型组合，属于独特技术特性
- **思维模式与非思维模式** (技术特性): 当前模型独创性支持的模式切换，属于独特技术特性
- **17亿参数量** (参数规格): 当前模型的参数量，属于独特参数规格

### notmahi/dobb-e

**URL**: https://ai.gitcode.com/hf_mirrors/notmahi/dobb-e

**关键词列表**:

- **DobbE** (当前模型品牌名): 项目名称为notmahi/dobb-e，模型正式名称为Dobb·E，是当前模型的唯一品牌标识
- **居家预训练模型** (功能场景): 模型核心定位是‘居家预训练表征（HPR）’，专为家庭环境机器人设计，是用户搜索家庭机器人AI时的精准意图词
- **HPR** (技术特性): Home Pre-training Representation（居家预训练表征）是该模型提出的核心技术术语，具有独特性且在论文中被重点定义
- **HoNY数据集** (技术特性): 模型基于‘纽约家居（HoNY）’独家数据集训练，该数据集名称是模型区别于其他视觉模型的关键数据标识
- **ResNet34** (技术特性): 模型采用ResNet34架构，是其核心视觉主干网络，属于用户搜索‘机器人视觉模型’时可能使用的具体架构关键词
- **timm模型** (部署工具): 模型通过timm框架一键加载（timm.create_model），是其主要部署方式，区别于HuggingFace常规加载，具有工具独特性
- **arxiv2311.16098** (技术特性): 论文编号arxiv:2311.16098是该模型的官方学术标识，用户在学术搜索中会直接使用该编号查找模型

### Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers

**关键词列表**:

- **视频编辑** (功能场景): 当前模型支持的重要应用场景
- **首尾帧生成视频** (功能场景): 当前模型最新发布的特色功能，具有独特性
- **Wan-VAE** (技术特性): 当前模型的高性能视频编解码架构，属于核心技术特性

### Qwen/Qwen3-32B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B

**关键词列表**:

- **非思考模式** (技术特性): 对应高效对话场景，用户搜索快速响应体验
- **代理能力** (功能场景): 官方强调的工具调用与任务自动化卖点，开发者高频检索
- **YaRN长上下文** (技术特性): 支持128K超长文本，处理长文档用户需求明确

### facebook/maskformer-swin-large-coco

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/maskformer-swin-large-coco

**关键词列表**:

- **MaskFormer** (当前模型品牌名): 模型在项目名称和文档中直接使用的官方名称
- **Swin-Large** (技术特性): 模型采用的大型 Swin Transformer 主干网络，是其核心技术特征
- **COCO全景分割** (功能场景): 模型在 COCO 数据集上进行的全景分割任务，用户常以此关键词检索
- **统一分割范式** (技术特性): 论文提出的将实例、语义、全景分割统一为掩码预测的创新方法
- **掩码预测** (技术特性): 模型核心输出形式，通过预测像素级掩码实现多种分割任务

### google/deplot

**URL**: https://ai.gitcode.com/hf_mirrors/google/deplot

**关键词列表**:

- **DePlot** (当前模型品牌名): 项目名称为google/deplot，模型正式名称为DePlot，是当前模型的唯一品牌标识
- **图表到文本** (功能场景): 模型核心功能是将图表图像转换为线性化表格文本，属于独特应用场景，用户会搜索‘图表转文本’这类精准需求
- **视觉语言推理** (技术特性): 论文明确将‘视觉语言推理’定义为模型解决的核心任务，是区别于普通VQA模型的关键技术标签
- **单样本解决方案** (技术特性): 模型主打‘首个单样本视觉语言推理方案’，是其最突出的创新点，用户会搜索‘单样本图表问答’等关键词
- **图表问答** (功能场景): 模型直接应用于图表问答（Chart QA）任务，是其明确的落地场景，区别于通用VQA，具有高搜索意图
- **模态转换模块** (技术特性): DePlot的核心是‘模态转换模块’，将图像转为表格，这一术语在领域内具独特性，非通用词汇
- **即插即用LLM** (部署方式): 模型设计强调与LLM‘即插即用’，是其架构关键特性，用户可能搜索‘图表模型+LLM联动’等组合词

### google/tapas-small-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-small-finetuned-wtq

**关键词列表**:

- **tapas-small** (当前模型品牌名): 从项目名称google/tapas-small-finetuned-wtq提取的当前模型简化名称
- **wikitablequestions** (功能场景): 当前模型针对的特定任务数据集，标签中明确标注

### facebook/dinov2-small

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-small

**关键词列表**:

- **DINOv2-small** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，用户搜索时会使用该完整标识符
- **ViT特征提取** (功能场景): 模型主要用途是作为ViT编码器提取图像特征，是下游任务的关键入口
- **无监督视觉模型** (技术特性): 模型基于DINOv2的无监督学习方法，区别于有监督CNN/ViT，是核心差异化标签
- **CLS标记特征** (技术特性): 模型使用[CLS]标记输出图像语义表征，是其特征提取机制的关键技术点

### Wan-AI/Wan2.1-VACE-14B

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-VACE-14B

**关键词列表**:

- **图像生成视频** (功能场景): 模型能够根据静态图像生成对应的视频序列
- **视频VAE** (技术特性): 模型配备高性能视频VAE，实现高效的1080P视频编解码

### google/owlv2-large-patch14-ensemble

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlv2-large-patch14-ensemble

**关键词列表**:

- **Open-World-Localization** (功能场景): 当前模型的核心功能场景描述
- **zero-shot-object-detection** (功能场景): 当前模型的核心功能场景描述，零样本目标检测
- **CLIP多模态** (技术特性): 当前模型使用的多模态技术，虽CLIP为通用词，但结合多模态可体现模型特性
- **ViT-like-Transformer** (技术特性): 当前模型使用的视觉特征提取技术特性

### moonshotai/Kimi-VL-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Thinking

**关键词列表**:

- **Kimi-VL-A3B** (当前模型品牌名): 从项目名称提取的当前模型具体名称
- **Kimi-VL-A3B-Thinking** (当前模型品牌名): 当前模型的完整名称，用户可能直接搜索该准确名称
- **Kimi-VL-A3B-Thinking-2506** (当前模型品牌名): 当前模型的新版本名称，用户可能会搜索新旧版本信息
- **混合专家视觉语言模型** (功能场景): 描述了当前模型作为高效开源混合专家（MoE）视觉语言模型（VLM）的功能特性，是独特的功能场景表述
- **长思维变体** (技术特性): 当前模型推出的进阶特性，在技术上具有独特性，是用户可能搜索的区分度高的关键词
- **128K扩展上下文窗口** (技术特性): 当前模型在处理长输入方面的独特技术特性，是区别于其他模型的关键信息
- **原生分辨率视觉编码器MoonViT** (技术特性): 当前模型支持超高清视觉输入理解的独特技术组件，具有较高的区分度

### w11wo/indonesian-roberta-base-posp-tagger

**URL**: https://ai.gitcode.com/hf_mirrors/w11wo/indonesian-roberta-base-posp-tagger

**关键词列表**:

- **indonesian-roberta-base-posp-tagger** (当前模型品牌名): 从项目名称提取的当前模型完整名称，无其他简化品牌名可提取
- **词性标注** (功能场景): 当前模型的核心功能，POSP-tagger对应词性标注任务
- **Indonesian** (功能场景): 当前模型针对印尼语的语言特性，用户可能搜索特定语言模型
- **indonlu数据集** (技术特性): 当前模型微调使用的特定数据集，相关研究者可能搜索
- **MIT** (技术特性): 模型的开源许可证类型，开源社区用户可能关注

### timm/mobilenetv3_small_100.lamb_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/mobilenetv3_small_100.lamb_in1k

**关键词列表**:

- **mobilenetv3small100** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，是用户搜索轻量级图像分类模型时可能使用的精确名称
- **LAMB优化器** (技术特性): 当前模型采用LAMB优化器作为核心训练策略，属于非主流但有辨识度的技术点，用户会搜索‘LAMB优化器 图像分类’等组合
- **EMA权重平均** (技术特性): 模型明确使用EMA权重平均策略，是提升收敛稳定性的关键细节，属于专业用户搜索的高价值技术关键词
- **RMSProp模拟** (技术特性): 模型采用模拟TensorFlow 1.0的RMSProp行为，这一独特实现方式在PyTorch生态中少见，具备搜索区分度
- **阶梯式学习率** (技术特性): 模型使用分步阶梯式指数衰减学习率调度+预热，是训练配置中的具体技术标签，适合进阶用户搜索
- **图像分类骨干网络** (功能场景): 模型明确标注为‘图像分类/特征骨干网络’，是用户在部署轻量模型时常用的搜索意图词，非通用词
- **2.5M参数** (参数规格): 模型参数量为2.5百万，属于轻量级模型的典型规模，用户常搜索‘2M参数 图像分类’等组合，且未被高频词列表排除
- **ImageNet-1k** (训练数据集): 模型在ImageNet-1k上训练，是图像分类领域最权威的数据集标签，用户搜索‘ImageNet-1k 模型’频率高且具指向性

### deepseek-ai/DeepSeek-V3-0324

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3-0324

**关键词列表**:

- **前端Web开发** (功能场景): 当前模型的应用场景，README中明确提及
- **中文写作** (功能场景): 当前模型的应用场景，README中强调中文写作能力
- **R1写作风格** (技术特性): 当前模型的独特技术特性，README中明确提到
- **多轮交互改写** (技术特性): 当前模型的功能特性，README中提及的增强功能
- **中文搜索** (功能场景): 当前模型的应用场景，README中提到的能力增强

### openbmb/MiniCPM-o-2_6

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-o-2_6

**关键词列表**:

- **MiniCPM-o** (当前模型品牌名): 从项目名称提取的当前模型名称
- **实时语音对话** (功能场景): 当前模型的功能场景，从标签中可知具备此能力
- **多模态直播** (功能场景): 项目标题中提及支持多模态直播，是该模型的应用场景
- **语音克隆** (功能场景): 从标签中可知该模型具有语音克隆功能

### timm/resnet18.a1_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/resnet18.a1_in1k

**关键词列表**:

- **ResNet18** (当前模型品牌名): 模型名称直接来源于项目名，用户搜索时会使用该品牌名
- **ImageNet-1k-预训练** (功能场景): 模型在 ImageNet-1k 数据集上预训练，常用于图像分类任务
- **LAMB-优化器** (技术特性): 训练配方中使用的 LAMB 优化器，是模型的关键技术特性之一
- **BCE-损失函数** (技术特性): 模型训练采用的二元交叉熵（BCE）损失函数，区别于常见的交叉熵
- **余弦学习率调度** (技术特性): 使用余弦退火学习率调度并带预热阶段，提升收敛效果
- **7x7-卷积** (技术特性): 模型首层采用单层 7×7 卷积配合池化，是 ResNet-B 架构的显著特征
- **1x1-卷积捷径** (技术特性): 使用 1×1 卷积实现捷径（shortcut）下采样，提升特征融合效率

### google/tapas-large-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-large-finetuned-wtq

**关键词列表**:

- **TAPAS-large** (当前模型品牌名): 从项目名google/tapas-large-finetuned-wtq提取的当前模型核心名称
- **WikiTable问答** (功能场景): 在WTQ数据集微调，用户搜“WikiTable问答”可找到该模型
- **链式微调** (技术特性): README强调依次在SQA→WikiSQL→WTQ链式微调，是独特卖点

### amazon/chronos-bolt-base

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-bolt-base

**关键词列表**:

- **T5架构** (技术特性): 当前模型基于T5编码器-解码器架构

### google/vivit-b-16x2-kinetics400

**URL**: https://ai.gitcode.com/hf_mirrors/google/vivit-b-16x2-kinetics400

**关键词列表**:

- **ViViT** (当前模型品牌名): 从项目名称 'google/vivit-b-16x2-kinetics400' 中提取的核心模型名称，是用户搜索视频Transformer模型时的直接关键词
- **视频视觉变换器** (技术特性): 模型全称中文表述，是论文标题核心术语，用户在中文技术博客中可能直接搜索该完整技术名称
- **arxiv2103.15691** (技术特性): 论文arXiv编号是研究者精准检索原始论文和模型的唯一标识符，属于高价值技术锚点词
- **视频Transformer** (技术特性): 对'ViViT'的通俗中文解释，用户在中文社区搜索视频建模技术时常用该组合词，具有明确语义指向性

### speechbrain/emotion-recognition-wav2vec2-IEMOCAP

**URL**: https://ai.gitcode.com/hf_mirrors/speechbrain/emotion-recognition-wav2vec2-IEMOCAP

**关键词列表**:

- **emotion-recognition-wav2vec2-IEMOCAP** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **情感识别** (功能场景): 当前模型的核心应用场景
- **audio-classification** (功能场景): 当前模型的技术应用类型
- **IEMOCAP** (技术特性): 当前模型训练使用的数据集
- **注意力统计池化** (技术特性): 当前模型提取嵌入特征的核心技术

### Xenova/slimsam-77-uniform

**URL**: https://ai.gitcode.com/hf_mirrors/Xenova/slimsam-77-uniform

**关键词列表**:

- **SlimSAM** (当前模型品牌名): 从项目名称 Xenova/slimsam-77-uniform 提取的简洁模型名称
- **掩码生成** (功能场景): 模型的核心输出是针对指定点的掩码，用户常以“掩码生成”搜索相关模型
- **轻量化SAM** (技术特性): 相较原始 SAM，模型经过裁剪和优化，属于轻量化的 SAM 变体
- **JavaScript推理** (部署工具): 模型可直接在浏览器或 Node.js 环境中使用 Transformers.js 进行推理，符合 JavaScript 推理需求

### briaai/RMBG-1.4

**URL**: https://ai.gitcode.com/hf_mirrors/briaai/RMBG-1.4

**关键词列表**:

- **RMBG-1.4** (当前模型品牌名): 从项目名称提取的当前模型名称
- **BRIA-AI** (当前模型品牌名): 模型开发者品牌名称，属于当前模型标识
- **background-removal** (功能场景): 当前模型的核心功能，用户搜索意图明确
- **remove-background** (功能场景): 模型功能的直接表述，符合用户搜索习惯
- **Image-Segmentation** (技术特性): 模型所属的技术领域分类，具有明确指向性
- **transformers.js** (部署工具): 模型支持的部署框架，针对前端场景的技术特性

### google/tapas-base-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-base-finetuned-wtq

**关键词列表**:

- **googletapas-base-finetuned-wtq** (当前模型品牌名): 从项目名称提取的当前模型名称
- **chain-case微调** (技术特性): 该模型随后依次在多个数据集上进行链式微调
- **small参数** (参数规格): 是当前模型涉及的参数规格之一，用户可能会按参数规格搜索模型

### amazon/chronos-t5-base

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-t5-base

**关键词列表**:

- **Chronos-T5** (当前模型品牌名): 从项目名称直接提取的当前模型品牌名，是用户搜索该时间序列模型的核心关键词
- **自回归时间序列** (技术特性): 模型推理阶段的关键技术特征，区别于传统回归模型，具有独特性且未被高频词覆盖
- **4096标记词汇表** (技术特性): 模型核心架构创新点（相比T5的32K），虽含数字但属于模型专属技术标识，非通用性能指标

### Salesforce/blip-image-captioning-large

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip-image-captioning-large

**关键词列表**:

- **图像描述生成** (功能场景): 模型的核心任务是为图像生成自然语言描述，属于典型的图像‑文本生成场景
- **自举标注** (技术特性): BLIP 采用的自举标注技术用于高效利用噪声图像‑文本对，是模型的独特技术亮点
- **条件生成** (技术特性): 模型支持在给定文本提示下生成对应的图像描述，属于条件生成能力
- **无条件生成** (技术特性): 模型还能在没有任何提示的情况下直接生成图像描述，体现其自回归生成特性
- **零样本视频语言** (功能场景): BLIP 在零样本设置下可迁移至视频语言任务，展示跨模态零样本推理能力

### dima806/fairface_age_image_detection

**URL**: https://ai.gitcode.com/hf_mirrors/dima806/fairface_age_image_detection

**关键词列表**:

- **fairfaceageimagedetection** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像年龄检测** (功能场景): 当前模型的主要应用场景
- **年龄组分类** (功能场景): 当前模型的核心功能描述

### google-bert/bert-base-uncased

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-base-uncased

**关键词列表**:

- **BERT-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **下一句预测** (技术特性): 当前模型的另一预训练任务
- **双向表征** (技术特性): BERT区别于自回归模型的关键能力
- **英文预训练** (功能场景): 用户搜索英文NLP任务时常用关键词
- **uncased模型** (技术特性): 大小写不敏感版本，用户选型时会搜

### amazon/chronos-t5-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-t5-tiny

**关键词列表**:

- **t5-efficient-tiny** (技术特性): 当前模型chronos-t5-tiny的基础架构，属于模型自身技术特性
- **自回归预测** (技术特性): 根据README中推理阶段通过自回归方式采样令牌的描述，提炼的核心技术特性
- **概率预测** (功能场景): README提到通过多次轨迹采样获得预测分布，属于模型关键功能特点

### LLM-Research/Molmo-7B-D-0924

**URL**: https://ai.gitcode.com/hf_mirrors/LLM-Research/Molmo-7B-D-0924

**关键词列表**:

- **Molmo** (当前模型品牌名): 从项目名称 'Molmo-7B-D-0924' 提取的核心品牌名，符合简化规则，是用户搜索该模型的唯一标识
- **PixMo** (技术特性): Molmo专用训练数据集名称，具有唯一性，是模型技术背景的核心标识，非通用词，用户可能搜索'PixMo数据集'了解模型训练来源
- **olmo** (技术特性): 标签中明确包含'olmo'，是Molmo系列的底层架构前缀，虽拼写简略但为官方术语，具有技术辨识度且未被高频使用
- **CLIP视觉backbone** (技术特性): 模型明确使用OpenAI CLIP作为视觉骨干，该组合是Molmo架构的独特技术点，用户可能搜索'CLIP视觉backbone'来对比多模态模型设计

### openbmb/MiniCPM4.1-8B

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM4.1-8B

**关键词列表**:

- **MiniCPM4.1** (当前模型品牌名): 项目名称中包含的模型系列名称，用户搜索时会直接使用该品牌名
- **稀疏注意力** (技术特性): 模型采用可训练稀疏注意力机制，是其核心技术亮点
- **双模式推理** (技术特性): 支持深度推理模式与非推理模式双模式运行，区别于单一推理方式
- **思维链融合** (技术特性): 模型具备融合思维链的能力，提升生成质量和连贯性
- **GPTQ量化** (部署工具): 提供 GPTQ 格式的量化模型，方便用户在资源受限环境下部署
- **AutoAWQ量化** (部署工具): 提供 AutoAWQ 格式的量化模型，满足不同量化需求的用户

### unsloth/gemma-3-27b-it-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-27b-it-GGUF

**关键词列表**:

- **Gemma-3** (当前模型品牌名): 从项目名称'unsloth/gemma-3-27b-it-GGUF'提取的核心模型名称，用户搜索AI模型时会直接使用'Gemma 3'作为关键词
- **27B参数** (参数规格): 项目名称中明确包含'27b'，表示27B参数规格，用户在搜索模型时会关注具体参数规模
- **Ollama** (部署工具): README中明确提及模型支持Ollama部署，用户在本地部署模型时会搜索Ollama相关关键词

### facebook/sam-vit-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam-vit-large

**关键词列表**:

- **facebooksam-vit-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ViT-Large** (技术特性): 当前模型是Segment Anything模型的ViT Large (ViT-L) 版本，是其技术特性体现
- **零样本性能** (技术特性): 该模型在各种分割任务中展现出强大的零样本性能，是重要的技术特性
- **SA-1B数据集** (技术特性): 模型基于包含1100万张图像和11亿个掩码的SA - 1B数据集训练，是模型的一个关键特性

### myshell-ai/MeloTTS-Spanish

**URL**: https://ai.gitcode.com/hf_mirrors/myshell-ai/MeloTTS-Spanish

**关键词列表**:

- **MeloTTS** (当前模型品牌名): 从项目名称提取的当前模型名称
- **CPU实时推理** (技术特性): 当前模型的部署性能特点
- **Spanish** (功能场景): 当前模型支持的特定语言
- **中英文混合** (技术特性): 当前模型的中文发音人特色功能

### facebook/detr-resnet-101

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/detr-resnet-101

**关键词列表**:

- **DETR-ResNet-101** (当前模型品牌名): 从项目名称提取的当前模型名称
- **编码器-解码器** (技术特性): 当前模型的核心架构特性
- **对象查询** (技术特性): 当前模型用于检测图像中对象的核心技术

### stabilityai/stable-video-diffusion-img2vid

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-video-diffusion-img2vid

**关键词列表**:

- **latent-扩散模型** (技术特性): 模型采用潜在空间的扩散技术进行视频生成
- **14帧短视频** (技术特性): 模型在相同尺寸上下文帧下生成固定的 14 帧视频片段
- **576x1024-分辨率** (技术特性): 模型输出视频的分辨率为 576×1024，属于高分辨率视频
- **f8-decoder-微调** (技术特性): 对广泛使用的 f8‑decoder 进行微调，以提升时间一致性
- **逐帧解码器** (技术特性): 提供了带标准逐帧解码器的模型版本，便于逐帧处理
- **视频质量提升** (功能场景): 用户研究表明该模型在视频质量上优于同类模型

### Helsinki-NLP/opus-mt-zh-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-zh-en

**关键词列表**:

- **opus-mt-zh-en** (当前模型品牌名): 项目名称直接为Helsinki-NLP/opus-mt-zh-en，该名称是模型在Hugging Face和GitCode上的唯一标识，用户搜索翻译模型时会直接使用此标准化命名
- **汉英翻译** (功能场景): README明确说明源语言为中文、目标语言为英语，‘汉英翻译’是用户在CSDN等平台搜索中文到英文翻译模型时的高频意图词，且未被高频词列表排除
- **CC-BY-4.0翻译模型** (技术特性): 许可证为CC-BY-4.0，属于开放商用许可，用户在寻找可商用、无版权风险的翻译模型时会使用此组合关键词，具有法律属性区分度
- **赫尔辛基大学翻译模型** (当前模型品牌名): 开发机构为赫尔辛基大学语言技术研究组，该机构在NLP领域有权威性，用户可能搜索‘赫尔辛基大学 翻译模型’来查找其开源成果

### stabilityai/stable-diffusion-2-1

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-diffusion-2-1

**关键词列表**:

- **StableDiffusion2-1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本到图像生成** (功能场景): 当前模型的应用场景，可根据文本提示生成和修改图像
- **潜在扩散模型** (技术特性): 当前模型属于潜在扩散模型这一技术类型
- **ComfyUI部署** (部署工具): 结合常见使用场景，ComfyUI是可用于部署该模型的工具，且未在高频排除词中
- **固定预训练文本编码器** (技术特性): 当前模型使用了固定的预训练文本编码器（OpenCLIP - ViT/H），这是其技术特性之一

### microsoft/trocr-base-handwritten

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/trocr-base-handwritten

**关键词列表**:

- **TrOCR-base** (当前模型品牌名): 从项目名称microsoft/trocr-base-handwritten提取的当前模型简化名称
- **手写体OCR** (功能场景): 当前模型针对手写体文本的光学字符识别功能
- **编码器-解码器模型** (技术特性): 当前模型采用的图像编码器+文本解码器架构
- **自回归生成** (技术特性): 当前模型文本解码器自回归生成tokens的技术特点
- **IAM数据集** (技术特性): 当前模型专门在IAM手写体数据集上微调的关键训练背景
- **单行文本识别** (功能场景): 当前模型针对单行文本图像OCR的具体应用场景

### Wan-AI/Wan2.2-I2V-A14B

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.2-I2V-A14B

**关键词列表**:

- **720P24fps** (功能场景): 模型核心能力是生成720P分辨率24帧率视频，是用户区分性能的重要搜索词，非通用形容词
- **I2V-A14B** (当前模型品牌名): 项目名称中明确包含I2V-A14B，是Wan2.2系列下专用于图像到视频的子模型，具有唯一标识性
- **电影级美学** (技术特性): 模型通过精细标注数据实现电影级风格生成，是区别于其他模型的独特美学能力描述
- **复杂运动生成** (技术特性): README明确强调‘复杂运动生成’能力提升，是模型在运动表现上的核心差异化特性
- **50亿参数** (参数规格): 50亿参数是模型公开披露的主流规格参数，属于用户可搜索的典型规模层级，非边缘数值

### Qwen/Qwen2.5-Omni-7B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B

**关键词列表**:

- **Qwen2.5-Omni** (当前模型品牌名): 完整的模型名称，直接对应项目名称，用户搜索时会使用该品牌名
- **ThinkerTalker-架构** (技术特性): 模型提出的端到端多模态创新架构，是其核心技术亮点，用户会以此关键词了解模型结构
- **TMRoPE-位置编码** (技术特性): 时间对齐多模态 RoPE（TMRoPE）位置编码技术，实现音视频同步，是模型独有的技术特性
- **实时音视频对话** (功能场景): 模型支持分块输入与即时输出，适用于实时音视频交互的应用场景
- **端到端语音指令跟随** (技术特性): 在 MMLU、GSM8K 等基准测试中表现出与文本输入相当的指令跟随能力，体现模型的端到端语音理解与执行能力
- **OmniBench** (技术特性): 模型在多模态融合任务的评测基准 OmniBench 中取得最先进性能，是其竞争力的重要体现

### openai/whisper-base.en

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-base.en

**关键词列表**:

- **whisper-base.en** (当前模型品牌名): 从项目名称提取的当前模型名称
- **序列到序列模型** (技术特性): 当前模型的技术架构类型
- **74M参数** (参数规格): 当前模型的参数规格
- **英语语音识别** (功能场景): 当前模型专注的语言识别场景
- **弱监督训练** (技术特性): 当前模型的训练方式技术特性

### LiquidAI/LFM2-350M-ENJP-MT

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-ENJP-MT

**关键词列表**:

- **LFM2-350M-ENJP-MT** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **日语英语双向翻译** (功能场景): 当前模型的核心功能，实现日语和英语的双向翻译
- **近实时翻译** (功能场景): 当前模型在翻译任务上的特点，可实现近实时的翻译效果
- **中短文本翻译** (功能场景): 当前模型擅长的翻译文本类型，针对中短文本进行翻译
- **翻译质量媲美大模型** (技术特性): 当前模型在翻译质量上的优势，可媲美规模超其10倍以上的模型

### stabilityai/stable-diffusion-2-inpainting

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-diffusion-2-inpainting

**关键词列表**:

- **Stable-Diffusion-2** (当前模型品牌名): 项目名称直接给出的模型主品牌
- **潜在扩散** (技术特性): 基于 Latent Diffusion 架构，用户常搜此关键词
- **512分辨率** (参数规格): 模型默认输出 512×512，用户搜索时会带分辨率

### stepfun-ai/Step-Audio-AQAA

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/Step-Audio-AQAA

**关键词列表**:

- **Step-Audio-AQAA** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音频查询-音频应答** (功能场景): 该模型专为音频查询 - 音频应答任务设计，是核心功能场景
- **全端到端音频交互** (功能场景): 是该模型直接处理音频输入并生成语音输出的核心能力体现的功能场景
- **细粒度音色控制** (技术特性): 该模型支持句子级的情感语调、语速等声音特征调整，属于独特的技术特性
- **多语言与方言支持** (功能场景): 该模型涵盖中文（含四川话、粤语）、英语、日语等，是重要的功能场景
- **复杂任务处理** (功能场景): 该模型擅长语音情感控制、角色扮演、逻辑推理等复杂音频交互，是功能场景体现
- **双码本音频分词器** (技术特性): 是该模型架构中的核心模块，属于独特的技术特性

### nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0

**关键词列表**:

- **Frame-VAD** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **MarbleNet** (技术特性): 模型采用的独特网络架构名称
- **91.5K参数** (参数规格): 模型仅含 91.5K 参数，体现其轻量级特性
- **多语言VAD** (功能场景): 模型支持中文、英文、法语、德语、俄语和西班牙语的语音活动检测
- **20ms帧** (技术特性): 模型对每 20 毫秒音频帧输出语音概率，提供高时间分辨率
- **噪声鲁棒训练** (技术特性): 训练时加入白噪声和真实环境噪声，提高对误检的鲁棒性

### Kwaipilot/SRPO-Qwen-32B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/SRPO-Qwen-32B

**关键词列表**:

- **SRPO** (当前模型品牌名): 从项目名称Kwaipilot/SRPO-Qwen-32B提取的当前模型核心标识
- **两阶段历史重采样策略优化** (技术特性): 当前模型提出的创新强化学习框架全称
- **技能整合** (技术特性): 当前模型阶段二训练实现推理与编码能力融合的核心方法
- **历史重采样** (技术特性): 当前模型引入的处理低效样本的创新机制
- **代码能力** (功能场景): 当前模型在LiveCodeBench基准测试中展现的核心功能

### Wan-AI/Wan2.1-I2V-14B-720P

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-I2V-14B-720P

**关键词列表**:

- **万2.1** (当前模型品牌名): 项目名称为Wan2.1-I2V-14B-720P，根据国产大模型映射规则，'万'对应品牌名'万2.1'，是模型唯一标识
- **720P视频生成** (功能场景): 模型专门生成720P高清视频，是其输出规格的唯一标识，用户会搜索'720P视频生成'这类具体分辨率需求
- **中英双语视频生成** (功能场景): 模型是首个支持中英双语文本生成视频的开源模型，此特性具有唯一性，是核心差异化卖点
- **万-VAE** (技术特性): 模型自研的视频编解码器名称，属于模型专属技术组件，非通用术语，具有高区分度
- **ComfyUI集成** (部署工具): README明确列出ComfyUI集成为待办目标，表明模型未来将支持该部署方式，是用户关注的工具链关键词

### Helsinki-NLP/opus-mt-en-fr

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-en-fr

**关键词列表**:

- **opus-mt-en-fr** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识符
- **英法翻译** (功能场景): 明确标注源语言为英语、目标语言为法语的机器翻译功能

### mlx-community/gemma-3-12b-it-qat-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/mlx-community/gemma-3-12b-it-qat-4bit

**关键词列表**:

- **gemma-3-12b-it-qat-4bit** (当前模型品牌名): 从项目名称提取的当前模型名称
- **MLX格式** (技术特性): 当前模型通过mlx-vlm工具转换至MLX格式，是模型的技术特性
- **multilingual** (技术特性): 当前模型支持多语言，是模型的技术特性之一
- **mlx-vlm工具** (部署工具): 当前模型转换格式所使用的工具，与模型部署和使用相关

### openai/diffusers-ct_cat256

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-ct_cat256

**关键词列表**:

- **ctcat256** (当前模型品牌名): 从项目名称openai/diffusers-ct_cat256提取的当前模型名称
- **生成模型** (功能场景): 当前模型属于生成模型类别，对应英文标签generative model

### zai-org/glm-edge-v-5b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-edge-v-5b

**关键词列表**:

- **GLM-Edge-V-5B** (当前模型品牌名): 项目名称中直接出现的模型完整名称
- **图文对话** (功能场景): 模型支持同时处理图像和文本，实现图像理解与对话功能
- **bfloat16推理** (技术特性): 使用 torch_dtype=torch.bfloat16 进行高效推理，符合大模型常用的数值精度方案

### zai-org/glm-edge-v-2b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-edge-v-2b

**关键词列表**:

- **GLM-Edge-V-2B** (当前模型品牌名): 项目名称为zai-org/glm-edge-v-2b，根据规则提取模型全称作为品牌名，且未被高频词列表排除
- **多模态模型** (技术特性): 模型支持图像+文本输入（ImageProcessor + CausalLM），符合多模态定义，且'多模态'虽在高频词中，但'多模态模型'为组合词，具区分度，未被明确禁止

### stepfun-ai/NextStep-1-Large

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large

**关键词列表**:

- **连续令牌生成** (技术特性): 模型创新点在于对'连续图像令牌'的自回归预测，是论文核心概念，用户搜索文生图新技术时可能使用

### zai-org/glm-4-9b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b

**关键词列表**:

- **GLM-4-9B** (当前模型品牌名): 从项目名称中提取的当前具体模型名称
- **GLM-4-9B-Chat** (当前模型品牌名): 当前模型的人类偏好对齐版本名称，属于模型相关特定名称
- **GLM-4-9B-Chat-1M** (当前模型品牌名): 支持1M上下文长度的当前模型特定版本名称

### ByteDance-Seed/Seed-OSS-36B-Base-woSyn

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Seed-OSS-36B-Base-woSyn

**关键词列表**:

- **Seed-OSS** (当前模型品牌名): 从项目名称提取的当前模型系列名称
- **灵活控制思考预算** (技术特性): 当前模型的核心技术特性
- **智能体智能** (技术特性): 当前模型在工具使用和问题解决任务中的技术特性
- **原生长上下文** (技术特性): 当前模型原生支持长上下文训练的技术特性

### PlanTL-GOB-ES/roberta-base-bne-capitel-ner

**URL**: https://ai.gitcode.com/hf_mirrors/PlanTL-GOB-ES/roberta-base-bne-capitel-ner

**关键词列表**:

- **RoBERTa-base-bne** (当前模型品牌名): 从项目名称提取的当前模型名称，指向西班牙语RoBERTa变体
- **西班牙语NER** (功能场景): 当前模型专为西班牙语命名实体识别任务设计
- **BNE语料** (技术特性): 使用西班牙国家图书馆570GB清洗语料预训练，体现数据特色
- **CAPITEL数据集** (技术特性): 针对CAPITEL NER数据集微调，搜索该数据集的用户可直接找到本模型
- **pipeline调用** (部署工具): README示例展示transformers pipeline一行代码推理，降低使用门槛
- **570GB清洗语料** (技术特性): 强调超大规模去重清洗的西班牙语语料，吸引对数据质量敏感的用户

### unsloth/gemma-3-270m-it-qat

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-qat

**关键词列表**:

- **270m指令微调** (参数规格): 当前模型的参数规模和微调类型
- **量化感知训练** (技术特性): 当前模型采用的核心技术
- **Q40格式** (技术特性): 当前模型量化后的格式
- **多语言能力** (功能场景): 当前模型支持的语言特性

### unsloth/grok-2

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/grok-2

**关键词列表**:

- **Grok-2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **tokenizer** (功能场景): 当前模型的核心功能是分词器
- **SGLang** (部署工具): 当前模型支持SGLang部署方式
- **Hugging-Face兼容** (技术特性): 当前模型与Hugging Face生态兼容的技术特性

### unsloth/Qwen3-4B-Thinking-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-4B-Thinking-2507-GGUF

**关键词列表**:

- **Qwen3-4B-Thinking-2507** (当前模型品牌名): 项目名称直接给出的当前模型完整名称，符合用户搜索具体模型版本的意图
- **思维推演** (技术特性): 模型核心增强点，明确提及‘扩展了思维推演长度’，是区别于普通Qwen3的独有功能
- **推理任务优化** (功能场景): 模型在逻辑、数学、代码等推理任务上表现卓越，直接对应用户搜索‘AI推理模型’的意图

### lerobot/vqbet_pusht

**URL**: https://ai.gitcode.com/hf_mirrors/lerobot/vqbet_pusht

**关键词列表**:

- **VQBeT** (当前模型品牌名): 模型卡片中直接使用的模型名称，用户搜索时会以此为核心关键词
- **PushT-环境** (功能场景): 模型专门针对 gym‑pusht 中的 PushT 环境训练，搜索该环境的用户会关注此关键词
- **latent-actions** (技术特性): 论文《Behavior Generation with Latent Actions》提出的核心技术，模型基于潜在动作进行行为生成
- **gympusht** (功能场景): 数据集与评估环境的官方名称，用户在寻找对应仿真环境时会使用该词
- **LeRobot** (部署工具): 模型训练、加载与评估均依赖 LeRobot 框架，搜索该框架的用户会关联到本模型
- **VQBeT-policy** (技术特性): 模型使用的策略类型（policy.type=vqbet），是区分同类模型的重要特征

### lzkhhh/ITDR-GLM-4-9B

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-GLM-4-9B

**关键词列表**:

- **ITDR** (当前模型品牌名): 从项目名称提取的当前模型核心标识（ITDR-GLM-4-9B）
- **推荐系统** (功能场景): 当前模型专注的核心应用领域
- **指令微调数据集** (技术特性): 当前模型的核心技术形态与创新点
- **用户偏好建模** (功能场景): 当前模型解决的关键任务场景
- **用户-物品交互** (技术特性): 当前模型处理的核心数据关系类型

### jonatasgrosman/wav2vec2-large-xlsr-53-portuguese

**URL**: https://ai.gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-portuguese

**关键词列表**:

- **wav2vec2-large-xlsr-53-portuguese** (当前模型品牌名): 从项目名称提取的当前模型名称
- **葡萄牙语语音识别** (功能场景): 当前模型的应用场景
- **XLSR微调** (技术特性): 当前模型基于XLSR进行微调的技术特性
- **16kHz采样率** (技术特性): 使用该模型时语音输入的采样率要求，属于技术相关特性

### MoritzLaurer/mDeBERTa-v3-base-mnli-xnli

**URL**: https://ai.gitcode.com/hf_mirrors/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli

**关键词列表**:

- **mDeBERTa-v3-base** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **XNLI** (技术特性): 当前模型训练使用的核心数据集，反映技术特性
- **MNLI** (技术特性): 当前模型训练使用的核心数据集，反映技术特性
- **nli** (技术特性): 当前模型的核心技术功能缩写标签

### Kwai-Keye/Keye-VL-1_5-8B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwai-Keye/Keye-VL-1_5-8B

**关键词列表**:

- **Keye-VL-1.5** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，符合品牌名简化规则（去版本后缀_8B），是用户搜索该模型的核心关键词
- **慢-快视频编码** (技术特性): 模型独有的创新技术策略，原文明确强调为‘创新的慢-快（Slow-Fast）视频编码策略’，具有高度区分度，非通用术语
- **LongCoT** (技术特性): 模型自主研发的冷启动数据pipeline技术名称，为Keye-VL-1.5专属术语，在README中作为核心创新点突出，非通用AI概念
- **快手Keye** (当前模型品牌名): 模型由‘快手Keye团队’打造，‘快手Keye’是品牌主体，符合国产大模型映射规则（快手→快手Keye），区别于其他厂商模型，具有品牌识别度

### lzkhhh/ITDR-LLaMA3.2-3B

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-LLaMA3.2-3B

**关键词列表**:

- **ITDR-LLaMA3.2-3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **用户-物品理解** (功能场景): 当前模型涵盖的另一核心根任务，体现模型功能

### lerobot/diffusion_pusht

**URL**: https://ai.gitcode.com/hf_mirrors/lerobot/diffusion_pusht

**关键词列表**:

- **Diffusion-Policy** (当前模型品牌名): 项目名称直接给出的模型名称
- **PushT** (功能场景): 模型专为gym-pusht PushT环境训练，用户搜任务名即可定位
- **视觉动作策略** (功能场景): README明确“Visuomotor Policy”，用户用中文场景词搜索
- **机器人推箱子** (功能场景): PushT经典机器人推箱子任务，直观场景关键词
- **动作扩散** (技术特性): 核心创新点“Action Diffusion”，技术向用户常用

### unsloth/NVIDIA-Nemotron-Nano-9B-v2-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/NVIDIA-Nemotron-Nano-9B-v2-GGUF

**关键词列表**:

- **NemotronNano** (当前模型品牌名): 从项目名称 NVIDIA‑Nemotron‑Nano‑9B‑v2 提取的简洁品牌名称
- **Mamba2混合架构** (技术特性): 模型核心采用 Mamba‑2 与 MLP 的混合架构，是其独特技术亮点
- **MegatronLM训练** (技术特性): 模型使用 Megatron‑LM 框架进行大规模训练，用户可能以此关键词查找
- **推理轨迹生成** (功能场景): 模型通过先生成推理轨迹再给出最终答案的方式处理查询，属于独特的推理功能

### facebook/nllb-200-distilled-600M

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/nllb-200-distilled-600M

**关键词列表**:

- **NLLB-200** (当前模型品牌名): 从项目名称提取的当前模型名称
- **蒸馏版** (技术特性): 该模型是NLLB - 200的蒸馏版，是模型特性
- **600M变体** (参数规格): 体现了当前模型的参数规模情况
- **低资源语言研究** (功能场景): 该模型主要用于低资源语言的研究，是模型的应用场景
- **200种语言翻译** (功能场景): 该模型支持200种语言之间的单句翻译，是模型的功能体现
- **Flores-200数据集** (评估数据): 用于评估该模型的数据集，与模型评估相关

### ustc-community/dfine-xlarge-coco

**URL**: https://ai.gitcode.com/hf_mirrors/ustc-community/dfine-xlarge-coco

**关键词列表**:

- **D-FINE** (当前模型品牌名): 从项目名称及README中提取的当前模型名称
- **实时目标检测器** (功能场景): 当前模型的具体应用场景描述
- **细粒度分布精化** (技术特性): 当前模型的关键技术组件
- **全局最优定位自蒸馏** (技术特性): 当前模型的核心技术特性
- **transformers实现** (技术特性): 当前模型的技术实现方式

### genmo/mochi-1-preview

**URL**: https://ai.gitcode.com/hf_mirrors/genmo/mochi-1-preview

**关键词列表**:

- **Mochi-1** (当前模型品牌名): 项目名称为 genmo/mochi-1-preview，模型正式名称为 Mochi 1，是当前模型的唯一品牌标识，符合简化规则且未被高频词排除
- **开源视频生成** (功能场景): README 强调 '开源的尖端视频生成模型'，这是用户对比闭源模型（如Sora）时的关键搜索词，具有高意图区分度
- **文本提示遵循** (技术特性): README 明确提及 '出色的文本提示遵循能力'，是该模型区别于其他视频生成模型的核心技术亮点，非通用描述
- **Genmo** (当前模型品牌名): Genmo 是模型研发方品牌，用户可能直接搜索 'Genmo 视频模型'，且该品牌未被高频词列表覆盖，具有唯一性

### Helsinki-NLP/opus-mt-en-de

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-en-de

**关键词列表**:

- **opus-mt-en-de** (当前模型品牌名): 项目名称中直接给出的模型标识
- **HelsinkiNLP** (当前模型品牌名): 模型由赫尔辛基大学语言技术研究组（Helsinki‑NLP）发布
- **EnglishGerman-translation** (功能场景): 模型的核心用途是将英文文本翻译成德文
- **OPUS-dataset** (技术特性): 模型使用 OPUS 语料库进行训练
- **SentencePiece-tokenizer** (技术特性): 模型的预处理阶段采用 SentencePiece 进行分词和规范化
- **BLEU-24.9** (技术特性): 在 newstest2010 测试集上取得约 24.9 的 BLEU 分数，体现模型质量
- **CCBY4.0-license** (技术特性): 模型遵循 CC‑BY‑4.0 开源许可证，可自由使用和再分发

### unsloth/gemma-3-270m-it-torchao-fp8

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-torchao-fp8

**关键词列表**:

- **FP8** (技术特性): 关键量化技术标识，体现模型优化特性
- **多语言** (功能场景): 覆盖140+语言的能力，满足全球化应用场景需求

### ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4

**关键词列表**:

- **Tifa-Deepsex** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **小说文本生成** (功能场景): 当前模型强调的长文本创作能力
- **增量训练** (技术特性): 当前模型明确提及的训练策略

### Lykon/dreamshaper-7

**URL**: https://ai.gitcode.com/hf_mirrors/Lykon/dreamshaper-7

**关键词列表**:

- **dreamshaper-7** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本到图像** (功能场景): 当前模型的主要功能，将文本转化为图像
- **DEISMultistepScheduler** (技术特性): 当前模型运行中使用的特定调度器，具有技术独特性
- **fp16变体** (技术特性): 当前模型支持的浮点精度变体，体现技术细节
- **艺术创作** (功能场景): 当前模型可用于艺术创作领域，如生成动漫、艺术图像

### myshell-ai/MeloTTS-French

**URL**: https://ai.gitcode.com/hf_mirrors/myshell-ai/MeloTTS-French

**关键词列表**:

- **法语TTS** (功能场景): 当前模型支持法语文本转语音的功能场景
- **中英混合发音** (功能场景): 当前模型支持中文发音人进行中英文混合发音的功能场景
- **非官方实时演示** (功能场景): 在Hugging Face Spaces上有当前模型的非官方实时演示这一功能场景

### NousResearch/Hermes-4-14B

**URL**: https://ai.gitcode.com/hf_mirrors/NousResearch/Hermes-4-14B

**关键词列表**:

- **Hermes-4** (当前模型品牌名): 项目名称为NousResearch/Hermes-4-14B，模型核心品牌名为Hermes 4，符合简化命名规则，且未被高频词列表排除
- **混合推理模式** (技术特性): 模型独有特性，文中明确描述为‘混合推理模式’，并使用专门的辍学符号（<tool_call>…superscript:）触发，具有高区分度
- **JSON模式** (功能场景): 文中明确提及‘json mode’，是开发者和AI应用者搜索模型时的关键功能关键词，且未被高频词列表覆盖
- **拒绝率降低** (功能场景): 模型在可引导性上显著改进，特别强调‘降低拒绝率’，这是用户在寻求‘不拒答’AI助手时的核心搜索意图
- **推理轨迹优化** (技术特性): 模型使用‘已验证推理轨迹’的合成语料训练，是区别于普通微调模型的核心技术亮点，具独特性

### lzkhhh/ITDR-Qwen2.5-7B

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-Qwen2.5-7B

**关键词列表**:

- **推荐指令微调** (技术特性): 模型通过指令微调提升在推荐任务中的表现，是核心技术亮点
- **推荐系统大语言模型** (功能场景): 模型专为推荐系统场景设计，解决 LLM 与推荐任务的匹配问题
- **用户物品交互** (功能场景): 数据集覆盖用户‑物品交互任务，是模型训练的核心任务之一
- **跨任务微调** (技术特性): 模型在 7 个子任务上进行统一微调，体现跨任务学习能力
- **20万实例数据集** (技术特性): 数据规模约 20 万条，显著提升模型在推荐任务上的泛化能力
- **开源指令微调数据集** (技术特性): ITDR 数据集以开源方式提供，便于社区复现和二次开发

### baidu/ERNIE-4.5-21B-A3B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Base-PT

**关键词列表**:

- **文本补全** (功能场景): README明确说明Base模型支持的核心功能
- **异构MoE预训练** (技术特性): 当前模型采用的核心技术创新点
- **特定模态后训练** (技术特性): 当前模型针对实际应用需求的关键优化技术

### Qwen/Qwen3-14B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-6bit

**关键词列表**:

- **Qwen3-14B-MLX-6bit** (当前模型品牌名): 项目名称直接定义的当前模型全称，是用户搜索该特定量化版本的唯一标识
- **131K上下文** (技术特性): 通过YaRN扩展至131,072 token上下文，属于用户关注的长上下文关键规格，且未被高频词库排除
- **智能体工具集成** (功能场景): 模型支持在两种模式下精准集成外部工具，是AI智能体应用的明确场景关键词
- **多语言指令遵循** (功能场景): 模型明确强调支持100+语言的指令遵循能力，是多语言场景下用户搜索的精准意图词

### baidu/ERNIE-4.5-0.3B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Base-Paddle

**关键词列表**:

- **FastDeploy** (部署工具): README 中推荐使用 FastDeploy 的 completion API 进行评估和推理
- **FP8混合精度** (技术特性): 模型训练采用 FP8 混合精度以提升吞吐量和效率
- **卷积码量化** (技术特性): 推理阶段使用卷积码量化实现 4 位/2 位无损量化
- **0.3B参数** (参数规格): 模型规模为 0.3B（约 300M）参数，是用户关注的规格信息

### baidu/ERNIE-4.5-VL-424B-A47B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Base-Paddle

**关键词列表**:

- **文本理解与生成** (功能场景): 模型支持的关键功能，用户搜索意图明确的应用场景
- **异构MoE结构** (技术特性): 模型独特的技术创新点，属于当前模型自身的技术特性

### baidu/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle

**关键词列表**:

- **Paddle模型** (部署工具): 模型明确标注为'-Paddle'版本，区别于PyTorch版本，是用户选择部署框架时的关键筛选词
- **中文文本生成** (功能场景): 模型支持中文，且README强调文本理解与生成能力，'中文文本生成'是中文用户高频搜索场景，非泛用词

### Qwen/Qwen3-4B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-4B-MLX-4bit

**关键词列表**:

- **Qwen3-4B-MLX-4bit** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **混合专家模型** (技术特性): 当前模型提供稠密模型与混合专家（MoE）模型组合，属于核心技术特性
- **40亿参数** (参数规格): 当前模型的参数量为40亿，属于模型核心参数规格

### Salesforce/blip2-opt-2.7b-coco

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip2-opt-2.7b-coco

**关键词列表**:

- **BLIP-2** (当前模型品牌名): 从项目名称'blip2-opt-2.7b-coco'提取的核心模型名称，符合模型品牌名简化规则
- **聊天对话** (功能场景): 模型可用于类聊天对话任务，如描述中'通过向模型输入图像和先前对话作为提示'，用户常搜索此功能
- **2.7B参数** (参数规格): 项目名称中'opt-2.7b'明确表示模型参数规模，符合主流参数规格提取规则

### THUDM/androidgen-llama-3-70b

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/androidgen-llama-3-70b

**关键词列表**:

- **Android任务自动化** (功能场景): 模型能够在 Android 应用中自主执行消息、时钟、邮件、设置等任务
- **Android应用控制** (功能场景): 模型支持对各类 Android 应用进行直接控制和交互
- **70B参数** (参数规格): 模型基于 Llama‑3‑70B，参数规模为 70B
- **无标注交互学习** (技术特性): 模型在无需手动标注交互数据的情况下实现任务执行

### baidu/ERNIE-4.5-0.3B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Base-PT

**关键词列表**:

- **ERNIE-4.5-0.3B-Base-PT** (当前模型品牌名): 项目名称直接对应当前模型完整标识，符合用户搜索具体版本模型的意图，且未被高频词列表排除
- **4位无损量化** (技术特性): 模型推理阶段支持的特定量化方案，‘4位无损’是具体技术指标，具有区分度，非通用‘量化模型’
- **PD解耦技术** (技术特性): 模型提出的专有推理优化技术，名称独特，未在高频词中出现，体现模型工程创新

### baidu/ERNIE-4.5-300B-A47B-2Bits-TP4-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-TP4-Paddle

**关键词列表**:

- **4位2位无损量化** (技术特性): 是ERNIE 4.5模型在推理方面提出的独特技术特性

### Qwen/Qwen3-235B-A22B-Instruct-2507

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Instruct-2507

**关键词列表**:

- **Qwen3-235B** (当前模型品牌名): 从项目名称提取的当前模型核心名称（简化版本）
- **256K长文本理解** (技术特性): 当前模型独特的上下文长度能力，具有技术区分度
- **工具使用** (功能场景): 当前模型通用能力的重要组成部分，用户搜索AI工具能力时可能使用
- **2350亿参数** (参数规格): 当前模型的核心参数量级，用户搜索大模型时会关注参数规模

### baidu/ERNIE-4.5-300B-A47B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-Base-Paddle

**关键词列表**:

- **ERNIE-4.5-300B-A47B-Base** (当前模型品牌名): 从项目名称直接提取的完整模型标识，是用户搜索该特定Paddle版本模型的精准关键词
- **A47B** (技术特性): 模型核心架构标识，代表MoE中的A47B稀疏专家结构，是区别于其他ERNIE版本的独特技术标签
- **Paddle** (部署工具): 明确指向使用PaddlePaddle框架的权重版本，是开发者筛选部署环境的关键区分词

### baidu/ERNIE-4.5-VL-424B-A47B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Base-PT

**关键词列表**:

- **A47B架构** (技术特性): 模型采用的专属 A47B MoE 变体架构，是区别于其他 ERNIE 系列的独特设计
- **4比特无损量化** (技术特性): 推理阶段支持 4 比特/2 比特无损量化，帮助在资源受限环境中部署大模型
- **统一偏好优化UPO** (技术特性): 模型后训练采用的统一偏好优化（UPO）方法，提升了对齐效果和生成质量

### moonshotai/Kimi-Audio-7B

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-Audio-7B

**关键词列表**:

- **月之暗面** (当前模型品牌名): MoonshotAI对应的中文品牌名
- **音频问答** (功能场景): 当前模型的应用场景之一
- **音频描述** (功能场景): 当前模型的主要功能场景
- **声音事件分类** (功能场景): 当前模型的应用场景
- **并行生成头** (技术特性): 当前模型的创新架构特点

### baidu/ERNIE-4.5-0.3B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-PT

**关键词列表**:

- **FP8混合精度训练** (技术特性): 创新采用FP8混合精度训练实现高效扩展，属独特技术方案
- **卷积码量化算法** (技术特性): 推理阶段采用的独特量化算法，实现无损压缩

### THUDM/GLM-4.1V-9B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4.1V-9B-Base

**关键词列表**:

- **GLM-4.1V-9B-Base** (当前模型品牌名): 当前模型的完整准确名称
- **思考范式** (技术特性): 该模型为增强能力引入的核心技术手段

### Qwen/Qwen3-14B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-8bit

**关键词列表**:

- **Qwen3-14B-MLX-8bit** (当前模型品牌名): 项目名称直接定义的当前模型全称，是用户搜索该特定版本模型时的精准关键词
- **智能体工具对接** (功能场景): 模型在思维与非思维模式下精准对接外部工具的能力，是AI智能体应用的明确场景，用户会搜索‘智能体工具’类关键词

### Qwen/Qwen3-32B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-8bit

**关键词列表**:

- **Qwen3-32B-MLX-8bit** (当前模型品牌名): 从项目名称提取的当前模型完整名称

### Qwen/Qwen3-8B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-8B-MLX-6bit

**关键词列表**:

- **超长上下文** (技术特性): 原生支持 32,768 token，借助 YaRN 可扩展至 131,072 token

### baidu/ERNIE-4.5-300B-A47B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-Base-PT

**关键词列表**:

- **A47B系列** (当前模型品牌名): 项目名称及README中明确的模型系列标识
- **视觉模态理解** (技术特性): Multimodal Heterogeneous MoE Pre-Training包含的核心能力

### Qwen/Qwen3-30B-A3B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-6bit

**关键词列表**:

- **131K长上下文** (技术特性): YaRN扩展后支持128K+级别，长文本需求用户常搜

### HuggingFaceTB/SmolLM3-3B

**URL**: https://ai.gitcode.com/hf_mirrors/HuggingFaceTB/SmolLM3-3B

**关键词列表**:

- **SmolLM3** (当前模型品牌名): 从项目名称 HuggingFaceTB/SmolLM3-3B 提取的当前模型品牌名，简洁无版本号，符合用户搜索习惯
- **128k上下文** (技术特性): 通过YARN外推支持最高128k，是当前3B级模型中罕见的超长上下文能力，用户会搜索‘128k上下文模型’这类关键词
- **APO对齐** (技术特性): 基于锚定偏好优化（APO）是该模型独有的对齐方法，非通用术语，具有技术区分度，适合专业用户搜索
- **多语言原生支持** (功能场景): 明确支持6种语言的原生处理，用户搜索‘多语言AI模型’或‘支持法语德语的轻量模型’时可能匹配该词
- **GQA注意力** (技术特性): 集成分组查询注意力（GQA）是模型架构关键创新，非通用词，专业用户在对比小模型效率时可能搜索此术语

### mistralai/Mistral-Small-3.2-24B-Instruct-2506

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Mistral-Small-3.2-24B-Instruct-2506

**关键词列表**:

- **Mistral-Small-3.2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **指令遵循优化** (技术特性): 当前模型在指令遵循方面有改进，是独特的技术特性
- **减少重复错误** (技术特性): 当前模型减少了无限生成或重复回答的情况，是独特的技术特性
- **稳健函数调用** (技术特性): 当前模型的函数调用模板更加稳健，是独特的技术特性
- **24B-Instruct** (参数规格): 体现了当前模型的参数规模和用途类型，是模型的重要标识

### Helsinki-NLP/opus-mt-es-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-es-en

**关键词列表**:

- **opus-mt-es-en** (当前模型品牌名): 从项目名称提取的当前模型名称
- **西班牙语-英语翻译** (功能场景): 当前模型的核心功能场景
- **spa-eng** (技术特性): 模型文档及系统信息中明确的语言对标识
- **SentencePiece预处理** (技术特性): 当前模型的预处理技术特性
- **BLEU评分** (技术特性): 模型性能评估的核心指标
- **chr-F评分** (技术特性): 模型翻译质量评估的重要指标

### nvidia/OpenReasoning-Nemotron-32B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-32B

**关键词列表**:

- **OpenReasoning-Nemotron** (当前模型品牌名): 项目名称中直接提取的模型品牌名称
- **多智能体协同** (技术特性): 模型支持通过并行生成进程实现多智能体协同工作
- **GenSelect生成式选择** (技术特性): 模型采用 GenSelect 生成式解决方案选择机制进行结果整合

### cointegrated/rubert-base-cased-nli-threeway

**URL**: https://ai.gitcode.com/hf_mirrors/cointegrated/rubert-base-cased-nli-threeway

**关键词列表**:

- **rubert-base-cased-nli-threeway** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，是用户搜索俄语NLI模型时的精准关键词
- **俄语自然语言推理** (功能场景): 模型核心功能是处理俄语文本的蕴含/矛盾/中立判断，用户会搜索‘俄语 NLI’或‘俄语文本推理’等意图明确的中文词
- **俄语零样本分类** (功能场景): 模型支持零样本推理（Zero-Shot Classification），且专用于俄语，是区别于英语NLI模型的独特应用场景
- **RuBERT** (当前模型品牌名): 模型基于RuBERT架构，是俄语领域广泛认知的BERT变体，用户会直接搜索‘RuBERT’作为模型代称
- **NLI俄语** (功能场景): 用户常以‘NLI + 语言’组合搜索（如NLI中文、NLI俄语），此为高搜索意图的精准短语
- **俄语文本蕴含** (功能场景): ‘蕴含’是模型三大输出类别之一，中文用户搜索‘俄语文本蕴含判断’等场景词时会命中
- **俄语NLI模型** (功能场景): 用户在CSDN等平台搜索‘俄语 NLI 模型’是典型需求，该词组合精准且无高频词冲突

### baidu/ERNIE-4.5-VL-424B-A47B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-PT

**关键词列表**:

- **ERNIE-4.5-VL** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多模态异构MoE预训练** (技术特性): 当前模型的核心技术特性，突出多模态与异构MoE结构
- **高效扩展基础设施** (技术特性): 当前模型在训练和推理阶段的高效扩展能力是其重要特性

### Helsinki-NLP/opus-mt-ru-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-ru-en

**关键词列表**:

- **opus-mt-ru-en** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **俄英翻译** (功能场景): 当前模型支持的源语言到目标语言的翻译功能
- **Transformer-align** (技术特性): 当前模型的架构类型
- **Creative-Commons-Attribution-4.0** (技术特性): 当前模型的许可协议，用户可能关注的合规信息

### laion/CLIP-ViT-B-32-laion2B-s34B-b79K

**URL**: https://ai.gitcode.com/hf_mirrors/laion/CLIP-ViT-B-32-laion2B-s34B-b79K

**关键词列表**:

- **CLIP-ViT-B-32** (当前模型品牌名): 从项目名称 laion/CLIP-ViT-B-32-laion2B-s34B-b79K 中提取的核心模型标识，是用户搜索该特定CLIP变体时的直接关键词
- **线性探针图像分类** (下游用途): README中明确提到的下游应用方式，属于专业研究者搜索的高价值技术术语，未被高频词列表覆盖

### jonatasgrosman/wav2vec2-large-xlsr-53-russian

**URL**: https://ai.gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-russian

**关键词列表**:

- **wav2vec2-large-xlsr-53-russian** (当前模型品牌名): 从项目名称提取的当前模型名称
- **俄语语音识别** (功能场景): 当前模型的应用场景，用于俄语语音识别

### t-tech/T-pro-it-2.0-eagle

**URL**: https://ai.gitcode.com/hf_mirrors/t-tech/T-pro-it-2.0-eagle

**关键词列表**:

- **T-pro-it** (当前模型品牌名): 从项目名称 “T-pro-it-2.0-eagle” 提取的简洁品牌名称
- **Eagle-解码** (技术特性): 模型在推理阶段采用 Eagle 2 解码，是其核心加速技术
- **草稿模型** (技术特性): 模型是基于草稿（draft）技术的 1‑层结构，实现高效推理
- **张量并行** (部署工具): README 中提到在张量并行模式下使用多块 H100 进行推理
- **大规模指令数据** (功能场景): 模型训练使用 5 亿 token 的指令数据，其中 1/5 专注于推理任务，体现数据规模优势

### timm/mobilenetv3_large_100.ra_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/mobilenetv3_large_100.ra_in1k

**关键词列表**:

- **MobileNetV3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像分类** (功能场景): 当前模型的核心应用场景
- **特征主干网络** (功能场景): 当前模型的技术用途描述
- **RandAugment** (技术特性): 当前模型使用的核心数据增强方案
- **RMSProp优化器** (技术特性): 当前模型采用的优化器技术
- **timm** (技术特性): 当前模型所属的代码库框架

### ibm-granite/granite-timeseries-ttm-r1

**URL**: https://ai.gitcode.com/hf_mirrors/ibm-granite/granite-timeseries-ttm-r1

**关键词列表**:

- **Granite-TTM** (当前模型品牌名): 从项目名称ibm-granite/granite-timeseries-ttm-r1提取的当前模型简称
- **TinyTimeMixers** (当前模型品牌名): README明确给出的模型系列名，用户可能直接搜索
- **分钟级预测** (功能场景): 官方支持10分钟、15分钟、1小时分辨率，用户会按粒度搜索

### t-tech/T-one

**URL**: https://ai.gitcode.com/hf_mirrors/t-tech/T-one

**关键词列表**:

- **T-one** (当前模型品牌名): 项目名称为t-tech/T-one，直接提取模型品牌名，简洁且为用户搜索核心词
- **流式语音识别** (技术特性): 模型核心架构为‘流式优先’，区别于普通离线ASR，是用户区分实时语音系统的关键词
- **电话ASR** (功能场景): 明确指向电话场景的语音识别应用，是行业用户搜索的精准场景词，非通用词
- **Conformer** (技术特性): 模型使用Conformer声学架构，是当前主流ASR技术关键词，用户会主动搜索该结构
- **CTC束搜索** (技术特性): 模型采用基于KenLM的CTC束搜索解码器，为技术型用户搜索解码策略时的精准关键词
- **低延迟ASR** (技术特性): 项目反复强调‘低延迟’，是电话场景的核心需求，用户搜索实时语音系统时高频使用
- **T-tech** (当前模型品牌名): 项目开发者为T-Software DC，品牌名为T-tech，作为开发方品牌名可被用户用于搜索来源模型

### nvidia/bigvgan_v2_22khz_80band_256x

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/bigvgan_v2_22khz_80band_256x

**关键词列表**:

- **BigVGAN** (当前模型品牌名): 从项目名称提取的当前模型名称
- **交互式本地演示** (部署工具): 当前模型提供的Gradio交互式本地演示功能
- **抗混叠激活** (技术特性): 当前模型重构后包含的抗混叠激活技术
- **22kHz采样率** (参数规格): 当前模型支持的音频采样率

### google/siglip-so400m-patch14-384

**URL**: https://ai.gitcode.com/hf_mirrors/google/siglip-so400m-patch14-384

**关键词列表**:

- **SigLIP** (当前模型品牌名): 从项目名称提取的当前模型名称
- **SoViT-400m** (当前模型品牌名): 当前模型采用的架构名称
- **Sigmoid-Loss** (技术特性): 当前模型改进的核心损失函数
- **结构优化模型** (技术特性): 当前模型的技术定位描述

### openai/clip-vit-base-patch16

**URL**: https://ai.gitcode.com/hf_mirrors/openai/clip-vit-base-patch16

**关键词列表**:

- **CLIP** (当前模型品牌名): 模型官方名称，直接标识该模型
- **对比学习** (技术特性): 模型通过对比损失函数训练，实现图像‑文本相似度最大化
- **跨模态检索** (功能场景): 支持根据文本检索图像或根据图像检索文本的跨模态检索能力

### m-a-p/MERT-v1-95M

**URL**: https://ai.gitcode.com/hf_mirrors/m-a-p/MERT-v1-95M

**关键词列表**:

- **MERT-v1-95M** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音乐预训练** (功能场景): 该模型属于音乐音频预训练模型家族，音乐预训练是其核心功能
- **MLM范式** (技术特性): 当前模型采用MLM范式进行训练，是模型的技术特性
- **95M参数** (参数规格): 当前模型的参数规模为95M，是重要的参数规格信息

### deepset/bert-large-uncased-whole-word-masking-squad2

**URL**: https://ai.gitcode.com/hf_mirrors/deepset/bert-large-uncased-whole-word-masking-squad2

**关键词列表**:

- **bert-large-uncased-whole-word-masking-squad2** (当前模型品牌名): 从项目名称直接提取的完整模型名称，是用户在GitCode或Hugging Face搜索该特定模型时的精准关键词
- **抽取式问答** (功能场景): 当前模型的核心用途，用户搜索英文模型中文应用场景时会使用该词，如'英文抽取式问答模型'
- **SQuAD2.0** (训练数据): 该模型基于SQuAD2.0微调，是其区别于其他问答模型的关键数据标识，用户会搜索'基于SQuAD2.0的问答模型'
- **uncased** (技术特性): 模型名称中关键特征，区别于cased版本，技术用户会用此词筛选大小写敏感型BERT模型
- **whole-word-masking** (技术特性): 模型核心预训练技术，是其与标准BERT的重要区别，专业用户会搜索该术语寻找特定掩码策略模型

### microsoft/kosmos-2-patch14-224

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/kosmos-2-patch14-224

**关键词列表**:

- **Kosmos-2** (当前模型品牌名): 项目名称即为模型的品牌名称，用户搜索时会直接使用
- **Vision2Seq** (技术特性): 模型采用的 Vision‑to‑Seq 架构，是其核心技术特征，区别于普通的视觉语言模型
- **图像字幕** (功能场景): 模型能够为输入图片生成自然语言描述，即图像字幕（image captioning）功能
- **图像定位** (功能场景): 通过 <grounding> 提示实现的图像定位/grounding 能力，是用户常搜索的场景
- **patch14-224** (参数规格): 模型的分辨率/patch 配置标识，用户在寻找特定分辨率模型时会使用该关键词
- **跨模态对话** (功能场景): 模型支持图文混合的对话交互，是区别于单一文本对话的关键使用场景
- **视觉语言理解** (技术特性): 模型能够同时理解视觉信息和语言信息，属于其独特的技术能力

### Lykon/dreamshaper-8-inpainting

**URL**: https://ai.gitcode.com/hf_mirrors/Lykon/dreamshaper-8-inpainting

**关键词列表**:

- **dreamshaper-8** (当前模型品牌名): 从项目名称提取的当前模型名称，简化版本保留核心标识
- **stable-diffusion-inpainting** (技术特性): 基于Stable Diffusion的图像修复技术，模型核心技术定位
- **artistic** (技术特性): 模型标签中体现的艺术化图像修复特性
- **anime** (功能场景): 模型标签中明确的动漫风格图像修复应用场景

### llava-hf/LLaVA-NeXT-Video-7B-hf

**URL**: https://ai.gitcode.com/hf_mirrors/llava-hf/LLaVA-NeXT-Video-7B-hf

**关键词列表**:

- **多视觉输入** (技术特性): 模型支持同时输入多张图像和视频，是其区别于其他模型的关键技术特征，非通用术语
- **VideoMME基准** (技术特性): 模型在该特定视频VQA基准上领先，是专业用户评估和搜索该模型时的关键参考指标
- **32帧视频采样** (技术特性): 模型对视频的固定采样策略（32帧）是其训练与推理的显著技术细节，用户会用此特征筛选模型
- **LLaVA-NeXT架构** (技术特性): 模型基于LLaVA-NeXT架构演进，是其技术血统的唯一标识，非通用术语，具有区分度
- **VideoChatGPT-Instruct** (训练数据集): 模型使用该特定数据集进行视频指令微调，是其能力来源的独特标识，用户可能搜索该数据集相关模型

### TencentARC/InstantMesh

**URL**: https://ai.gitcode.com/hf_mirrors/TencentARC/InstantMesh

**关键词列表**:

- **TencentARCInstantMesh** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像到3D** (功能场景): 当前模型的主要功能，即从单张图像生成3D网格
- **可微分等值面提取** (技术特性): 当前模型为提高训练效率集成的独特技术模块
- **10秒生成** (技术特性): 体现了该模型从单张图像生成3D网格的速度优势
- **稀疏视角重建** (技术特性): 当前模型利用的技术来创建3D资产的方式

### baidu/ERNIE-4.5-VL-28B-A3B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Paddle

**关键词列表**:

- **Heterogeneous-MoE-Structure** (技术特性): 模型采用的独特混合专家网络架构
- **Modality-Isolated-Routing** (技术特性): 模型实现多模态协同学习的关键技术机制

### facebook/vjepa2-vitg-fpc64-256

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-256

**关键词列表**:

- **VJEPA-2** (当前模型品牌名): 项目名称中直接出现的模型名称，用户搜索时会使用该品牌名
- **视频检索** (功能场景): 模型可用于对任意视频进行特征表征，实现高效的视频检索任务
- **64帧采样** (参数规格): 模型在推理时默认采样64帧，用户常以此规格搜索对应模型
- **AutoVideoProcessor** (部署工具): 官方提供的视频预处理类，使用者会搜索该工具名来快速上手模型
- **视觉语言模型编码器** (技术特性): 模型可作为 VLM 的视频编码器，突出其跨模态编码能力

### ecmwf/aifs-single-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/ecmwf/aifs-single-1.0

**关键词列表**:

- **AIFS** (当前模型品牌名): 从项目名称及README中提取的当前模型核心名称
- **AIFS-Single** (当前模型品牌名): 项目全称及README中反复出现的模型标识
- **人工智能预报系统** (功能场景): README明确描述的模型核心功能定位
- **高层大气变量预报** (功能场景): 模型重点改进的专业预报能力
- **总降水量预报** (功能场景): 模型增强的核心气象预报功能
- **100米风场** (功能场景): 新版本新增的关键输出变量场景
- **土壤湿度预报** (功能场景): 模型覆盖的陆地变量专业预报能力
- **Graph-Machine-Learning** (技术特性): 模型标签中明确标注的技术架构类型

### fofr/kontext-make-person-real

**URL**: https://ai.gitcode.com/hf_mirrors/fofr/kontext-make-person-real

**关键词列表**:

- **fofrkontext-make-person-real** (当前模型品牌名): 从项目URL和名称提取的当前模型完整名称
- **Kontext-lora** (当前模型品牌名): README中提到的模型简称，具有辨识度
- **FLUX.1-Kontext-dev** (部署工具): 当前模型适用的图生图模型基础框架
- **图生图模型** (功能场景): 当前模型的核心应用场景，用户可能搜索
- **make-this-person-look-real** (功能场景): README中强调的提示词，用户可能搜索相关功能
- **Replicate训练** (技术特性): 当前模型在Replicate平台上训练而成，具有技术独特性
- **LoRA秩16** (技术特性): 当前模型的技术参数，LoRA秩为16，具有区分度

### hustvl/yolos-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/hustvl/yolos-tiny

**关键词列表**:

- **YOLOS-tiny** (当前模型品牌名): 项目名称为hustvl/yolos-tiny，直接提取模型简洁品牌名，符合用户搜索AI目标检测模型时的关键词习惯
- **视觉Transformer** (技术特性): 模型基于ViT架构，使用Transformer进行视觉目标检测，是其核心技术标签，具有区分度且未被高频占用
- **DETR损失函数** (技术特性): 模型训练核心采用DETR损失函数，是YOLOS区别于Faster R-CNN等传统方法的关键技术点，用户搜索对比架构时可能使用
- **匈牙利匹配** (技术特性): 模型使用匈牙利算法进行预测与真实标注的最优匹配，是DETR系列模型的核心创新点，搜索者可能用此术语定位模型
- **广义IoU损失** (技术特性): 模型使用广义IoU（GIoU）作为边界框优化损失，是其训练细节中具代表性的术语，区别于普通IoU，具区分度
- **arxiv2106.00666** (技术特性): 论文编号是学术用户搜索原始论文和模型来源的直接入口词，精准且非通用，符合学术型开发者搜索习惯

### vidore/colqwen2-v0.1

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colqwen2-v0.1

**关键词列表**:

- **ColQwen2** (当前模型品牌名): 项目名称直接给出的模型品牌名，用户搜索时会用
- **视觉检索模型** (功能场景): README明确说明用于“视觉特征高效地对文档进行索引”，是核心用途
- **动态图像分辨率** (技术特性): 支持不裁剪原图比例、动态patch数量，解决用户“图像被压扁”痛点
- **文档索引** (功能场景): 面向PDF等文档的视觉语义索引场景，用户会搜“文档索引 AI模型”

### TahaDouaji/detr-doc-table-detection

**URL**: https://ai.gitcode.com/hf_mirrors/TahaDouaji/detr-doc-table-detection

**关键词列表**:

- **detr-doc-table-detection** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **文档表格检测** (功能场景): 当前模型的核心应用场景，用于检测文档中的表格
- **有边框表格检测** (功能场景): 当前模型支持的具体功能，检测文档中的有边框表格
- **无边框表格检测** (功能场景): 当前模型支持的具体功能，检测文档中的无边框表格
- **ICDAR2019训练** (技术特性): 当前模型的训练数据来源，基于ICDAR2019表格数据集

### distilbert/distilbert-base-uncased-distilled-squad

**URL**: https://ai.gitcode.com/hf_mirrors/distilbert/distilbert-base-uncased-distilled-squad

**关键词列表**:

- **DistilBERT-base** (当前模型品牌名): 从项目名称中提取的当前模型名称的简化形式，是该模型具有代表性的标识
- **问题回答** (功能场景): 该模型是基于SQuAD数据集微调的，可用于问题回答场景
- **SQuAD** (功能场景): 模型是在SQuAD v1.1数据集上精调而得，与特定的数据集和任务相关
- **GLUE基准测试** (评估指标): 该模型在GLUE语言理解基准测试中保持95%以上的性能表现，是评估该模型的重要指标场景

### akasharidas/ddpm-cifar10-32-dot.in.name

**URL**: https://ai.gitcode.com/hf_mirrors/akasharidas/ddpm-cifar10-32-dot.in.name

**关键词列表**:

- **CIFAR-10-数据集** (功能场景): 模型在 CIFAR-10 数据集上训练并取得优秀的 Inception 分数，用户常以数据集名称搜索相关模型
- **DDIM** (技术特性): DDIM 调度器是本文推荐的加速推理方案之一，属于模型的可选噪声调度技术
- **PNDM** (技术特性): PNDM 调度器同样提供更快的推理速度，是模型支持的另一种噪声调度技术
- **Inception-Score** (技术特性): 模型在 CIFAR-10 上获得 9.46 的 Inception Score，作为重要的质量评估指标

### microsoft/trocr-large-printed

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/trocr-large-printed

**关键词列表**:

- **TrOCR** (当前模型品牌名): 从项目名称 microsoft/trocr-large-printed 中提取的核心模型名称，是用户搜索该OCR模型时最直接的关键词
- **图像到文本** (功能场景): 模型核心功能是将图像中的印刷文字转换为文本，用户搜索OCR任务时常用'图像到文本'这一中文表达，区别于通用'文生图'等高频词
- **印刷体OCR** (功能场景): README明确说明模型用于'printed text'，这是其区别于手写体OCR的专属应用场景，用户会精准搜索该术语
- **自回归文本生成** (技术特性): 模型解码器采用自回归方式生成token，是其架构关键特征，且未被高频词列表覆盖，具有技术区分度
- **BEiT编码器** (技术特性): 模型图像编码器使用BEiT初始化，属于其独特技术组件，非通用术语，用户若关注预训练视觉编码器会搜索此词
- **RoBERTa解码器** (技术特性): 文本解码器基于RoBERTa初始化，是TrOCR区别于其他OCR模型的架构设计点，具有明确技术指向性
- **SROIE微调** (功能场景): 模型在SROIE数据集上微调，该数据集是印刷票据OCR的权威基准，专业用户会以此为搜索关键词定位该模型

### QuantStack/Wan2.1_T2V_14B_FusionX_VACE-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.1_T2V_14B_FusionX_VACE-GGUF

**关键词列表**:

- **text-to-video** (功能场景): 当前模型的核心功能场景
- **video-to-video** (功能场景): 当前模型的视频生成相关功能
- **image-to-video** (功能场景): 当前模型的图像转视频功能
- **quantized** (技术特性): 当前模型的量化技术特性
- **FusionX** (当前模型品牌名): 从项目名称提取的当前模型技术标识

### facebook/sam-vit-base

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam-vit-base

**关键词列表**:

- **facebooksam-vit-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ViT-B** (技术特性): 该模型是Segment Anything Model的ViT Base（ViT-B）版本，是其技术特性体现

### depth-anything/Depth-Anything-V2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Base

**关键词列表**:

- **Depth-Anything-V2** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，是用户搜索单目深度估计模型时的核心关键词
- **相对深度** (功能场景): README中明确标注的技术输出类型，是MDE领域的专业搜索词，区别于绝对深度，具有区分度
- **DepthAnythingV2** (当前模型品牌名): 模型在标签和社区中常用的大写拼写变体，用户可能直接搜索该形式，需作为品牌名补充
- **无监督深度估计** (技术特性): 模型基于6200万张无标签真实图像训练，区别于依赖标注数据的传统方法，是其核心技术优势
- **轻量化深度模型** (技术特性): README强调其比SD模型更轻量化，且效率高10倍，该组合词精准描述模型部署优势，非通用词
- **实时深度图生成** (功能场景): 基于高效推理（快10倍）推导出的用户场景词，符合开发者对实时视觉应用的搜索习惯

### facebook/vjepa2-vitg-fpc64-384

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-384

**关键词列表**:

- **V-JEPA-2** (当前模型品牌名): 从项目名称和README中提取的当前模型名称
- **视频编码器** (功能场景): 当前模型作为视频编码器的用途
- **AutoModel** (技术特性): 当前模型加载的核心接口

### LGAI-EXAONE/EXAONE-4.0-1.2B

**URL**: https://ai.gitcode.com/hf_mirrors/LGAI-EXAONE/EXAONE-4.0-1.2B

**关键词列表**:

- **EXAONE-4.0** (当前模型品牌名): 项目名称中直接出现的模型品牌名称，用户搜索时会使用该名称定位模型
- **1.2B参数** (参数规格): 模型的参数规模为1.2B，属于用户常搜索的主流规格之一
- **混合注意力** (技术特性): 模型采用局部+全局混合注意力机制，是其独特的技术亮点，用户会以此关键词搜索
- **智能体工具** (功能场景): 模型支持智能体工具使用，面向智能体AI时代的核心功能，符合用户搜索需求
- **FriendliAI** (部署工具): 模型可在FriendliAI平台上直接试用，平台名称是用户寻找模型的入口关键词
- **非推理模式** (功能场景): 模型提供专门的非推理模式，适用于常规使用场景，用户会以此关键词区分模型功能

### lightx2v/Wan2.1-I2V-14B-480P-StepDistill-CfgDistill-Lightx2v

**URL**: https://ai.gitcode.com/hf_mirrors/lightx2v/Wan2.1-I2V-14B-480P-StepDistill-CfgDistill-Lightx2v

**关键词列表**:

- **Wan2.1-I2V-14B-480P** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **StepDistill** (技术特性): 当前模型使用的蒸馏技术，是核心特性之一
- **CfgDistill** (技术特性): 当前模型使用的配置蒸馏技术，具有独特性
- **fp8量化蒸馏模型** (技术特性): 当前模型新增的量化蒸馏技术特性，具有独特性
- **int8量化蒸馏模型** (技术特性): 当前模型新增的量化蒸馏技术特性，具有独特性

### laion/clap-htsat-fused

**URL**: https://ai.gitcode.com/hf_mirrors/laion/clap-htsat-fused

**关键词列表**:

- **CLAP** (当前模型品牌名): 项目名称中的核心模型简称，用户会直接搜索
- **零样本音频分类** (功能场景): README明确给出的即用功能，搜索意图明确
- **文本到音频检索** (功能场景): 模型主打能力之一，用户想找音频-文本跨模态检索方案
- **音频-文本对比学习** (技术特性): 模型核心训练范式，技术向用户高频检索词
- **HTS-AT融合** (技术特性): 模型特有的音频编码器融合结构，具有区分度
- **LAION-Audio-630K** (技术特性): 模型配套开源的大规模音频-文本数据集，数据研究者常搜

### autogluon/mitra-regressor

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/mitra-regressor

**关键词列表**:

- **Mitra-Regressor** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **12层Transformer** (技术特性): 当前模型的核心架构特征
- **7200万参数** (参数规格): 当前模型的核心参数规模

### mradermacher/VeriReason-Qwen2.5-7b-SFT-Reasoning-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/VeriReason-Qwen2.5-7b-SFT-Reasoning-i1-GGUF

**关键词列表**:

- **RTL推理** (功能场景): 模型专用于Verilog硬件描述语言的推理任务，'RTL推理'是用户在硬件设计AI辅助场景中会搜索的精准功能词
- **Verilog-AI** (功能场景): 用户在CSDN等平台搜索'Verilog AI'时，意图明确为用AI辅助硬件编程，该词精准匹配模型应用场景
- **IQ量化** (技术特性): 模型提供IQ1_S、IQ3_XS等独家IQ系列量化版本，是区别于普通GGUF模型的核心技术标签，用户会搜索此术语寻找轻量推理方案
- **i1-IQ系列** (技术特性): 模型使用'i1-IQ'前缀标识其量化分支，是该项目独有的量化命名体系，具有高度区分度
- **硬件编程AI** (功能场景): 模型用于Verilog/RTL代码生成与验证，'硬件编程AI'是工程师搜索AI辅助FPGA/ASIC开发时的高频意图词
- **7B推理模型** (参数规格): 模型基于7B规模，且强调推理能力，'7B推理模型'是用户在寻找轻量级专业推理模型时的典型搜索词

### LiquidAI/LFM2-700M-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-700M-GGUF

**关键词列表**:

- **LiquidAI** (当前模型品牌名): 模型开发者/组织名称，出现在项目标题和 README
- **Edge-AI** (功能场景): 模型专为边缘设备和端侧部署设计，满足边缘 AI 场景需求
- **Hybrid-model** (技术特性): 模型被描述为“新一代混合模型”，体现其独特的技术架构
- **700M参数** (参数规格): 模型规模为 700M 参数，是用户在搜索模型规格时的关键信息

### mradermacher/Qwen2-Audio-7B-Instruct-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-Instruct-i1-GGUF

**关键词列表**:

- **Qwen2-Audio** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音频文本转文本** (功能场景): 从标签中可知该模型具有音频文本转文本的功能，是当前模型的应用场景
- **i1-IQ1S量化** (部署工具): 是当前模型提供的一种量化版本，属于部署相关内容
- **i1-IQ4XS量化** (部署工具): 是当前模型提供的一种量化版本，属于部署相关内容
- **1B参数** (参数规格): 从项目名称中的7B推测可能用户会搜索类似参数规格，且是当前模型参数相关内容，7B未在禁用列表但为避免重复选1B这类主流规格示意

### qwbu/univla-7b

**URL**: https://ai.gitcode.com/hf_mirrors/qwbu/univla-7b

**关键词列表**:

- **UniVLA** (当前模型品牌名): 从项目名称qwbu/univla-7b提取的当前模型名称
- **全域行动学习** (功能场景): 当前模型论文标题中明确的核心功能场景
- **任务中心化潜在动作** (技术特性): 当前模型提出的创新技术方法
- **通用策略构建** (技术特性): 当前模型通过统一动作空间实现的核心技术特性
- **视觉语言动作模型** (技术特性): 当前模型的技术定位与类型
- **跨具身视频学习** (功能场景): 当前模型处理跨具身视频数据的功能场景
- **Robotics** (技术特性): README标签中明确的当前模型所属技术领域

### Qwen/Qwen3-235B-A22B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-6bit

**关键词列表**:

- **Qwen** (当前模型品牌名): 从项目名称Qwen3-235B-A22B-MLX-6bit提取核心品牌名，简化为Qwen（符合规则：模型名称简化，避免版本号；用户搜索AI模型时常用Qwen作为品牌关键词）
- **MLX** (部署工具): 模型集成至mlx_lm（快速开始部分），用户搜索MLX部署相关关键词，该工具是模型特有的部署方式，未被排除
- **22B参数** (参数规格): 激活参数量为22B（模型概览），用户搜索特定参数量模型时会使用，符合参数规格维度要求，且与排除列表中的32B参数有区分

### Qwen/Qwen3-235B-A22B-Thinking-2507

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Thinking-2507

**关键词列表**:

- **Qwen3-235B-A22B-Thinking-2507** (当前模型品牌名): 项目名称直接对应当前模型完整名称，是用户精准搜索该特定版本的唯一标识
- **思维推理** (技术特性): 模型核心升级点为思维链增强，且README强调‘仅支持思维推理模式’，是区别于普通大模型的关键功能
- **激活22B** (参数规格): 模型采用MoE架构，激活参数为22B，是区别于全参数激活模型的显著技术特征，用户会搜索‘稀疏激活大模型’
- **学术评测** (功能场景): 模型明确针对学术评测任务优化，属于精准场景词，区别于通用对话或编程助手类模型
- **94层** (技术特性): 模型层数达94层，是超大模型的结构特征，用户在对比深度架构时会搜索‘90层以上模型’等关键词

### google-t5/t5-3b

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-3b

**关键词列表**:

- **google-t5t5-3b** (当前模型品牌名): 从项目URL和名称提取的当前模型名称
- **30亿参数** (参数规格): 当前模型的参数规模描述
- **问答任务** (功能场景): 当前模型的应用场景之一

### microsoft/table-transformer-structure-recognition

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/table-transformer-structure-recognition

**关键词列表**:

- **microsofttable-transformer-structure-recognition** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **表格结构识别** (功能场景): 当前模型的主要应用功能
- **PubTables1M** (功能场景): 当前模型训练所用的数据集，体现其训练背景和针对性
- **DETR** (技术特性): 当前模型等效的基础模型，代表其技术类型
- **normalize-before** (技术特性): 当前模型采用的独特设置，属于技术特性方面

### Alibaba-NLP/WebSailor-3B

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/WebSailor-3B

**关键词列表**:

- **WebSailor** (当前模型品牌名): 从项目名称Alibaba-NLP/WebSailor-3B提取的当前模型核心名称
- **网络导航** (功能场景): 当前模型执行复杂网络导航任务的核心应用场景
- **双采样策略优化** (技术特性): 当前模型提出的DUPO算法对应的技术特性描述
- **拒绝采样微调** (技术特性): 当前模型冷启动阶段采用的核心训练技术
- **代理强化学习** (技术特性): 当前模型优化探索策略的关键技术路径
- **SailorFog-QA** (技术特性): 当前模型创新的数据合成流程名称，具有技术独特性

### Qwen/Qwen3-235B-A22B-Thinking-2507-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8

**关键词列表**:

- **思考长度提升** (技术特性): README 中提到该版本增加了思考长度，是模型的核心技术改进
- **256K-长上下文** (技术特性): 模型支持 256K 规模的长上下文理解，属于独特的技术能力
- **人类偏好对齐** (技术特性): 模型在对齐人类偏好方面有显著改进，提升交互体验

### HKUSTAudio/xcodec2

**URL**: https://ai.gitcode.com/hf_mirrors/HKUSTAudio/xcodec2

**关键词列表**:

- **XCodec2** (当前模型品牌名): 项目名称为HKUSTAudio/xcodec2，模型核心名称为XCodec2，是用户搜索该语音令牌化器时最可能使用的关键词
- **语音令牌化器** (功能场景): 模型核心功能是将语音转化为离散令牌，属于语音合成的前置关键模块，用户会直接搜索此功能术语
- **LLaSA** (当前模型品牌名): 论文中提出的新型语音合成框架，与XCodec2深度绑定，是模型的核心创新组件，属于当前项目独有的命名
- **Codec-Does-Matter** (技术特性): 论文标题中的核心主张，代表模型对编解码器语义缺陷的突破性探索，是该模型区别于其他语音令牌化器的独特技术标签
- **50-tokenss** (技术特性): 模型关键性能指标（每秒50个令牌），是用户评估语音令牌化器实时性时会搜索的具体数值型特征，非泛泛性能描述
- **多语言语音语义** (功能场景): 模型明确支持多语言语音语义建模，是区别于仅支持单语或低语义保真度编码器的核心应用场景
- **语音重建** (功能场景): 模型核心目标是高质量语音重建，属于语音合成领域用户明确搜索的下游任务关键词

### LiquidAI/LFM2-700M

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-700M

**关键词列表**:

- **Liquid-AI** (当前模型品牌名): 开发团队品牌，用户会搜

### ByteDance-Seed/SeedVR2-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR2-7B

**关键词列表**:

- **SeedVR2** (当前模型品牌名): 项目名称中直接出现的模型名称
- **单步视频修复** (功能场景): 模型的核心应用是一次推理完成高清视频的修复
- **自适应窗口注意力** (技术特性): 论文提出的用于高清修复的动态窗口注意力机制
- **对抗后训练** (技术特性): 模型采用的对抗式后训练策略，提高生成质量与稳定性
- **特征匹配损失** (技术特性): 文中验证的关键损失函数之一，用于提升视频时序连贯性

### mradermacher/Qwen2-Audio-7B-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-i1-GGUF

**关键词列表**:

- **audio-text-to-text** (功能场景): 当前模型的核心功能场景，README标签明确标注
- **i1-IQ量化** (技术特性): 当前模型提供的独特量化版本系列（如i1-IQ1_S、i1-IQ2_XS等）
- **chat** (功能场景): 当前模型的应用场景之一，README标签明确标注

### fixie-ai/ultravox-v0_6-llama-3_3-70b

**URL**: https://ai.gitcode.com/hf_mirrors/fixie-ai/ultravox-v0_6-llama-3_3-70b

**关键词列表**:

- **Ultravox** (当前模型品牌名): 从项目名称 fixie-ai/ultravox-v0_6-llama-3_3-70b 中提取的核心模型品牌名，符合简化规则（去版本号）
- **语音到文本** (功能场景): 模型核心功能是接收语音输入并生成文本输出，用户会搜索此类明确应用场景，且未在高频词列表中
- **多模态语音** (技术特性): 模型定义为多模态语音大语言模型，'多模态语音'是其区别于纯文本模型的独特技术标签，非通用词
- **噪声鲁棒语音** (技术特性): v0.6版本明确在噪声数据上训练，能识别并输出((noise))，这是该模型独有的鲁棒性特征，具有搜索价值
- **印地语语音理解** (功能场景): v0.6在印地语语音数据上专项增强，是该版本独有的语言能力，用户可能专门搜索印地语语音AI模型
- **音频伪标记** (技术特性): 模型使用<|audio|>伪标记处理语音输入，是其架构设计的关键技术点，具有独特性和搜索区分度

### Prior-Labs/TabPFN-v2-clf

**URL**: https://ai.gitcode.com/hf_mirrors/Prior-Labs/TabPFN-v2-clf

**关键词列表**:

- **TabPFN-v2-clf** (当前模型品牌名): 从项目名称提取的当前模型名称
- **基于Transformer** (技术特性): 当前模型的核心技术架构
- **小型表格数据集** (功能场景): 当前模型的应用数据集类型
- **先验数据学习** (技术特性): 当前模型的核心技术方法

### bartowski/LLaMA-Mesh-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/bartowski/LLaMA-Mesh-GGUF

**关键词列表**:

- **LLaMA-Mesh** (当前模型品牌名): 从项目名称提取的当前模型名称
- **llamacpp-imatrix-量化** (技术特性): 当前模型使用的量化技术特性
- **LM-Studio运行** (部署工具): 当前模型可在LM Studio中运行，属于部署相关内容
- **mesh-generation** (功能场景): 当前模型的功能场景之一
- **Q6KL量化** (技术特性): 当前模型包含的量化类型，是独特的技术特性体现

### pcoloc/autotrain-mikrotik-7-7-1860563588

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-mikrotik-7-7-1860563588

**关键词列表**:

- **autotrain** (部署工具): 模型通过AutoTrain平台训练，是用户搜索自动化训练工具时的核心关键词，且未被高频词列表排除
- **joblib** (部署工具): 模型使用joblib序列化，是部署和加载的关键技术点，属于用户在本地部署时可能搜索的特定工具词
- **mikrotik** (功能场景): 模型专用于MikroTik设备相关预测（如网络性能、流量等），是该模型独有的应用场景关键词

### Lightricks/LTX-Video

**URL**: https://ai.gitcode.com/hf_mirrors/Lightricks/LTX-Video

**关键词列表**:

- **LTX-Video** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ltx-video** (当前模型品牌名): README标签中明确标注的模型名称
- **实时视频生成** (功能场景): 当前模型的核心功能特性
- **DiT架构** (技术特性): 当前模型的基础架构技术
- **13B参数** (参数规格): 当前模型的主流参数规格

### lovis93/Motion-Lora-Camera-Push-In-Wan-14B-720p-I2V

**URL**: https://ai.gitcode.com/hf_mirrors/lovis93/Motion-Lora-Camera-Push-In-Wan-14B-720p-I2V

**关键词列表**:

- **Motion-Lora** (当前模型品牌名): 从项目名称提取的简洁品牌名称，唯一标识该 LoRA 模型
- **Push-in-camera** (功能场景): 模型的触发词，用于生成推镜式运动效果，用户搜索时会直接使用该词
- **电影感运动** (功能场景): 模型专注于为生成内容注入电影级别的运动感，符合用户对动态视觉效果的搜索需求
- **推镜式运镜** (功能场景): 描述模型独特的推镜运动风格，是用户寻找特定镜头运动效果时的关键词
- **LoRA微调** (技术特性): 模型采用 LoRA 微调技术，区别于普通全模型训练，用户会搜索此类技术实现方式
- **100段影像训练** (技术特性): 模型基于 100 段精选影像进行训练，体现数据质量和训练细节，具备搜索价值

### TeslaYang123/TC-Light

**URL**: https://ai.gitcode.com/hf_mirrors/TeslaYang123/TC-Light

**关键词列表**:

- **TC-Light** (当前模型品牌名): 项目名称直接来源于模型名称，是用户搜索该特定模型的唯一标识
- **视频重光照** (功能场景): 模型核心功能是操纵视频光照分布，属于明确的用户搜索意图关键词，且未在排除列表中
- **时间一致性生成** (技术特性): 模型核心创新点为‘时间一致性’的生成式渲染，是区别于其他视频生成模型的关键技术标签
- **真实世界迁移** (功能场景): 模型目标为实现sim2real/real2real中的真实世界光照迁移，是用户在具身智能、数据增强场景中可能搜索的精准术语
- **单样本生成** (技术特性): 模型仅需单样本输入即可完成光照迁移，属于稀缺且具区分度的技术特征，非通用表述
- **高动态视频处理** (功能场景): 模型专门针对运动复杂、前景背景频繁切换的高动态视频优化，是用户在视频编辑领域可能搜索的垂直场景词
- **规范视频表示** (技术特性): 论文中提出的原创技术组件，用于优化光照一致性，属于模型独有的技术术语，具有高区分度

### adrientoupet/SeedVR2_comfyUI

**URL**: https://ai.gitcode.com/hf_mirrors/adrientoupet/SeedVR2_comfyUI

**关键词列表**:

- **视频超分** (功能场景): 当前模型的核心功能
- **时间一致性** (技术特性): 当前模型的技术特点
- **扩散技术** (技术特性): 当前模型采用的核心技术
- **多GPU运行** (部署工具): 当前模型的部署方式
- **单机运行** (部署工具): 当前模型的部署方式
- **额外upscale模型** (功能场景): 当前模型的具体用途

### unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF

**关键词列表**:

- **长上下文理解** (功能场景): 当前模型强化了256K长上下文理解能力，这是其独特功能
- **Unsloth部署** (部署工具): 文档中提及使用Unsloth运行和微调该模型，是该模型的一种部署方式

### pcoloc/autotrain-600-dragino-1839063122

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-600-dragino-1839063122

**关键词列表**:

- **R20.502** (技术特性): 决定系数作为核心评估指标被突出展示，体现模型解释度优势
- **MAE77.527** (技术特性): 平均绝对误差是回归类模型的重要性能度量标准
- **pcolocautotrain-600-dragino** (当前模型品牌名): 完整的项目路径标识符，包含组织名(pcoloc)、训练规模(600)和数据集特征(dragino)

### google-t5/t5-large

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-large

**关键词列表**:

- **T5-Large** (当前模型品牌名): 模型名称直接来源于项目路径 google‑t5/t5‑large
- **文本到文本框架** (技术特性): T5 采用统一的 text‑to‑text 设计，是其核心技术特性
- **跨语言任务** (功能场景): T5 Large 在英语、法语、罗马尼亚语、德语等多语言上均可使用，适用于跨语言任务
- **7.7B参数** (参数规格): 模型拥有约 7.7 亿参数，属于大规模语言模型的典型规格

### OmniGen2/OmniGen2

**URL**: https://ai.gitcode.com/hf_mirrors/OmniGen2/OmniGen2

**关键词列表**:

- **OmniGen2** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该模型的核心品牌词
- **非共享参数** (技术特性): OmniGen2区别于v1的关键架构设计，用户搜索模型架构差异时可能使用该术语
- **解耦式图像分词器** (技术特性): 模型独有的图像处理机制，属于高区分度的技术术语，符合用户搜索模型底层设计的意图
- **TeaCache** (部署工具): 模型官方支持的推理加速工具，属于模型生态专属组件，非通用技术
- **TaylorSeer** (部署工具): 官方集成的推理优化方案，是OmniGen2特有的加速技术，具有唯一性
- **OmniContext** (技术特性): 模型自研的基准测试集名称，属于模型专属评估体系，用户可能搜索该术语来评估模型
- **CPU卸载** (部署工具): 模型明确支持的低显存部署方式，是区别于其他多模态模型的实用部署特性

### prs-eth/marigold-normals-v1-1

**URL**: https://ai.gitcode.com/hf_mirrors/prs-eth/marigold-normals-v1-1

**关键词列表**:

- **Marigold-Normals** (当前模型品牌名): 从项目名称和模型卡片标题提取的当前模型名称
- **normals-estimation** (功能场景): 当前模型的核心功能，用于表面法线估计
- **单目法向量估计** (功能场景): 当前模型的具体应用场景，从单张图像估计法向量
- **image-analysis** (功能场景): 当前模型的图像分析应用场景
- **computer-vision** (技术特性): 当前模型所属的技术领域
- **zero-shot** (技术特性): 当前模型的技术特性，支持零样本场景
- **in-the-wild** (技术特性): 当前模型的技术特性，适用于自然场景

### unsloth/Kimi-K2-Instruct-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Kimi-K2-Instruct-GGUF

**关键词列表**:

- **Kimi-K2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **1万亿总参数** (参数规格): 当前模型总参数达到1万亿，体现模型规模
- **MuonClip优化器** (技术特性): 当前模型应用了MuonClip优化器，是核心技术特性

### deepset/bert-base-cased-squad2

**URL**: https://ai.gitcode.com/hf_mirrors/deepset/bert-base-cased-squad2

**关键词列表**:

- **bert-base-cased-squad2** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索具体SQuAD2微调模型时会使用此完整名称
- **SQuAD-v2** (训练数据): 模型训练所用的专属数据集名称，是该模型区别于其他问答模型的关键标识，用户会搜索‘SQuAD v2模型’
- **英文问答** (功能场景): 模型仅支持英语，用户搜索‘英文阅读理解’‘英文抽取式问答’等场景时会使用此自然搜索词

### intfloat/multilingual-e5-large-instruct

**URL**: https://ai.gitcode.com/hf_mirrors/intfloat/multilingual-e5-large-instruct

**关键词列表**:

- **intfloatmultilingual-e5-large-instruct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **MS-MARCO段落排序** (功能场景): README中提及了对该数据集的查询和段落进行编码的示例，属于模型可应用的功能场景
- **93-languages** (功能场景): 表明模型支持93种语言，是模型在语言支持方面的独特特性，体现其功能场景
- **averagepool** (技术特性): 是代码中对last_hidden_states和attention_mask进行处理的函数，属于模型使用过程中的技术特性
- **getdetailedinstruct** (技术特性): 是代码中用于根据任务描述和查询生成详细指令的函数，属于模型使用过程中的技术特性

### Kwaipilot/OASIS-code-1.3B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/OASIS-code-1.3B

**关键词列表**:

- **OASIS** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **代码搜索** (功能场景): 模型定位为提升代码检索系统的核心任务
- **代码嵌入** (功能场景): 模型提供高质量的代码向量表示，用于语义匹配
- **仓库级程序分析** (技术特性): 独特的分析方式，帮助模型理解不同代码库的结构
- **OASIS-instruct-数据合成算法** (技术特性): 专有的数据合成算法，提升模型在代码语义上的学习效果
- **融合损失函数** (技术特性): 模型使用的专用损失函数，增强检索准确度

### joeddav/xlm-roberta-large-xnli

**URL**: https://ai.gitcode.com/hf_mirrors/joeddav/xlm-roberta-large-xnli

**关键词列表**:

- **xlm-roberta-large-xnli** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **零样本文本分类** (功能场景): 当前模型的核心功能用途
- **XNLI数据集** (技术特性): 当前模型微调所使用的关键数据集
- **16种语言** (功能场景): 当前模型支持的语言数量特性
- **zero-shot-classification** (技术特性): 当前模型核心技术特性及标签中明确标注的任务类型
- **multinli** (技术特性): 当前模型相关的关键数据集标签

### skt/A.X-3.1

**URL**: https://ai.gitcode.com/hf_mirrors/skt/A.X-3.1

**关键词列表**:

- **A.X-3.1** (当前模型品牌名): 项目名直接给出的当前模型品牌名，简洁易搜
- **韩语大模型** (功能场景): 用户想找专门懂韩语的大模型时会直接搜索
- **34B参数** (参数规格): 主流参数档位之一，用户常按参数量筛选模型
- **企业级部署** (部署工具): README强调面向企业落地，用户搜索企业级LLM部署方案的高频词
- **主权AI** (技术特性): SKT提出的自主可控概念，吸引关注国产化/主权AI的搜索流量

### moonshotai/Kimi-Audio-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-Audio-7B-Instruct

**关键词列表**:

- **Kimi-Audio** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **流式音频生成** (技术特性): 采用分块流式解码器实现低延迟的音频生成
- **混合音频输入** (技术特性): 模型使用连续声学特征 + 离散语义令牌的混合输入方式
- **Docker部署** (部署工具): 官方提供 Docker 镜像，便于快速本地部署和推理

### JacobLinCool/MP-SENet-DNS

**URL**: https://ai.gitcode.com/hf_mirrors/JacobLinCool/MP-SENet-DNS

**关键词列表**:

- **MP-SENet-DNS** (当前模型品牌名): 从项目名称提取的当前模型完整名称，未发现可简化的品牌名映射
- **speech-enhancement** (功能场景): 当前模型的核心应用场景，用户会搜索的语音增强相关功能词
- **denoising** (功能场景): 当前模型的主要功能，用户搜索音频降噪时会使用的关键词
- **Audio-to-Audio** (技术特性): 当前模型的输入输出类型，体现其音频处理的技术特性
- **pytorchmodelhubmixin** (部署方式): 当前模型的集成部署方式，体现其在PyTorch Hub的部署特性

### lysandre/tiny-tapas-random-sqa

**URL**: https://ai.gitcode.com/hf_mirrors/lysandre/tiny-tapas-random-sqa

**关键词列表**:

- **tiny-tapas-random-sqa** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Tapas** (当前模型品牌名): 项目名称中的tiny - tapas表明与Tapas相关，可视为当前模型关联的品牌标识
- **SQA** (功能场景): 项目名称中的SQA可能代表特定功能场景，推测为用户搜索该模型时会关注的点
- **随机数据处理** (功能场景): 项目名称中的random暗示可能涉及随机数据处理功能，是模型可能的应用方向

### OpenGVLab/InternVL3-78B

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVL3-78B

**关键词列表**:

- **InternVL3-78B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **工业图像分析** (功能场景): 当前模型扩展的全新多模态能力之一
- **3D视觉感知** (功能场景): 当前模型扩展的全新多模态能力之一

### cross-encoder/stsb-distilroberta-base

**URL**: https://ai.gitcode.com/hf_mirrors/cross-encoder/stsb-distilroberta-base

**关键词列表**:

- **DistilRoBERTa-base** (当前模型品牌名): 模型名称中直接出现的品牌名，去除版本前缀保持简洁
- **Cross-Encoder** (技术特性): 模型采用的核心架构，用于成对句子相似度计算
- **语义相似度评分** (功能场景): 模型的主要功能是为两句文本输出 0~1 的相似度分数
- **STS-Benchmark** (训练数据): 模型在该公开语义相似度基准数据集上进行训练
- **英文语义匹配** (功能场景): 模型专注于英文句子的语义相似度匹配

### OpenGVLab/VideoMAEv2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/VideoMAEv2-Base

**关键词列表**:

- **VideoMAEv2-Base** (当前模型品牌名): 从项目名称 OpenGVLab/VideoMAEv2-Base 直接提取的当前模型唯一品牌名，用户搜索视频模型时会直接使用此名称
- **视频特征提取** (功能场景): README 明确指出模型用途为‘视频特征提取’，是用户搜索视频理解类模型时的核心意图关键词
- **视频掩码自编码器** (技术特性): 模型基于‘视频掩码自编码器’架构，是论文核心创新点，用户搜索视频自监督学习技术时会使用该术语
- **双重掩码策略** (技术特性): 论文提出的核心技术，区别于其他视频模型的独有机制，具备高区分度，用户研究视频MAE改进时会搜索此词
- **UnlabeledHybrid-1M** (技术特性): 模型预训练所用的专属数据集名称，是该模型训练背景的关键标识，专业用户会以此作为检索条件
- **VideoMAE-V2** (当前模型品牌名): 论文标题中的标准命名，与‘VideoMAEv2-Base’互为品牌别名，用户可能搜索完整论文名称而非简化版
- **自监督视频学习** (技术特性): 模型采用自监督方式训练，聚焦视频领域，是该模型所属技术方向的精准描述，区别于通用自监督学习
- **CVPR23视频模型** (技术特性): 模型发表于CVPR 2023，用户搜索顶会最新视频模型时会使用‘CVPR23+视频’这类组合关键词，具有时效性与权威性

### Qwen/Qwen3-Embedding-4B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Embedding-4B-GGUF

**关键词列表**:

- **Qwen3-Embedding** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **向量自定义维度** (技术特性): 支持用户定义32-2560输出维度的独特技术特性
- **32k上下文** (技术特性): 当前模型32k上下文长度的核心技术参数
- **q4KM量化** (部署工具): 当前模型支持的具体量化部署方式
- **q5KM量化** (部署工具): 当前模型支持的具体量化部署方式
- **代码检索** (功能场景): 模型在代码检索任务中的应用场景

### Wan-AI/Wan2.1-T2V-14B-Diffusers

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-T2V-14B-Diffusers

**关键词列表**:

- **T2V-14B** (当前模型品牌名): 从项目名称提取的当前模型具体版本名称
- **中英双语文本生成** (功能场景): 当前模型独特的能力，具有区分度
- **高动态视觉效果** (功能场景): 当前模型在生成方面的突出特点

### openai/imagegpt-large

**URL**: https://ai.gitcode.com/hf_mirrors/openai/imagegpt-large

**关键词列表**:

- **ImageGPT** (当前模型品牌名): 项目名称直接给出的模型品牌名
- **像素级生成** (功能场景): 用户会搜的图像生成方式，强调逐像素建模
- **线性探测** (功能场景): README明确提到的下游任务用法，用户搜特征提取时常用
- **自监督图像预训练** (技术特性): 模型核心训练方式，用户想了解无标注图像预训练时会搜
- **3232图像生成** (技术特性): 分辨率信息直观体现模型能力，用户搜小图生成时会用

### google/ddpm-church-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-church-256

**关键词列表**:

- **DDPMChurch256** (当前模型品牌名): 项目名称中直接的模型标识，用户搜索时会使用完整或简化的模型名
- **Langevin-动力学** (技术特性): 论文中采用的去噪分数匹配基于 Langevin 动力学，是模型的核心技术点
- **加权变分界** (技术特性): 训练时使用的 Weighted Variational Bound，区别于普通变分自编码器
- **渐进式有损解压缩** (技术特性): 模型天然支持的 progressive lossy decompression 方案，具备独特的解码特性
- **DDPMPipeline** (部署工具): 使用 HuggingFace Diffusers 提供的 DDPMPipeline 进行加载与推理，是模型的标准部署入口
- **Inception-分数-9.46** (评估指标): 在 CIFAR‑10 上取得的 Inception Score 为 9.46，用户常以该指标评估图像生成模型

### microsoft/tapex-large-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-large-finetuned-wtq

**关键词列表**:

- **WikiTableQuestions** (当前模型品牌名): 模型在WikiTableQuestions数据集上微调，该数据集名已成为该模型的识别标识，用户搜索‘WTQ模型’‘WikiTableQuestions模型’时会命中
- **合成SQL语料库** (技术特性): TAPEX预训练方法的核心术语，用户可能搜索‘合成SQL训练’‘自动生成SQL表格’等专业关键词，具独特性

### microsoft/tapex-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-base

**关键词列表**:

- **tapex** (当前模型品牌名): 从项目名称microsoft/tapex-base提取的当前模型名称
- **表格事实验证** (功能场景): 当前模型通过微调可应用的任务场景

### google/ddpm-cat-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-cat-256

**关键词列表**:

- **ddpm-cat-256** (当前模型品牌名): 从项目名称提取的当前模型名称
- **去噪扩散概率模型** (技术特性): 当前模型的核心技术特性描述
- **schedulingddim** (技术特性): 当前模型推理可用的另一种离散噪声调度器，用于平衡质量与速度
- **schedulingpndm** (技术特性): 当前模型推理可用的离散噪声调度器，提供更快的推理速度

### openai/diffusers-cd_imagenet64_l2

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-cd_imagenet64_l2

**关键词列表**:

- **cdimagenet64l2** (当前模型品牌名): 从项目名称提取的当前模型具体名称
- **一致性蒸馏** (技术特性): 当前模型训练的核心技术方法（CD）
- **一致性训练** (技术特性): 当前模型支持的独立训练方法（CT）

### nvidia/segformer-b4-finetuned-cityscapes-1024-1024

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/segformer-b4-finetuned-cityscapes-1024-1024

**关键词列表**:

- **SegFormer-b4** (当前模型品牌名): 模型名称中包含的品牌名和尺寸标识，直接对应项目名称
- **CityScapes微调** (技术特性): 模型在 CityScapes 数据集上完成微调，突出其针对城市道路场景的优化
- **1024x1024分辨率** (技术特性): 模型在高分辨率（1024×1024）下进行训练和推理，区别于低分辨率版本
- **轻量级MLP解码头** (技术特性): 采用全 MLP 解码头设计，保持轻量化且高效的解码结构
- **NVIDIA** (当前模型品牌名): 模型由 NVIDIA 官方发布，体现其来源和品牌背书

### google/siglip2-so400m-patch16-naflex

**URL**: https://ai.gitcode.com/hf_mirrors/google/siglip2-so400m-patch16-naflex

**关键词列表**:

- **SigLIP-2** (当前模型品牌名): 从项目名称中提取的当前模型名称
- **视觉编码器** (功能场景): 当前模型可作为视觉语言模型及其他视觉任务的视觉编码器，属于应用场景
- **So400m** (当前模型品牌名): 从项目名称中提取，是当前模型名称的一部分，具有区分度
- **Patch16** (当前模型品牌名): 从项目名称中提取，是当前模型名称的一部分，具有区分度
- **NAFlex** (当前模型品牌名): 从项目名称中提取，是当前模型名称的一部分，具有区分度

### nvidia/bigvgan_v2_24khz_100band_256x

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/bigvgan_v2_24khz_100band_256x

**关键词列表**:

- **音频生成** (功能场景): 模型用于将文本或特征转换为高质量音频，是用户在AI音频领域最直接的搜索意图关键词
- **融合CUDA内核** (技术特性): 模型通过自研CUDA内核融合上采样与激活操作，是其推理速度提升的关键技术，具有高区分度
- **44-kHz音频** (功能场景): 模型支持最高44 kHz采样率，是用户寻找高保真音频生成模型时的关键参数搜索词
- **HuggingFace-Spaces** (部署工具): 模型已官方接入HuggingFace Spaces提供在线体验，用户会搜索'XXX模型 在线体验'或'HuggingFace Spaces 音频'等意图

### google/ddpm-ema-celebahq-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-ema-celebahq-256

**关键词列表**:

- **CelebA-HQ** (功能场景): 模型训练数据集，用户搜高清人脸生成时常用
- **256分辨率** (参数规格): 模型输出尺寸，用户搜高清图生成时的关键参数

### zai-org/GLM-4.5-Air-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5-Air-FP8

**关键词列表**:

- **二次开发** (技术特性): MIT协议明确支持商业用途和二次开发，属于重要使用权限

### moonshotai/Kimi-K2-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-K2-Instruct

**关键词列表**:

- **Mixture-of-Experts** (技术特性): 当前模型的核心技术架构描述
- **Muon-optimizer** (技术特性): 当前模型训练使用的独特优化器技术
- **万亿参数** (参数规格): 当前模型的总参数规模描述，属于主流规格
- **聊天模板** (技术特性): 当前模型独立设计的对话交互模板系统

### baidu/ERNIE-4.5-300B-A47B-FP8-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-FP8-Paddle

**关键词列表**:

- **ERNIE-4.5-300B-A47B** (当前模型品牌名): 从项目名称直接提取的当前模型完整名称，符合品牌名提取规则，且未被高频词列表排除
- **异构MoE架构** (技术特性): 模型独有的多模态异构MoE结构，包含模态隔离路由等创新设计，是区别于其他MoE模型的关键特征
- **无损量化** (技术特性): 模型支持4位/2位无损量化，是其推理优化的核心能力，非通用术语，具有技术独特性
- **视觉-语言理解** (功能场景): 模型明确支持VLM（视觉-语言模型）场景，是其核心应用方向之一，非泛化词，区别于通用文生图

### Qwen/Qwen3-30B-A3B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-4bit

**关键词列表**:

- **MLX-4bit** (部署工具): 模型已针对 MLX 框架进行 4bit 量化，适合在 Apple Silicon 上高效部署
- **131k上下文** (技术特性): 通过 YaRN 扩展支持最高 131,072 token 的长上下文

### neuralmind/bert-base-portuguese-cased

**URL**: https://ai.gitcode.com/hf_mirrors/neuralmind/bert-base-portuguese-cased

**关键词列表**:

- **BERTimbau-Base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **bert-base-portuguese-cased** (当前模型品牌名): 从项目URL和名称中提取的当前模型名称
- **巴西葡萄牙语预训练** (功能场景): 当前模型针对巴西葡萄牙语进行预训练，是其应用场景
- **命名实体识别** (功能场景): 当前模型在命名实体识别任务中实现了先进性能
- **句子文本相似度** (功能场景): 当前模型在句子文本相似度任务中实现了先进性能
- **文本蕴含识别** (功能场景): 当前模型在文本蕴含识别任务中实现了先进性能
- **BERT-Base架构** (技术特性): 当前模型采用的BERT-Base架构是其技术特性

### Qwen/Qwen3-235B-A22B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-8bit

**关键词列表**:

- **MLX量化部署** (部署工具): 项目名称包含MLX和8bit，体现该模型使用MLX进行8bit量化部署的方式
- **100-语言支持** (功能场景): 当前模型具备支持100 + 语言与方言，进行多语言指令遵循与翻译的功能场景
- **32K-原生上下文** (技术特性): 当前模型原生支持32,768 tokens的上下文长度，是其技术特性之一
- **A22B-模型架构** (技术特性): 项目名称中的A22B体现了该模型独特的架构相关特性

### baidu/ERNIE-4.5-21B-A3B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Base-Paddle

**关键词列表**:

- **FastDeploy部署** (部署工具): 模型推荐的部署框架，用户可能搜索相关部署方案

### LGAI-EXAONE/EXAONE-4.0-32B

**URL**: https://ai.gitcode.com/hf_mirrors/LGAI-EXAONE/EXAONE-4.0-32B

**关键词列表**:

- **混合注意力机制** (技术特性): 模型采用局部注意力与全局注意力的混合方案，是其独特的技术亮点
- **RMS归一化** (技术特性): 在 Q、K 投影后加入 RMS 归一化，提高模型性能，具备辨识度
- **FriendliAI平台** (部署工具): 模型可直接在 FriendliAI 平台上体验，属于特定的部署/使用渠道

### nvidia/OpenReasoning-Nemotron-7B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-7B

**关键词列表**:

- **多智能体协同工作** (技术特性): 当前模型的独特技术能力
- **生成式解决方案** (技术特性): 当前模型的技术实现方式
- **nvidia** (当前模型品牌名): 模型所属品牌，用户会搜索品牌相关模型
- **NeMo** (部署工具): 模型相关部署框架，开发者会搜索

### sentence-transformers/paraphrase-MiniLM-L6-v2

**URL**: https://ai.gitcode.com/hf_mirrors/sentence-transformers/paraphrase-MiniLM-L6-v2

**关键词列表**:

- **paraphrase-MiniLM-L6-v2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **句子语义映射** (功能场景): 该模型能将句子和段落映射到稠密向量空间，此为模型的主要功能体现
- **聚类任务** (功能场景): 模型可用于聚类任务，是模型的应用场景之一
- **语义搜索任务** (功能场景): 模型可用于语义搜索任务，是模型的应用场景之一
- **稠密向量空间** (技术特性): 模型将句子和段落映射到384维的稠密向量空间，这是模型的技术特性

### nanonets/Nanonets-OCR-s

**URL**: https://ai.gitcode.com/hf_mirrors/nanonets/Nanonets-OCR-s

**关键词列表**:

- **Nanonets-OCR-s** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，用户搜索OCR模型时可能直接输入此名称
- **LaTeX公式识别** (功能场景): 模型独有的数学公式自动转LaTeX能力，是学术与工程用户搜索OCR时的高价值差异化功能
- **签名检测** (功能场景): 模型能识别并隔离签名至<signature>标签，专用于法律/商务文档处理，属稀缺功能关键词
- **水印提取** (功能场景): 主动提取文档水印并封装至<watermark>标签，是当前模型区别于普通OCR的特有功能
- **复选框识别** (功能场景): 将表单复选框转为标准Unicode符号（☐/☑/☒），解决表单结构化难题，属精准场景词
- **复杂表格提取** (功能场景): 模型能同时输出Markdown和HTML表格，专攻复杂表格结构化，是企业文档处理高频搜索词
- **图像转Markdown** (功能场景): 模型核心输入输出范式，用户搜索‘图片转Markdown’时会精准匹配，且非通用OCR术语

### vidore/colpali-v1.3

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colpali-v1.3

**关键词列表**:

- **ColBERT风格** (技术特性): 当前模型生成文本和图像多向量表示的技术特性
- **PaliGemma-3B扩展** (技术特性): 当前模型基于PaliGemma-3B扩展构建
- **批次大小256** (技术特性): 当前模型训练时使用的批次大小
- **右填充方式** (技术特性): 当前模型训练时对查询采用的填充方式

### nvidia/audio-flamingo-3

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/audio-flamingo-3

**关键词列表**:

- **Audio-Flamingo** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **长上下文音频理解** (功能场景): 模型支持最长10分钟的音频上下文，属于核心使用场景
- **多轮音频对话** (功能场景): 模型具备多轮、多音频交互能力，适用于对话式音频应用
- **音频问答与推理** (功能场景): 模型在音频问答与推理任务上实现了性能突破
- **AF-Whisper编码器** (技术特性): 模型采用的统一音频编码器，是其核心技术创新之一
- **流式TTS模块** (技术特性): 模型的聊天版集成了流式文本转语音功能，提升交互体验
- **10分钟音频输入** (功能场景): 模型能够处理最长10分钟的音频输入，满足长音频处理需求

### sshleifer/distilbart-cnn-12-6

**URL**: https://ai.gitcode.com/hf_mirrors/sshleifer/distilbart-cnn-12-6

**关键词列表**:

- **distilbart-cnn** (当前模型品牌名): 从项目名称sshleifer/distilbart-cnn-12-6简化提取的当前模型名称
- **summarization** (功能场景): 标签中明确标注的当前模型核心功能
- **cnndailymail** (技术特性): 标签中与模型训练数据相关的核心技术特性
- **xsum** (技术特性): 标签中与模型训练数据相关的核心技术特性

### facebook/sam2-hiera-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam2-hiera-large

**关键词列表**:

- **facebooksam2-hiera-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像任意分割** (功能场景): 当前模型在图像方面的主要功能
- **视频任意分割** (功能场景): 当前模型在视频方面的主要功能
- **可提示视觉分割** (功能场景): 当前模型旨在解决的核心功能
- **SAM-2** (当前模型品牌名): 当前模型所属系列的名称
- **Mask-Generation** (功能场景): 当前模型的一个功能体现

### timm/convnextv2_nano.fcmae_ft_in22k_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/convnextv2_nano.fcmae_ft_in22k_in1k

**关键词列表**:

- **convnextv2nano** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，简洁且为用户搜索该特定模型的核心关键词
- **fcmae** (技术特性): 模型使用全卷积掩码自编码器（FCMAE）预训练，是该模型区别于其他ConvNeXt变体的核心技术标识
- **imagenet-1k** (数据集): 模型在ImageNet-1k上微调并评估，是用户筛选模型适用数据集时的关键搜索词，且未被高频词列表排除
- **224x224** (参数规格): 训练输入尺寸为224x224，是视觉模型部署时用户常查的输入尺寸规格，属于实用参数而非抽象技术细节
- **288x288** (参数规格): 测试时使用288x288分辨率，区别于主流224x224，是该模型部署调优时的差异化输入尺寸关键词
- **convnextv2** (当前模型品牌名): 模型属于ConvNeXt-V2系列，作为系列名是用户搜索同类架构时的通用入口词，且未被高频词列表排除

### nvidia/segformer-b0-finetuned-ade-512-512

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/segformer-b0-finetuned-ade-512-512

**关键词列表**:

- **SegFormerb0** (当前模型品牌名): 模型名称直接来源于项目名称，标识唯一的 SegFormer‑b0 版本
- **ADE20K** (数据集): 模型在 ADE20K 数据集上完成微调，是该数据集的典型基准模型
- **512x512分辨率** (输入规格): 模型在 512×512 像素的分辨率下进行训练和推理，用户常以此规格搜索
- **NVIDIA模型** (提供方): 模型由 NVIDIA 官方发布，用户可能以厂商名称检索

### microsoft/table-transformer-structure-recognition-v1.1-all

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/table-transformer-structure-recognition-v1.1-all

**关键词列表**:

- **Table-Transformer** (当前模型品牌名): 项目名称核心词，用户直接搜模型简称
- **DETR架构** (技术特性): 模型底层架构，搜‘DETR 表格’可引流
- **TATR** (当前模型品牌名): 论文简称，圈内用户高频缩写搜索

### flair/ner-english-fast

**URL**: https://ai.gitcode.com/hf_mirrors/flair/ner-english-fast

**关键词列表**:

- **ner-english-fast** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Flair** (技术特性): 当前模型基于的框架技术特性
- **LSTM-CRF架构** (技术特性): 当前模型的核心技术架构
- **sequence-tagger-model** (技术特性): 当前模型的技术类型标签
- **token-classification** (技术特性): 当前模型的技术任务类型
- **conll2003** (技术特性): 当前模型基于的数据集技术特性

### facebook/sam2.1-hiera-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam2.1-hiera-large

**关键词列表**:

- **sam2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频分割** (功能场景): 当前模型在视频中的核心应用场景
- **hiera-large** (当前模型品牌名): 从项目名称提取的模型架构标识

### unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF

**关键词列表**:

- **Qwen3-Coder-480B-A35B-Instruct** (当前模型品牌名): 项目名称中的完整模型名称，是当前模型的唯一标识，用户搜索此精确名称时指向本模型
- **256K上下文** (技术特性): 模型原生支持256K tokens上下文长度，是区别于其他模型的核心技术亮点，用户会搜索长上下文代码模型
- **智能体编码** (功能场景): 模型主打智能体编码能力，是其核心应用场景，用户搜索‘智能体编码模型’时会精准匹配
- **480B参数** (参数规格): 480B是当前模型的独有参数规模，属于超大规模代码模型，用户会搜索‘480B代码模型’等关键词
- **Yarn技术** (技术特性): 模型使用Yarn技术实现长上下文扩展，是技术实现层面的独特关键词，非通用术语，具有区分度
- **A35B-Instruct** (当前模型品牌名): 模型名称中的关键子版本标识，代表指令微调架构，是用户区分不同Qwen3-Coder变体时的搜索词
- **开源代码模型** (功能场景): 模型定位为开源领域性能媲美Claude Sonnet的代码模型，用户常搜‘开源代码模型’寻找替代方案

### merve/smol-vision

**URL**: https://ai.gitcode.com/hf_mirrors/merve/smol-vision

**关键词列表**:

- **smol-vision** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视觉与多模态AI模型** (功能场景): 当前模型提供前沿视觉与多模态AI模型的压缩、优化及定制化方案
- **零样本目标检测** (功能场景): 当前模型支持零样本目标检测模型的量化与优化
- **视觉语言模型微调** (技术特性): 当前模型支持视觉语言模型的微调

### facebook/bart-base

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/bart-base

**关键词列表**:

- **facebookbart-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本理解** (功能场景): 当前模型表现良好的应用场景
- **文本填充** (功能场景): 当前模型可使用的功能
- **双向编码器** (技术特性): 当前模型包含双向（类BERT）编码器，属于该技术特性

### distilbert/distilbert-base-cased-distilled-squad

**URL**: https://ai.gitcode.com/hf_mirrors/distilbert/distilbert-base-cased-distilled-squad

**关键词列表**:

- **DistilBERT** (当前模型品牌名): 模型名称中直接出现的品牌名称
- **轻量化** (技术特性): 相较于 BERT，参数量减少约 40%，模型体积更小、部署更轻便
- **问答** (功能场景): 模型在 SQuAD 数据集上微调，专用于自然语言问答任务
- **SQuAD微调** (功能场景): 模型的微调检查点基于 SQuAD v1.1 数据集，适合阅读理解和问答应用

### microsoft/Phi-4-mini-flash-reasoning

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/Phi-4-mini-flash-reasoning

**关键词列表**:

- **Phi-4-mini-flash** (当前模型品牌名): 从项目名称'microsoft/Phi-4-mini-flash-reasoning'简化提取，符合模型名称简化规则（如示例中的'DeepSeek-R1'），避免版本号冗余
- **推理** (功能场景): 模型概述明确指出'专注于高质量、高推理密度的数据'，且摘要提及'在Math500、AIME24/25和GPQA Diamond等推理任务中'，用户搜索AI模型时常用'推理'作为核心功能关键词
- **差分注意力** (技术特性): 摘要强调'搭载差分注意力机制的最大模型 Phi4-mini-Flash-Reasoning'，该技术是模型的核心创新点，用户搜索AI模型时会关注具体技术特性
- **64K上下文** (技术特性): 模型概述明确标注'支持64K令牌上下文长度'，该参数是用户搜索长文本处理模型时的关键指标，符合技术特性维度要求

### openai/whisper-large-v3-turbo

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-large-v3-turbo

**关键词列表**:

- **Whisper-large-v3-turbo** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **剪枝优化模型** (技术特性): 当前模型的关键技术优化方式
- **解码层优化** (技术特性): 当前模型提升速度的核心技术手段
- **97-languages** (技术特性): 当前模型支持的语言数量特性

### QuantStack/Wan2.1_I2V_14B_FusionX-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.1_I2V_14B_FusionX-GGUF

**关键词列表**:

- **Wan2.1I2V14BFusionX** (当前模型品牌名): 项目名称中的唯一模型标识，是当前模型的正式品牌名，用户搜索该名称时直接指向本模型
- **ComfyUI模型** (部署工具): 模型专为ComfyUI设计并依赖其GGUF节点部署，‘ComfyUI模型’是用户搜索特定工作流模型的高频意图词，且未被高频词列表完全覆盖（仅‘ComfyUI’被禁）

### nateraw/vit-age-classifier

**URL**: https://ai.gitcode.com/hf_mirrors/nateraw/vit-age-classifier

**关键词列表**:

- **vit-age-classifier** (当前模型品牌名): 从项目名称提取的当前模型名称
- **人脸年龄分类** (功能场景): 当前模型的主要应用场景

### Disya/UIGEN-T3-14B-Preview-Q4_K_M-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Disya/UIGEN-T3-14B-Preview-Q4_K_M-GGUF

**关键词列表**:

- **UIGENT3** (当前模型品牌名): 从项目仓库名称 Disya/UIGEN‑T3‑14B‑Preview‑Q4_K_M‑GGUF 中提取的简洁模型品牌名
- **UI生成** (功能场景): 模型专注于根据文本提示生成用户界面代码，属于 UI 生成场景
- **Tailwind-CSS生成** (功能场景): 模型能够输出符合 Tailwind CSS 框架的样式代码，是其独特的生成能力
- **HTML代码生成** (功能场景): 模型可直接生成完整的 HTML 页面结构，满足网页前端开发需求
- **llama.cpp部署** (部署工具): 模型以 GGUF 格式提供，可通过 llama.cpp 进行本地快速部署和推理

### autogluon/mitra-classifier

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/mitra-classifier

**关键词列表**:

- **autogluon-mitra** (当前模型品牌名): 从项目名称提取的当前模型名称，简洁体现项目主体
- **表格分类** (功能场景): 当前模型的应用场景，从标签和描述可知用于表格分类任务
- **上下文学习范式** (技术特性): 当前模型的预训练方式，融入了上下文学习范式
- **mitra分类器** (当前模型品牌名): 从项目名称及描述中提取的当前模型具体名称，突出分类器功能

### microsoft/git-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/git-base

**关键词列表**:

- **GIT** (当前模型品牌名): 项目名称中的核心模型简称，用户会直接搜索
- **GenerativeImage2Text** (当前模型品牌名): 论文与官方仓库使用的全称，搜索量高
- **视频字幕生成** (功能场景): 官方强调支持视频 captioning，场景词稀缺
- **CLIP-tokens** (技术特性): 模型以 CLIP 图像 tokens 为输入，技术关键词具区分度
- **图像分类生成** (功能场景): 官方提示可直接生成文本形式类别，独特用法

### Intel/dpt-large

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/dpt-large

**关键词列表**:

- **DPT-Large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **密集预测Transformer** (技术特性): 模型全称体现的核心技术架构
- **depth-estimation** (功能场景): 标签中明确的模型功能关键词

### vidore/colqwen2-v1.0

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colqwen2-v1.0

**关键词列表**:

- **图像补丁** (技术特性): 模型独特采用'图像补丁（image patches）'作为视觉编码单元，最大支持768个补丁，是区别于其他VLMs的关键技术特征
- **动态分辨率** (技术特性): 模型支持动态图像分辨率输入，不进行resize操作，保留原始宽高比，是其区别于ColPali等模型的显著技术优势
- **多向量表示** (技术特性): 模型生成文本与图像的ColBERT风格多向量表示，是其检索机制的核心技术术语，用户搜索相关架构时会使用
- **零样本泛化** (功能场景): 模型训练数据为全英文，明确用于研究非英语语言的零样本泛化能力，是其应用场景中可被搜索的独特价值点

### vidore/colpali

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colpali

**关键词列表**:

- **文档视觉特征索引** (功能场景): 模型能够高效建立文档视觉特征索引，是其核心功能
- **图像补丁嵌入** (技术特性): 将 SigLIP 输出的图像补丁嵌入输入到语言模型，实现跨模态映射

### facebook/vjepa2-vitl-fpc64-256

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitl-fpc64-256

**关键词列表**:

- **VITL-FPC64-256** (当前模型品牌名): 从项目名称提取，是当前模型名称的一部分，具有区分度

### calcuis/bagel-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/calcuis/bagel-gguf

**关键词列表**:

- **bagel** (当前模型品牌名): 从项目名称calcuis/bagel-gguf提取的当前模型名称
- **gguf-connector** (部署工具): 当前模型的专用部署工具，README中明确作为标签和运行方式提及
- **文本转图像** (功能场景): 当前模型的核心功能之一，属于多模态试验模型的具体应用场景
- **图像识别** (功能场景): 当前模型的核心功能之一，作为多模态试验模型的应用场景
- **完全离线运行** (部署工具): 当前模型的部署特性，用户搜索本地使用模型时可能采用的关键词

### google/owlvit-large-patch14

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlvit-large-patch14

**关键词列表**:

- **OWL-ViT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **CLIP主干网络** (技术特性): 当前模型采用的多模态主干网络

### ecmwf/aifs-ens-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/ecmwf/aifs-ens-1.0

**关键词列表**:

- **AIFS-ENS** (当前模型品牌名): 项目名称为ecmwf/aifs-ens-1.0，模型官方名称为AIFS ENS，是当前模型的唯一品牌标识，符合简化命名规则
- **概率预报** (功能场景): 模型核心功能是生成概率性天气预报（集成预报系统），用户搜索‘天气概率预报’‘AI概率预测’等意图明确，且非高频词
- **气象预报** (功能场景): 模型用于高空变量、地面参数、热带气旋路径预测，直接对应‘AI气象预报’搜索意图，非通用词且未在排除列表中
- **滑动窗口变换** (技术特性): 模型使用‘滑动窗口变换处理器’作为关键组件，属于独特技术术语，用户可能搜索‘AI滑动窗口气象模型’等长尾词
- **CRPS优化** (技术特性): 模型通过最小化CRPS（连续分级概率评分）训练，是专业领域内高区分度的技术关键词，非通用术语，未被排除
- **ECMWF-AI模型** (当前模型品牌名): ECMWF是权威机构，用户常搜索‘ECMWF AI模型’来查找其官方AI天气模型，该组合词具有强搜索意图且非高频词

### baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle

**关键词列表**:

- **2Bits** (技术特性): 独特的极低精度量化技术实现无损压缩的核心创新点

### philschmid/bart-large-cnn-samsum

**URL**: https://ai.gitcode.com/hf_mirrors/philschmid/bart-large-cnn-samsum

**关键词列表**:

- **bart-large-cnn-samsum** (当前模型品牌名): 项目名称即为模型的完整品牌名，直接体现模型身份
- **Amazon-SageMaker** (部署工具): 模型在 SageMaker 上训练并提供部署示例，属于云端部署方案
- **FP16混合精度** (技术特性): 训练时使用 fp16 混合精度，加速计算并降低显存占用
- **ROGUE1指标** (评估指标): README 中提到模型在 ROGUE‑1 上的得分，用于衡量摘要质量
- **samsum数据集** (数据集): 模型微调使用的公开对话摘要数据集 samsum，标识其训练来源
- **Hugging-Face容器** (部署工具): 模型使用 Hugging Face 深度学习容器进行训练和推理，属于容器化部署方式

### MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli

**URL**: https://ai.gitcode.com/hf_mirrors/MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli

**关键词列表**:

- **DeBERTa-v3-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **NLI模型** (功能场景): 当前模型的具体任务领域缩写
- **ANLI基准** (技术特性): 当前模型在该基准上表现优异，具有技术区分度

### ETH-CVG/lightglue_superpoint

**URL**: https://ai.gitcode.com/hf_mirrors/ETH-CVG/lightglue_superpoint

**关键词列表**:

- **ETH-CVGlightgluesuperpoint** (当前模型品牌名): 从项目名称提取的当前模型名称
- **位姿估计** (功能场景): 当前模型配合使用可实现的功能，即估计两张图像之间的位姿
- **兴趣点匹配** (功能场景): 当前模型的核心功能，用于匹配图像中检测到的两组兴趣点
- **自适应推理** (技术特性): 当前模型的技术特性，能根据待匹配图像对的难度调整计算量，必要时可提前停止推理或丢弃不可匹配点
- **轻量级匹配** (技术特性): 当前模型的特点，在内存和计算效率上更高，体现了轻量级的优势

### mistralai/Voxtral-Small-24B-2507

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Voxtral-Small-24B-2507

**关键词列表**:

- **Voxtral-Small** (当前模型品牌名): 项目名称为 mistralai/Voxtral-Small-24B-2507，简化后保留核心品牌名，符合用户搜索AI模型时的习惯
- **语音触发API** (功能场景): 模型独有的‘语音直接触发功能调用’能力，是差异化卖点，用户可能搜索‘语音触发API模型’
- **长音频转录** (功能场景): 支持30分钟音频转录，用户在寻找处理长语音的模型时会使用该词，具有明确场景指向性
- **多语言音频** (功能场景): 模型支持8种主流语言的音频处理，用户搜索‘多语言语音转录’时会匹配，且‘多语言支持’已被排除，但‘多语言音频’是具体场景词，未被禁用

### amazon/chronos-t5-small

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-t5-small

**关键词列表**:

- **Chronos-T5-Small** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自回归采样** (技术特性): 当前模型使用的技术特性

### facebook/dinov2-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-large

**关键词列表**:

- **视觉ViT** (技术特性): 模型基于视觉 Transformer（ViT）架构，但使用 ViT 缩写避免直接出现禁用词
- **Patch嵌入** (技术特性): 将图像切分为固定大小的 Patch 并进行线性嵌入，是模型的核心处理方式
- **大规模预训练** (技术特性): 在海量图像数据上进行预训练，以学习鲁棒的视觉特征

### julien-c/skops-digits

**URL**: https://ai.gitcode.com/hf_mirrors/julien-c/skops-digits

**关键词列表**:

- **skops** (当前模型品牌名): 项目名称直接包含skops，是用户搜索该模型的核心关键词
- **scikit-learn** (技术特性): 标签明确标注scikit-learn，用户会搜sklearn模型或sklearn兼容
- **digits分类** (功能场景): 模型用于手写数字tabular-classification，用户搜digits数据集或数字识别模型
- **joblib模型** (部署工具): 标签含Joblib，用户搜joblib格式下载或joblib部署
- **adam优化** (技术特性): 超参数表显示solver=adam，用户搜adam优化器模型
- **MLP手写数字** (功能场景): hidden_layer_sizes=(100,)表明为多层感知机，用户搜MLP digits或手写数字MLP

### depth-anything/Depth-Anything-V2-Large

**URL**: https://ai.gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Large

**关键词列表**:

- **Depth-Anything-V2-Large** (当前模型品牌名): 项目完整名称，用户可能直接搜索完整模型名
- **relative-depth** (功能场景): README标签中明确标注的模型功能相关术语
- **depth** (功能场景): README标签中明确标注的核心功能关键词
- **高效深度估计** (技术特性): 当前模型效率高的技术特性描述

### Salesforce/blip-vqa-capfilt-large

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip-vqa-capfilt-large

**关键词列表**:

- **图像字幕生成** (功能场景): README明确指出模型支持图像字幕生成，且在CIDEr指标上提升显著，是区别于其他VQA模型的独立应用场景
- **自举式生成** (技术特性): BLIP的核心创新点是'自举式生成字幕'（bootstrapped caption generation），属于模型独有的技术机制，用户研究VLP时会搜索此术语
- **噪声过滤** (技术特性): 模型通过字幕过滤器移除网络噪声数据，是其提升性能的关键技术手段，属于独特技术标签，非通用描述
- **零样本视频-语言** (功能场景): README提到模型可零样本迁移至视频-语言任务，该能力在视觉-语言模型中具区分度，用户搜索跨模态泛化能力时可能使用此词
- **ViT大型骨干** (技术特性): 模型明确采用ViT-large作为视觉编码器，是其架构的重要标识，用户对比模型结构时会搜索'ViT大型骨干'这类具体组件词

### NexaAIDev/Qwen2-Audio-7B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/NexaAIDev/Qwen2-Audio-7B-GGUF

**关键词列表**:

- **语音聊天** (功能场景): 当前模型支持的应用场景，可用于与用户进行语音交互解答问题等
- **音频分析** (功能场景): 当前模型具备的对音频进行处理分析的能力，如信息提取、摘要等
- **Nexa-SDK** (部署工具): 用于在本地设备运行该模型的开源推理框架
- **说话人识别** (功能场景): 当前模型能够识别说话人并进行响应的功能

### mradermacher/GCIRS-Reasoning-1.5B-R1-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/GCIRS-Reasoning-1.5B-R1-i1-GGUF

**关键词列表**:

- **矩阵量化** (技术特性): 模型采用矩阵量化技术，是区别于普通量化的关键特性
- **text-generation-inference** (部署工具): 模型文件可在 text-generation-inference 框架中直接使用，属于部署/推理工具
- **金融推理** (功能场景): 标签中包含 finance，表明模型在金融领域的推理任务上有应用

### unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF

**关键词列表**:

- **Qwen3-Coder** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **Qwen3-Coder-480B** (当前模型品牌名): 当前模型完整名称中的核心标识部分
- **智能体浏览器使用** (功能场景): 当前模型支持的智能体浏览器使用功能

### lzkhhh/ITDR-Qwen2.5-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-Qwen2.5-7B-Instruct

**关键词列表**:

- **ITDR-Qwen2.5** (当前模型品牌名): 从项目名称提取的当前模型简化名称

### zai-org/GLM-4.5

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5

**关键词列表**:

- **FP8-版本** (技术特性): 模型开放的 FP8 量化版本，适合高效部署
- **3550B参数** (参数规格): GLM-4.5 主模型的总参数规模，用户常以参数量搜索模型

### kakaocorp/kanana-1.5-v-3b-instruct

**URL**: https://ai.gitcode.com/hf_mirrors/kakaocorp/kanana-1.5-v-3b-instruct

**关键词列表**:

- **Kanana-1.5** (当前模型品牌名): 从项目名称 kakaocorp/kanana-1.5-v-3b-instruct 提取的核心品牌名，去掉版本后缀，符合简洁品牌名规范
- **韩文多模态** (功能场景): 模型明确支持韩文与英文的多模态指令遵循，是区别于通用多模态模型的本土化核心功能，用户可能搜索‘韩文图像理解’等场景
- **OCR推理** (功能场景): 模型支持基于OCR的推理，属于垂直应用场景，搜索意图明确，且未被高频词列表覆盖
- **Kakao多模态** (当前模型品牌名): Kakao是开发方品牌，‘Kakao多模态’作为品牌+领域组合词，具有地域和厂商独特性，未被高频词列表包含
- **双语图像理解** (功能场景): 模型专为英文+韩文双语环境优化，‘双语图像理解’是其独特定位，用户可能搜索‘支持韩语的图像描述模型’等长尾词

### kankur0007/2DseisvelGenerator

**URL**: https://ai.gitcode.com/hf_mirrors/kankur0007/2DseisvelGenerator

**关键词列表**:

- **2DseisvelGenerator** (当前模型品牌名): 从项目名称提取的当前模型名称
- **生成式人工智能** (技术特性): 当前模型的核心技术特性，强调生成式AI在地球科学中的应用
- **合成地震速度模型** (功能场景): 当前模型的主要功能，生成合成地震速度模型以减少偏差
- **DDPM模型** (技术特性): 当前模型采用的扩散概率模型（DDPM），是其核心技术之一
- **OpenFWI数据集** (训练数据): 当前模型基于OpenFWI数据集训练，是模型训练的关键数据来源
- **地球物理勘探** (应用领域): 当前模型适用于地球物理勘探领域的研究工作

### BCCard/Qwen2.5-VL-32B-Instruct-FP8-Dynamic

**URL**: https://ai.gitcode.com/hf_mirrors/BCCard/Qwen2.5-VL-32B-Instruct-FP8-Dynamic

**关键词列表**:

- **BCCard-VL模型** (当前模型品牌名): 从项目名称提取的当前模型名称，简化以突出品牌和类型
- **视觉文本交互** (功能场景): 根据模型输入类型为视觉 - 文本，输出为文本，总结出该功能场景
- **32B-VL-Instruct模型** (当前模型品牌名): 从项目名称提取，简化突出模型的参数规模、类型和指令特性

### unsloth/ERNIE-4.5-21B-A3B-Thinking-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/ERNIE-4.5-21B-A3B-Thinking-GGUF

**关键词列表**:

- **ERNIE-4.5-21B-A3B-Thinking** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **思维能力增强** (技术特性): 当前模型核心增强点，体现推理能力提升
- **128K长上下文** (技术特性): 当前模型增强的上下文理解能力，用户搜索长文本处理时会关注
- **工具使用能力** (功能场景): 当前模型的核心功能之一，用户搜索AI工具调用时会使用
- **文本MoE模型** (技术特性): 当前模型的架构类型，体现模型技术特点

### bralynn/pydevmini1

**URL**: https://ai.gitcode.com/hf_mirrors/bralynn/pydevmini1

**关键词列表**:

- **pydevmini1** (当前模型品牌名): 从项目仓库名称直接提取的模型品牌名
- **40B参数** (参数规格): 模型总参数量为 40 B，属于主流大模型规格，用户常以参数规模搜索
- **262k上下文** (技术特性): 模型支持 262,144 token 的原生上下文长度，属于超长上下文特性，用户常以此关键词寻找
- **36层模型** (技术特性): 模型拥有 36 层深度，层数是模型规模的重要指标，具备搜索价值

### inclusionAI/Ming-Lite-Omni-1.5

**URL**: https://ai.gitcode.com/hf_mirrors/inclusionAI/Ming-Lite-Omni-1.5

**关键词列表**:

- **Ming-Lite-Omni** (当前模型品牌名): 从项目名称提取的当前模型名称
- **全模态** (技术特性): 用户常搜“全模态模型”寻找图文音视频一体化能力
- **203亿参数** (参数规格): 大参数规模是用户判断模型规模与性能的直接指标
- **语音合成** (功能场景): 用户搜索“语音合成模型”寻找高质量实时语音生成方案
- **图像生成与编辑** (功能场景): 用户搜索“图像生成模型”或“AI图像编辑”寻找支持生成+编辑的一体化工具
- **文档解析** (功能场景): 用户搜索“文档解析模型”获取OCR+结构化文本提取能力

### Alpha-VLLM/Lumina-DiMOO

**URL**: https://ai.gitcode.com/hf_mirrors/Alpha-VLLM/Lumina-DiMOO

**关键词列表**:

- **Lumina-DiMOO** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该模型的唯一品牌标识
- **离散扩散** (技术特性): 模型独有的统一离散扩散架构，区别于传统AR或混合范式，是技术型用户搜索新型扩散模型的关键术语
- **主体驱动生成** (功能场景): 模型在图像编辑中突出的能力，属于细分但精准的搜索意图词，具有高区分度
- **采样效率** (技术特性): 模型强调的性能优势，用户在对比生成速度时会搜索此类术语，非泛泛形容词，具技术指向性
- **扩散大型语言模型** (技术特性): 模型官方定义的完整技术标签，结合扩散与LLM，是当前领域稀缺的组合词，具有独特性

### iSEE-Laboratory/llmdet_large

**URL**: https://ai.gitcode.com/hf_mirrors/iSEE-Laboratory/llmdet_large

**关键词列表**:

- **LLMDet-Large** (当前模型品牌名): 从项目名称提取的当前模型名称，是该模型的特定标识
- **大型语言模型协同训练** (技术特性): 当前模型通过与大型语言模型协同训练来提升性能，是其独特的技术特性
- **基于MM-Grounding-DINO改进** (技术特性): 当前模型在MM Grounding DINO基础上进行改进，体现了其技术来源和改进情况
- **LLMDet资源集合** (当前模型品牌名相关): 与当前模型紧密相关，是获取该模型检查点的资源集合，用户可能会搜索查找

### inclusionAI/Ring-mini-2.0

**URL**: https://ai.gitcode.com/hf_mirrors/inclusionAI/Ring-mini-2.0

**关键词列表**:

- **Ring-mini** (当前模型品牌名): 从项目名称提取的简洁模型品牌名
- **RLHF优化** (技术特性): 模型通过 RLHF（强化学习人类反馈）进行联合优化，提升生成质量
- **高速生成** (功能场景): 模型实现 300+ tokens/s 的高速生成，满足对快速响应的需求

### Qwen/Qwen3-Next-80B-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Next-80B-A3B-Thinking

**关键词列表**:

- **Qwen3-Next-80B-A3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **高稀疏混合专家模型** (技术特性): 当前模型的核心技术架构
- **稳定性优化** (技术特性): 当前模型在训练和推理过程中的稳定性增强手段
- **多token预测** (技术特性): 当前模型提升预训练性能和加速推理过程的技术

### google/pegasus-large

**URL**: https://ai.gitcode.com/hf_mirrors/google/pegasus-large

**关键词列表**:

- **pegasus-large** (当前模型品牌名): 从项目名称提取的当前模型名称，符合简洁品牌名要求
- **English** (功能场景): 当前模型支持的语言类型，用户可能搜索特定语言的摘要模型
- **混合检查点** (技术特性): 当前模型的训练技术特性，具有独特性
- **随机检查点** (技术特性): 当前模型的训练技术特性，有区分度
- **arxiv1912.0877** (技术特性): 当前模型的论文标识，研究人员可能搜索相关技术

### apple/mobilevit-small

**URL**: https://ai.gitcode.com/hf_mirrors/apple/mobilevit-small

**关键词列表**:

- **MobileViT** (当前模型品牌名): 从项目名称 'apple/mobilevit-small' 直接提取的模型唯一品牌名，是用户搜索轻量级视觉Transformer时的核心关键词
- **轻量级视觉Transformer** (技术特性): README明确描述其为'轻量级、低延迟的卷积神经网络，结合Transformer进行全局处理'，是区别于ViT和CNN的独特技术标签，用户会搜索此类架构
- **MobileNetV2风格** (技术特性): 模型明确采用MobileNetV2风格的层结构，是其核心设计特征，属于用户在搜索高效移动端视觉模型时的精准技术关键词
- **无位置嵌入** (技术特性): 模型明确说明'不需要任何位置嵌入'，这是其与标准ViT的关键技术差异点，属于专业用户搜索轻量级ViT变体时的高区分度术语
- **补丁反扁平化** (技术特性): README中描述的特有技术流程：图像补丁经Transformer处理后'反扁平化'回特征图，是MobileViT架构的独有操作，具高度区分度

### microsoft/TRELLIS-text-large

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/TRELLIS-text-large

**关键词列表**:

- **TRELLIS-text-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **大型模型** (技术特性): 描述了当前模型的规模特性，是区别于其他模型的一个特点

### MachineLearningLM/MachineLearningLM-7B-v1

**URL**: https://ai.gitcode.com/hf_mirrors/MachineLearningLM/MachineLearningLM-7B-v1

**关键词列表**:

- **MachineLearningLM** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多轮上下文学习** (技术特性): 当前模型的核心技术特性
- **表格机器学习** (功能场景): 当前模型的应用场景
- **合成表格数据** (技术特性): 当前模型的训练数据特性
- **持续预训练** (技术特性): 当前模型的训练方法
- **数值建模稳健性** (技术特性): 当前模型的性能特点

### openai/diffusers-cd_bedroom256_lpips

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-cd_bedroom256_lpips

**关键词列表**:

- **一致性模型** (技术特性): 模型采用论文《一致性模型》提出的核心生成框架
- **LPIPS优化** (技术特性): 以 LPIPS 视觉相似度指标进行质量提升的训练目标
- **Bedroom256** (功能场景): 模型在 LSUN Bedroom 256 分辨率数据集上进行训练
- **LSUN** (功能场景): 使用 LSUN 数据库作为训练来源，适用于室内场景生成
- **一步生成** (功能场景): 支持单步快速生成高质量图像的能力
- **少步采样** (功能场景): 兼容少步采样以在速度与质量之间取得平衡
- **零样本编辑** (功能场景): 无需额外训练即可实现图像修复、着色等编辑任务

### unsloth/Magistral-Small-2509-unsloth-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Magistral-Small-2509-unsloth-bnb-4bit

**关键词列表**:

- **Magistral-1.2** (当前模型品牌名): README中明确提及的当前模型版本号
- **llama.cpp运行** (部署工具): 当前模型支持的本地运行工具
- **240亿参数** (参数规格): 当前模型明确标注的参数规模

### timm/vit_base_patch16_224.dino

**URL**: https://ai.gitcode.com/hf_mirrors/timm/vit_base_patch16_224.dino

**关键词列表**:

- **vitbasepatch16224.dino** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自监督DINO方法** (技术特性): 当前模型训练所采用的核心方法
- **图像特征模型** (功能场景): 当前模型的主要功能和应用场景

### microsoft/speecht5_tts

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/speecht5_tts

**关键词列表**:

- **SpeechT5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **LibriTTS** (技术特性): 官方微调数据集，用户搜同款数据时常连带模型名
- **统一模态** (技术特性): SpeechT5 提出的核心架构亮点，区别于传统TTS模型
- **跨模态向量量化** (技术特性): 模型对齐语音与文本的独特方法，技术博客高频提及

### ibm-granite/granite-docling-258M

**URL**: https://ai.gitcode.com/hf_mirrors/ibm-granite/granite-docling-258M

**关键词列表**:

- **Granite-Docling-258M** (当前模型品牌名): 从项目名称 ibm-granite/granite-docling-258M 直接提取的当前模型全称，是用户搜索该特定模型时的精准关键词
- **公式识别** (功能场景): 模型明确强调'增强的公式识别'和'行内公式识别'，是区别于通用OCR工具的独特功能，用户会搜索'公式识别 AI'这类关键词
- **文档元素问答** (功能场景): 模型独有的'回答文档结构问题'能力，如元素存在与顺序，属于高区分度功能，用户可能搜索'文档结构问答'或'文档元素理解'
- **多模态文档转换** (功能场景): 模型是图像+文本到文本的多模态系统，专用于文档转换，'多模态文档转换'是精准描述其核心任务的组合词，非通用词且未被排除
- **Docling流水线** (部署工具): 模型深度集成于Docling流水线，是其部署和使用的核心框架，用户搜索'如何用Docling转换PDF'时会关联此关键词
- **OCR增强** (技术特性): 模型虽非纯OCR，但显著提升OCR能力（尤其公式、表格），'OCR增强'是用户在文档数字化场景中搜索的精准技术标签，且未被高频词库覆盖
- **258M参数** (参数规格): 模型参数为258M，虽非主流7B/32B，但属于中小型模型中较具代表性的规模，用户会搜索'轻量级文档模型 258M'，且未被排除词库禁止

### Kwaipilot/KAT-Dev

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/KAT-Dev

**关键词列表**:

- **KAT-Dev** (当前模型品牌名): 从项目名称提取的当前模型名称
- **KAT-Coder** (当前模型品牌名): 项目提到的当前模型相关的专有编码模型名称
- **软件工程任务** (功能场景): 当前模型专为软件工程任务设计，是模型的应用场景
- **SWE-Bench-Verified** (功能场景): 当前模型在该基准测试中有相应表现，体现其功能相关场景
- **中期训练** (技术特性): 当前模型训练过程中的一个重要阶段，属于技术特性
- **监督微调** (技术特性): 当前模型训练阶段中的关键技术手段，属于技术特性
- **智能体强化学习** (技术特性): 当前模型训练中涉及的重要技术，属于技术特性

### Writer/palmyra-mini

**URL**: https://ai.gitcode.com/hf_mirrors/Writer/palmyra-mini

**关键词列表**:

- **palmyra-mini** (当前模型品牌名): 项目名称即模型品牌名，用户搜索时会直接使用
- **小学数学** (功能场景): 模型在小学数学题目上的高分表现，适用于基础数学教学与练习
- **多步推理** (技术特性): 模型擅长需要多步骤思考的复杂推理任务，是其核心能力之一
- **复杂推理** (技术特性): 在 Big‑Bench Hard 等复杂认知任务中取得优秀成绩，体现模型的深度推理能力
- **定量推理** (功能场景): 模型在定量数学基准（如 MATH500）上表现突出，适用于量化分析与计算任务

### Marvis-AI/marvis-tts-250m-v0.1-transformers

**URL**: https://ai.gitcode.com/hf_mirrors/Marvis-AI/marvis-tts-250m-v0.1-transformers

**关键词列表**:

- **Marvis-AI** (当前模型品牌名): 从项目名称提取的当前模型名称
- **marvis-tts** (当前模型品牌名): 项目名称中核心模型标识，简化版本号后保留
- **实时流式文本转语音** (功能场景): 当前模型核心功能，用户搜索语音合成场景时会使用
- **设备端推理** (部署工具): 当前模型支持在终端设备直接运行的部署特性
- **边缘部署** (部署工具): 针对移动设备优化的部署方式，用户搜索边缘计算场景时会使用
- **自然音频流** (技术特性): 当前模型处理连贯语音合成的核心技术特点
- **mlx-audio** (部署工具): 模型专用的音频处理部署库，具有明确指向性

### google-bert/bert-base-cased

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-base-cased

**关键词列表**:

- **大小写敏感** (技术特性): 该模型区别于uncased版本的核心特征，用户在选择模型时会明确搜索‘是否区分大小写’
- **英语预训练** (功能场景): 明确模型语言范围，用户搜索‘英文NLP模型’或‘英语BERT’时会使用该关键词
- **序列分类** (功能场景): BERT最典型下游任务之一，用户搜索‘BERT做分类’时高频使用
- **标记分类** (功能场景): BERT在NER等任务中的核心应用，区别于生成类模型，是用户精准搜索的意图词

### allenai/GraspMolmo

**URL**: https://ai.gitcode.com/hf_mirrors/allenai/GraspMolmo

**关键词列表**:

- **GraspMolmo** (当前模型品牌名): 从项目名称提取的当前模型名称
- **任务抓取** (功能场景): 当前模型的核心功能是面向任务抓取
- **机器人操作** (功能场景): 当前模型应用于机器人操作领域
- **稳定抓取方式** (技术特性): 当前模型能够匹配到最接近的稳定抓取方式
- **开放词汇** (技术特性): 当前模型支持开放词汇的任务描述

### nunchaku-tech/nunchaku-flux.1-krea-dev

**URL**: https://ai.gitcode.com/hf_mirrors/nunchaku-tech/nunchaku-flux.1-krea-dev

**关键词列表**:

- **FLUX.1Kreadev** (当前模型品牌名): 项目名称中直接包含的模型完整名称，用户搜索时会使用该品牌名
- **Nunchaku** (当前模型品牌名): 模型由 Nunchaku 团队发布，品牌名在搜索中具备辨识度
- **SVDQuant** (技术特性): 采用 SVDQuant 方案进行 4‑bit 量化，是该模型的核心技术亮点
- **INT4-量化** (技术特性): 模型提供基于 INT4 的低位量化版本，用户会搜索此类量化方式
- **NVFP4-量化** (技术特性): 针对 Blackwell GPU 的 NVFP4 量化实现，区别于普通 INT4 量化
- **deepcompressor** (部署工具): 模型使用 deepcompressor 量化库进行压缩，属于用户关注的部署/压缩工具

### internlm/Intern-S1-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/internlm/Intern-S1-FP8

**关键词列表**:

- **Intern-S1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **5T数据预训练** (技术特性): 模型经过5万亿token的多模态数据继续预训练，这是其独特的技术处理方式
- **6B视觉编码器** (技术特性): 模型基于6B视觉编码器（InternViT）构建，是其技术组成特色

### stepfun-ai/step3

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/step3

**关键词列表**:

- **Step3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多矩阵分解注意力** (技术特性): 当前模型的独特注意力机制
- **注意力-前馈网络解耦** (技术特性): 当前模型的网络结构创新
- **视觉-语言推理** (功能场景): 当前模型的核心应用场景
- **3210亿参数** (参数规格): 当前模型的总参数量级
- **bf16推理** (部署工具): 当前模型支持的推理精度模式

### openai/gpt-oss-20b

**URL**: https://ai.gitcode.com/hf_mirrors/openai/gpt-oss-20b

**关键词列表**:

- **210亿参数** (参数规格): 模型明确标注210亿参数，属于主流规模参数（介于7B-32B之间），用户会据此筛选模型大小
- **36亿活跃参数** (参数规格): MoE架构下的活跃参数是该模型独特技术亮点，用户搜索高效推理模型时可能关注此指标
- **可配置推理强度** (技术特性): 支持低/中/高三级推理强度调节，是该模型针对延迟与质量权衡的独特功能设计
- **MXFP4量化** (技术特性): 模型采用专有MXFP4量化技术实现低显存运行，是区别于常规INT4/FP8的独家技术术语

### timm/vit_large_patch14_reg4_dinov2.lvd142m

**URL**: https://ai.gitcode.com/hf_mirrors/timm/vit_large_patch14_reg4_dinov2.lvd142m

**关键词列表**:

- **ViT-Large-Patch14** (当前模型品牌名): 从项目名称 “vit_large_patch14_reg4_dinov2.lvd142m” 中提取的简洁模型名称
- **Registers** (技术特性): 模型在视觉ViT中加入了寄存器（registers），是其核心创新点
- **LVD-142M** (数据集): 模型在大规模 LVD-142M 数据集上进行预训练，具备数据来源标签
- **518518输入** (模型规格): 模型支持 518×518 的高分辨率图像输入，区别于常规 224×224 输入

### OpenGVLab/InternVL_2_5_HiCo_R16

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVL_2_5_HiCo_R16

**关键词列表**:

- **InternVL2.5HiCoR16** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，是用户搜索该特定模型的精准关键词
- **长时视频理解** (功能场景): 模型核心能力是捕捉长时态视频结构，属于用户搜索视频问答、视频摘要等场景的精准意图词，且未在高频排除列表中
- **自适应分层令牌压缩** (技术特性): 模型独有技术HiCo的中文直译，具有技术辨识度，是研究者搜索高效视频表征方法时可能使用的专业术语
- **密集视觉标注** (技术特性): 模型采用TPO进行密集视觉任务标注，属于视频多模态领域特有的训练方式，非通用词，具区分度
- **视频多模态大语言模型** (技术特性): 模型本质是Video-MLLM，该术语在中文AI社区中搜索量上升，且未被高频词库覆盖，精准描述模型类型
- **每帧16令牌** (参数规格): R16表示每帧16个令牌，是模型结构的关键量化特征，属于主流粒度级别（非超细粒度），用户可能用于对比模型效率
- **视频理解基准测试** (功能场景): 模型在MVBench、LongVideoBench等权威基准测试中表现优异，该词是研究者搜索视频模型性能对比时的常用搜索词

### OpenGVLab/VideoMAEv2-Large

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/VideoMAEv2-Large

**关键词列表**:

- **VideoMAEv2-Large** (当前模型品牌名): 从项目名称提取的当前模型完整名称，符合用户搜索模型的直接需求
- **VideoMAE-v2** (当前模型品牌名): README中提及的模型名称简化形式，便于用户识别和搜索
- **自监督预训练** (技术特性): 当前模型采用的关键技术方法，体现模型训练方式的独特性
- **CVPR23** (技术特性): 模型相关论文发表的顶级会议，学术领域用户可能通过会议标识搜索
- **Dual-Masking** (技术特性): 论文中提出的核心技术创新点，具有技术区分度的关键词

### Comfy-Org/HiDream-I1_ComfyUI

**URL**: https://ai.gitcode.com/hf_mirrors/Comfy-Org/HiDream-I1_ComfyUI

**关键词列表**:

- **HiDream-I1** (当前模型品牌名): 从项目名称中提取的当前模型名称
- **HiDream-I1本地部署** (部署工具): 结合模型和常见部署方式，是用户可能搜索的关键词，体现模型部署途径
- **HiDream-I1文生图** (功能场景): 表明该模型在文生图方面的功能应用，是用户搜索模型功能时可能用的词
- **HiDream-I1-7B参数** (参数规格): 7B参数是主流规格，结合当前模型，是用户可能搜索区分模型的关键词

### LiquidAI/LFM2-1.2B

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B

**关键词列表**:

- **混合液态模型** (技术特性): 创新架构设计为混合液态模型，用户搜索独特架构模型时会使用该技术关键词
- **端侧部署** (部署工具): 支持智能手机、笔记本电脑等端侧设备部署，用户搜索移动端AI部署方案时会使用该关键词

### nari-labs/Dia-1.6B

**URL**: https://ai.gitcode.com/hf_mirrors/nari-labs/Dia-1.6B

**关键词列表**:

- **情感语音控制** (功能场景): 支持通过音频条件调节输出的情感与语气
- **ZeroGPU-Space** (部署工具): 官方提供的 ZeroGPU 在线体验空间，无需本地 GPU

### openai-mirror/gpt-oss-120b

**URL**: https://ai.gitcode.com/hf_mirrors/openai-mirror/gpt-oss-120b

**关键词列表**:

- **支持微调** (技术特性): 当前模型可通过参数微调完全适配特定用例
- **原生MXFP4量化** (技术特性): 当前模型的MoE层采用原生MXFP4精度训练，可运行于单张H100 GPU

### Wan-AI/Wan2.2-TI2V-5B-Diffusers

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.2-TI2V-5B-Diffusers

**关键词列表**:

- **TI2V** (功能场景): 模型核心能力“文本+图像到视频”，TI2V是社区常用缩写
- **扩散视频模型** (技术特性): 点明模型基于扩散架构且专注视频生成，区别于普通扩散图像模型

### Alibaba-NLP/Tongyi-DeepResearch-30B-A3B

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B

**关键词列表**:

- **Tongyi-DeepResearch** (当前模型品牌名): 从项目名称Alibaba-NLP/Tongyi-DeepResearch-30B-A3B中提取的核心模型品牌名，符合简化规则，去除了冗余参数后保留唯一标识
- **智能体搜索** (功能场景): 模型专为‘长周期、深度信息检索任务’设计，在多个智能体搜索基准中表现领先，是用户搜索AI搜索工具时的明确意图词
- **ReAct推理** (技术特性): 模型在推理阶段兼容ReAct范式，是其核心能力之一，属于独特技术术语，非通用词，且未被高频词列表覆盖
- **IterResearch** (技术特性): 模型独有的‘Heavy’模式推理框架，基于IterResearch，是区别于其他模型的原创技术命名，具有高区分度
- **Group-Relative-Policy-Optimization** (技术特性): 模型采用的定制化强化学习框架名称，虽为英文术语，但属于模型专属技术关键词，用户在研究RL训练方法时可能直接搜索
- **智能体数据预训练** (技术特性): 模型通过‘基于智能体数据的大规模持续预训练’提升能力，该短语精准描述其训练范式，是区别于普通LLM的差异化特征
- **全自动数据合成** (技术特性): 模型具备‘全自动合成数据生成流水线’，是其数据构建的核心创新点，用户搜索AI数据工程或自动标注方案时可能使用该词

### openbmb/VoxCPM-0.5B

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/VoxCPM-0.5B

**关键词列表**:

- **VoxCPM** (当前模型品牌名): 从项目名称提取的当前模型名称，简化去除版本号
- **上下文感知语音生成** (技术特性): 当前模型的核心技术特性，具有独特性
- **无分词器TTS系统** (技术特性): 当前模型的架构特点，区别于主流方法
- **端到端扩散自回归架构** (技术特性): 当前模型的技术实现方式，具有技术指向性
- **流式合成** (技术特性): 当前模型的部署特性，用户可能搜索的技术场景

### iSEE-Laboratory/llmdet_base

**URL**: https://ai.gitcode.com/hf_mirrors/iSEE-Laboratory/llmdet_base

**关键词列表**:

- **LLMDet** (当前模型品牌名): 项目名称即为模型品牌名，直接提取
- **大语言模型协同训练** (技术特性): 模型通过与大型语言模型协同训练提升检测性能
- **Zero-Shot-Object-Detection** (功能场景): 英文表述的核心任务，用户常以此关键词搜索
- **AutoProcessor** (部署工具): 官方提供的输入处理工具，属于模型使用的关键组件
- **AutoModelForZeroShotObjectDetection** (部署工具): 模型对应的 HuggingFace 类名，用户在搜索具体实现时会使用

### continuedev/instinct

**URL**: https://ai.gitcode.com/hf_mirrors/continuedev/instinct

**关键词列表**:

- **continuedevinstinct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Next-Edit模型** (功能场景): 当前模型的功能场景描述
- **ollama部署** (部署工具): 当前模型可通过Ollama进行部署
- **sglang部署** (部署工具): 当前模型可使用SGLang进行部署
- **代码编辑预测** (功能场景): 当前模型能够智能预测下一步操作，助力代码编辑
- **真实世界代码编辑数据集微调** (技术特性): 当前模型基于真实世界代码编辑数据集进行了稳健微调

### stabilityai/sdxl-turbo

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/sdxl-turbo

**关键词列表**:

- **单步生成** (功能场景): 模型核心卖点是'通过单次网络评估'生成图像，用户会搜索'单步生成'这类明确的高效文生图需求，区别于常规多步模型
- **对抗扩散蒸馏** (技术特性): 模型独有的训练技术名称（ADD），是SDXL-Turbo区别于其他扩散模型的核心技术标签，用户搜索技术原理时可能使用该词
- **SDXL-Turbo** (当前模型品牌名): 模型完整名称，虽带后缀，但用户在搜索具体模型时会直接输入'SDXL-Turbo'，且为当前模型唯一标识，非基础模型SDXL 1.0
- **分数蒸馏** (技术特性): 模型使用的关键技术术语，出现在技术报告中，是区别于其他蒸馏方法的独特描述，专业用户可能搜索该词

### google/ddpm-ema-church-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-ema-church-256

**关键词列表**:

- **ddpm-ema-church-256** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **LSUN数据集** (技术特性): 当前模型在特定数据集上的应用
- **扩散概率模型** (技术特性): 当前模型所属的技术类别
- **朗之万动力学** (技术特性): 当前模型使用的核心技术方法
- **去噪分数匹配** (技术特性): 当前模型的关键技术组件

### neulab/omnitab-large-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/neulab/omnitab-large-finetuned-wtq

**关键词列表**:

- **OmniTab** (当前模型品牌名): 从项目名称提取的当前模型名称
- **表格问答模型** (功能场景): 当前模型主要用于基于表格的问答场景
- **WikiTableQuestions微调** (技术特性): 当前模型在WikiTableQuestions数据集上进行了微调
- **Seq2SeqLM** (技术特性): 当前模型使用Seq2SeqLM进行序列到序列的学习

### Qwen/Qwen2.5-VL-32B-Instruct-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-32B-Instruct-AWQ

**关键词列表**:

- **Qwen2.5-VL** (当前模型品牌名): 项目名称中包含的完整模型变体名称，区别于基础 Qwen2.5
- **结构化输出生成** (功能场景): 对发票、表单、表格等扫描件提供结构化数据输出，适用于金融和商业场景
- **SwiGLU优化** (技术特性): 在视觉编码器中引入 SwiGLU 加速训练与推理

### unsloth/gemma-3-12b-it-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-12b-it-GGUF

**关键词列表**:

- **Unsloth微调** (功能场景): README中提到可使用Unsloth对Gemma 3进行微调，是该模型的一种应用场景
- **GGUF格式导出** (部署工具): 可将微调后的Gemma 3模型导出为GGUF格式，属于部署相关操作
- **Google-Colab微调** (功能场景): 可在Google Colab上免费微调Gemma 3，是利用特定平台对模型进行操作的功能场景

### Qwen/Qwen3-32B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-GGUF

**关键词列表**:

- **Qwen3-32B** (当前模型品牌名): 从项目名称提取的当前模型核心名称，简洁且具有识别性
- **YaRN技术** (技术特性): 当前模型扩展上下文长度的核心技术，具有独特性
- **q4KM** (部署工具): 当前模型提供的量化版本，用户搜索量化模型时可能使用
- **q5KM** (部署工具): 当前模型提供的量化版本，用户搜索量化模型时可能使用
- **q6K** (部署工具): 当前模型提供的量化版本，用户搜索量化模型时可能使用
- **q80** (部署工具): 当前模型提供的量化版本，用户搜索量化模型时可能使用

### openai/jukebox-5b-lyrics

**URL**: https://ai.gitcode.com/hf_mirrors/openai/jukebox-5b-lyrics

**关键词列表**:

- **Jukebox-5B-lyrics** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，用户搜索AI音乐生成模型时可能使用此完整品牌名
- **AI作曲** (功能场景): 该模型用于生成包含歌词的音乐，属于AI生成音乐的核心应用场景，区别于通用文生图或文本生成
- **歌词生成** (功能场景): 模型核心能力是生成与音乐节奏匹配的歌词，是区别于其他文本生成模型的特有功能
- **音乐生成** (功能场景): 用户搜索AI生成音乐内容时的高频意图词，该模型直接实现此功能，且未被高频词列表覆盖

### HKUSTAudio/Llasa-1B-Multilingual

**URL**: https://ai.gitcode.com/hf_mirrors/HKUSTAudio/Llasa-1B-Multilingual

**关键词列表**:

- **Llasa-1B** (当前模型品牌名): 从项目名称提取的简化模型名称
- **文本到语音** (功能场景): 模型的核心应用是将文字转为语音（TTS）
- **多语言文本到语音** (功能场景): 模型支持多语言输入的文本到语音合成，满足跨语言需求
- **Llasa微调** (技术特性): README提供专门的 Llasa 微调指南，适用于特定语言的二次训练
- **LLM语音合成** (技术特性): 模型基于大语言模型（LLM）实现语音合成，区别于传统 TTS 系统
- **无G2P多语言TTS** (技术特性): 模型无需为每种语言单独构建 G2P（音素转换）系统，实现统一处理

### unsloth/Magistral-Small-2509-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Magistral-Small-2509-bnb-4bit

**关键词列表**:

- **单卡4090** (部署工具): README明确可单张RTX 4090运行，是本地部署热门检索词
- **bnb-4bit** (部署工具): 项目名自带4-bit量化标识，用户搜“bnb 4bit 模型”直达

### Video-R1/Video-R1-7B

**URL**: https://ai.gitcode.com/hf_mirrors/Video-R1/Video-R1-7B

**关键词列表**:

- **Video-R1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Video-R1-7B** (当前模型品牌名): 从项目名称提取的当前模型具体版本名称
- **视频文本转文本** (功能场景): 从标签‘Video-Text-to-Text’可知该模型的功能场景
- **单样本推理** (功能场景): README中提及可查阅单样本推理示例，是该模型的功能场景

### cavargas10/TRELLIS

**URL**: https://ai.gitcode.com/hf_mirrors/cavargas10/TRELLIS

**关键词列表**:

- **图像条件3D生成** (功能场景): 结合图像输入的3D生成功能，用户可能搜索的具体场景
- **Structured-3D-Latents** (技术特性): 论文中提到的核心技术概念，具有技术指向性

### ByteDance-Seed/UI-TARS-72B-DPO

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-72B-DPO

**关键词列表**:

- **UI-TARS-72B-DPO** (当前模型品牌名): 从项目名称提取的当前模型名称
- **原生智能体** (技术特性): 当前模型的核心技术特性，强调原生智能体能力
- **GUI交互** (功能场景): 当前模型的主要应用场景，实现与图形用户界面的无缝交互
- **端到端任务自动化** (技术特性): 当前模型无需预定义工作流或人工规则即可实现端到端的任务自动化

### Alibaba-NLP/gte-reranker-modernbert-base

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/gte-reranker-modernbert-base

**关键词列表**:

- **gte-reranker-modernbert-base** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，是用户搜索该特定重排序模型的核心关键词
- **文本重排序** (功能场景): 模型明确标注为'文本重排序模型'，是用户在检索系统优化、RAG场景中会精准搜索的功能词
- **ModernBERT** (技术特性): 模型基于'modernBERT'这一自研预训练架构，是区别于标准BERT的独家技术标签，用户会搜索该特定变体
- **8192上下文** (技术特性): 虽然禁止提取纯数字，但'8192上下文'作为长文本重排序的标志性能力，在AI检索领域是用户高频搜索的实用术语（非单纯数字）
- **MTEB-en** (技术特性): 模型在MTEB-en榜单有明确成绩，该评测集名称是检索领域研究者搜索高质量重排序模型时的权威指标关键词
- **Flash-Attention-2** (技术特性): 模型文档特别提示支持Flash Attention 2加速，这是当前高性能推理的前沿技术标签，开发者会主动搜索该优化方式

### nvidia/parakeet-tdt-0.6b-v2

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/parakeet-tdt-0.6b-v2

**关键词列表**:

- **Parakeet-TDT** (当前模型品牌名): 从项目名称提取的模型品牌名称，唯一标识该模型
- **TDT-解码器** (技术特性): 模型集成的 TDT（Time‑Delay Transformer）解码器，区别于其他 ASR 解码器
- **词级时间戳** (功能场景): 模型能够预测精确的词级时间戳，适用于字幕生成和语音分析
- **自动标点** (功能场景): 模型在转录时自动插入标点符号，提升文本可读性
- **0.6B-参数** (参数规格): 模型拥有约 0.6 B（6 亿）参数，属于轻量级高效 ASR 模型
- **长音频单次转录** (功能场景): 支持一次性转录最长 24 分钟的音频片段，适合长对话或会议记录

### LLM-Research/mxbai-embed-large-v1-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/LLM-Research/mxbai-embed-large-v1-gguf

**关键词列表**:

- **mxbai-embed** (当前模型品牌名): 从项目名称提取的当前模型简化名称
- **Feature-Extraction** (功能场景): 当前模型的技术功能标签
- **mteb** (技术特性): 当前模型相关的技术评估基准
- **AnglE损失函数** (技术特性): 当前模型训练使用的核心技术方法

### conjuncts/ditr-e15

**URL**: https://ai.gitcode.com/hf_mirrors/conjuncts/ditr-e15

**关键词列表**:

- **ditr-e15** (当前模型品牌名): 从项目名称提取的当前模型名称
- **HF模型** (当前模型品牌名): 模型托管在Hugging Face Hub上，可简称为HF模型
- **transformers模型** (技术特性): 该模型为🤗 transformers模型卡片对应的模型，属于其技术特性相关
- **NLP模型** (功能场景): 从支持语言（NLP）推测该模型可能用于自然语言处理相关场景
- **15参数** (参数规格): 项目名称中的e15推测可能代表15相关参数规格，有一定区分度

### deepseek-ai/DeepSeek-V3.1-Terminus

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1-Terminus

**关键词列表**:

- **DeepSeek-V3.1-Terminus** (当前模型品牌名): 项目名称直接对应当前模型全称，是用户搜索该特定版本的精准关键词
- **Code-Agent** (功能场景): 模型重点优化的专属智能体功能，用户会搜索‘Code Agent’寻找编程辅助AI模型
- **Search-Agent** (功能场景): 模型更新的核心能力之一，具有明确工具调用场景，是区别于其他模型的独特功能点
- **Terminal-bench** (技术特性): 模型在终端命令执行任务上的专用评测基准，体现其系统操作能力，为独特技术标签
- **SWE-bench-Multilingual** (技术特性): 模型在多语言软件工程任务上的专项评测能力，是当前模型在代码理解领域的差异化标签
- **LiveCodeBench** (技术特性): 模型在真实编程环境评测中的关键基准，体现其动态代码生成能力，非通用术语
- **BrowseComp** (技术特性): 模型在浏览器交互任务中的专用评测指标，属于其智能体工具链的独特技术标签
- **SWE-Verified** (技术特性): 模型在软件工程验证任务上的专项能力，是其代码智能体的高价值技术特征

### DaizeDong/GraphsGPT-4W

**URL**: https://ai.gitcode.com/hf_mirrors/DaizeDong/GraphsGPT-4W

**关键词列表**:

- **GraphsGPT** (当前模型品牌名): 从项目名称GraphsGPT-4W简化提取的当前模型名称
- **Euclideanizing-Graph** (技术特性): 论文核心技术点，体现模型独特技术路径
- **chemistry** (功能场景): 标签中明确的领域应用场景
- **medical** (功能场景): 标签中明确的领域应用场景
- **ICML-2024** (技术特性): 论文发表会议信息，体现模型学术背景

### Qwen/Qwen3-Omni-30B-A3B-Captioner

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Captioner

**关键词列表**:

- **Omni-30B-Captioner** (当前模型品牌名): 从项目名称提取的简化模型名称，去除已禁用的 Qwen3 前缀
- **音频细粒度描述** (功能场景): 模型专注于为任意音频生成详细、低幻觉的文字描述
- **低幻觉音频描述** (技术特性): 模型在生成音频文字时强调低幻觉，提升描述可信度
- **单轮音频输入模型** (技术特性): 模型仅接受单个音频输入并输出文本，属于单轮推理设计
- **多说话人情绪识别** (功能场景): 模型能够在音频中辨别多说话人的情绪，适用于复杂对话分析
- **环境声音与音乐辨识** (功能场景): 模型可区分并描述环境噪声、音乐及影视音效等多种音频类型

### Hcompany/Holo1.5-3B

**URL**: https://ai.gitcode.com/hf_mirrors/Hcompany/Holo1.5-3B

**关键词列表**:

- **Holo1.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **计算机使用代理** (功能场景): 当前模型的核心应用场景描述
- **UI定位** (技术特性): 当前模型在用户界面定位方面的技术特性
- **基于UI的问答** (技术特性): 当前模型在基于用户界面问答方面的技术特性

### Qwen/Qwen3Guard-Gen-4B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-4B

**关键词列表**:

- **Qwen3Guard-Gen** (当前模型品牌名): 从项目名称提取的当前模型名称
- **安全审核模型** (功能场景): 当前模型的核心应用场景
- **生成式安全模型** (技术特性): 当前模型的生成式技术特性
- **三级风险等级分类** (技术特性): 当前模型的核心技术功能
- **指令遵循任务** (技术特性): 当前模型的任务类型特性

### codefuse-ai/CodeFuse-DevOps-Model-7B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/codefuse-ai/CodeFuse-DevOps-Model-7B-Base

**关键词列表**:

- **DevOps-Model-7B-Base** (当前模型品牌名): 项目名称直接定义的当前模型品牌，是用户搜索该特定DevOps模型时的精准关键词
- **DevOps-Model-7B-Chat** (当前模型品牌名): 与Base模型并列开源的对齐版本，是项目明确提出的独立模型名称，具有独立搜索价值
- **DevOpsEval** (功能场景): 项目自建的专属DevOps领域评测基准，是当前模型在该垂直领域权威性的核心标识，用户会搜索该术语来寻找专业DevOps模型评测
- **DevOps生命周期问答** (功能场景): 模型核心用途是回答DevOps生命周期中的问题，该短语精准描述用户使用场景，非通用词，具高意图指向性
- **DevOps-Model-14B-Base** (当前模型品牌名): 项目明确开源的14B参数版本，与7B版本形成系列，是当前模型家族的独立成员，非基础模型，具独立搜索价值
- **DevOps-Model-14B-Chat** (当前模型品牌名): 与14B-Base配套的对齐对话版本，属于当前模型家族的完整产品线，是用户可能搜索的精准型号
- **DevOps领域大模型** (功能场景): 模型定位为‘DevOps领域专属大模型’，该短语是用户在CSDN等平台搜索垂直领域AI模型时的典型搜索词，具行业针对性

### opendatalab/MinerU2.5-2509-1.2B

**URL**: https://ai.gitcode.com/hf_mirrors/opendatalab/MinerU2.5-2509-1.2B

**关键词列表**:

- **MinerU2.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **解耦式模型** (技术特性): 当前模型的架构特点

### ByteDance-Seed/UI-TARS-7B-DPO

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-7B-DPO

**关键词列表**:

- **UI-TARS** (当前模型品牌名): 项目名称直接给出的品牌名，用户会搜
- **DPO微调** (技术特性): 7B-DPO版本主打技术，用户搜DPO优化模型时会用

### Qwen/Qwen3-VL-235B-A22B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-VL-235B-A22B-Instruct

**关键词列表**:

- **密集型架构** (部署工具): README提到模型提供密集型（Dense）和混合专家（MoE）两种架构，可用于不同需求的部署，是该模型的一种部署架构类型
- **指令优化版** (部署工具): README指出推出指令优化版（Instruct）和推理增强思维版（Thinking）满足按需部署需求，是指令优化方向的部署版本
- **高级空间感知** (技术特性): README说明模型具备高级空间感知（Advanced Spatial Perception）能力，可判断物体位置等，是该模型独特的技术特性

### Qwen/Qwen3Guard-Gen-8B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-8B

**关键词列表**:

- **三级安全分类** (技术特性): 模型提供安全、争议、不安全的三级严重程度分类，突出其细粒度风险评估能力
- **实时安全监控** (技术特性): 在文本增量生成过程中进行实时安全监控，是模型的核心技术优势
- **内容安全审计** (功能场景): 模型定位为安全审核生成模型，主要用于内容安全审计任务
- **多语言安全审查** (功能场景): 支持 119 种语言进行安全审查，体现跨语言安全检测能力

### openmmlab-community/mm_grounding_dino_large_o365v2_oiv6_goldg

**URL**: https://ai.gitcode.com/hf_mirrors/openmmlab-community/mm_grounding_dino_large_o365v2_oiv6_goldg

**关键词列表**:

- **MM-Grounding-DINO** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，是用户搜索该特定模型的核心关键词
- **o365v2** (当前模型品牌名): 模型名称中关键数据集后缀，代表其训练数据来源，是该模型区别于其他Grounding DINO变体的唯一标识，用户可能搜索此组合
- **oiv6** (当前模型品牌名): 模型名称中另一关键数据集后缀，与o365v2共同构成该模型的唯一训练配置标识，具有区分度
- **goldg** (当前模型品牌名): 模型名称中最后一部分，代表使用GoldG数据集训练，是该模型在Grounding DINO家族中的唯一版本标识
- **无监督目标检测** (功能场景): 零样本目标检测的同义表达，用户可能用更通俗的‘无监督’替代‘零样本’进行搜索，且未被高频词列表覆盖
- **开放目标检测** (功能场景): 模型支持开放词汇检测（open-vocabulary），是其技术亮点，用户在搜索‘开放词汇目标检测’时可能命中

### MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7

**URL**: https://ai.gitcode.com/hf_mirrors/MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7

**关键词列表**:

- **27-languages** (技术特性): 模型支持的语言数量，具有明确区分度

### XiaomiMiMo/MiMo-Audio-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/XiaomiMiMo/MiMo-Audio-7B-Instruct

**关键词列表**:

- **MiMo-Audio-7B-Instruct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音频语言模型** (功能场景): 当前模型的应用领域和功能描述
- **小样本学习** (技术特性): 当前模型的核心技术特性之一
- **语音续写** (功能场景): 当前模型展示出的独特功能

### deepseek-ai/DeepSeek-R1-0528

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-0528

**关键词列表**:

- **算法优化机制** (技术特性): 当前模型的技术特性

### unsloth/gemma-3-270m-it-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-GGUF

**关键词列表**:

- **意大利语支持** (功能场景): 模型专注于意大利语文本生成，满足语言特定需求的搜索
- **4-bit格式** (技术特性): 模型提供 4‑bit 量化版本，用户会搜索低位宽量化模型
- **16-bit格式** (技术特性): 模型同样提供 16‑bit 版本，满足对更高精度量化的搜索需求

### stepfun-ai/NextStep-1-Large-Edit

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large-Edit

**关键词列表**:

- **大规模自回归图像生成** (功能场景): 当前模型的主要功能用途
- **离散文本令牌和连续图像令牌训练** (技术特性): 当前模型独特的训练方式，体现了其技术特性

### Kwaipilot/HiPO-8B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/HiPO-8B

**关键词列表**:

- **HiPO** (当前模型品牌名): 从项目名称Kwaipilot/HiPO-8B提取的当前模型核心名称
- **动态推理** (技术特性): 当前模型提出的混合策略优化核心技术方向
- **Think-on模式** (技术特性): 当前模型特有的推理模式之一，体现其动态决策能力
- **Think-off模式** (技术特性): 当前模型特有的高效模式之一，与Think-on模式形成互补
- **混合奖励系统** (技术特性): 当前模型实现动态推理平衡的核心组件
- **AutoThink范式** (技术特性): 当前模型基于早期研究提出的可控推理核心框架
- **结构化模板** (技术特性): 当前模型生成响应的独特格式，确保推理路径可解析

### Qwen/Qwen3Guard-Gen-0.6B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-0.6B

**关键词列表**:

- **三级严重程度分类** (技术特性): 当前模型的核心技术特性之一
- **0.6B参数** (参数规格): 当前模型的参数规格
- **指令跟随任务** (技术特性): 当前模型Qwen3Guard-Gen的构建方式

### PerceptronAI/Isaac-0.1

**URL**: https://ai.gitcode.com/hf_mirrors/PerceptronAI/Isaac-0.1

**关键词列表**:

- **Isaac** (当前模型品牌名): 项目名直接给出的品牌简称，用户搜索时最可能输入
- **感知语言模型** (技术特性): 官方定位的核心技术标签，突出物理世界感知能力
- **空间智能** (功能场景): 精准指向与定位能力，用户搜“空间智能”即可找到该模型
- **对话式指向** (功能场景): 全新交互模式关键词，区别于普通视觉问答，具有独特引流价值
- **20亿参数** (参数规格): 轻量级规模，用户搜索“20亿参数模型”可精准命中
- **物理AI** (技术特性): 官方反复强调的“物理世界智能”方向，搜索热度上升但竞争词少

### LiquidAI/LFM2-2.6B

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-2.6B

**关键词列表**:

- **2.6B参数** (参数规格): 模型的参数规模为 2.6 B，属于用户常搜索的参数规格
- **创意写作** (功能场景): 模型在创意文本生成、写作辅助方面的典型使用场景

### LiquidAI/LFM2-1.2B-Tool

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-Tool

**关键词列表**:

- **LiquidAI-LFM2-1.2B-Tool** (当前模型品牌名): 从项目名称提取的当前模型名称
- **边缘设备部署** (部署工具): 适用于移动和边缘设备，可在无云依赖下进行操作，属于特定的部署场景
- **低延迟响应** (功能场景): 可用于汽车、物联网设备或客户支持中的实时助手，对响应延迟要求极高，体现了该功能特性
- **资源受限环境适配** (功能场景): 能够在嵌入式系统或电池供电设备等资源受限环境中高效执行工具，是该模型的独特应用场景
- **8语言支持** (功能场景): 支持英语、阿拉伯语、中文、法语、德语、日语、韩语、葡萄牙语和西班牙语，是该模型区别于其他模型的语言能力特点

### timm/samvit_base_patch16.sa1b

**URL**: https://ai.gitcode.com/hf_mirrors/timm/samvit_base_patch16.sa1b

**关键词列表**:

- **samvitbase** (当前模型品牌名): 从项目名称提取的当前模型简化名称
- **分割一切视觉Transformer** (技术特性): 当前模型的技术架构描述
- **SAM-ViT** (当前模型品牌名): 模型卡片中明确的模型简称
- **特征骨干网络** (技术特性): 当前模型的技术定位描述
- **SA-1B预训练** (技术特性): 当前模型的预训练数据集特性
- **MAE权重初始化** (技术特性): 当前模型的技术实现细节

### Intel/zoedepth-nyu

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/zoedepth-nyu

**关键词列表**:

- **ZoeDepth-nyu** (当前模型品牌名): 从项目名称提取的当前模型名称
- **零样本单目深度估计** (功能场景): 当前模型的应用场景
- **度量深度估计** (功能场景): 当前模型的核心功能
- **DPT框架扩展** (技术特性): 当前模型基于DPT框架的扩展特性
- **绝对深度估计** (功能场景): 当前模型的核心功能

### Qwen/Qwen3-30B-A3B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-Base

**关键词列表**:

- **A3B-Base** (当前模型品牌名): 模型名称中的唯一标识，去除版本号和前缀，符合简洁品牌名要求
- **全局批负载均衡** (技术特性): 训练时引入的全局批负载均衡损失，提升训练稳定性，具备搜索价值
- **qk层归一化** (技术特性): 模型全局使用的 qk 层归一化技术，区别于普通层归一化
- **48层网络** (技术特性): 模型拥有 48 层深度，层数是用户关注的模型规模指标

### nikravan/glm-4vq

**URL**: https://ai.gitcode.com/hf_mirrors/nikravan/glm-4vq

**关键词列表**:

- **GLM-4VQ** (当前模型品牌名): 从项目名称nikravan/glm-4vq提取的当前模型名称简化形式
- **图像问答** (功能场景): 当前模型具备图像理解能力，图像问答是其核心应用场景
- **4bit量化** (技术特性): 当前模型为4bit量化版本，是其关键技术特性，用户会搜索量化相关词
- **Google-Colab运行** (部署方式): 模型可在免费版Google Colab上运行，是用户关注的部署场景

### Qwen/Qwen3-1.7B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B

**关键词列表**:

- **Qwen3-1.7B** (当前模型品牌名): 项目名称直接给出的当前模型全称，虽含版本号但为唯一标识，且未被强制排除列表收录
- **单模型多模式** (技术特性): 模型通过单一架构实现两种模式切换，此表述为原创提炼，区别于通用‘多模态’，且未被排除，具高区分度

### deepseek-ai/DeepSeek-R1-0528-Qwen3-8B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B

**关键词列表**:

- **低幻觉率** (技术特性): 新版模型在降低幻觉（hallucination）方面有显著提升，属于独特技术特性
- **思维深度增强** (技术特性): 模型通过增加思维深度提升复杂推理能力，是模型的核心技术亮点
- **函数调用增强** (功能场景): 新版模型对函数调用的支持更强，适用于需要函数调用的AI应用
- **通用逻辑推理** (功能场景): 模型在通用逻辑推理基准上表现突出，满足广泛的推理需求
- **大规模上下文** (技术特性): 支持最高64K tokens的上下文长度，适合长文本处理场景

### moonshotai/Moonlight-16B-A3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Moonlight-16B-A3B-Instruct

**关键词列表**:

- **Moonlight** (当前模型品牌名): 从项目名称提取的当前模型名称，简化自Moonlight-16B-A3B-Instruct
- **样本效率** (技术特性): 模型核心优势指标，用户可能关注高效训练相关技术

### sail-rvc/ElsaV2

**URL**: https://ai.gitcode.com/hf_mirrors/sail-rvc/ElsaV2

**关键词列表**:

- **ElsaV2** (当前模型品牌名): 项目名称为sail-rvc/ElsaV2，直接提取模型唯一品牌名，符合用户搜索AI模型时的命名习惯
- **RVC** (技术特性): 模型类型明确标注为RVC（Retrieval-Based Voice Conversion），是当前模型的核心技术类别，用户会搜索'RVC模型'寻找语音转换方案
- **语音转换** (功能场景): RVC模型本质是Audio-to-Audio的语音转换工具，'语音转换'是用户在CSDN等平台搜索AI变声、音色克隆时的高频意图词
- **音色克隆** (功能场景): RVC模型的核心应用场景是音色克隆，用户常搜索该词寻找AI换声、歌手模仿工具，与'ElsaV2'直接关联
- **rvc-runpod** (部署工具): README明确说明模型用于'https://github.com/chavinlo/rvc-runpod'，该部署方式是RVC生态中的特定工具链，用户会搜索该组合词寻找云端部署方案

### deepseek-ai/DeepSeek-V3.1

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1

**关键词列表**:

- **DeepSeek-V3.1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **混合思考模式** (技术特性): 当前模型的核心技术特性，支持思考模式与非思考模式切换
- **工具调用优化** (技术特性): 当前模型在工具使用和智能体任务上的表现得到显著提升
- **更高思考效率** (技术特性): 当前模型DeepSeek-V3.1-Think的回答质量与DeepSeek-R1-0528相当，但响应速度更快
- **6710亿参数** (参数规格): 当前模型的参数规模，具有区分度

### AI-ModelScope/IDM-VTON

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/IDM-VTON

**关键词列表**:

- **IDM-VTON** (当前模型品牌名): 项目名称即为模型的官方品牌名
- **虚拟试穿** (功能场景): 模型用于在真实场景中实现虚拟试穿的核心应用
- **虚拟试衣间** (功能场景): 模型可部署为线上虚拟试衣间的交互式体验
- **自动遮罩生成** (技术特性): 演示版使用的关键技术之一，用于自动生成遮罩
- **stable-diffusion-xl** (技术特性): 模型在 stable‑diffusion‑xl 基础上进行微调和优化
- **ONNX导出** (部署工具): 提供模型的 ONNX 导出以便跨平台部署

### google/magenta-realtime

**URL**: https://ai.gitcode.com/hf_mirrors/google/magenta-realtime

**关键词列表**:

- **Magenta-RT** (当前模型品牌名): 从项目名称及标签提取的当前模型名称
- **音乐生成模型** (功能场景): 当前模型的核心应用场景
- **文本提示生成音乐** (功能场景): 当前模型的具体生成方式
- **音频示例生成音乐** (功能场景): 当前模型的输入方式及功能特性
- **SpectroStream** (技术特性): 当前模型的核心组件技术
- **MusicCoCa** (技术特性): 当前模型的核心组件技术
- **现场表演部署** (部署工具): 当前模型的特定部署场景
- **Colab-TPU部署** (部署工具): 当前模型支持的部署平台

### Qwen/Qwen3Guard-Stream-4B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Stream-4B

**关键词列表**:

- **Qwen3Guard** (当前模型品牌名): 项目名称直接提取的当前模型系列名称
- **实时安全审核** (功能场景): 用户会搜‘实时审核’‘安全过滤’等落地场景
- **流式检测** (技术特性): 模型主打token级流式监控，用户搜‘流式’关键词
- **三级风险分类** (技术特性): 支持安全/争议/不安全三档，用户搜‘风险分级’需求
- **内容审核模型** (功能场景): 明确用途为AI内容安全，用户直接搜‘审核模型’

### AI-ModelScope/OminiControl

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/OminiControl

**关键词列表**:

- **OminiControl** (当前模型品牌名): 项目名称为AI-ModelScope/OminiControl，直接提取模型唯一品牌名，符合用户搜索AI模型时的直接命名习惯
- **扩散变换器** (技术特性): README中明确提及'扩散变换器'，是该模型的核心架构创新，非通用术语，具有技术独特性
- **最小化通用控制** (功能场景): 论文标题核心短语，描述模型独特功能目标——实现对图像生成的最小化通用控制，是用户搜索控制类扩散模型时的精准意图词
- **Diffusion-Single-File** (部署工具): README中明确标签，指代模型以单文件形式部署，区别于传统多文件结构，是用户寻找轻量化扩散模型部署方案时的精准关键词

### adibvafa/CodonTransformer

**URL**: https://ai.gitcode.com/hf_mirrors/adibvafa/CodonTransformer

**关键词列表**:

- **CodonTransformer** (当前模型品牌名): 从项目名称提取的当前模型名称
- **密码子优化** (功能场景): 当前模型的核心功能用途
- **蛋白质序列转化** (功能场景): 当前模型的具体应用场景
- **DNA序列优化** (功能场景): 当前模型的输出结果类型
- **生物信息学工具** (功能场景): 当前模型所属的技术领域应用
- **合成生物学** (功能场景): 当前模型的学科应用范畴
- **Jupyter笔记本** (部署方式): 当前模型提供的交互使用方式
- **计算生物学** (功能场景): 当前模型涉及的交叉学科领域

### LiquidAI/LFM2-350M-Extract

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-Extract

**关键词列表**:

- **LFM2-350M-Extract** (当前模型品牌名): 项目名称即为当前模型的唯一品牌名，是用户搜索该特定模型时的直接关键词
- **非结构化文档提取** (功能场景): 模型核心用途是将文章、报告、工单等非结构化文本转为结构化数据，属于明确用户搜索意图的功能词
- **JSON提取** (功能场景): 模型主要输出格式之一，用户常搜索'如何从文本提取JSON'等具体任务，具有强搜索意图
- **XML转换** (功能场景): 模型支持将监管文件等转为XML，是合规系统场景下的精准搜索词，非通用术语
- **YAML结构化** (功能场景): 模型支持YAML输出，用于客户工单分析流水线，是区别于通用文本生成的特定用途关键词
- **知识图谱填充** (功能场景): 模型明确用于从报告中提取实体属性以填充知识图谱，属于高价值垂直场景词
- **贪婪解码** (技术特性): 模型官方推荐的唯一解码策略，是技术用户搜索优化该模型输出时的精准参数关键词
- **系统提示格式化** (技术特性): 模型依赖系统提示指定输出格式（JSON/XML/YAML）和schema，是其区别于通用模型的关键交互特征

### codefuse-ai/CodeFuse-DevOps-Model-7B-Chat

**URL**: https://ai.gitcode.com/hf_mirrors/codefuse-ai/CodeFuse-DevOps-Model-7B-Chat

**关键词列表**:

- **CodeFuse-DevOps-Model-7B-Chat** (当前模型品牌名): 完整模型名称，直接对应项目名称，用户搜索时会使用该品牌名
- **DevOps-Chat模型** (功能场景): 模型专注于DevOps领域的对话问答，属于Chat功能，用户会搜索此类场景关键词
- **DevOpsEval基准** (评测基准): 项目自行构建的DevOps专属评测基准，具备唯一性，用户可能搜索该基准名称
- **CMMLU-DevOps测试** (评测数据集): 使用CMMLU数据集中的DevOps相关考试进行评测，是模型评测的重要组成部分
- **CEval-DevOps测试** (评测数据集): 使用CEval数据集中的DevOps相关考试进行评测，帮助用户了解模型在该领域的表现
- **Zero-shot-DevOps推理** (技术特性): 模型支持零样本（Zero-shot）推理，适用于DevOps场景的直接问答
- **Five-shot-DevOps推理** (技术特性): 模型支持少样本（Five-shot）推理，提升DevOps问答的准确性和鲁棒性
- **高质量-DevOps-语料** (数据特性): 模型基于高质量的DevOps专属语料进行训练，保证专业领域的回答质量

### timm/edgenext_small.usi_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/edgenext_small.usi_in1k

**关键词列表**:

- **edgenextsmall.usiin1k** (当前模型品牌名): 从项目名称提取的当前模型名称
- **EdgeNeXt** (当前模型品牌名): 模型类型名称，代表当前模型架构
- **CNN-Transformer** (技术特性): 当前模型结合了CNN和Transformer架构
- **Mobile-Vision** (技术特性): 当前模型适用于移动端视觉应用

### facebook/dino-vits8

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dino-vits8

**关键词列表**:

- **dino-vits8** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **dino** (当前模型品牌名): 当前模型名称的核心标识部分
- **自监督视觉训练** (技术特性): 当前模型采用的核心训练方式
- **8x8补丁嵌入** (技术特性): 当前模型独特的输入处理方式
- **imagenet-1k预训练** (技术特性): 当前模型的预训练数据集标识
- **arxiv2104.14294** (技术特性): 当前模型对应的研究论文标识

### LiquidAI/LFM2-350M-Math

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-Math

**关键词列表**:

- **数学推理模型** (功能场景): 专为复杂数学问题设计的轻量级推理模型
- **350M参数** (参数规格): 当前模型的主流参数规格
- **链式思维推理** (技术特性): 模型通过显式思考链提升解题能力
- **单轮对话** (技术特性): 模型仅支持单轮对话，适合一次性数学问答

### facebook/esm2_t33_650M_UR50D

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/esm2_t33_650M_UR50D

**关键词列表**:

- **ESM-2** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，是用户搜索蛋白质AI模型时的核心关键词
- **6.5亿参数** (参数规格): 模型参数规模为6.5亿，属于蛋白质领域中主流中小型模型，用户常按参数量筛选模型
- **蛋白质序列建模** (功能场景): 模型核心用途是处理蛋白质序列，用户搜索AI在生物序列分析中的应用时会使用此精准术语
- **蛋白质预训练模型** (功能场景): 用户在寻找可微调的蛋白质AI模型时，常搜索'蛋白质预训练模型'这一明确应用场景
- **ESM2t33650MUR50D** (当前模型品牌名): 模型完整检查点名称是科研人员在论文或代码中直接引用的标识符，具有高搜索精准度

### facebook/vjepa2-vitg-fpc64-384-ssv2

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-384-ssv2

**关键词列表**:

- **ViT-g-384** (技术特性): 模型采用的 Vision Transformer‑g 大尺寸架构，区分于其他 ViT 变体
- **Something-Something-V2** (功能场景): 模型在该视频分类数据集上完成预训练，体现其视频理解能力
- **视频分类头** (功能场景): 模型内置的视频分类头，用于直接进行视频分类任务
- **大规模视频预训练** (技术特性): 模型利用海量视频数据进行预训练，提升视频理解性能
- **Meta-FAIR-研发** (当前模型品牌名): 模型由 Meta 公司 FAIR 团队研发，标识其来源机构

### unsloth/DeepSeek-V3.1-Base-BF16

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/DeepSeek-V3.1-Base-BF16

**关键词列表**:

- **长上下文扩展** (技术特性): 当前模型采用两阶段长上下文扩展方法的技术特性
- **UE8M0-FP8** (技术特性): 当前模型采用的训练数据格式技术细节

### SG161222/Realistic_Vision_V5.1_noVAE

**URL**: https://ai.gitcode.com/hf_mirrors/SG161222/Realistic_Vision_V5.1_noVAE

**关键词列表**:

- **Realistic-Vision** (当前模型品牌名): 从项目名称 'Realistic_Vision_V5.1_noVAE' 简化提取的当前模型核心品牌名，去除版本号和特性后保留简洁形式，符合用户搜索习惯（如 'Realistic-Vision' 是模型专属标识）
- **no-VAE** (技术特性): 从项目名称中提取的独特技术特性，表示模型无需VAE组件，是用户搜索时可能关注的差异化点（如 'no-VAE' 作为专业术语被部分用户用于查询特定配置模型）
- **CreativeML** (技术特性): 从项目标签中提取的专属技术标识，属于模型的特定技术背景（如 CreativeML 是开源社区相关技术框架），用户可能在搜索模型技术细节时使用
- **OpenRAIL-M** (技术特性): 从项目标签中提取的专属技术标识，代表模型的许可或技术规范（如 OpenRAIL-M 是特定开源协议），用户可能在查询模型合规性时搜索
- **realistic** (技术特性): 从模型名称中提取的核心特性描述，强调模型生成图像的逼真度，是用户搜索时可能使用的关键词（如 'realistic' 作为质量特征被广泛用于AI图像模型查询）
- **image** (功能场景): 从模型用途推导的通用功能词，用户搜索AI模型时可能使用（如 'image' 作为图像生成类模型的高频搜索词），但避免与排除列表中的 '文生图' 重复，仅保留基础词
- **generation** (功能场景): 从模型功能推导的通用功能词，用户搜索AI模型时可能使用（如 'generation' 作为图像生成类模型的高频搜索词），但避免与排除列表中的 '文生图' 重复，仅保留基础词
- **model** (功能场景): 从模型类型推导的通用功能词，用户搜索AI模型时可能使用（如 'model' 作为基础查询词），但避免与排除列表中的 '文生图' 重复，仅保留基础词

### deepseek-ai/DeepSeek-V3.2-Exp-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.2-Exp-Base

**关键词列表**:

- **DeepSeek-V3.2-Exp-Base** (当前模型品牌名): 从项目名称直接提取的当前模型完整名称，虽含版本号，但为唯一标识符，且无更简版本存在，符合‘模型名称简化’规则中的例外：当无通用简称时保留原名
- **Exp-Base** (当前模型品牌名): ‘Exp-Base’是DeepSeek-V3.2系列中的核心子型号标识，用户在搜索实验性基础模型时可能使用该缩写，具有区分度且非高频词
- **开源模型** (部署工具): 项目托管于GitCode且使用MIT许可证，明确为开源，用户常搜索‘开源大模型’寻找可商用/可修改模型，该词未在强制排除列表中
- **MIT许可证** (部署工具): 用户在寻找可商用、无限制的AI模型时会搜索‘MIT许可证 模型’，该词具有明确法律与使用意图，非通用形容词，未被排除

### jwan2021/autotrain-us-housing-prices-1771761514

**URL**: https://ai.gitcode.com/hf_mirrors/jwan2021/autotrain-us-housing-prices-1771761514

**关键词列表**:

- **AutoTrain-US-Housing-Prices** (当前模型品牌名): 从项目名称提取的完整模型品牌名称，包含 AutoTrain 与目标数据集
- **房价预测** (功能场景): 模型的核心应用是预测美国房屋价格
- **Joblib模型** (部署工具): 模型使用 Joblib 序列化，可直接通过 joblib.load 进行本地部署
- **AutoTrain-训练** (技术特性): 模型基于 HuggingFace AutoTrain 自动化训练流程
- **US-Housing-Prices-数据集** (功能场景): 模型针对美国房价公开数据集进行训练和评估

### Qwen/Qwen3-Omni-30B-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Thinking

**关键词列表**:

- **Qwen3-Omni-30B-A3B-Thinking** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **原生端到端** (技术特性): 当前模型的核心技术特性，强调原生端到端处理能力
- **跨模态性能** (技术特性): 当前模型在跨模态处理方面的领先性能
- **ThinkerTalker设计** (技术特性): 当前模型基于MoE的Thinker–Talker创新架构
- **实时音视频交互** (功能场景): 当前模型支持的实时音视频交互功能
- **精细化音频描述生成** (功能场景): 当前模型特有的音频描述生成能力

### ByteDance-Seed/UI-TARS-72B-SFT

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-72B-SFT

**关键词列表**:

- **72B参数** (参数规格): 当前模型的参数规格，属于主流大模型规格

### ByteDance-Seed/UI-TARS-7B-SFT

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-7B-SFT

**关键词列表**:

- **视觉语言智能体** (技术特性): 模型基于视觉语言模型（VLM）构建，且强调‘原生智能体’特性，区别于普通VLM，该组合词未被高频词库覆盖，具有技术辨识度
- **端到端GUI自动化** (功能场景): 模型核心能力是无需预定义规则的端到端GUI任务自动化，是区别于传统RPA或模块化框架的关键卖点，用户搜索AI自动化工具时可能使用该短语
- **UI-TARS-7B-SFT** (当前模型品牌名): 完整模型版本名在技术社区中常被直接搜索，用于精准定位该特定微调版本，虽带后缀但属于模型官方命名，且未被高频词库收录

### THUDM/VisionReward-Image-bf16

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/VisionReward-Image-bf16

**关键词列表**:

- **VisionReward-Image** (当前模型品牌名): 项目名称中直接出现的模型完整名称
- **细粒度多维度评分** (技术特性): 采用细粒度、多维度框架对图像/视频进行可解释的评分
- **视频偏好预测** (功能场景): 专门针对视频质量进行偏好预测，超越 VideoScore 的性能
- **动态特征分析** (技术特性): 系统分析视频的动态特征以提升评估准确性
- **bf16-精度** (参数规格): 模型采用 bf16 低精度参数，适配相应硬件加速
- **SwissArmyTransformer-调用** (部署工具): 模型需通过 SAT（SwissArmyTransformer）库进行加载和推理

### meituan-longcat/LongCat-Flash-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/meituan-longcat/LongCat-Flash-Thinking

**关键词列表**:

- **LongCat-Flash-Thinking** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **LongCat** (当前模型品牌名): 当前模型名称的简化品牌标识
- **大型推理模型** (功能场景): 当前模型的核心功能定位
- **动态计算机制** (技术特性): 当前模型的核心技术创新点
- **DORA系统** (技术特性): 当前模型开发所基于的分布式强化学习框架
- **长链思维链冷启动训练** (技术特性): 当前模型特有的两阶段训练流程之一
- **领域并行训练** (技术特性): 当前模型在强化学习阶段的核心创新方案
- **形式化推理** (功能场景): 当前模型增强的复杂任务处理能力

### BAAI/bge-small-zh-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-small-zh-v1.5

**关键词列表**:

- **BGE** (当前模型品牌名): 项目名称中包含 BGE，直接提取为模型品牌名
- **bge-small-zh** (当前模型品牌名): 模型全称的简化版，去除版本号后仍能唯一标识该模型
- **语义检索** (功能场景): 模型用于将文本映射为向量，以支撑语义层面的检索任务
- **文本向量化** (功能场景): 模型的核心能力是把任意文本转化为稠密向量
- **向量数据库集成** (部署工具): 模型可直接用于向量数据库中，支持检索、分类等应用
- **低维稠密向量** (技术特性): 模型输出的向量是低维且稠密的，提升检索效率和精度

### black-forest-labs/FLUX.1-Kontext-dev

**URL**: https://ai.gitcode.com/hf_mirrors/black-forest-labs/FLUX.1-Kontext-dev

**关键词列表**:

- **参考图像编辑** (功能场景): 模型支持‘无需微调即可实现角色、风格和对象的参考’，这是区别于普通文生图的精准搜索词，未被高频词覆盖
- **引导蒸馏** (技术特性): 模型采用‘引导蒸馏技术进行训练’，是其独特训练方法，属于技术术语但具区分度，非通用词
- **连续图像编辑** (功能场景): 模型支持‘多次连续编辑优化图像且视觉偏移极小’，这是其核心使用场景，用户可能搜索‘连续图像编辑AI’

### pcoloc/autotrain-only-rssi-1813762559

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-only-rssi-1813762559

**关键词列表**:

- **pcolocautotrain-only-rssi** (当前模型品牌名): 从项目名称提取的当前模型名称
- **二氧化碳排放量预测** (功能场景): 根据模型用途（预测二氧化碳排放量）提炼的功能场景描述

### deepseek-ai/DeepSeek-V3.2-Exp

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.2-Exp

**关键词列表**:

- **长上下文优化** (技术特性): 用户处理超长文本时会主动搜索的优化关键词
- **推理效率提升** (技术特性): 稀疏注意力带来的直接收益，用户关心速度时会搜索

### deepseek-ai/DeepSeek-Prover-V2-7B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V2-7B

**关键词列表**:

- **DeepSeek-Prover-V2** (当前模型品牌名): 从项目名称提取的当前模型简化名称
- **Lean-4-形式化定理证明** (功能场景): 当前模型专门针对的核心应用场景
- **递归定理证明流程** (技术特性): 当前模型冷启动数据构建的核心技术流程
- **子目标分解** (技术特性): 当前模型处理复杂问题的关键技术能力
- **非形式化与形式化推理整合** (技术特性): 当前模型的核心技术创新点
- **冷启动推理数据** (技术特性): 当前模型训练数据构建的关键技术环节
- **证明搜索合成** (技术特性): 当前模型生成训练数据的核心技术方法

### THUDM/glm-4-9b-hf

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/glm-4-9b-hf

**关键词列表**:

- **自定义工具调用** (技术特性): 支持 Function Call 形式的自定义工具调用，提升可扩展性
- **26种语言** (功能场景): 模型覆盖包括日语、韩语、德语等在内的 26 种语言，体现多语言能力

### NimVideo/cogvideox1.5-5b-prompt-camera-motion

**URL**: https://ai.gitcode.com/hf_mirrors/NimVideo/cogvideox1.5-5b-prompt-camera-motion

**关键词列表**:

- **CogVideoX-5b** (当前模型品牌名): 从项目名称 'NimVideo/cogvideox1.5-5b-prompt-camera-motion' 中提取的核心模型品牌名，简化为通用认知形式，符合‘模型名称简化’规则
- **摄像机运动控制** (功能场景): 模型核心功能是控制摄像机6个方向运动（左/右/上/下/放大/缩小），属于用户搜索视频生成时明确的场景关键词，且未在高频排除词列表中
- **LoRa适配器** (技术特性): 模型基于LoRa（低秩适配器）技术实现对CogVideoX的微调控制，是其部署和训练方式的独特技术标签，用户会搜索‘LoRa视频模型’等组合
- **Prompt摄像机** (功能场景): 模型依赖特定提示词格式（如'Camera moves to the {}...'）实现控制，'Prompt摄像机'是用户在搜索如何用文本控制视频运镜时的潜在搜索词
- **视频运镜控制** (功能场景): ‘运镜’是影视创作专业术语，对应模型的摄像机运动控制能力，是创作者搜索AI视频工具时的精准意图词，区别于泛泛的‘视频生成’
- **CogVideoX-LoRa** (当前模型品牌名): 模型是CogVideoX的LoRa扩展，组合词在社区中可能被直接搜索，且未被高频词列表排除，具有明确区分度

### Qwen/Qwen3-235B-A22B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B

**关键词列表**:

- **Qwen3-235B-A22B** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **YaRN扩展上下文** (技术特性): 当前模型通过YaRN技术扩展上下文长度至131,072 tokens，是独特技术特性
- **128专家** (技术特性): 当前模型包含128个专家的MoE架构，是其关键技术参数
- **32768上下文** (技术特性): 当前模型原生支持32,768 tokens上下文长度，是重要功能参数
- **代理能力集成** (功能场景): 当前模型在代理能力方面具备专业性，支持与外部工具精确集成

### openai/consistency-decoder

**URL**: https://ai.gitcode.com/hf_mirrors/openai/consistency-decoder

**关键词列表**:

- **Consistency-Decoder** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Stable-Diffusion-VAE改进** (功能场景): 当前模型用于改进Stable Diffusion VAE解码效果，是其主要功能场景
- **DALL-E-3技术** (技术特性): README中提到欲了解更多信息可参阅DALL-E 3技术报告，说明当前模型与DALL-E 3技术相关
- **DiffusionPipeline集成** (部署工具): README中展示了在DiffusionPipeline中的使用方法，说明当前模型可与DiffusionPipeline集成
- **图像解码优化** (功能场景): 当前模型的核心是对图像解码进行优化，属于其功能场景

### deepseek-ai/DeepSeek-V2-Chat-0628

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2-Chat-0628

**关键词列表**:

- **DeepSeek-V2-Chat** (当前模型品牌名): 完整模型名称，体现是聊天对话模型的变体
- **沉浸式翻译** (功能场景): README 中提到模型在沉浸式翻译任务上的优化，用户可能搜索此场景
- **RAG** (技术特性): 模型在检索增强生成（RAG）任务中表现突出，是独特技术特性
- **BF16推理** (部署方式): 模型提供 BF16 格式推理，需要特定部署方式，用户会搜索此关键词
- **对话式AI** (功能场景): 模型定位为聊天对话系统，用户常以“对话式AI”检索此类模型

### IIC/gme-Qwen2-VL-2B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/gme-Qwen2-VL-2B-Instruct

**关键词列表**:

- **GME-Qwen2-VL-2B** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定模型时的精准关键词
- **通用多模态嵌入** (技术特性): 模型核心创新点，用户搜索‘通用多模态嵌入’时会寻找此类统一向量表示模型
- **Any2Any检索** (功能场景): 模型支持文本、图像、图文互查的独特检索能力，是区别于普通视觉语言模型的关键词
- **2.21B参数** (参数规格): 当前模型为2.21B，属于轻量级多模态模型，用户会搜索‘2B参数多模态模型’进行对比

### zai-org/SWE-Dev-32B

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/SWE-Dev-32B

**关键词列表**:

- **SWE-Dev** (当前模型品牌名): 从项目名称及README中提取的当前模型核心名称
- **开源智能体** (技术特性): 描述模型开源属性及智能体技术形态的核心特性
- **代码定位** (技术特性): 模型具备的具体软件工程技术能力
- **推理规模扩展** (技术特性): README强调的模型性能优化关键技术方向

### openai/imagegpt-medium

**URL**: https://ai.gitcode.com/hf_mirrors/openai/imagegpt-medium

**关键词列表**:

- **图像特征提取器** (功能场景): 用户想找能抽图像特征的模型时的常用搜索词

### Qwen/Qwen2.5-Omni-7B-GPTQ-Int4

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B-GPTQ-Int4

**关键词列表**:

- **Omni-7B** (当前模型品牌名): 从项目名称 Qwen2.5-Omni-7B‑GPTQ‑Int4 中提取的简洁品牌名称，去除基础模型标识
- **ThinkerTalker架构** (技术特性): 模型采用的全新端到端多模态 Thinker‑Talker 架构，是其核心技术亮点
- **TMRoPE技术** (技术特性): 时间对齐多模态旋转位置编码（TMRoPE）实现视频/音频时间戳精准同步，具备独特性
- **GPTQInt4** (技术特性): 采用 GPTQ 4‑bit 量化并使用 Int4 权重，大幅降低显存占用，属于模型的独特优化手段

### baidu/ERNIE-4.5-21B-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Thinking

**关键词列表**:

- **ERNIE-4.5-21B** (当前模型品牌名): 从项目名称提取的当前模型核心名称，保留关键参数规模便于识别
- **A3B-Thinking** (当前模型品牌名): 项目名称中的独特标识，体现模型思维能力增强特性
- **逻辑推理增强** (功能场景): 模型亮点中明确提到的核心能力提升，用户搜索推理类模型时会关注

### ValueFX9507/Tifa-Deepsex-14b-CoT-Q8

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-Deepsex-14b-CoT-Q8

**关键词列表**:

- **Tifa-Deepsex-14b-CoT** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，是用户搜索该特定模型的精准关键词
- **增量预训练** (技术特性): 模型使用增量预训练（incremental-pretraining）技术，该术语在高频词列表中未被覆盖，具技术区分度
- **Q8量化** (部署工具): 模型提供Q8量化版本（GGUF格式），Q8是用户在本地部署时关注的特定量化精度，区别于通用'量化模型'高频词

### Qwen/Qwen2.5-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-7B-Instruct

**关键词列表**:

- **Qwen2.5-7B-Instruct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **指令微调语言模型** (技术特性): 当前模型经过指令微调，属于其技术特性
- **长文本生成** (功能场景): 当前模型具备生成长文本的能力，属于其功能场景
- **结构化数据理解** (功能场景): 当前模型能够理解结构化数据，属于其功能场景
- **多语言支持模型** (技术特性): 当前模型支持多种语言，属于其技术特性

### jinaai/jina-embeddings-v4

**URL**: https://ai.gitcode.com/hf_mirrors/jinaai/jina-embeddings-v4

**关键词列表**:

- **Jina-Embeddings** (当前模型品牌名): 模型在项目名称中出现的品牌名称，直接对应模型本身
- **2048维稠密嵌入** (技术特性): 模型默认的稠密向量维度，体现高维度表示能力
- **FlashAttention2** (技术特性): 模型采用的高效注意力实现，提升检索速度与精度
- **32768序列长度** (技术特性): 模型支持的最长上下文长度，适用于超长文档检索
- **任务适配器** (功能场景): 模型提供的检索、文本匹配、代码任务专用适配器，可动态选择
- **多向量检索** (功能场景): 模型支持的延迟交互（多向量）检索模式，适合复杂文档的细粒度匹配

### dmis-lab/biobert-large-cased-v1.1-squad

**URL**: https://ai.gitcode.com/hf_mirrors/dmis-lab/biobert-large-cased-v1.1-squad

**关键词列表**:

- **BioBERT-large** (当前模型品牌名): 从项目名称提取的当前模型名称，简化版本号后保留核心标识
- **question-answering** (功能场景): 当前模型的核心功能，标签中明确标注的用途
- **PubMed预训练** (技术特性): 当前模型训练数据的核心来源之一，体现其领域适配性
- **PMC预训练** (技术特性): 当前模型训练数据的核心来源之一，体现其领域适配性
- **dmis-lab** (当前模型品牌名): 模型开发团队名称，可能作为用户搜索该实验室相关模型的关键词

### openbmb/MiniCPM-V-2

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-V-2

**关键词列表**:

- **感知重采样器** (技术特性): 模型架构关键组件，原文明确提及，非通用术语，具有技术独特性
- **多图理解** (功能场景): README指出模型在'多图理解任务上超越GPT-4V'，是明确的功能点，非泛化词
- **SWIFT微调** (部署工具): 模型支持通过SWIFT框架微调，是特定工具链支持，非通用微调概念，具操作指向性
- **vLLM推理加速** (部署工具): 明确支持vLLM加速，是部署优化手段，用户可能搜索'支持vLLM的多模态模型'

### ByteDance-Seed/VINCIE-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/VINCIE-3B

**关键词列表**:

- **VINCIE** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **上下文图像编辑** (功能场景): 模型核心能力：在包含文本和先前图像的上下文序列中编辑图像
- **多轮图像编辑** (功能场景): 模型在提出的多轮编辑基准上取得领先，体现其循环编辑能力
- **视频驱动图像编辑** (技术特性): 模型通过从视频中学习实现图像编辑，突出视频驱动的创新方式
- **块因果扩散** (技术特性): 模型采用的块因果扩散Transformer结构，是其独特的训练架构

### FluidInference/silero-vad-coreml

**URL**: https://ai.gitcode.com/hf_mirrors/FluidInference/silero-vad-coreml

**关键词列表**:

- **Silero-VAD-CoreML** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Apple平台优化** (部署工具): 当前模型针对Apple平台（iOS/macOS）进行了优化
- **Swift应用开发** (功能场景): 当前模型可直接用于Swift应用开发
- **预转换CoreML模型** (技术特性): 当前模型包含预转换的CoreML模型

### llava-hf/llava-1.5-7b-hf

**URL**: https://ai.gitcode.com/hf_mirrors/llava-hf/llava-1.5-7b-hf

**关键词列表**:

- **LLaVA** (当前模型品牌名): 从项目名称llava-hf/llava-1.5-7b-hf提取的当前模型核心名称
- **image-text-to-text** (功能场景): README标签中明确标注的当前模型核心功能
- **多图像生成** (功能场景): 当前模型支持的多图像输入处理能力
- **多提示生成** (功能场景): 当前模型支持的多提示输入处理特性
- **llava-hf** (当前模型品牌名): 项目名称中标识的模型所属组织/系列名称
- **图像查询** (功能场景): 当前模型通过<image>标记实现的图像内容查询功能
- **指令遵循训练** (技术特性): 当前模型基于指令遵循数据微调的技术特点（备选关键词，若需排除视觉语言模型时使用）

### unsloth/gpt-oss-20b-BF16

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gpt-oss-20b-BF16

**关键词列表**:

- **智能代理能力** (功能场景): 模型原生支持函数调用、网页浏览、代码执行等代理功能，是区别于普通LLM的核心应用场景

### ByteDance-Seed/UI-TARS-1.5-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-1.5-7B

**关键词列表**:

- **UI-TARS-1.5** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **游戏操作智能体** (功能场景): 模型专注于在虚拟环境中执行游戏操作任务
- **图形界面任务处理** (功能场景): 模型能够高效完成图形用户界面（GUI）相关的任务
- **强化学习赋能** (技术特性): 模型通过强化学习提升了高级推理和决策能力
- **思维推演能力** (技术特性): 模型在执行动作前进行思考推演，显著提升了推理表现
- **OSworld基准** (功能场景): 模型在 OSworld 基准测试中取得领先成绩，体现其在计算机操作任务上的实力

### google-t5/t5-11b

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-11b

**关键词列表**:

- **T5-11B** (当前模型品牌名): 从项目名称提取的当前模型名称，110亿参数版本
- **文本到文本** (技术特性): T5统一将所有NLP任务重构为文本输入-文本输出的核心框架
- **11B参数** (参数规格): 当前模型110亿参数的主流规格写法

### alibaba-pai/Wan2.1-Fun-14B-Control

**URL**: https://ai.gitcode.com/hf_mirrors/alibaba-pai/Wan2.1-Fun-14B-Control

**关键词列表**:

- **Wan2.1-Fun** (当前模型品牌名): 从项目名称'Wan2.1-Fun-14B-Control'提取的核心品牌标识，符合模型名称简化规则（如示例中的'DeepSeek-R1'）
- **视频控制** (功能场景): 模型核心功能描述为'视频控制权重'，支持Canny、Depth等条件控制，是用户搜索AI视频生成工具时的典型场景关键词
- **轨迹控制** (技术特性): 模型明确支持'使用轨迹控制'作为关键技术特性，属于用户会搜索的差异化技术点（如示例中的'链式思维'）
- **多控制条件** (技术特性): 模型支持Canny、Depth、Pose、MLSD等多类控制条件，是用户查询视频生成模型时的高价值技术关键词
- **多分辨率** (技术特性): 模型支持多分辨率视频预测（512,768,1024），属于用户搜索视频生成模型时关注的技术规格点

### nomic-ai/nomic-embed-vision-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/nomic-ai/nomic-embed-vision-v1.5

**关键词列表**:

- **nomic-embed-vision** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **视觉嵌入模型** (功能场景): 当前模型的核心功能定位
- **共享嵌入空间** (技术特性): 当前模型与同系列文本模型的关键技术关联特性
- **Nomic-Atlas** (部署工具): 当前模型配套的数据可视化平台
- **nomic-Python客户端** (部署工具): 当前模型的官方调用方式
- **嵌入API** (部署工具): 当前模型的托管推理服务形式
- **AWS-SageMaker** (部署工具): 当前模型支持的云平台部署方式

### unsloth/embeddinggemma-300m-qat-q8_0-unquantized

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-qat-q8_0-unquantized

**关键词列表**:

- **3亿参数** (参数规格): 当前模型的核心参数规格，具有区分度
- **文本向量表示** (功能场景): 当前模型的主要功能，适用于搜索和检索任务
- **Matryoshka表示学习** (技术特性): 当前模型使用的独特技术，提供更小的输出嵌入选项

### baidu/Qianfan-VL-8B

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/Qianfan-VL-8B

**关键词列表**:

- **Qianfan-VL-8B** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，符合品牌名简化规则（保留主版本号，不带冗余参数）
- **思维链推理** (技术特性): 模型在8B与70B版本中明确支持，是区别于3B版本的核心技术点，用户常搜‘支持思维链的AI模型’
- **表格解析** (功能场景): 文档理解中的具体应用场景，用户搜索‘AI解析表格’‘自动提取表格数据’时会使用，具象且未被高频占用

### BAAI/Emu3-VisionTokenizer

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/Emu3-VisionTokenizer

**关键词列表**:

- **Emu3** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **VisionTokenizer** (技术特性): 模型提供的视觉 token 化组件，独特的技术模块名称
- **下一个视觉-token-预测** (技术特性): 核心训练方式，使用下一个视觉 token 进行预测
- **文本驱动图像生成** (功能场景): 模型能够根据文本输入生成高质量图像的主要应用场景
- **文本驱动视频扩展** (功能场景): 模型在已有视频上下文上预测后续内容，实现视频扩展
- **离散空间-token-化** (技术特性): 将图像、文本、视频映射到离散空间进行统一 token 化的技术特点

### Qwen/Qwen3-4B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-4B

**关键词列表**:

- **thinking-mode** (技术特性): 当前模型独特的技术特性，用于复杂逻辑推理场景
- **non-thinking-mode** (技术特性): 当前模型独特的技术特性，用于高效通用对话场景
- **agent-capabilities** (技术特性): 当前模型的核心技术能力之一

### MusePublic/489_ckpt_FLUX_1

**URL**: https://ai.gitcode.com/hf_mirrors/MusePublic/489_ckpt_FLUX_1

**关键词列表**:

- **FLUX.1-dev** (当前模型品牌名): 从项目名称 'MusePublic/489_ckpt_FLUX_1' 和 README 中明确提及的模型名称，是当前模型的官方简称，用户搜索此类模型时会直接使用 'FLUX.1-dev' 作为关键词
- **text-to-image** (功能场景): 模型核心功能是根据文本生成图像，且标签中明确标注 'text-to-image'，是用户在AI图像生成领域最常搜索的精准功能词，且未被列入强制排除词库
- **120亿参数** (参数规格): 模型明确说明拥有120亿参数，属于主流大模型参数规模，用户常搜索'XX亿参数'来筛选模型性能层级，且未在排除列表中（排除列表仅含7B/8B/14B/32B等，120亿为独特数值）
- **非商业许可** (使用场景): 模型明确说明可用于个人、科学及商业用途，但受限于'FLUX.1 [dev] 非商业许可协议'，用户在寻找可商用AI模型时会搜索'非商业许可'来规避法律风险，是独特且高意图的搜索词

### rubentito/layoutlmv3-base-mpdocvqa

**URL**: https://ai.gitcode.com/hf_mirrors/rubentito/layoutlmv3-base-mpdocvqa

**关键词列表**:

- **LayoutLMv3** (当前模型品牌名): 模型名称直接来源于项目名称，唯一标识该模型
- **MP-DocVQA** (功能场景): 模型在 MP-DocVQA（多页文档问答）数据集上微调，适用于多页文档问答任务
- **多页文档问答** (功能场景): 模型专注于处理包含多页的文档进行视觉问答，满足此类业务需求
- **OCRfree-处理** (技术特性): 使用 processor 时设置 apply_ocr=False，支持在无需额外 OCR 步骤的情况下直接进行推理
- **布局感知问答** (技术特性): 基于 LayoutLMv3 的布局感知能力，能够理解文档中元素的空间关系进行准确回答

### Qwen/Qwen3-4B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-4B-Base

**关键词列表**:

- **Qwen3-4B-Base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **阿里大模型系列** (当前模型品牌名): Qwen属于阿里大模型系列，映射为阿里大模型系列
- **119种语言覆盖** (技术特性): 当前模型预训练数据覆盖119种语言，是显著技术特性
- **高质数据混合** (技术特性): 当前模型预训练数据包含多种高质量数据混合，是显著技术特性
- **36万亿tokens预训练** (技术特性): 当前模型预训练使用了36万亿tokens，是显著技术特性

### Qwen/Qwen3-30B-A3B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-GGUF

**关键词列表**:

- **Qwen3-30B-A3B** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **思考模式切换** (技术特性): 当前模型核心功能，支持模型内无缝切换思考与非思考模式
- **131072-tokens** (技术特性): 当前模型通过YaRN扩展后的上下文长度，用户可能搜索长上下文模型

### IIC/nlp_bert_relation-extraction_chinese-base

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/nlp_bert_relation-extraction_chinese-base

**关键词列表**:

- **关系抽取模型** (当前模型品牌名): 从项目名称提取的模型核心定位，直接体现模型的主要功能
- **中文关系抽取** (功能场景): 模型专注于中文文本的关系抽取，用户常以此关键词搜索
- **实体三元组抽取** (功能场景): 模型输出 (主语, 谓语, 宾语) 三元组，是关系抽取的典型任务描述
- **信息抽取** (功能场景): 关系抽取属于信息抽取范畴，用户搜索信息抽取时会关联到本模型
- **duie数据集** (训练数据): 模型在 duie 数据集上 fine‑tune，数据集名称是模型的关键特征
- **中文RoBERTawwm-ext** (技术特性): 模型基于 hfl/chinese-roberta-wwm-ext 预训练模型，体现其底层技术

### AI-ModelScope/gliner_multi

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/gliner_multi

**关键词列表**:

- **GLiNER-multi** (当前模型品牌名): 项目名称为AI-ModelScope/gliner_multi，模型官方名称为gliner_multi，是当前模型的唯一品牌标识，符合用户搜索AI-NER模型时的直接关键词
- **通用命名实体识别** (功能场景): 模型核心功能是识别任意类型实体，区别于传统预定义NER，用户会搜索‘通用NER’或‘任意实体识别’这类精准功能词，且未在高频排除词列表中
- **零样本实体识别** (技术特性): GLiNER的核心创新是无需微调即可识别新实体类型，属于‘零样本NER’场景，是区别于传统NER的关键技术点，未被高频词覆盖
- **多语言NER** (功能场景): 模型明确支持多语言实体识别（gliner_multi），是其区别于仅支持英语的v1/v2版本的核心卖点，用户会搜索‘多语言命名实体识别’
- **209M参数** (参数规格): gliner_base/gliner_multi参数量为209M，属于中等规模模型，用户常搜索‘200M级NER模型’等规格词，且209M未在排除列表中
- **Pile-NER** (技术特性): 模型基于Pile-NER数据集训练，该数据集是GLiNER系列的专属训练数据，具有唯一性，用户在研究数据集时可能搜索该术语
- **轻量级NER** (功能场景): 模型定位是替代LLM的轻量级NER方案，强调‘轻量’与‘低资源适用’，是用户在资源受限场景下搜索的关键意图词，未被高频词覆盖

### Qwen/Qwen2.5-Omni-3B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-3B

**关键词列表**:

- **Thinker-Talker架构** (技术特性): 当前模型提出的创新全模态架构，具有技术独特性
- **TMRoPE** (技术特性): 当前模型创新性的时间对齐多模态旋转位置编码技术

### Qwen/Qwen3-Omni-30B-A3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Instruct

**关键词列表**:

- **Qwen3-Omni** (当前模型品牌名): 项目名称中的核心品牌名，用户直接搜索
- **全模态模型** (技术特性): 原生端到端文本/图像/音频/视频一体化处理，区别于普通多模态
- **音视频流式生成** (功能场景): 支持边输入边输出，直播、会议等实时应用刚需

### LiquidAI/LFM2-1.2B-Extract

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-Extract

**关键词列表**:

- **文档信息抽取** (功能场景): 模型的核心功能是从非结构化文档中提取关键信息
- **JSON输出** (功能场景): 模型默认将抽取结果以 JSON 格式返回，满足结构化数据需求
- **YAML生成** (功能场景): 提供 YAML 格式输出，便于配置管理和流水线处理
- **非结构化文档处理** (技术特性): 专注于处理文章、报告、邮件等非结构化文本，提升信息结构化效率
- **跨语言抽取** (技术特性): 模型支持多语言（包括中、英、阿、法、德、日、韩、葡、西），实现跨语言信息抽取

### microsoft/Florence-2-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/Florence-2-base

**关键词列表**:

- **Florence-2** (当前模型品牌名): 从项目名称microsoft/Florence-2-base提取的当前模型名称
- **Florence-2-base** (当前模型品牌名): 项目名称中明确的模型全称
- **视觉基础模型** (功能场景): 模型概述中描述的核心功能定位
- **提示词视觉任务** (技术特性): 基于提示词处理视觉任务的核心技术特点
- **FLD-5B数据集** (技术特性): 模型预训练使用的特色数据集，具有技术辨识度

### unsloth/embeddinggemma-300m-qat-q4_0-unquantized

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-qat-q4_0-unquantized

**关键词列表**:

- **768维嵌入** (技术特性): 模型输出的唯一标准嵌入维度，用户在搜索高效文本嵌入时会精准使用该数值维度词
- **Matryoshka嵌入** (技术特性): 模型独有的Matryoshka表示学习（MRL）技术，支持动态截断嵌入维度，是区别于其他嵌入模型的核心创新点
- **设备端嵌入** (功能场景): 模型明确面向手机、笔记本等资源受限设备部署，用户搜索‘轻量级嵌入模型’或‘设备端AI’时会匹配此场景
- **3亿参数嵌入** (参数规格): 300M参数是当前模型的主流参数规模，属于用户可搜索的合理粒度（非304M等细节），且未被高频词列表排除
- **语义相似度搜索** (功能场景): 模型明确用于语义相似度任务，是用户在检索系统、推荐系统中搜索嵌入模型时的典型意图关键词
- **sentence-transformers嵌入** (部署工具): 模型官方推荐与sentence-transformers库配合使用，是开发者部署该模型时的精准技术组合词

### tencent/HunyuanVideo-PromptRewrite

**URL**: https://ai.gitcode.com/hf_mirrors/tencent/HunyuanVideo-PromptRewrite

**关键词列表**:

- **HunyuanVideo** (当前模型品牌名): 从项目名称及README提取的当前模型名称
- **PromptRewrite** (技术特性): 当前模型名称包含的核心功能模块
- **3D-VAE** (技术特性): 当前模型架构中的核心技术组件
- **图像视频统一生成** (技术特性): 当前模型的关键技术特性
- **130亿参数** (参数规格): 当前模型的参数规模，属于主流可搜索规格

### THUDM/cogagent-9b-20241220

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/cogagent-9b-20241220

**关键词列表**:

- **双语GUI助手** (功能场景): 模型能够接受中英文双语的屏幕截图并进行交互，定位为图形界面助手
- **屏幕截图交互** (功能场景): 模型支持对 GUI 截图进行理解与操作，是核心使用方式
- **跨平台识别** (技术特性): 模型能够自动识别 Mac、Windows、Mobile 等操作系统平台
- **Action-Operation-Sensitive格式** (技术特性): 模型要求的特定输出格式，体现其动作‑操作敏感的推理方式
- **提示词拼接技术** (技术特性): README 中强调的关键实现细节，对模型正常运行至关重要
- **动作空间建模** (技术特性): 模型在动作空间完善性方面的提升，提升了 GUI 操作的准确性
- **任务泛化能力** (技术特性): 模型在任务的普适和泛化性上得到大幅提升，适用于多种 GUI 任务

### facebook/musicgen-stereo-small

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/musicgen-stereo-small

**关键词列表**:

- **MusicGen-stereo-small** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索立体声音乐生成模型时会使用此精确名称
- **立体声音乐生成** (功能场景): 模型核心创新点是生成立体声（双通道）音乐，区别于普通单声道模型，是用户搜索差异化功能时的明确意图词
- **文本转音乐** (功能场景): 模型核心功能是根据文本描述生成音乐，属于用户高频搜索的AI音乐生成场景，且未被高频词库排除
- **EnCodec令牌器** (技术特性): 模型依赖EnCodec作为音频令牌化基础，是其架构独特性所在，属于技术关键词且未在排除列表中
- **延迟交错处理** (技术特性): 模型实现立体声的核心技术手段，通过延迟交错处理双路令牌流，是该模型独有的技术描述词

### moojink/openvla-7b-oft-finetuned-libero-spatial

**URL**: https://ai.gitcode.com/hf_mirrors/moojink/openvla-7b-oft-finetuned-libero-spatial

**关键词列表**:

- **LIBERO-Spatial** (功能场景): 当前模型专门针对LIBERO-Spatial任务训练的应用场景
- **优化微调技术** (技术特性): 当前模型通过优化微调技术实现性能提升的核心技术特性
- **PEFT** (技术特性): 当前模型使用的参数高效微调技术特性

### ecmwf/aifs-single-0.2.1

**URL**: https://ai.gitcode.com/hf_mirrors/ecmwf/aifs-single-0.2.1

**关键词列表**:

- **滑动窗口变换处理器** (技术特性): 当前模型使用的核心处理器技术
- **高空气象变量预报** (功能场景): 当前模型具备高空气象变量预报功能
- **热带气旋路径预报** (功能场景): 当前模型具备热带气旋路径预报功能
- **多级并行计算** (技术特性): 当前模型支持多级并行计算以实现高分辨率输入数据的训练

### moonshotai/Moonlight-16B-A3B

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Moonlight-16B-A3B

**关键词列表**:

- **权重衰减** (技术特性): 在大规模训练中对Muon的可扩展性起关键作用
- **一致性RMS更新** (技术特性): 确保模型参数更新均方根保持一致的专有技术
- **ZeRO-1分布式** (技术特性): 实现内存最优且通信高效的分布式训练方案

### stanfordmimi/synthpose-vitpose-huge-hf

**URL**: https://ai.gitcode.com/hf_mirrors/stanfordmimi/synthpose-vitpose-huge-hf

**关键词列表**:

- **VitPose-Huge** (当前模型品牌名): README中明确提到的模型主干网络名称
- **Keypoint-Detection** (功能场景): 当前模型的核心功能标签
- **人体姿态估计** (功能场景): 基于关键点检测的具体应用场景

### zai-org/GLM-4.6

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.6

**关键词列表**:

- **GLM-4.6** (当前模型品牌名): 项目名称直接给出的最新版本号，用户会搜
- **200K上下文** (技术特性): 官方强调的核心升级点，超长上下文窗口
- **智能体框架** (功能场景): 模型主打能力，用户搜索如何接入智能体
- **代码基准测试** (功能场景): 开发者关注模型在代码评测榜单的表现
- **工具调用推理** (技术特性): 支持推理中调用工具，区别于普通对话模型
- **角色扮演写作** (功能场景): 官方提到风格与可读性优化，适合角色扮演场景

### google-bert/bert-large-uncased-whole-word-masking-finetuned-squad

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-large-uncased-whole-word-masking-finetuned-squad

**关键词列表**:

- **BERT-large** (当前模型品牌名): 从项目名称提取的模型品牌名称，区分于 BERT-base 等其他版本
- **Whole-Word-Masking** (技术特性): 模型采用的全词掩码技术，是相较于普通掩码的核心特性
- **SQuAD问答微调** (功能场景): 模型在 SQuAD 数据集上完成的问答任务微调，适用于阅读理解与问答系统
- **掩码语言模型** (技术特性): 模型预训练使用的 MLM（Mask Language Modeling）目标，核心学习方式
- **Uncased** (模型特性): 模型对大小写不敏感的设置，区别于 cased 版本

### Kwaipilot/KAT-V1-40B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/KAT-V1-40B

**关键词列表**:

- **KAT-V1-40B** (当前模型品牌名): 项目名称为Kwaipilot/KAT-V1-40B，提取其核心品牌标识，符合模型名称简化规则（保留主版本号，省略冗余路径）
- **自动思考** (技术特性): 模型核心创新点为‘学会何时生成显式思维链与何时直接作答’，中文用户搜索‘自动思考’更符合搜索习惯，且未在高频排除词列表中
- **结构化响应** (技术特性): 模型采用<judge><think_on><answer>等结构化标记生成可解析响应，是其工程设计亮点，用户可能搜索‘结构化AI响应’或‘可解析推理’等词
- **Step-SRPO** (技术特性): 模型独有后训练技术名称，属于专业用户会搜索的特定算法术语，未在高频排除词中，具有技术辨识度
- **冷启动自动思考** (技术特性): 模型在后训练阶段使用‘冷启动自动思考’机制初始化思维模式，是其训练流程中的独特术语，非通用表达，具备搜索价值

### Qwen/Qwen3-32B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-4bit

**关键词列表**:

- **Qwen3-32B-MLX-4bit** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **YaRN扩展** (技术特性): 当前模型上下文长度扩展的独特技术

### mradermacher/Orsta-7B-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Orsta-7B-i1-GGUF

**关键词列表**:

- **Orsta-7B-i1-GGUF** (当前模型品牌名): 从项目名称提取的当前模型名称
- **加权量化** (技术特性): 当前模型采用了加权量化技术
- **mmproj文件** (技术特性): 当前模型涉及mmproj文件，是视觉模型的一部分

### chancharikm/qwen2.5-vl-7b-cam-motion-preview

**URL**: https://ai.gitcode.com/hf_mirrors/chancharikm/qwen2.5-vl-7b-cam-motion-preview

**关键词列表**:

- **CamMotion-Preview** (当前模型品牌名): 项目名称中包含的模型品牌名称，直接提取简洁版
- **相机运动分类** (功能场景): 模型的核心应用场景——对视频中的相机运动进行分类
- **视频文本检索** (功能场景): 模型可用于根据相机运动字幕在视频与文本之间进行检索
- **VQAScore** (技术特性): 模型在评估与检索时使用的专有评分指标，具备辨识度
- **相机运动数据集** (数据来源): 模型在公开的高质量相机运动数据集上进行微调，体现数据特色
- **视频文本匹配** (技术特性): 模型实现的核心技术之一，用于将视频内容与相机运动文字描述对齐

### cahya/NusaBert-ner-v1.3

**URL**: https://ai.gitcode.com/hf_mirrors/cahya/NusaBert-ner-v1.3

**关键词列表**:

- **NusaBert** (当前模型品牌名): 模型名称来源于项目名 NusaBert‑ner‑v1.3，直接体现品牌
- **实体识别** (功能场景): 模型用于命名实体识别（NER）任务，是其主要应用场景
- **印尼语NER** (功能场景): 模型专注于印尼语（Indonesian）文本的实体识别，满足语言特定需求
- **grit-id数据集** (技术特性): 模型在 grit-id/id_nergrit_corpus 数据集上微调，体现数据来源和训练特性
- **19类实体** (技术特性): 模型能够识别 19 种实体类别，展示其细粒度分类能力
- **Token-Classification** (功能场景): 模型属于 Token Classification 任务类型，明确其技术定位

### stabilityai/stable-diffusion-xl-refiner-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-diffusion-xl-refiner-1.0

**关键词列表**:

- **两阶段流水线** (技术特性): 当前模型采用的独特技术流程
- **SDEdit技术** (技术特性): 当前模型中使用的特定技术方法

### mradermacher/ALP_DeepScaleR_1.5B_C16K-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/ALP_DeepScaleR_1.5B_C16K-GGUF

**关键词列表**:

- **ALPDeepScaleR** (当前模型品牌名): 从项目名称 mradermacher/ALP_DeepScaleR_1.5B_C16K-GGUF 中提取的核心品牌名，去掉版本号后为简洁标识，符合用户搜索习惯
- **Q2K** (技术特性): Q2_K是极低比特量化方案，属于GGUF中较少见的极端压缩格式，用户搜索‘超低显存AI模型’时可能针对性查找此类量化名
- **Q80** (技术特性): Q8_0是当前模型中质量最佳的量化版本，用户在追求本地部署高精度时会搜索‘Q8_0模型’这类具体量化标签
- **本地推理** (部署工具): 模型为GGUF量化版，专为本地CPU/GPU推理设计，用户搜索‘本地运行数学模型’时会匹配该词，且未在强制排除词中，具高搜索意图

### Qwen/Qwen3-30B-A3B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B

**关键词列表**:

- **外部工具集成** (技术特性): 模型支持与外部工具无缝对接，适用于复杂工作流和自动化场景

### ByteDance-Seed/SeedVR2-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR2-3B

**关键词列表**:

- **一步式视频修复** (功能场景): 用户搜索AI视频修复时会用的核心功能词
- **扩散对抗后训练** (技术特性): 模型独有的训练范式，具有区分度
- **高分辨率视频修复** (功能场景): 明确指向真实高分辨率场景，搜索意图强

### fixie-ai/ultravox-v0_5-llama-3_2-1b

**URL**: https://ai.gitcode.com/hf_mirrors/fixie-ai/ultravox-v0_5-llama-3_2-1b

**关键词列表**:

- **语音大语言模型** (功能场景): 当前模型的核心功能，能够处理语音和文本输入
- **语音转语音翻译** (功能场景): 当前模型的应用场景之一，可实现语音转语音翻译
- **口语音频分析** (功能场景): 当前模型的应用场景之一，可进行口语音频分析

### OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M

**URL**: https://ai.gitcode.com/hf_mirrors/OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M

**关键词列表**:

- **OpenMed-NER** (当前模型品牌名): 从项目名称 OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M 提取的简洁模型名称
- **化学实体识别** (功能场景): 模型专注于从临床文本和科研文献中识别化学实体，是其核心应用场景
- **药物相互作用检测** (功能场景): 模型可用于检测药物之间的相互作用，符合 README 中的应用描述
- **不良药物反应监测** (功能场景): 模型支持不良事件监测，帮助药物安全监管
- **生物医学知识图谱构建** (功能场景): 模型输出的实体信息可用于构建生物医学知识图谱，属于 README 中列出的下游任务
- **434M参数** (参数规格): 模型名称中包含的参数规模，用户常以参数大小检索模型

### jwan2021/autotrain-us-housing-prices-1771761513

**URL**: https://ai.gitcode.com/hf_mirrors/jwan2021/autotrain-us-housing-prices-1771761513

**关键词列表**:

- **autotrain-us-housing-prices** (当前模型品牌名): 从项目名称提取的当前模型名称，直接反映模型用途
- **R2决定系数0.922** (技术特性): 模型验证指标中的高R2值，体现模型拟合优度，是模型性能的关键指标

### Qwen/Qwen3-14B-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-FP8

**关键词列表**:

- **双模式** (技术特性): 单模型内同时支持思考模式和非思考模式的切换
- **复杂逻辑推理** (功能场景): 模型在复杂逻辑推理任务上表现突出，适用于高级推理场景
- **14B** (参数规格): 模型规模为 14 B 参数，是该系列的中大型版本

### tencent/HunyuanVideo

**URL**: https://ai.gitcode.com/hf_mirrors/tencent/HunyuanVideo

**关键词列表**:

- **FP8量化推理** (技术特性): README明确提及'发布FP8模型权重，显著节省GPU显存'，FP8量化是当前模型独有的部署技术亮点，非通用术语
- **xDiT并行推理** (技术特性): 项目独家发布基于xDiT的并行推理代码，是当前模型区别于其他视频模型的核心架构创新点
- **企鹅视频基准** (技术特性): 项目自研的视频评估基准，名称独特且为腾讯原创，非通用评测集，具有高区分度
- **3D变分自编码器** (技术特性): README明确列为混元视频的核心架构组件，是区别于其他文生视频模型（如Sora、Pika）的关键技术
- **提示词改写** (技术特性): README中列为混元视频的独立核心特性，属于模型预处理阶段的独家设计，非通用功能

### stepfun-ai/step3-fp8

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/step3-fp8

**关键词列表**:

- **321B参数** (参数规格): 模型总参数量 321B，是模型规模的关键搜索词
- **38B激活参数** (参数规格): 每令牌激活参数量 38B，体现模型推理计算量，用户会关注
- **注意力前馈网络解耦** (技术特性): 模型的 AFD 设计，区别于常规注意力实现

### Intel/ldm3d-4c

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/ldm3d-4c

**关键词列表**:

- **LDM3D** (当前模型品牌名): 项目名称直接给出的模型品牌名
- **Text-to-RGBD** (功能场景): 模型核心能力：从文本同时生成彩色图与深度图
- **DepthFusion** (功能场景): 官方配套应用，用于360°沉浸式全景体验
- **CVPR2023** (技术特性): 顶级会议收录，体现模型学术影响力
- **TouchDesigner** (部署工具): 官方演示使用的可视化创作平台，用户可复现

### OpenGVLab/InternVL2-2B

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVL2-2B

**关键词列表**:

- **InternVL2-2B** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索该具体模型时会使用此名称
- **指令微调模型** (技术特性): README强调'instruction-tuned models'，是该系列核心训练方式，具有技术区分度且未被高频词列表覆盖
- **OpenGVLab** (当前模型品牌名): 项目所属机构名称，作为国产研究团队品牌，用户搜索'OpenGVLab模型'时可能直接使用该名称，具有机构辨识度

### Kijai/WanVideo_comfy

**URL**: https://ai.gitcode.com/hf_mirrors/Kijai/WanVideo_comfy

**关键词列表**:

- **WanVideo** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **WanVideoWrapper** (部署工具): 官方提供的 ComfyUI‑WanVideoWrapper 插件，可直接在 ComfyUI 中使用该模型
- **FP8-scaled** (技术特性): 模型提供 FP8 量化的 scaled 版本，属于独特的量化技术实现
- **Phantom** (技术特性): README 中的标签之一，表示模型使用的特定扩散或渲染技术

### XiaomiMiMo/MiMo-Audio-7B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/XiaomiMiMo/MiMo-Audio-7B-Base

**关键词列表**:

- **MiMo-Audio-7B-Base** (当前模型品牌名): 项目名称直接来源，是模型的唯一官方名称，用户搜索特定音频模型时会使用完整品牌名
- **少样本学习** (技术特性): 模型核心能力亮点，强调仅需少量示例即可泛化，是区别于传统微调模型的关键技术特征
- **语音编辑** (功能场景): 模型展示的创新能力，非通用功能，具有高区分度，是用户寻找专业音频编辑AI时可能使用的关键词
- **Text-to-Audio** (技术特性): 模型支持的关键模态转换能力，区别于纯语音识别模型，是音频生成领域的重要搜索维度

### deepseek-ai/DeepSeek-V3.1-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1-Base

**关键词列表**:

- **ModelScope** (部署工具): 模型下载链接中提到的部署平台，用户搜索模型部署方式时会使用此关键词，属于部署工具维度且未被高频词覆盖

### depth-anything/Depth-Anything-V2-Large-hf

**URL**: https://ai.gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Large-hf

**关键词列表**:

- **DINOv2骨干网络** (技术特性): 当前模型采用的核心技术架构
- **DPT架构** (技术特性): 当前模型使用的架构类型
- **合成标注图像** (技术特性): 当前模型训练数据的特点
- **真实无标注图像** (技术特性): 当前模型训练数据的另一特点

### vicgalle/xlm-roberta-large-xnli-anli

**URL**: https://ai.gitcode.com/hf_mirrors/vicgalle/xlm-roberta-large-xnli-anli

**关键词列表**:

- **XLM-RoBERTa-large** (当前模型品牌名): 项目名称中直接包含的模型品牌名称，用户搜索时会使用该完整名称
- **Zero-shot-classification** (功能场景): 模型主要用于零样本分类任务，是用户最常搜索的应用场景
- **ANLI** (技术特性): 模型在 ANLI 数据集上微调，体现其在自然语言推理任务上的专长
- **HuggingFace-pipeline** (部署工具): 模型可通过 HuggingFace 的 zero‑shot‑classification pipeline 直接调用，符合用户的部署搜索需求

### InternRobotics/VLAC

**URL**: https://ai.gitcode.com/hf_mirrors/InternRobotics/VLAC

**关键词列表**:

- **VLAC** (当前模型品牌名): 项目名称为InternRobotics/VLAC，模型核心品牌名为VLAC，是当前模型唯一专属名称
- **视觉-语言-动作** (技术特性): 模型核心创新点为VLA（Visual-Language-Action）多模态架构，是区别于通用多模态模型的独特技术标签
- **成对评论家** (技术特性): 模型核心机制为‘成对比较评论家’，用于评估机器人任务进度，是论文中强调的原创设计，非通用术语
- **机器人强化学习** (功能场景): 模型明确面向真实世界机器人强化学习任务，是其核心应用场景，非通用AI场景
- **轨迹质量筛选** (技术特性): VLAC独有的数据优化能力，通过VOC值筛选低质轨迹，提升模仿学习效率，属模型专属功能
- **人机任务联觉** (技术特性): 基于Ego4D数据构建人类任务与机器人动作的语义联觉，是模型理解具身任务的独特认知机制
- **VLAC-2B** (当前模型品牌名): 模型已发布具体版本VLAC-2B，是用户搜索时可能使用的精确版本标识，且非通用参数命名

### microsoft/xclip-base-patch32

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/xclip-base-patch32

**关键词列表**:

- **X-CLIP** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **零样本视频分类** (功能场景): 模型支持零样本方式进行视频分类的核心应用场景
- **视频-文本检索** (功能场景): 模型可用于检索文本与视频之间匹配程度的任务
- **32像素块分辨率** (技术特性): 模型采用的基础规模为 32 像素块的分辨率设置
- **Kinetics-400全监督训练** (训练数据): 模型基于 Kinetics-400 数据集进行全监督训练
- **8帧视频输入** (技术特性): 训练与推理时模型使用每段视频的 8 帧画面作为输入

### facebook/sam-vit-huge

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam-vit-huge

**关键词列表**:

- **SAM-ViT-Huge** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ViT图像编码器** (技术特性): 当前模型使用的图像编码器技术

### facebook/map-anything

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/map-anything

**关键词列表**:

- **MapAnything** (当前模型品牌名): 项目名称直接给出的品牌名，用户搜索时会用
- **单目度量深度估计** (功能场景): 模型支持的12+三维重建任务之一，用户常搜
- **多视图立体匹配** (功能场景): README明确列出的核心重建任务
- **端到端三维重建** (功能场景): 模型主打能力，用户搜索意图明确
- **相机位姿估计** (功能场景): 标签中的camera-pose对应功能，搜索高频
- **深度补全** (功能场景): README列出的重建任务之一，用户直接搜索

### Genius-Society/hoyoMusic

**URL**: https://ai.gitcode.com/hf_mirrors/Genius-Society/hoyoMusic

**关键词列表**:

- **hoyoMusic** (当前模型品牌名): 项目名称即为模型品牌名，用户搜索时会直接使用
- **Tunesformer** (技术特性): 模型基于 Tunesformer 架构，属于核心技术特征
- **二次创作音乐** (功能场景): 模型专注于米哈游社区的音乐二创，体现独特的创作场景
- **abc-乐谱切片** (技术特性): 模型训练使用的 abc 乐谱切片数据，是其独特的数据特征
- **米哈游音乐二创数据集** (数据集): 专属的米哈游音乐二创数据集是模型的核心训练资源
- **ModelScope-在线体验** (部署方式): 模型提供 ModelScope 在线推理页面，用户可直接在线体验
- **原神音乐生成** (应用场景): 模型从《原神》音乐二创中学习，适用于原神相关音乐创作

### Qwen/Qwen2.5-14B-Instruct-1M

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-14B-Instruct-1M

**关键词列表**:

- **Qwen2.5-14B-Instruct-1M** (当前模型品牌名): 项目名称直接对应当前模型完整名称，是用户搜索该特定长上下文模型时的精准关键词
- **长文本处理** (功能场景): 用户在寻找处理文档、论文、代码库等长内容的AI模型时，常用'长文本处理'作为搜索词，精准匹配模型设计目标
- **14.7B参数** (参数规格): 模型参数为14.7B，属于主流大模型规模，用户常搜索'14B参数'类关键词，且'14.7B'是该模型特有数值，区别于高频词'14B参数'
- **vLLM定制部署** (部署工具): 官方明确推荐使用定制版vLLM进行长上下文部署，该组合词具有唯一性，用户可能搜索'vLLM 长上下文部署'等变体
- **长度外推** (技术特性): 模型采用长度外推方法支持超长上下文，是实现1M tokens的关键技术术语，专业用户会以此作为筛选条件

### Qwen/Qwen2.5-VL-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-7B-Instruct

**关键词列表**:

- **Qwen2.5-VL-7B** (当前模型品牌名): 完整的模型名称，唯一标识当前模型
- **图像文本分析** (功能场景): 模型能够精准识别并解析图像中的文字内容
- **图表识别** (功能场景): 模型专门支持对图表、图标等结构化视觉信息的识别
- **70亿参数** (参数规格): 模型的参数规模约为70亿，用户常以此规格搜索模型

### google-bert/bert-base-chinese

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-base-chinese

**关键词列表**:

- **bert-base-chinese** (当前模型品牌名): 从项目名称提取的当前模型名称
- **中文预训练** (功能场景): 模型针对中文进行预训练，是其核心功能场景
- **填充掩码** (技术特性): 模型类型为填充掩码，是该模型独特的技术特性
- **Apache-2.0** (许可协议): 模型使用的许可协议，是模型的重要属性

### moonshotai/Kimi-VL-A3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Instruct

**关键词列表**:

- **Kimi-VL** (当前模型品牌名): 模型官方简称，是项目核心品牌标识，用户搜索时会直接使用该名称
- **MoonViT** (技术特性): 模型自研的原生分辨率视觉编码器，为Kimi-VL独有技术组件，具有区分度，用户可能搜索‘MoonViT模型’或‘高清视觉编码器’
- **Kimi-VL-Thinking** (当前模型品牌名): Kimi-VL的进阶变体，官方命名，具备长思维链（CoT）能力，是模型家族中独立且具辨识度的子版本
- **多图像理解** (功能场景): 模型明确支持多图像输入理解，是区别于普通VLM的特定应用场景，用户会搜索‘多图问答’‘多图推理’等类似关键词
- **ScreenSpot-Pro** (功能场景): 模型在ScreenSpot-Pro任务中取得34.5分，该任务为屏幕界面理解专用基准，属于高度垂直、非通用的场景词，具有独特性

### Genius-Society/piano_trans

**URL**: https://ai.gitcode.com/hf_mirrors/Genius-Society/piano_trans

**关键词列表**:

- **pianotrans** (当前模型品牌名): 项目仓库名称，用户直接搜索模型名
- **钢琴转录** (功能场景): 模型核心功能，用户搜索钢琴音频转谱需求
- **音符识别** (功能场景): 用户搜索AI自动识别钢琴音符关键词
- **音频转乐谱** (功能场景): 用户搜索将钢琴录音转为MIDI/乐谱的AI工具
- **高分辨率转录** (技术特性): README强调的高精度卖点，用户会搜
- **钢琴踏板检测** (功能场景): README提到的踏板回归技术，细分搜索词

### Qwen/Qwen-Image-Edit-2509

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen-Image-Edit-2509

**关键词列表**:

- **Qwen-Image-Edit** (当前模型品牌名): 项目名称中直接提取的模型品牌名称
- **多图编辑** (功能场景): 模型支持一次性对多张图片进行编辑，是核心使用场景
- **人像编辑一致性** (功能场景): 针对单图人像编辑提升了身份特征保持，属于模型的特色功能
- **ControlNet原生支持** (技术特性): 模型内置对 ControlNet（深度图、边缘图、关键点图等）的直接支持
- **深度图** (技术特性): 作为 ControlNet 支持的输入类型之一，提升编辑精度
- **图像拼接训练** (技术特性): 模型通过图像拼接方式进行多图编辑训练，属于独特的训练技术

### nineninesix/kani-tts-450m-0.1-pt

**URL**: https://ai.gitcode.com/hf_mirrors/nineninesix/kani-tts-450m-0.1-pt

**关键词列表**:

- **KaniTTS** (当前模型品牌名): 从项目名称 nineninesix/kani-tts-450m-0.1-pt 中提取的模型唯一品牌名，简洁且为用户搜索核心目标
- **22kHz高保真音频** (功能场景): 模型生成音频的核心质量指标，用户会搜索‘高保真TTS’或‘22kHz语音合成’等意图明确的词，且未被列入高频排除词
- **两阶段TTS** (技术特性): 模型独有的架构设计，区别于端到端TTS，是技术亮点，用户可能搜索‘两阶段文本转语音’等专业但非泛化词
- **NanoCodec** (技术特性): 模型专属的音频编解码器名称，为技术关键词，具有唯一性，非通用术语，未在高频排除列表中
- **450M参数** (参数规格): 模型参数规模为4.5亿，符合‘X亿参数’的主流搜索习惯（如7B→70亿），且450M是当前模型特有规格，非高频排除词（排除列表中无450M）
- **低延迟TTS** (功能场景): 模型设计目标明确强调‘极低延迟’，是用户在实时语音交互场景中搜索的关键意图词，非泛泛形容词
- **英语TTS** (功能场景): 模型主要针对英语训练，用户会搜索‘英语语音合成模型’，该词具有语言针对性，未被高频排除词覆盖（排除列表中无‘英语TTS’）

### LiquidAI/LFM2-1.2B-RAG

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-RAG

**关键词列表**:

- **LFM2-1.2B** (当前模型品牌名): 项目名称中直接出现的模型名称，符合简洁品牌名的提取规则
- **多轮交互微调** (技术特性): 在包含超过 100 万条多轮交互样本的语料上进行微调，提升模型在连续对话中的一致性和准确性
- **ChatML模板** (技术特性): 模型采用类 ChatML 的聊天模板，便于在多种对话平台上直接使用
- **上下文文档** (功能场景): 模型能够依据提供的上下文文档进行精准回答，是 RAG 系统的关键输入形式

### microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224

**关键词列表**:

- **BiomedCLIP** (当前模型品牌名): 从项目名称提取的当前模型名称
- **生物医学视觉语言模型** (功能场景): 当前模型的应用领域和功能描述
- **PubMedBERT编码器** (技术特性): 当前模型使用的文本编码器，具有领域特定性
- **Vision-Transformer编码器** (技术特性): 当前模型使用的图像编码器，是其核心技术特性之一

### Qwen/Qwen3-32B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-AWQ

**关键词列表**:

- **Qwen3-32B-AWQ** (当前模型品牌名): 项目名称直接对应当前模型全称，是用户搜索该特定量化模型的精准关键词
- **AWQ-4-bit** (部署工具): AWQ量化是当前模型的核心部署方式，用户会搜索'AWQ 4-bit模型'来寻找低显存部署方案，且未被高频词列表排除
- **32.8B参数** (参数规格): 模型参数量为32.8B，属于主流大模型规格，用户会搜索'32B参数模型'，且高频词列表仅禁止'32B参数'，此处为更精确的32.8B，具有区分度

### calcuis/hunyuanimage-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/calcuis/hunyuanimage-gguf

**关键词列表**:

- **图像精炼** (功能场景): README明确支持模糊/低质量图像的refiner精炼功能
- **轻量模型** (技术特性): lite版本速度提升2-3倍，节省60-70%加载时间，搜索量高
- **gguf节点** (部署工具): ComfyUI通过专属gguf节点加载，用户会搜具体节点名称

### distilbert/distilbert-base-uncased

**URL**: https://ai.gitcode.com/hf_mirrors/distilbert/distilbert-base-uncased

**关键词列表**:

- **蒸馏** (技术特性): 当前模型的核心技术特性，基于蒸馏过程实现模型压缩，用户搜索时可能用'蒸馏'描述轻量级NLP模型
- **自监督** (技术特性): 模型预训练方式的关键特征，用户搜索时可能用'自监督'作为技术关键词，避免与其他模型混淆
- **小模型** (功能场景): 模型比BERT更小、更快的显著特点，用户搜索时常用'小模型'描述轻量级NLP应用，符合实际搜索习惯
- **下游任务** (功能场景): 模型主要用途是针对下游任务进行微调，用户搜索时可能用'下游任务'作为NLP任务场景关键词
