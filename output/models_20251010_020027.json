[
  {
    "url": "https://gitcode.com/hf_mirrors/internlm/Intern-S1-FP8",
    "project_name": "internlm/Intern-S1-FP8",
    "readme": "\n\nIntern-S1\n\n\nÂ \nğŸ’»Github ä»“åº“ â€¢ ğŸ¤—æ¨¡å‹é›†åˆ â€¢ ğŸ“œæŠ€æœ¯æŠ¥å‘Šï¼ˆå³å°†å‘å¸ƒï¼‰ â€¢ ğŸ’¬åœ¨çº¿äº¤æµ\n\n\n    ğŸ‘‹ æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ Discord å’Œ å¾®ä¿¡ ç¤¾åŒº\n\n\n\nç®€ä»‹\næˆ‘ä»¬éš†é‡æ¨å‡º Intern-S1â€”â€”è¿„ä»Šä¸ºæ­¢æœ€å…ˆè¿›çš„å¼€æºå¤šæ¨¡æ€æ¨ç†æ¨¡å‹ã€‚Intern-S1 å…¼å…·å¼ºå¤§çš„é€šç”¨ä»»åŠ¡èƒ½åŠ›ä¸é¡¶å°–çš„ç§‘å­¦ä»»åŠ¡æ€§èƒ½ï¼Œè¶³ä»¥åª²ç¾é¢†å…ˆçš„é—­æºå•†ä¸šæ¨¡å‹ã€‚\nåŸºäº 235B MoE è¯­è¨€æ¨¡å‹ï¼ˆQwen3ï¼‰å’Œ 6B è§†è§‰ç¼–ç å™¨ï¼ˆInternViTï¼‰æ„å»ºï¼ŒIntern-S1 ç»è¿‡5ä¸‡äº¿ token çš„å¤šæ¨¡æ€æ•°æ®ç»§ç»­é¢„è®­ç»ƒï¼Œå…¶ä¸­åŒ…å«è¶…è¿‡2.5ä¸‡äº¿ç§‘å­¦é¢†åŸŸ tokenã€‚è¿™ä½¿å¾—æ¨¡å‹åœ¨ä¿æŒå¼ºå¤§é€šç”¨èƒ½åŠ›çš„åŒæ—¶ï¼Œåœ¨åŒ–å­¦ç»“æ„è§£æã€è›‹ç™½è´¨åºåˆ—ç†è§£ã€åŒ–åˆç‰©åˆæˆè·¯çº¿è§„åˆ’ç­‰ä¸“ä¸šç§‘å­¦é¢†åŸŸè¡¨ç°å“è¶Šï¼Œæˆä¸ºç°å®ç§‘ç ”åº”ç”¨ä¸­å¾—åŠ›çš„ç ”ç©¶åŠ©æ‰‹ã€‚\n\n\nç‰¹æ€§\n\nåœ¨è¯­è¨€ä¸è§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å¼ºåŠ²ï¼Œå°¤å…¶åœ¨ç§‘å­¦ä»»åŠ¡ä¸Šä¼˜åŠ¿æ˜¾è‘—\nåŸºäº 5T token å¤§è§„æ¨¡æ•°æ®é›†æŒç»­é¢„è®­ç»ƒï¼Œå…¶ä¸­è¶… 50% ä¸ºä¸“ä¸šç§‘å­¦æ•°æ®ï¼Œæ·±åº¦èåˆé¢†åŸŸçŸ¥è¯†\nåŠ¨æ€åˆ†è¯å™¨åŸç”Ÿæ”¯æŒåˆ†å­å¼ã€è›‹ç™½è´¨åºåˆ—å’Œåœ°éœ‡ä¿¡å·çš„ç†è§£\n\n\n\næ€§èƒ½è¡¨ç°\næˆ‘ä»¬åœ¨é€šç”¨æ•°æ®é›†å’Œç§‘å­¦æ•°æ®é›†ä¸Šå¯¹ Intern-S1 è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚ä»¥ä¸‹ä¸ºä¸è¿‘æœŸä¸»æµè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åŠå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½å¯¹æ¯”ï¼š\n\n\n\nåŸºå‡†æµ‹è¯•\nIntern-S1\nInternVL3-78B\nQwen2.5-VL-72B\nDS-R1-0528\nQwen3-235B-A22B\nKimi-K2-Instruct\nGemini-2.5 Pro\no3\nGrok-4\n\n\n\nMMLU-Pro83.5 âœ…73.072.183.482.282.786.085.085.9\nMMMU77.7 âœ…72.270.2---81.980.877.9\nGPQA77.349.949.080.671.177.883.883.387.5\nMMStar74.9 âœ…72.570.8---79.375.169.6\nMathVista81.5 ğŸ‘‘79.074.8---80.377.572.5\nAIME202586.010.710.987.581.551.483.088.991.7\nMathVision62.5 âœ…43.138.1---73.067.767.3\nIFEval86.775.683.979.785.090.291.592.292.8\nSFE44.3 ğŸ‘‘36.230.5---43.037.731.2\nPhysics44.0 âœ…23.115.7---40.047.942.8\nSmolInstruct51.0 ğŸ‘‘19.421.030.728.748.140.443.947.3\nChemBench83.4 ğŸ‘‘61.361.675.675.875.382.881.683.3\nMatBench75.0 ğŸ‘‘49.351.557.752.161.761.761.667.9\nMicroVQA63.9 ğŸ‘‘59.153.0---63.158.359.5\nProteinLMBench63.161.661.061.459.866.762.967.766.2\nMSEarthMCQ65.7 ğŸ‘‘57.237.6---59.961.058.0\nXLRS-Bench55.0 ğŸ‘‘49.350.9---45.243.645.4\n\n\n\nè¯´æ˜ï¼šâœ… ä»£è¡¨å¼€æºæ¨¡å‹ä¸­çš„æœ€ä½³æ€§èƒ½ï¼ŒğŸ‘‘ ä»£è¡¨æ‰€æœ‰æ¨¡å‹ä¸­çš„æœ€ä½³æ€§èƒ½\n\næˆ‘ä»¬ä½¿ç”¨ OpenCompass å’Œ VLMEvalkit å¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚\n\n\nå¿«é€Ÿå¼€å§‹\n\n\né‡‡æ ·å‚æ•°\næˆ‘ä»¬æ¨èä½¿ç”¨ä»¥ä¸‹è¶…å‚æ•°ä»¥ç¡®ä¿è·å¾—æ›´ä½³ç»“æœ\ntop_p = 1.0\ntop_k = 50\nmin_p = 0.0\ntemperature = 0.7\n\n\n\nTransformers\nä»¥ä¸‹æä¾›ç¤ºä¾‹ä»£ç ï¼Œå±•ç¤ºå¦‚ä½•åŸºäºæ–‡æœ¬å’Œå¤šæ¨¡æ€è¾“å…¥è¿›è¡Œç”Ÿæˆã€‚\n\nè¯·ä½¿ç”¨ transformers>=4.53.0 ç‰ˆæœ¬ä»¥ç¡®ä¿æ¨¡å‹æ­£å¸¸è¿è¡Œã€‚\n\n\n\næ–‡æœ¬è¾“å…¥\nfrom transformers import AutoProcessor, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"internlm/Intern-S1\"\nprocessor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"text\", \"text\": \"tell me about an interesting physical phenomenon.\"},\n        ],\n    }\n]\n\ninputs = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\").to(model.device, dtype=torch.bfloat16)\n\ngenerate_ids = model.generate(**inputs, max_new_tokens=32768)\ndecoded_output = processor.decode(generate_ids[0, inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True)\nprint(decoded_output)\n\n\n\nå›¾åƒè¾“å…¥\nfrom transformers import AutoProcessor, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"internlm/Intern-S1\"\nprocessor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"url\": \"http://images.cocodataset.org/val2017/000000039769.jpg\"},\n            {\"type\": \"text\", \"text\": \"Please describe the image explicitly.\"},\n        ],\n    }\n]\n\ninputs = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\").to(model.device, dtype=torch.bfloat16)\n\ngenerate_ids = model.generate(**inputs, max_new_tokens=32768)\ndecoded_output = processor.decode(generate_ids[0, inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True)\nprint(decoded_output)\n\n\n\nè§†é¢‘è¾“å…¥\nè¯·ç¡®ä¿å·²é€šè¿‡ pip install decord å®‰è£… decord è§†é¢‘è§£ç åº“ã€‚\nfrom transformers import AutoProcessor, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"internlm/Intern-S1\"\nprocessor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)\n\nmessages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"video\",\n                    \"url\": \"https://huggingface.co/datasets/hf-internal-testing/fixtures_videos/resolve/main/tennis.mp4\",\n                },\n                {\"type\": \"text\", \"text\": \"What type of shot is the man performing?\"},\n            ],\n        }\n    ]\n\ninputs = processor.apply_chat_template(\n        messages,\n        return_tensors=\"pt\",\n        add_generation_prompt=True,\n        video_load_backend=\"decord\",\n        tokenize=True,\n        return_dict=True,\n    ).to(model.device, dtype=torch.float16)\n\ngenerate_ids = model.generate(**inputs, max_new_tokens=32768)\ndecoded_output = processor.decode(generate_ids[0, inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True)\nprint(decoded_output)\n\n\n\néƒ¨ç½²æœåŠ¡\néƒ¨ç½² Intern-S1 ç³»åˆ—æ¨¡å‹çš„æœ€ä½ç¡¬ä»¶è¦æ±‚å¦‚ä¸‹ï¼š\n\n\n\næ¨¡å‹\nA100(GPUs)\nH800(GPUs)\nH100(GPUs)\nH200(GPUs)\n\n\n\n\ninternlm/Intern-S1\n8\n8\n8\n4\n\n\ninternlm/Intern-S1-FP8\n-\n4\n4\n2\n\n\n\næ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»»æ„ä¸€ä¸ª LLM æ¨ç†æ¡†æ¶æ¥åˆ›å»ºå…¼å®¹ OpenAI çš„æœåŠ¡å™¨ï¼š\n\n\nlmdeploy(>=0.9.2)\nlmdeploy serve api_server internlm/Intern-S1-FP8 --reasoning-parser intern-s1 --tool-call-parser intern-s1 --tp 4\n\n\n\nvllm\nvllm serve internlm/Intern-S1-FP8 --tensor-parallel-size 4 --trust-remote-code\n\n\n\nsglang\nå¯¹ Intern-S1 çš„ SGLang æ”¯æŒä»åœ¨å¼€å‘ä¸­ã€‚è¯·å‚è€ƒæ­¤ PRã€‚\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\n    python3 -m sglang.launch_server \\\n    --model-path internlm/Intern-S1-FP8 \\\n    --trust-remote-code \\\n    --tp 4 \\\n    --port 8001 \\\n    --mem-fraction-static 0.85 \\\n    --enable-multimodal \\\n    --grammar-backend none\n\n\n\né«˜çº§ç”¨æ³•\n\n\nå·¥å…·è°ƒç”¨\nå½“å‰è®¸å¤šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éƒ½å…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œè¿™é¡¹å¼ºå¤§åŠŸèƒ½ä½¿æ¨¡å‹èƒ½å¤Ÿé€šè¿‡ä¸å¤–éƒ¨å·¥å…·åŠAPIäº¤äº’æ¥æ‰©å±•å…¶åŠŸèƒ½ã€‚å€ŸåŠ©è¯¥èƒ½åŠ›ï¼Œæ¨¡å‹å¯æ‰§è¡Œè¯¸å¦‚è·å–å®æ—¶ä¿¡æ¯ã€è¿è¡Œä»£ç æˆ–è°ƒç”¨å…¶ä»–åº”ç”¨ç¨‹åºä¸­çš„å‡½æ•°ç­‰ä»»åŠ¡ã€‚\nå¯¹å¼€å‘è€…è€Œè¨€ï¼Œä¸€ä¸ªå…³é”®ä¼˜åŠ¿åœ¨äºè¶Šæ¥è¶Šå¤šçš„å¼€æºLLMsè¢«è®¾è®¡ä¸ºä¸OpenAI APIå…¼å®¹ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥ä½¿ç”¨OpenAIåº“ä¸­ç†Ÿæ‚‰çš„è¯­æ³•å’Œç»“æ„ï¼Œåœ¨è¿™äº›å¼€æºæ¨¡å‹ä¸Šå®ç°å·¥å…·è°ƒç”¨åŠŸèƒ½ã€‚å› æ­¤ï¼Œæœ¬æ•™ç¨‹æ¼”ç¤ºçš„ä»£ç å…·æœ‰é€šç”¨æ€§â€”â€”å®ƒä¸ä»…é€‚ç”¨äºOpenAIæ¨¡å‹ï¼Œä¹Ÿå…¼å®¹éµå¾ªç›¸åŒæ¥å£æ ‡å‡†çš„ä»»ä½•æ¨¡å‹ã€‚\nä¸ºå…·ä½“è¯´æ˜å…¶å®ç°æ–¹å¼ï¼Œè®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå®é™…ä»£ç ç¤ºä¾‹æ¥æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å·¥å…·è°ƒç”¨è·å–æœ€æ–°å¤©æ°”é¢„æŠ¥ï¼ˆåŸºäºlmdeploy api serverï¼‰ã€‚\n      \nfrom openai import OpenAI\nimport json\n\n\ndef get_current_temperature(location: str, unit: str = \"celsius\"):\n    \"\"\"Get current temperature at a location.\n\n    Args:\n        location: The location to get the temperature for, in the format \"City, State, Country\".\n        unit: The unit to return the temperature in. Defaults to \"celsius\". (choices: [\"celsius\", \"fahrenheit\"])\n\n    Returns:\n        the temperature, the location, and the unit in a dict\n    \"\"\"\n    return {\n        \"temperature\": 26.1,\n        \"location\": location,\n        \"unit\": unit,\n    }\n\n\ndef get_temperature_date(location: str, date: str, unit: str = \"celsius\"):\n    \"\"\"Get temperature at a location and date.\n\n    Args:\n        location: The location to get the temperature for, in the format \"City, State, Country\".\n        date: The date to get the temperature for, in the format \"Year-Month-Day\".\n        unit: The unit to return the temperature in. Defaults to \"celsius\". (choices: [\"celsius\", \"fahrenheit\"])\n\n    Returns:\n        the temperature, the location, the date and the unit in a dict\n    \"\"\"\n    return {\n        \"temperature\": 25.9,\n        \"location\": location,\n        \"date\": date,\n        \"unit\": unit,\n    }\n\ndef get_function_by_name(name):\n    if name == \"get_current_temperature\":\n        return get_current_temperature\n    if name == \"get_temperature_date\":\n        return get_temperature_date\n\ntools = [{\n    'type': 'function',\n    'function': {\n        'name': 'get_current_temperature',\n        'description': 'Get current temperature at a location.',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'location': {\n                    'type': 'string',\n                    'description': 'The location to get the temperature for, in the format \\'City, State, Country\\'.'\n                },\n                'unit': {\n                    'type': 'string',\n                    'enum': [\n                        'celsius',\n                        'fahrenheit'\n                    ],\n                    'description': 'The unit to return the temperature in. Defaults to \\'celsius\\'.'\n                }\n            },\n            'required': [\n                'location'\n            ]\n        }\n    }\n}, {\n    'type': 'function',\n    'function': {\n        'name': 'get_temperature_date',\n        'description': 'Get temperature at a location and date.',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'location': {\n                    'type': 'string',\n                    'description': 'The location to get the temperature for, in the format \\'City, State, Country\\'.'\n                },\n                'date': {\n                    'type': 'string',\n                    'description': 'The date to get the temperature for, in the format \\'Year-Month-Day\\'.'\n                },\n                'unit': {\n                    'type': 'string',\n                    'enum': [\n                        'celsius',\n                        'fahrenheit'\n                    ],\n                    'description': 'The unit to return the temperature in. Defaults to \\'celsius\\'.'\n                }\n            },\n            'required': [\n                'location',\n                'date'\n            ]\n        }\n    }\n}]\n\n\n\nmessages = [\n    {'role': 'user', 'content': 'Today is 2024-11-14, What\\'s the temperature in San Francisco now? How about tomorrow?'}\n]\n\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://0.0.0.0:23333/v1\"\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\nmodel_name = client.models.list().data[0].id\nresponse = client.chat.completions.create(\n    model=model_name,\n    messages=messages,\n    max_tokens=32768,\n    temperature=0.8,\n    top_p=0.8,\n    stream=False,\n    extra_body=dict(spaces_between_special_tokens=False, enable_thinking=False),\n    tools=tools)\nprint(response.choices[0].message)\nmessages.append(response.choices[0].message)\n\nfor tool_call in response.choices[0].message.tool_calls:\n    tool_call_args = json.loads(tool_call.function.arguments)\n    tool_call_result = get_function_by_name(tool_call.function.name)(**tool_call_args)\n    tool_call_result = json.dumps(tool_call_result, ensure_ascii=False)\n    messages.append({\n        'role': 'tool',\n        'name': tool_call.function.name,\n        'content': tool_call_result,\n        'tool_call_id': tool_call.id\n    })\n\nresponse = client.chat.completions.create(\n    model=model_name,\n    messages=messages,\n    temperature=0.8,\n    top_p=0.8,\n    stream=False,\n    extra_body=dict(spaces_between_special_tokens=False, enable_thinking=False),\n    tools=tools)\nprint(response.choices[0].message.content)\n\n\n\næ€è€ƒæ¨¡å¼ä¸éæ€è€ƒæ¨¡å¼åˆ‡æ¢\nIntern-S1 é»˜è®¤å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œé€šè¿‡å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›å¤ã€‚å¦‚éœ€ç¦ç”¨æ­¤åŠŸèƒ½ï¼Œå¯åœ¨ tokenizer.apply_chat_template ä¸­è®¾ç½® enable_thinking=Falseã€‚\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # think mode indicator\n)\n\nä½¿ç”¨LMDeployæœåŠ¡Intern-S1æ¨¡å‹æ—¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨è¯·æ±‚ä¸­è°ƒæ•´enable_thinkingå‚æ•°æ¥åŠ¨æ€æ§åˆ¶æ€è€ƒæ¨¡å¼ã€‚\nfrom openai import OpenAI\nimport json\n\nmessages = [\n{\n    'role': 'user',\n    'content': 'who are you'\n}, {\n    'role': 'assistant',\n    'content': 'I am an AI'\n}, {\n    'role': 'user',\n    'content': 'AGI is?'\n}]\n\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://0.0.0.0:23333/v1\"\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\nmodel_name = client.models.list().data[0].id\n\nresponse = client.chat.completions.create(\n    model=model_name,\n    messages=messages,\n    temperature=0.7,\n    top_p=0.8,\n    max_tokens=2048,\n    extra_body={\n        \"enable_thinking\": False,\n    }\n)\nprint(json.dumps(response.model_dump(), indent=2, ensure_ascii=False))\n\nå¯¹äº vllm å’Œ sglang ç”¨æˆ·ï¼Œå¯é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›è¡Œé…ç½®ï¼š\nextra_body={\n    \"chat_template_kwargs\": {\"enable_thinking\": False}\n}\n\n",
    "tags": [
      "Image-Text-to-Text",
      "Transformers",
      "Safetensors",
      "Apache License 2.0",
      "arxiv:2508.1576"
    ]
  },
  {
    "url": "https://gitcode.com/hf_mirrors/nunchaku-tech/nunchaku-flux.1-krea-dev",
    "project_name": "nunchaku-tech/nunchaku-flux.1-krea-dev",
    "readme": "\n\n\n\n\nnunchaku-flux.1-krea-dev æ¨¡å‹å¡ç‰‡\n\næœ¬ä»“åº“åŒ…å« FLUX.1-Krea-dev çš„ Nunchaku é‡åŒ–ç‰ˆæœ¬ï¼Œæ—¨åœ¨é€šè¿‡æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚è¯¥æ¨¡å‹ç»è¿‡ä¼˜åŒ–ï¼Œå¯å®ç°é«˜æ•ˆæ¨ç†ï¼ŒåŒæ—¶å°†æ€§èƒ½æŸå¤±é™è‡³æœ€ä½ã€‚\n\n\næ¨¡å‹è¯¦æƒ…\n\n\næ¨¡å‹æè¿°\n\nå¼€å‘è€…ï¼š Nunchaku å›¢é˜Ÿ\næ¨¡å‹ç±»å‹ï¼š æ–‡æœ¬åˆ°å›¾åƒ\nè®¸å¯è¯ï¼š flux-1-krea-dev-non-commercial-license\né‡åŒ–æºæ¨¡å‹ï¼š FLUX.1-Krea-dev\n\n\n\næ¨¡å‹æ–‡ä»¶\n\nsvdq-int4_r32-flux.1-krea-dev.safetensorsï¼šSVDQuant é‡åŒ–çš„ INT4 FLUX.1-Krea-dev æ¨¡å‹ã€‚é€‚ç”¨äºé Blackwell GPUï¼ˆ50 ç³»åˆ—ä¹‹å‰ï¼‰ç”¨æˆ·ã€‚\nsvdq-fp4_r32-flux.1-krea-dev.safetensorsï¼šSVDQuant é‡åŒ–çš„ NVFP4 FLUX.1-Krea-dev æ¨¡å‹ã€‚é€‚ç”¨äº Blackwell GPUï¼ˆ50 ç³»åˆ—ï¼‰ç”¨æˆ·ã€‚\n\n\n\næ¨¡å‹æ¥æº\n\næ¨ç†å¼•æ“ï¼š nunchaku\né‡åŒ–åº“ï¼š deepcompressor\nè®ºæ–‡ï¼š SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models\næ¼”ç¤ºï¼š svdquant.mit.edu\n\n\n\nä½¿ç”¨æ–¹æ³•\n\nDiffusers ä½¿ç”¨ï¼šå‚è§ flux.1-krea-dev.pyã€‚åªéœ€å°† safetensors æ–‡ä»¶æ›¿æ¢ä¸ºæœ¬ä»“åº“ä¸­çš„æ–‡ä»¶å³å¯ã€‚æœ‰å…³æ›´é«˜çº§çš„ç”¨æ³•ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„ æ•™ç¨‹ã€‚\nComfyUI ä½¿ç”¨ï¼šå‚è§ nunchaku-flux.1-dev.jsonã€‚åªéœ€å°† safetensors æ–‡ä»¶æ›¿æ¢ä¸ºæœ¬ä»“åº“ä¸­çš„æ–‡ä»¶å³å¯ã€‚\n\n\n\næ€§èƒ½\n\n\n\nå¼•ç”¨\n@inproceedings{\n  li2024svdquant,\n  title={SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models},\n  author={Li*, Muyang and Lin*, Yujun and Zhang*, Zhekai and Cai, Tianle and Li, Xiuyu and Guo, Junxian and Xie, Enze and Meng, Chenlin and Zhu, Jun-Yan and Han, Song},\n  booktitle={The Thirteenth International Conference on Learning Representations},\n  year={2025}\n}\n\n\n\nå½’å±å£°æ˜\nFLUX.1 [dev] æ¨¡å‹ç”± Black Forest Labs Inc. æ ¹æ® FLUX.1 [dev] éå•†ä¸šè®¸å¯åè®®æˆæƒã€‚ç‰ˆæƒæ‰€æœ‰ Black Forest Labs Inc.ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œå¯¹äºå› ä½¿ç”¨æœ¬æ¨¡å‹è€Œå¼•èµ·çš„ã€ä¸ä¹‹ç›¸å…³çš„æˆ–ç”±æ­¤äº§ç”Ÿçš„ä»»ä½•ç´¢èµ”ã€æŸå®³æˆ–å…¶ä»–è´£ä»»ï¼Œæ— è®ºæ˜¯åŸºäºåˆåŒã€ä¾µæƒè¡Œä¸ºè¿˜æ˜¯å…¶ä»–åŸå› ï¼ŒBlack Forest Labs Inc. å‡ä¸æ‰¿æ‹…è´£ä»»ã€‚\n",
    "tags": [
      "Text-to-Image",
      "Diffusers",
      "Safetensors",
      "English",
      "Other",
      "mit-han-lab/svdquant-datasets",
      "Quantization",
      "FLUX.1",
      "Diffusion",
      "SVDQuant",
      "FLUX.1-Krea-dev",
      "ICLR2025",
      "arxiv:2411.05007",
      "arxiv:2411.0500"
    ]
  }
]