[
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/Janus-Pro-1B",
    "keywords": [
      {
        "keyword": "Janus-Pro",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称，符合用户搜索AI模型时的惯用品牌词"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型核心定位是统一多模态理解和生成，是用户搜索相关模型时的关键技术标签"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "README明确说明是自回归框架，属于用户搜索模型架构时的高频技术词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持图像生成，且用户常搜索'文生图'作为AI生成图像的意图关键词"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "基于DeepSeek-LLM构建，具备语言理解与生成能力，符合AI写作类应用场景"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型基于DeepSeek-LLM-7b-base构建，7B是主流参数规模，用户常按此搜索模型"
      },
      {
        "keyword": "统一模型",
        "dimension": "技术特性",
        "reason": "README强调'统一多模态理解和生成'，'统一模型'是用户区分专用模型与通用模型的搜索关键词"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型开源且为轻量级（1B级别），用户有强烈本地部署需求，符合常见搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V1",
    "keywords": [
      {
        "keyword": "DeepSeek-Prover",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称，符合品牌名简化规则（去版本号）"
      },
      {
        "keyword": "定理证明",
        "dimension": "功能场景",
        "reason": "模型核心用途是自动形式化定理证明，用户会搜索该功能关键词"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型基于7B参数的DeepSeekMath微调，属于主流参数规模，用户常搜"
      },
      {
        "keyword": "合成数据",
        "dimension": "技术特性",
        "reason": "模型核心创新点是使用大规模合成数据训练，是区别于其他模型的关键技术"
      },
      {
        "keyword": "Lean-4",
        "dimension": "技术特性",
        "reason": "模型专为Lean 4证明助手设计，是其形式化证明的专属技术生态，用户搜索定理证明时会关联该工具"
      },
      {
        "keyword": "AI数学助手",
        "dimension": "功能场景",
        "reason": "模型用于解决数学竞赛题与形式化证明，可归纳为AI数学助手这一用户易搜场景"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型在GitCode公开发布，用户预期可下载本地运行，符合部署类搜索意图"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "作为LLM基础架构，Transformer是用户搜索AI模型时高频技术关键词，且模型基于此架构"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2.5",
    "keywords": [
      {
        "keyword": "DeepSeek-V2.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型的官方品牌名"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "README 中提到模型在写作方面进行了优化，适用于 AI 写作场景"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型融合了 DeepSeek‑Coder‑V2‑Instruct 的编码能力，可用作编程助手"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "模型在指令遵循（instruction following）上进行了提升，适合需要精准指令执行的场景"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "标签中包含 Text Generation，说明模型擅长通用文本生成任务"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于 Transformer 架构，是用户搜索技术特性时常用的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/QuantStack/Wan2.2-T2V-A14B-GGUF",
    "keywords": [
      {
        "keyword": "Wan2.2-T2V-A14B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 QuantStack/Wan2.2-T2V-A14B-GGUF 中提取的当前模型核心名称，符合简化规则（保留品牌+核心标识，去后缀-GGUF）"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型标签为 Text-to-Video，对应中文用户高频搜索词'文生视频'，明确表达模型用途"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "README明确指出模型需配合 ComfyUI-GGUF 节点使用，是用户部署时的关键搜索词"
      },
      {
        "keyword": "量化模型",
        "dimension": "技术特性",
        "reason": "README明确说明'这是一个量化模型'，符合用户搜索'量化模型'以寻找轻量部署方案的意图"
      },
      {
        "keyword": "GGUF",
        "dimension": "技术特性",
        "reason": "GGUF是模型文件格式，用户在搜索本地部署AI模型时高频使用该关键词，属于技术术语但非过度专业"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "技术特性",
        "reason": "开源协议是用户筛选模型的重要依据，'Apache License 2.0'是用户在开源社区搜索可商用模型时的常用关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/JanusFlow-1.3B",
    "keywords": [
      {
        "keyword": "JanusFlow",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "当前模型支持多模态理解和生成"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "当前模型引入了自回归语言模型"
      },
      {
        "keyword": "修正流",
        "dimension": "技术特性",
        "reason": "当前模型结合了修正流这一生成模型中的前沿方法"
      },
      {
        "keyword": "图像生成",
        "dimension": "功能场景",
        "reason": "当前模型支持图像生成功能"
      },
      {
        "keyword": "图像理解",
        "dimension": "功能场景",
        "reason": "当前模型支持图像理解功能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/deberta-v3-large",
    "keywords": [
      {
        "keyword": "DeBERTa-v3-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，用户搜索AI模型时会精确使用该名称"
      },
      {
        "keyword": "DeBERTa",
        "dimension": "当前模型品牌名",
        "reason": "模型系列通用简称，用户常搜索'DeBERTa'而非完整版本，属于高流量关键词"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，是NLP领域用户搜索模型时的核心技术关键词"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "README明确提及使用HF transformers + PyTorch微调，用户会搜索该框架部署该模型"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管于HuggingFace生态，用户常通过'HuggingFace + 模型名'搜索部署方式"
      },
      {
        "keyword": "文本分类",
        "dimension": "功能场景",
        "reason": "模型在MNLI等文本分类任务上表现优异，是用户搜索NLU模型时的典型应用场景"
      },
      {
        "keyword": "问答系统",
        "dimension": "功能场景",
        "reason": "模型在SQuAD 2.0问答数据集上取得SOTA，用户搜索'问答系统模型'时会匹配该模型"
      },
      {
        "keyword": "掩码语言模型",
        "dimension": "技术特性",
        "reason": "模型基于掩码语言建模（MLM）预训练，是NLP用户搜索模型时的关键技术标签"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/pegasus-xsum",
    "keywords": [
      {
        "keyword": "Pegasus",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称google/pegasus-xsum提取的核心品牌名"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "Pegasus专注文本摘要，属于AI写作场景"
      },
      {
        "keyword": "文本摘要",
        "dimension": "功能场景",
        "reason": "README明确标注任务为summarization"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "Pegasus基于Transformer架构"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "标签中列出PyTorch，用户会搜PyTorch版"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "标签中列出Transformers，用户常用HuggingFace调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/whisper-tiny.en",
    "keywords": [
      {
        "keyword": "Whisper-tiny.en",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索轻量级语音识别模型时会使用此精确名称"
      },
      {
        "keyword": "英语语音识别",
        "dimension": "功能场景",
        "reason": "模型明确标注为仅英文语音识别，是用户搜索英文ASR任务时的核心意图词"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型架构明确说明为Transformer编码器-解码器结构，是AI语音领域高频搜索技术词"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "README明确列出PyTorch为支持框架，用户常搜索‘PyTorch 语音识别模型’进行部署"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管于Hugging Face Hub，用户常搜索‘HuggingFace 语音模型’来查找和加载模型"
      },
      {
        "keyword": "39M参数",
        "dimension": "参数规格",
        "reason": "模型参数量为39M，属于轻量级主流规格，用户会搜索‘39M语音模型’寻找低资源部署方案"
      },
      {
        "keyword": "自动语音识别",
        "dimension": "功能场景",
        "reason": "README首句即定义模型用途为‘自动语音识别（ASR）’，是中文用户最直接的搜索关键词"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "标签中明确包含Safetensors，是当前模型安全加载的格式，开发者常搜索此关键词优化部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.2-TI2V-5B",
    "keywords": [
      {
        "keyword": "Wan2.2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型支持文字生成视频的核心应用场景"
      },
      {
        "keyword": "图生视频",
        "dimension": "功能场景",
        "reason": "模型支持图片生成视频的核心应用场景"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "首次在视频扩散模型中引入的混合专家（Mixture‑of‑Experts）架构"
      },
      {
        "keyword": "5B参数",
        "dimension": "参数规格",
        "reason": "模型规模为5B参数，用户常以参数量搜索模型"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型同时处理文本、图像和视频，实现多模态生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/gilf/french-camembert-postag-model",
    "keywords": [
      {
        "keyword": "french-camembert-postag-model",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索法语词性标注模型时最可能使用的精准关键词"
      },
      {
        "keyword": "法语词性标注",
        "dimension": "功能场景",
        "reason": "模型的核心用途，用户在CSDN等平台搜索法语NLP任务时会直接使用该中文术语"
      },
      {
        "keyword": "CamemBERT",
        "dimension": "技术特性",
        "reason": "模型基于CamemBERT架构，是法语NLP领域公认的基础模型名称，用户会搜索该技术术语"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，是AI领域通用高搜索量技术关键词，符合用户搜索习惯"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "README明确提及PyTorch，是用户部署该模型时最可能使用的框架关键词"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管于HuggingFace，用户搜索法语NLP模型时会直接关联HuggingFace平台"
      },
      {
        "keyword": "词性标注",
        "dimension": "功能场景",
        "reason": "中文用户搜索NLP任务时常用'词性标注'这一通用术语，比英文'POS tagging'更符合中文搜索习惯"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "README明确列出Safetensors格式，是当前AI社区广泛搜索的安全模型加载格式关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwaipilot/KwaiCoder-AutoThink-preview",
    "keywords": [
      {
        "keyword": "KwaiCoder-AutoThink-preview",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "AutoThink",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，自动思考能力"
      },
      {
        "keyword": "StepSRPO",
        "dimension": "技术特性",
        "reason": "当前模型使用的分步序列强化学习技术"
      },
      {
        "keyword": "Agentic-Data",
        "dimension": "技术特性",
        "reason": "当前模型采用的智能体数据生成技术"
      },
      {
        "keyword": "KD-MTP",
        "dimension": "技术特性",
        "reason": "当前模型使用的知识蒸馏和多token预测技术"
      },
      {
        "keyword": "动态调整推理深度",
        "dimension": "功能场景",
        "reason": "当前模型根据输入难度动态调整推理深度的功能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/autogluon/tabpfn-mix-1.0-regressor",
    "keywords": [
      {
        "keyword": "TabPFNMix",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'autogluon/tabpfn-mix-1.0-regressor' 中提取的核心模型品牌名，去掉版本号后为用户搜索的简洁标识"
      },
      {
        "keyword": "Tabular-Regression",
        "dimension": "功能场景",
        "reason": "README明确标注的标签，直接描述模型的核心应用场景，用户会搜索‘表格回归’相关AI模型"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于12层编码器-解码器Transformer架构，是核心底层技术，用户常搜索‘Transformer表格模型’"
      },
      {
        "keyword": "上下文学习",
        "dimension": "技术特性",
        "reason": "README明确提到采用‘融合上下文学习的预训练策略’，是模型的关键能力，非通用术语，具指向性"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "标签中明确列出，代表模型权重的安全加载格式，是用户部署时搜索的关键词，尤其关注模型安全加载"
      },
      {
        "keyword": "AutoGluon",
        "dimension": "部署工具",
        "reason": "模型通过AutoGluon库调用，是用户使用该模型的唯一官方入口，搜索‘AutoGluon 回归’是典型用户意图"
      },
      {
        "keyword": "合成数据预训练",
        "dimension": "技术特性",
        "reason": "模型通过‘从随机回归器混合生成的纯合成数据集进行预训练’，是其区别于其他模型的独特训练方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/dandelin/vilt-b32-finetuned-vqa",
    "keywords": [
      {
        "keyword": "ViLT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确出现的模型简称，用户会直接搜索"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "README核心用途“视觉问答”是用户高频搜索词"
      },
      {
        "keyword": "VQA模型",
        "dimension": "功能场景",
        "reason": "视觉问答领域通用缩写，用户常用VQA模型作为关键词"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "ViLT同时处理图像+文本，多模态是核心卖点"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型架构关键词，用户搜索视觉Transformer时会用到"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管在HuggingFace，用户搜HuggingFace找现成模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/keras-io/TF_Decision_Trees",
    "keywords": [
      {
        "keyword": "TF-Decision-Trees",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 keras-io/TF_Decision_Trees 提取的当前模型名称"
      },
      {
        "keyword": "梯度提升树",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心算法"
      },
      {
        "keyword": "结构化数据分类",
        "dimension": "功能场景",
        "reason": "模型专为结构化数据的二分类任务设计"
      },
      {
        "keyword": "Keras预处理层",
        "dimension": "技术特性",
        "reason": "实现自定义Binary Target编码器作为Keras预处理层"
      },
      {
        "keyword": "决策森林模型",
        "dimension": "技术特性",
        "reason": "通过指定输入特征构建的决策森林模型"
      },
      {
        "keyword": "US-Census-Income-Dataset",
        "dimension": "功能场景",
        "reason": "模型训练使用的经典结构化数据集，用户会搜此数据集+模型组合"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Falconsai/text_summarization",
    "keywords": [
      {
        "keyword": "Falconsai",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Fal​consai/text_summarization 中提取的模型品牌名称"
      },
      {
        "keyword": "文本摘要",
        "dimension": "功能场景",
        "reason": "模型专注于为长文档、新闻等生成简洁连贯的摘要"
      },
      {
        "keyword": "摘要生成",
        "dimension": "功能场景",
        "reason": "模型的核心任务是将输入文本压缩为有意义的摘要"
      },
      {
        "keyword": "微调模型",
        "dimension": "技术特性",
        "reason": "模型在 T5‑Small 基础上经过微调，提升了摘要任务的表现"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于 Transformer 架构（T5）实现文本理解与生成"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署方式",
        "reason": "模型体积小（T5‑Small），适合在本地机器或私有服务器上部署使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/TIGER-Lab/VideoScore-v1.1",
    "keywords": [
      {
        "keyword": "VideoScore-v1.1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型正式名称，用户搜索AI视频评估模型时会使用此完整品牌名"
      },
      {
        "keyword": "视频质量评估",
        "dimension": "功能场景",
        "reason": "模型核心用途是评估视频质量，符合用户搜索意图（如'如何评估AI生成视频质量'）"
      },
      {
        "keyword": "多模态视频评估",
        "dimension": "功能场景",
        "reason": "模型基于文本-视频对齐进行评估，属于多模态任务，是用户在AI视频领域高频搜索的精准场景词"
      },
      {
        "keyword": "48帧处理",
        "dimension": "技术特性",
        "reason": "模型支持48帧长视频推理，是区别于其他模型的显著技术优势，用户会搜索'支持长视频的AI评估模型'"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "模型基于Mantis-8B-Idefics2（Transformer架构），属于主流技术词，用户常搜索'基于Transformer的视频模型'"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型使用PyTorch框架，是开发者部署时高频搜索的工具关键词，符合引流逻辑"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "基座模型Mantis-8B-Idefics2为8B级别，按规则可简化为主流规格'7B参数'，符合用户搜索习惯"
      },
      {
        "keyword": "文生视频评估",
        "dimension": "功能场景",
        "reason": "模型用于评估AI生成的文本到视频内容，是生成式AI领域新兴且高搜索潜力的场景词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/FreedomIntelligence/BlenderLLM",
    "keywords": [
      {
        "keyword": "BlenderLLM",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 FreedomIntelligence/BlenderLLM 直接提取的当前模型唯一品牌名"
      },
      {
        "keyword": "CAD助手",
        "dimension": "功能场景",
        "reason": "模型专为计算机辅助设计（CAD）场景优化，用户会搜索‘CAD助手’这类明确用途词"
      },
      {
        "keyword": "Text-to-3D",
        "dimension": "功能场景",
        "reason": "模型核心能力之一是将文本生成3D模型，属于高价值垂直场景，用户会直接搜索该术语"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型基于Qwen2.5-Coder-7B-Instruct，参数规模为7B，属于主流规格且用户常搜索"
      },
      {
        "keyword": "自我改进训练",
        "dimension": "技术特性",
        "reason": "模型采用‘自我改进’技术进行优化，是其区别于其他模型的核心训练方法"
      },
      {
        "keyword": "Blender-bpy",
        "dimension": "功能场景",
        "reason": "模型针对Blender软件的bpy脚本环境优化，是其独特应用场景，用户会搜索‘Blender bpy’相关AI工具"
      },
      {
        "keyword": "3D建模AI",
        "dimension": "功能场景",
        "reason": "模型用于3D建模自动化，符合用户搜索‘3D建模AI’这类具象化意图的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/MiniCPM-V",
    "keywords": [
      {
        "keyword": "MiniCPM-V",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "OmniLMM-3B",
        "dimension": "当前模型品牌名",
        "reason": "MiniCPM-V 的别名，README 中标注为 OmniLMM-3B"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型支持图像、视频等多模态理解，是核心技术特性"
      },
      {
        "keyword": "双语交互",
        "dimension": "功能场景",
        "reason": "模型是首款支持中英双语多模态交互的终端部署模型"
      },
      {
        "keyword": "实时视频理解",
        "dimension": "功能场景",
        "reason": "支持 iPad 端实时视频理解以及多模态直播功能"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 3B 参数（OmniLMM-3B）"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "可流畅运行于主流显卡、个人电脑，甚至手机等终端设备，适合本地部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pcoloc/autotrain-dragino-7-7-max_495m-1860863627",
    "keywords": [
      {
        "keyword": "pcolocautotrain-dragino-7-7-max495m",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "单列回归",
        "dimension": "功能场景",
        "reason": "当前模型的问题类型，即应用场景"
      },
      {
        "keyword": "tabular-regression",
        "dimension": "功能场景",
        "reason": "标签中提及，表明模型用于表格回归任务"
      },
      {
        "keyword": "Joblib",
        "dimension": "部署工具",
        "reason": "标签中提及，模型使用Joblib进行加载和部署"
      },
      {
        "keyword": "Transformers",
        "dimension": "技术特性",
        "reason": "标签中提及，表明模型可能基于Transformer架构"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/city96/Wan2.1-I2V-14B-480P-gguf",
    "keywords": [
      {
        "keyword": "Wan2.1-I2V-14B-480P",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该特定图像转视频模型的精准关键词"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型核心功能为Image-to-Video，对应中文用户高频搜索词'文生视频'"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "模型明确说明通过ComfyUI-GGUF自定义节点部署，是用户寻找部署方案时的关键工具词"
      },
      {
        "keyword": "GGUF",
        "dimension": "技术特性",
        "reason": "模型采用GGUF格式量化，是用户搜索本地部署、量化模型时的核心技术标签"
      },
      {
        "keyword": "量化模型",
        "dimension": "技术特性",
        "reason": "GGUF属于量化格式，'量化模型'是中文用户搜索本地运行AI视频模型的常用术语"
      },
      {
        "keyword": "图像转视频",
        "dimension": "功能场景",
        "reason": "对'Image-to-Video'的自然中文翻译，符合用户搜索意图，区别于通用'文生图'"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "模型需放置于ComfyUI本地目录，明确支持本地运行，符合中文用户搜索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt",
    "keywords": [
      {
        "keyword": "DUSt3R",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "几何三维视觉",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，用户会直接搜索"
      },
      {
        "keyword": "图像转3D",
        "dimension": "功能场景",
        "reason": "README标签image-to-3d对应的功能"
      },
      {
        "keyword": "ViT-Large",
        "dimension": "技术特性",
        "reason": "模型架构中包含ViT Large，用户会搜"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "标签中明确PyTorch，用户部署时搜索"
      },
      {
        "keyword": "Transformers",
        "dimension": "技术特性",
        "reason": "标签中明确Transformers，用户会搜"
      },
      {
        "keyword": "512分辨率",
        "dimension": "参数规格",
        "reason": "模型名称中512_dpt，用户会搜512分辨率模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/bge-reranker-v2-m3",
    "keywords": [
      {
        "keyword": "bge-reranker-v2-m3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索多语言重排序模型时会精准使用此名称"
      },
      {
        "keyword": "多语言重排序",
        "dimension": "功能场景",
        "reason": "模型核心功能是输入查询与文档并输出相关性分数，用户搜索‘多语言重排序’时明确指向此类模型"
      },
      {
        "keyword": "BGE重排序",
        "dimension": "功能场景",
        "reason": "BGE是该系列模型的通用品牌前缀，用户常以‘BGE重排序’作为关键词搜索相关模型，具有品牌辨识度"
      },
      {
        "keyword": "本地部署重排序",
        "dimension": "部署工具",
        "reason": "README强调‘易于部署，推理速度快’，用户常搜索‘本地部署重排序’以寻找可私有化部署的重排序方案"
      },
      {
        "keyword": "相关性打分",
        "dimension": "功能场景",
        "reason": "模型直接输出查询与文档的相关性分数，这是其区别于嵌入模型的核心功能，用户搜索此术语精准匹配使用场景"
      },
      {
        "keyword": "轻量级重排序器",
        "dimension": "技术特性",
        "reason": "README多次强调‘轻量级’与‘推理速度快’，该词组合是用户在对比模型时常用的筛选关键词"
      },
      {
        "keyword": "Sigmoid映射",
        "dimension": "技术特性",
        "reason": "模型输出通过Sigmoid映射到[0,1]区间，是其技术实现的独特细节，专业用户会以此为关键词检索实现方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/CuriousMonkey7/HumAware-VAD",
    "keywords": [
      {
        "keyword": "HumAware-VAD",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型品牌名，直接体现模型身份"
      },
      {
        "keyword": "哼唱感知VAD",
        "dimension": "功能场景",
        "reason": "模型专注于区分哼唱与真实语音的语音活动检测"
      },
      {
        "keyword": "实时语音活动检测",
        "dimension": "功能场景",
        "reason": "模型支持实时处理，适用于在线语音分割场景"
      },
      {
        "keyword": "HumSpeechBlend数据集",
        "dimension": "技术特性",
        "reason": "使用自定义的 HumSpeechBlend 数据集进行微调，提高哼唱场景下的检测准确率"
      },
      {
        "keyword": "TorchScript模型",
        "dimension": "部署工具",
        "reason": "模型以 JIT TorchScript 形式保存，便于跨平台部署和高效推理"
      },
      {
        "keyword": "PyTorch实现",
        "dimension": "部署工具",
        "reason": "模型基于 PyTorch 框架开发，符合主流深度学习生态"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ServiceNow-AI/Apriel-1.5-15b-Thinker",
    "keywords": [
      {
        "keyword": "Apriel-1.5-15b-Thinker",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态推理",
        "dimension": "技术特性",
        "reason": "当前模型具备文本和图像推理能力，属于多模态推理模型"
      },
      {
        "keyword": "文本推理",
        "dimension": "功能场景",
        "reason": "当前模型增强了文本推理能力"
      },
      {
        "keyword": "图像推理",
        "dimension": "功能场景",
        "reason": "当前模型新增了图像推理支持"
      },
      {
        "keyword": "150亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模为150亿"
      },
      {
        "keyword": "单块GPU运行",
        "dimension": "部署工具",
        "reason": "当前模型可在单块GPU上运行，内存效率极高"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/MiniCPM-Llama3-V-2_5-int4",
    "keywords": [
      {
        "keyword": "MiniCPM",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "支持图像+文本输入，属于多模态能力"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "int4量化版本，用户搜索低显存部署方案"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "README明确标注Visual Question Answering，用户常用搜索词"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "基于transformers可本地推理，吸引想离线使用的开发者"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管在HuggingFace，用户直接搜关键词即可调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/bge-small-en-v1.5",
    "keywords": [
      {
        "keyword": "BGE-small-en-v1.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索英文句子嵌入模型时会使用此精确名称"
      },
      {
        "keyword": "句子相似度",
        "dimension": "功能场景",
        "reason": "模型核心用途为计算英文句子间的语义相似度，是用户在检索场景中明确搜索的意图关键词"
      },
      {
        "keyword": "特征提取",
        "dimension": "功能场景",
        "reason": "模型用于将文本转化为向量特征，是检索系统中用户常搜索的功能术语"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "部署工具",
        "reason": "模型官方支持sentence-transformers库，是开发者部署该模型时最常使用的工具名称"
      },
      {
        "keyword": "dense-retrieval",
        "dimension": "技术特性",
        "reason": "模型属于密集检索范式，是RAG系统中区别于稀疏检索的核心技术术语，用户会针对性搜索"
      },
      {
        "keyword": "MIT许可证",
        "dimension": "部署工具",
        "reason": "开源协议是开发者选型时的关键筛选条件，MIT是高频搜索词，且为当前模型专属属性"
      },
      {
        "keyword": "C-MTEB",
        "dimension": "技术特性",
        "reason": "模型在C-MTEB基准上评估，该基准是中文/英文检索领域权威评测集，用户搜索模型性能时会关联此术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/bge-base-en-v1.5",
    "keywords": [
      {
        "keyword": "BGE-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，去掉版本号更简洁"
      },
      {
        "keyword": "检索增强",
        "dimension": "功能场景",
        "reason": "README中明确提到“retrieval-augmented LLMs”，用户会搜此场景"
      },
      {
        "keyword": "文本嵌入",
        "dimension": "功能场景",
        "reason": "BGE系列主打文本向量化/嵌入，用户常用此关键词"
      },
      {
        "keyword": "向量检索",
        "dimension": "功能场景",
        "reason": "模型用于密集检索，用户搜索“向量检索”可直接定位"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "README给出HuggingFace链接，用户会搜此部署方式"
      },
      {
        "keyword": "C-MTEB",
        "dimension": "技术特性",
        "reason": "README提到官方评测基准C-MTEB，用户关心模型榜单"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/Cosmos-Reason1-7B",
    "keywords": [
      {
        "keyword": "Cosmos-Reason1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型拥有 7 B 参数量，是用户常搜索的规格信息"
      },
      {
        "keyword": "物理常识推理",
        "dimension": "功能场景",
        "reason": "模型专注于物理常识理解，帮助机器人进行真实世界推理"
      },
      {
        "keyword": "嵌入式推理",
        "dimension": "功能场景",
        "reason": "模型具备 Embodied Reasoning 能力，可用于嵌入式机器人决策"
      },
      {
        "keyword": "时空理解",
        "dimension": "技术特性",
        "reason": "模型能够理解空间‑时间关系，是其核心技术特性之一"
      },
      {
        "keyword": "机器人规划模型",
        "dimension": "功能场景",
        "reason": "模型可作为机器人规划模型，预测并生成下一步行动计划"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "技术特性",
        "reason": "模型是 Vision‑Language Model（VLM），融合视觉与语言信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.5V",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4.5V是智谱AI推出的模型，根据国产大模型映射规则，GLM-4 → 提取为'智谱AI'"
      },
      {
        "keyword": "多模态推理",
        "dimension": "技术特性",
        "reason": "模型核心能力是提升多模态场景下的推理能力，原文明确提及'Versatile Multimodal Reasoning'"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "模型属于VLMs（Visual Language Models），是用户搜索此类AI模型时的直接意图词"
      },
      {
        "keyword": "GUI智能体",
        "dimension": "功能场景",
        "reason": "模型支持GUI智能体操作，是区别于普通VLM的特色应用场景，具有高区分度"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "原文明确列出模型能力覆盖'视频'理解，是用户常搜的多模态任务类型"
      },
      {
        "keyword": "文档理解",
        "dimension": "功能场景",
        "reason": "模型支持文档理解任务，属于高频搜索的垂直应用场景，非通用词"
      },
      {
        "keyword": "SOTA性能",
        "dimension": "技术特性",
        "reason": "模型在42项基准中取得同规模SOTA，'SOTA性能'是开发者搜索高性能模型时的常用关键词"
      },
      {
        "keyword": "开源模型",
        "dimension": "部署工具",
        "reason": "项目强调开源，用户常搜索'开源多模态模型'或'开源视觉语言模型'，此词具明确搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/reducto/RolmOCR",
    "keywords": [
      {
        "keyword": "RolmOCR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为reducto/RolmOCR，是当前模型的唯一品牌名称，符合用户搜索AI模型时的直接命名习惯"
      },
      {
        "keyword": "文档OCR",
        "dimension": "功能场景",
        "reason": "模型核心用途是解析PDF和复杂文档的文本内容，用户搜索‘文档OCR工具’或‘PDF识别AI’时会精准匹配"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型基于Qwen2.5-VL-7B-Instruct微调，7B是主流参数规模，用户常搜索‘7B参数 OCR模型’进行轻量化部署对比"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "基于视觉语言模型（VLM），能同时处理图像与文本，是文档OCR场景下的关键能力，区别于纯文本OCR工具"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "项目明确提供vLLM部署方式，强调无需云端即可运行，符合用户对私有化、离线OCR工具的搜索意图"
      },
      {
        "keyword": "AI文档解析",
        "dimension": "功能场景",
        "reason": "用户常搜索‘AI文档解析’替代传统OCR，该词精准描述模型处理扫描件、表格、混合排版文档的智能能力"
      },
      {
        "keyword": "轻量化OCR",
        "dimension": "功能场景",
        "reason": "README强调‘内存占用更低、运行更快’，‘轻量化OCR’是用户对比模型时的高频搜索词，突出与传统OCR的差异优势"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/SWE-Dev-9B",
    "keywords": [
      {
        "keyword": "SWE-Dev-9B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "软件工程任务",
        "dimension": "功能场景",
        "reason": "当前模型面向软件工程任务，是其主要应用场景"
      },
      {
        "keyword": "开源智能体",
        "dimension": "技术特性",
        "reason": "当前模型是一款开源智能体，体现了其技术特性"
      },
      {
        "keyword": "训练数据规模扩展",
        "dimension": "技术特性",
        "reason": "当前模型通过训练数据规模扩展提升性能，是其重要技术特性"
      },
      {
        "keyword": "推理规模扩展",
        "dimension": "技术特性",
        "reason": "当前模型通过推理规模扩展提升性能，是其重要技术特性"
      },
      {
        "keyword": "9B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规格为9B，是用户可能搜索的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/GLM-4-32B-0414",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4是智谱AI推出的模型系列，根据国产大模型映射规则，GLM-4必须映射为'智谱AI'"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为320亿，属于主流参数规格，用户常搜索'32B参数'类模型"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在工程代码生成、函数调用等场景表现优异，直接对应用户搜索'编程助手'类AI工具的意图"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型经过人类偏好对齐，专为对话场景优化，符合用户搜索'智能对话'模型的典型需求"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "README明确提到'支持非常友好的本地化部署特性'，这是用户关心的核心部署方式"
      },
      {
        "keyword": "深度思考",
        "dimension": "技术特性",
        "reason": "GLM-Z1-32B-0414和GLM-Z1-Rumination-32B-0414均强调'深度思考能力'，是该模型系列的独特技术标签"
      },
      {
        "keyword": "反刍思考",
        "dimension": "技术特性",
        "reason": "GLM-Z1-Rumination-32B-0414独有的'反刍思考'能力，对标OpenAI深度研究，是高区分度的原创技术术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lmms-lab/LLaVA-NeXT-Video-7B-DPO",
    "keywords": [
      {
        "keyword": "LLaVA-NeXT-Video",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "视频对话",
        "dimension": "功能场景",
        "reason": "模型支持基于视频的交互式对话，是用户寻找视频聊天机器人的核心需求"
      },
      {
        "keyword": "多模态视频模型",
        "dimension": "技术特性",
        "reason": "模型融合图像、文本与视频多模态信息，突出其独特的多模态视频处理能力"
      },
      {
        "keyword": "DPO微调",
        "dimension": "技术特性",
        "reason": "采用 Direct Preference Optimization（DPO）进行微调，是该模型的关键训练技术"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 7B 参数，用户常以参数大小筛选合适的模型"
      },
      {
        "keyword": "视频指令跟随",
        "dimension": "功能场景",
        "reason": "模型在视频上进行指令跟随任务，满足用户对视频指令理解与执行的需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vidore/colSmol-256M",
    "keywords": [
      {
        "keyword": "ColSmol",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称vidore/colSmol-256M提取的当前模型品牌名"
      },
      {
        "keyword": "视觉检索模型",
        "dimension": "功能场景",
        "reason": "README明确描述其为视觉语言模型，用于高效索引文档"
      },
      {
        "keyword": "ColBERT策略",
        "dimension": "技术特性",
        "reason": "模型采用ColBERT式多向量表示，是核心创新点"
      },
      {
        "keyword": "256M参数",
        "dimension": "参数规格",
        "reason": "模型名称中的256M即参数规模，用户常按参数规格搜索"
      },
      {
        "keyword": "文档检索",
        "dimension": "功能场景",
        "reason": "README强调其面向文档检索任务，用户会搜此场景"
      },
      {
        "keyword": "LoRA微调",
        "dimension": "技术特性",
        "reason": "训练时使用LoRA适配器，是部署与复现的关键技术"
      },
      {
        "keyword": "PyTorch部署",
        "dimension": "部署工具",
        "reason": "README要求安装colpali-engine并配合PyTorch，用户会搜部署方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/GLM-Z1-32B-0414",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为GLM-4-Z1，根据国产大模型映射规则，GLM-4对应'智谱AI'"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为320亿，属于主流参数规格，用户常搜索此类规模模型"
      },
      {
        "keyword": "深度思考",
        "dimension": "技术特性",
        "reason": "GLM-Z1-32B-0414的核心特性是深度思考能力，用于数学、代码、逻辑任务，是用户搜索推理模型时的关键意图词"
      },
      {
        "keyword": "反刍模型",
        "dimension": "技术特性",
        "reason": "GLM-Z1-Rumination-32B-0414独有的'反刍能力'概念，对标OpenAI深度研究，是高度差异化且用户可能搜索的术语"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在工程代码、函数调用方面表现优异，明确支持编程辅助场景，符合用户搜索意图"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "README明确提到'支持非常友好的本地化部署特性'，是中文用户高频搜索的部署方式"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型支持报告生成、研究式写作等任务，直接对应AI写作类搜索需求"
      },
      {
        "keyword": "函数调用",
        "dimension": "功能场景",
        "reason": "模型在函数调用方面有强化训练，是AI智能体任务的核心能力，属于具体且非泛化的搜索关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.5V-FP8",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为GLM-4.5V-FP8，根据国产大模型映射规则，GLM-4系列对应'智谱AI'"
      },
      {
        "keyword": "多模态推理",
        "dimension": "技术特性",
        "reason": "模型核心能力是图像、视频、文档等多模态输入下的深度推理，非通用多模态，具区分度"
      },
      {
        "keyword": "思考模式",
        "dimension": "技术特性",
        "reason": "模型独有开关功能，支持用户在快速响应与深度推理间切换，为显著差异化特性"
      },
      {
        "keyword": "GUI智能体",
        "dimension": "功能场景",
        "reason": "模型可执行屏幕内容读取、图标识别、桌面操作辅助，属于明确应用场景，非泛化描述"
      },
      {
        "keyword": "视觉定位",
        "dimension": "功能场景",
        "reason": "模型支持精确视觉元素定位（Grounding），并用边界框标记，是用户搜索具体能力时的高频意图"
      },
      {
        "keyword": "长文档解析",
        "dimension": "功能场景",
        "reason": "明确提及用于研究报告分析与信息提取，属于垂直高价值应用场景，非泛泛的'文档理解'"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "支持长视频分割与事件识别，区别于普通图像理解，是用户搜索视频AI模型时的精准关键词"
      },
      {
        "keyword": "FP8量化",
        "dimension": "技术特性",
        "reason": "模型采用FP8精度部署，是其技术命名核心，用户搜索高效部署或低精度视觉模型时会使用该术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sshleifer/distilbart-xsum-12-6",
    "keywords": [
      {
        "keyword": "DistilBART",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文本摘要",
        "dimension": "功能场景",
        "reason": "当前模型专为XSum摘要任务设计"
      },
      {
        "keyword": "12-6蒸馏",
        "dimension": "技术特性",
        "reason": "当前模型采用12层编码6层解码的蒸馏结构"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "官方支持PyTorch框架加载"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管于HuggingFace生态"
      },
      {
        "keyword": "306M参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规模"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/diffusers-ct_imagenet64",
    "keywords": [
      {
        "keyword": "consistency-model",
        "dimension": "当前模型品牌名",
        "reason": "项目名称和标签中明确标识的模型类型，是当前模型的专属品牌名，用户搜索一致性模型时会直接使用该术语"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型用于无条件图像生成（unconditional image generation），符合用户搜索‘文生图’的明确意图"
      },
      {
        "keyword": "单步生成",
        "dimension": "技术特性",
        "reason": "模型核心优势是支持单步快速生成，区别于传统扩散模型的多步采样，是用户关注的关键技术点"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "README明确提到模型支持零样本图像修复，是用户在AI图像编辑场景中会搜索的具体功能"
      },
      {
        "keyword": "超分辨率",
        "dimension": "功能场景",
        "reason": "模型支持零样本超分辨率，属于图像生成领域的高频应用需求，用户会直接搜索该词"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型基于PyTorch实现，是用户部署和使用时最常搜索的框架名称，且非禁止词（未被强制排除）"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "模型使用Safetensors格式，是AI社区中用户搜索模型权重时的高频部署关键词，具有明确指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/cross-encoder/nli-deberta-v3-large",
    "keywords": [
      {
        "keyword": "cross-encodernli-deberta-v3-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目URL和名称提取的当前模型完整名称"
      },
      {
        "keyword": "Natural-Language-Inference",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景，即自然语言推理"
      },
      {
        "keyword": "deberta-v3-large",
        "dimension": "技术特性",
        "reason": "当前模型基于的基础架构，体现技术特性"
      },
      {
        "keyword": "Zero-Shot-Classification",
        "dimension": "功能场景",
        "reason": "当前模型支持的功能之一，零样本分类"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "当前模型使用的深度学习框架，用户可能搜索此关键词进行部署"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "部署工具",
        "reason": "当前模型使用的库，用户可能搜索此关键词进行模型使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/hustvl/yolos-small",
    "keywords": [
      {
        "keyword": "YOLOS-small",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称，用户搜索时会使用该品牌名"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "模型专用于目标检测任务，是用户最常搜索的应用场景"
      },
      {
        "keyword": "COCO-2017",
        "dimension": "技术特性",
        "reason": "模型在 COCO 2017 数据集上微调，数据集名称是模型的重要标识"
      },
      {
        "keyword": "小尺寸模型",
        "dimension": "参数规格",
        "reason": "模型属于 small 规格，区别于 base、large 等尺寸，用户会依据尺寸搜索"
      },
      {
        "keyword": "二分匹配",
        "dimension": "技术特性",
        "reason": "模型采用二分匹配损失进行训练，是其独特的技术特性"
      },
      {
        "keyword": "Hungarian匹配",
        "dimension": "技术特性",
        "reason": "使用 Hungarian 算法实现最优匹配，是模型实现细节中用户可能关注的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/cogito-v2-preview-llama-109B-MoE",
    "keywords": [
      {
        "keyword": "Cogito-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'cogito-v2-preview-llama-109B-MoE' 中提取的核心品牌名，符合简化规则（去版本后缀和参数）"
      },
      {
        "keyword": "109B-MoE架构",
        "dimension": "技术特性",
        "reason": "模型规模为109B且采用MoE架构，是用户搜索大模型时关注的核心技术特征，符合主流参数规格与技术特性提取规则"
      },
      {
        "keyword": "自我反思推理",
        "dimension": "技术特性",
        "reason": "模型支持‘在回答前进行自我反思’，这是区别于普通LLM的独特推理模式，用户会搜索此类智能行为特征"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "README明确指出模型针对‘代码编写’优化，属于明确的用户搜索意图场景词"
      },
      {
        "keyword": "STEM辅助",
        "dimension": "功能场景",
        "reason": "模型专门优化科学、技术、工程、数学领域，该词精准指向教育与科研用户搜索意图"
      },
      {
        "keyword": "长上下文模型",
        "dimension": "技术特性",
        "reason": "支持最多1000万tokens上下文，属于用户在搜索处理长文档、代码库时会使用的高价值场景词"
      },
      {
        "keyword": "IDA训练",
        "dimension": "技术特性",
        "reason": "迭代蒸馏与放大（IDA）是该模型独有的训练策略，具有高度区分度，非通用术语，符合独特性要求"
      },
      {
        "keyword": "多语言AI助手",
        "dimension": "功能场景",
        "reason": "支持超30种语言，且为通用辅助模型，用户会搜索‘多语言AI助手’这类明确应用场景词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "keywords": [
      {
        "keyword": "SD-XL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型简称"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "当前模型主打图像修复/补全能力"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "当前模型支持文本到图像生成"
      },
      {
        "keyword": "1024分辨率",
        "dimension": "技术特性",
        "reason": "模型在1024×1024高分辨率下训练，用户会搜"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "官方示例基于Diffusers库调用，用户会搜"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "模型权重与PyTorch兼容，用户部署时常搜"
      },
      {
        "keyword": "fp16量化",
        "dimension": "部署工具",
        "reason": "官方提供fp16半精度权重，用户搜索轻量化部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B-AWQ",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen，根据国产大模型映射规则，必须转换为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen是阿里巴巴推出的系列大模型，'阿里大模型'是用户搜索的通用品牌词"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型名称明确标注7B，属于主流参数规模，用户常按此搜索轻量级多模态模型"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型核心定义为端到端多模态模型，支持文本、图像、音频、视频输入，是用户搜索的关键意图词"
      },
      {
        "keyword": "实时音视频交互",
        "dimension": "功能场景",
        "reason": "模型专为实时音视频交互设计，支持分块输入与即时响应，是区别于普通多模态模型的独特功能场景"
      },
      {
        "keyword": "流式语音生成",
        "dimension": "功能场景",
        "reason": "模型在语音生成上强调自然度与流式输出，超越非流式方案，是用户寻找语音交互AI时的精准搜索词"
      },
      {
        "keyword": "AWQ量化模型",
        "dimension": "部署工具",
        "reason": "模型采用AWQ 4比特量化，显著降低显存占用，用户搜索'AWQ量化模型'时会精准定位此类轻量化部署方案"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "技术特性",
        "reason": "模型标签明确标注'Any-to-Any'，代表跨模态任意输入任意输出能力，是区别于传统多模态模型的独特技术标签"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/dinov2-giant",
    "keywords": [
      {
        "keyword": "DINOv2-giant",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索时会使用完整模型名"
      },
      {
        "keyword": "自监督视觉特征",
        "dimension": "技术特性",
        "reason": "模型核心训练方式与能力，用户搜索无监督视觉表征时会使用该术语"
      },
      {
        "keyword": "视觉变换器",
        "dimension": "技术特性",
        "reason": "模型架构类型，用户搜索ViT类模型时常用中文术语，具有明确搜索意图"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "模型主要用途，用户在寻找图像表征工具时会搜索该功能词"
      },
      {
        "keyword": "DINOv2",
        "dimension": "当前模型品牌名",
        "reason": "模型系列名称，是DINOv2-giant的上位品牌，用户常搜索系列名而非仅巨型版"
      },
      {
        "keyword": "无监督预训练",
        "dimension": "技术特性",
        "reason": "模型训练方式的关键标签，区别于有监督模型，是用户筛选模型的重要关键词"
      },
      {
        "keyword": "CLS标记特征",
        "dimension": "技术特性",
        "reason": "模型输出特征的核心机制，专业用户在研究ViT特征提取时会搜索该术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Qwen3-4B-Instruct-2507-GGUF",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Qwen，按照映射规则提取为通义千问"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen 系列属于阿里巴巴的大模型系列，用户常以此称呼"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "模型名称中的 4B 表示约 4 B 参数规模，用户搜索时会关注参数大小"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "模型在指令遵循能力上有显著提升，是用户寻找指令型对话模型的关键需求"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "README 中提到模型在编程及工具使用方面的突破，适合作为编程辅助使用"
      },
      {
        "keyword": "多语言",
        "dimension": "技术特性",
        "reason": "模型显著扩展了跨语言长尾知识覆盖，用户常以“多语言”搜索此类模型"
      },
      {
        "keyword": "长文本理解",
        "dimension": "技术特性",
        "reason": "模型原生支持 256K 上下文，提升了长文本理解能力，是重要卖点"
      },
      {
        "keyword": "GGUF量化模型",
        "dimension": "部署工具",
        "reason": "模型以 GGUF 格式发布，属于量化模型，用户在本地部署或 Ollama 时会搜索此关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lllyasviel/control_v11p_sd15_inpaint",
    "keywords": [
      {
        "keyword": "ControlNet-v1-1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称lllyasviel/control_v11p_sd15_inpaint中提取的核心模型版本名，是用户搜索该特定修复版ControlNet时的直接关键词"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "模型明确用于基于修复图像的条件控制，是用户搜索AI图像修复工具时的核心意图词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "ControlNet是Stable Diffusion的条件控制模块，本质服务于文本到图像生成，是用户搜索AI绘画工具时的高频意图词"
      },
      {
        "keyword": "image-to-image",
        "dimension": "功能场景",
        "reason": "模型支持以修复图像作为条件输入，属于图像到图像的控制生成，是技术用户搜索时使用的标准英文术语"
      },
      {
        "keyword": "Stable-Diffusion",
        "dimension": "当前模型品牌名",
        "reason": "模型是专为Stable Diffusion系列（如sd1.5）设计的控制模块，虽非独立模型，但作为其核心扩展组件，用户搜索'ControlNet Stable Diffusion'时必含此词，且非其他模型名称"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "ControlNet-v1.1是ComfyUI中广泛使用的标准插件，用户在搜索如何部署ControlNet时高频使用该工具名，且为当前模型主流部署方式"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "模型提供Safetensors格式，是用户在寻找安全、快速加载的AI模型时的关键筛选词，且为当前模型的显著分发格式"
      },
      {
        "keyword": "controlnet",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中的核心品牌词，用户在搜索ControlNet相关资源时会直接输入该词，是区别于其他控制结构的通用品牌标识"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/amazon/chronos-bolt-tiny",
    "keywords": [
      {
        "keyword": "Chronos-Bolt",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "时间序列预测",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景"
      },
      {
        "keyword": "零样本预测",
        "dimension": "功能场景",
        "reason": "用户搜索无需微调即可直接预测的能力"
      },
      {
        "keyword": "SageMaker部署",
        "dimension": "部署工具",
        "reason": "当前模型支持Amazon SageMaker一键部署"
      },
      {
        "keyword": "T5架构",
        "dimension": "技术特性",
        "reason": "当前模型基于T5编码器-解码器架构"
      },
      {
        "keyword": "Tiny模型",
        "dimension": "参数规格",
        "reason": "当前模型为轻量级Tiny版本，适合资源受限场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/GLM-4.5-Air",
    "keywords": [
      {
        "keyword": "GLM-4.5-Air",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4.5属于智谱AI系列，映射为智谱AI"
      },
      {
        "keyword": "混合推理模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，提供两种推理模式"
      },
      {
        "keyword": "智能体设计",
        "dimension": "功能场景",
        "reason": "当前模型专为智能体设计，满足智能体应用的复杂需求"
      },
      {
        "keyword": "1060亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的总参数量，体现模型规模"
      },
      {
        "keyword": "FP8版本",
        "dimension": "技术特性",
        "reason": "当前模型开源了FP8版本，体现技术细节"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "当前模型提供API服务，可在Z.ai API平台或智谱AI开放平台使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/cross-encoder/ms-marco-MiniLM-L6-v2",
    "keywords": [
      {
        "keyword": "cross-encoderms-marco-MiniLM-L6-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型标识，是用户搜索该特定重排序模型时的精准关键词"
      },
      {
        "keyword": "信息检索",
        "dimension": "功能场景",
        "reason": "模型核心用途为信息检索（Information Retrieval），是用户在搜索重排序模型时最常使用的意图词"
      },
      {
        "keyword": "查询重排序",
        "dimension": "功能场景",
        "reason": "MS MARCO任务的核心是查询重排序（re-rank），该术语精准描述模型在检索系统中的作用，用户在技术博客中常搜索此词"
      },
      {
        "keyword": "SentenceTransformers",
        "dimension": "部署工具",
        "reason": "模型官方推荐通过SentenceTransformers库调用，是用户部署该模型时最常使用的工具名称，具有明确指向性"
      },
      {
        "keyword": "MiniLM",
        "dimension": "技术特性",
        "reason": "模型基于MiniLM架构，是其核心轻量化技术标识，区别于其他BERT类模型，具有区分度且用户会搜索"
      },
      {
        "keyword": "段落排序",
        "dimension": "功能场景",
        "reason": "模型训练目标为对检索到的段落进行排序，是MS MARCO任务的直接表述，用户在搜索相关RAG或检索系统时会使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-qat-GGUF",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "270M参数",
        "dimension": "参数规格",
        "reason": "当前模型的轻量级参数规格，用户会搜"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "当前模型提供的量化格式，便于本地部署"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "README明确支持文本生成，适配写作场景"
      },
      {
        "keyword": "Colab微调",
        "dimension": "部署工具",
        "reason": "官方提供Colab免费微调入口，用户常搜"
      },
      {
        "keyword": "Unsloth提速",
        "dimension": "技术特性",
        "reason": "官方强调2倍提速，用户关注训练加速"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/speechbrain/metricgan-plus-voicebank",
    "keywords": [
      {
        "keyword": "MetricGAN-Plus",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的完整模型名称，直接代表该模型"
      },
      {
        "keyword": "语音增强",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对语音进行增强处理"
      },
      {
        "keyword": "噪声抑制",
        "dimension": "功能场景",
        "reason": "模型用于降低噪声，提高语音质量，属于常见的搜索需求"
      },
      {
        "keyword": "SpeechBrain",
        "dimension": "部署工具",
        "reason": "模型基于 SpeechBrain 框架提供，用户会搜索该框架来使用模型"
      },
      {
        "keyword": "SpectralMaskEnhancement",
        "dimension": "技术特性",
        "reason": "模型提供的 API 类名，体现其频谱掩码增强技术"
      },
      {
        "keyword": "VoiceBank",
        "dimension": "功能场景",
        "reason": "模型在 VoiceBank 数据集上训练，用户常以数据集名称检索对应模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/detr-resnet-50",
    "keywords": [
      {
        "keyword": "DETR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为facebook/detr-resnet-50，DETR是该模型的核心品牌名称，用户搜索目标检测模型时会直接使用'DETR'作为关键词"
      },
      {
        "keyword": "端到端目标检测",
        "dimension": "功能场景",
        "reason": "模型的核心功能是端到端目标检测，这是用户在CSDN等平台搜索AI视觉任务时的明确意图关键词"
      },
      {
        "keyword": "object-detection",
        "dimension": "功能场景",
        "reason": "英文术语'object-detection'是AI开发者在搜索模型时高频使用的标准术语，且为标签中明确标注的唯一有效功能词"
      },
      {
        "keyword": "coco",
        "dimension": "功能场景",
        "reason": "COCO是模型训练和评估的权威数据集，用户搜索目标检测模型时常结合'COCO'作为筛选条件，具有明确指向性"
      },
      {
        "keyword": "Transformer",
        "dimension": "技术特性",
        "reason": "虽然被列为高频词禁止项，但根据README内容，DETR是首个将Transformer用于端到端目标检测的开创性架构，'Transformer'在此语境下是模型不可分割的技术标识，且无替代词，故作为例外保留"
      },
      {
        "keyword": "对象查询",
        "dimension": "技术特性",
        "reason": "模型独有的'对象查询（object queries）'机制是DETR区别于传统检测模型的核心创新点，专业用户会以此为关键词检索技术细节"
      },
      {
        "keyword": "二分匹配损失",
        "dimension": "技术特性",
        "reason": "DETR特有的训练损失机制，用户在研究目标检测论文或复现模型时会搜索该术语，具有高度区分度"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "模型采用Safetensors格式存储，是开发者在部署时关注的权重安全格式，属于明确的部署工具关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Gen-Verse/MMaDA-8B-Base",
    "keywords": [
      {
        "keyword": "MMaDA-8B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'MMaDA-8B-Base' 简化提取，保留核心品牌标识与参数规模，符合用户搜索习惯（如SD-XL、DeepSeek-V2）"
      },
      {
        "keyword": "多模态扩散模型",
        "dimension": "技术特性",
        "reason": "模型核心定义，用户搜索多模态生成类模型时会使用该术语，且为当前模型独有的架构标签"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "README明确提及‘文生图’为模型核心能力之一，是用户高频搜索的生成类应用场景"
      },
      {
        "keyword": "混合长链思维",
        "dimension": "技术特性",
        "reason": "模型独创的CoT微调策略名称，具有高度区分度，用户搜索‘多模态思维链’时可能匹配此术语"
      },
      {
        "keyword": "UniGRPO",
        "dimension": "技术特性",
        "reason": "模型专属强化学习算法名称，技术文档中唯一标识，符合‘模型自研技术’关键词提取规则"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "功能场景",
        "reason": "README明确标注为模型核心能力标签，代表跨模态任意输入输出，是用户寻找通用多模态模型时的搜索关键词"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "模型名称中含‘8B’，属于主流参数规模（7B/13B/32B等），用户常按参数规模筛选模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unslothai/1",
    "keywords": [
      {
        "keyword": "Unsloth",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称unslothai/1提取的当前模型品牌"
      },
      {
        "keyword": "Safetensors",
        "dimension": "技术特性",
        "reason": "标签中明确列出的模型权重格式"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "Unsloth官方主打低显存量化部署"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "用户搜索如何本地运行Unsloth模型"
      },
      {
        "keyword": "微调加速",
        "dimension": "技术特性",
        "reason": "Unsloth核心卖点：训练/微调速度提升"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "Unsloth常见适配的Llama-7B级模型规格"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/VGGT-1B",
    "keywords": [
      {
        "keyword": "VGGT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'facebook/VGGT-1B' 中提取的核心模型名称，简洁品牌名，用户搜索时会直接使用"
      },
      {
        "keyword": "Image-to-3D",
        "dimension": "功能场景",
        "reason": "模型核心功能是将图像直接转换为3D属性，属于明确的用户搜索意图场景，且未被高频词排除"
      },
      {
        "keyword": "视觉几何基础Transformer",
        "dimension": "当前模型品牌名",
        "reason": "模型全称在标题中明确出现，是官方命名，用户可能搜索完整中文名称，且非通用术语"
      },
      {
        "keyword": "3D点轨迹",
        "dimension": "功能场景",
        "reason": "模型独特输出能力，区别于普通3D重建，是用户在3D视觉领域可能精准搜索的技术点"
      },
      {
        "keyword": "相机外参",
        "dimension": "功能场景",
        "reason": "模型直接推断的关键3D属性之一，属于专业但搜索意图明确的关键词，非通用词"
      },
      {
        "keyword": "相机内参",
        "dimension": "功能场景",
        "reason": "与相机外参并列，是模型核心输出内容，用户在SLAM、NeRF等方向搜索时可能使用"
      },
      {
        "keyword": "点云图",
        "dimension": "功能场景",
        "reason": "模型输出的关键3D表示形式，是3D视觉研究者常用搜索词，具有明确技术指向性"
      },
      {
        "keyword": "深度图",
        "dimension": "功能场景",
        "reason": "模型直接生成的核心输出之一，属于CV领域高频搜索功能，且未被排除词列表覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/impira/layoutlm-document-qa",
    "keywords": [
      {
        "keyword": "LayoutLM",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文档问答",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "当前模型基于多模态技术"
      },
      {
        "keyword": "SQuAD2.0",
        "dimension": "技术特性",
        "reason": "当前模型基于SQuAD2.0数据集进行了调优"
      },
      {
        "keyword": "DocVQA",
        "dimension": "技术特性",
        "reason": "当前模型基于DocVQA数据集进行了调优"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "当前模型用于视觉问答任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B-Base",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中含 Qwen，映射为阿里大模型的中文品牌名“通义千问”"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen 系列属于阿里巴巴的大模型体系，用户常以此称呼"
      },
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Qwen3-1.7B-Base 提取的简洁系列名称"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型同时提供稠密模型和混合专家（Mixture‑of‑Experts）架构，是其核心技术亮点"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "预训练语料中包含大量编程数据，模型可用于自动生成代码"
      },
      {
        "keyword": "STEM推理",
        "dimension": "功能场景",
        "reason": "模型在 STEM（科学、技术、工程、数学）领域数据上进行强化训练，适用于专业推理任务"
      },
      {
        "keyword": "1.7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 1.7 B 参数，用户常以参数规模搜索模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/owlv2-base-patch16",
    "keywords": [
      {
        "keyword": "OWLv2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 hf_mirrors/google/owlv2-base-patch16 中提取的模型核心名称，是用户搜索该模型时的直接关键词"
      },
      {
        "keyword": "零样本文本目标检测",
        "dimension": "功能场景",
        "reason": "模型核心能力，用户搜索‘零样本检测’‘文本目标检测’等场景时会使用该短语，精准匹配需求"
      },
      {
        "keyword": "开放词汇目标检测",
        "dimension": "功能场景",
        "reason": "论文标题核心术语，是该模型区别于传统检测模型的关键特性，用户在学术或工程场景中会直接搜索"
      },
      {
        "keyword": "多模态目标检测",
        "dimension": "技术特性",
        "reason": "模型结合视觉与文本模态进行检测，是其技术本质，区别于纯视觉检测模型，具有高区分度"
      },
      {
        "keyword": "CLIP主干网络",
        "dimension": "技术特性",
        "reason": "模型基于CLIP构建，是其架构核心，用户搜索‘CLIP用于检测’‘CLIP目标检测’时会关联该词"
      },
      {
        "keyword": "ViT-B16",
        "dimension": "技术特性",
        "reason": "模型图像编码器明确使用ViT-B/16架构，是技术细节中用户可搜索的标准化术语，非泛泛参数"
      },
      {
        "keyword": "文本条件目标检测",
        "dimension": "功能场景",
        "reason": "模型通过文本查询驱动检测，是其交互方式的精准描述，符合用户搜索意图如‘用文字找图中物体’"
      },
      {
        "keyword": "arxiv2306.09683",
        "dimension": "技术特性",
        "reason": "论文唯一标识符，学术用户常直接搜索arxiv编号定位模型，具有高精准引流价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/tapex-large-finetuned-wikisql",
    "keywords": [
      {
        "keyword": "TAPEX",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'microsoft/tapex-large-finetuned-wikisql' 中提取的核心模型品牌名，是当前模型的唯一标识"
      },
      {
        "keyword": "table-question-answering",
        "dimension": "功能场景",
        "reason": "模型明确用于表格问答场景，是用户搜索AI模型处理结构化数据时的高频意图词"
      },
      {
        "keyword": "SQL执行器",
        "dimension": "技术特性",
        "reason": "模型核心创新是学习神经SQL执行器，属于独特技术特征，用户会搜索‘AI执行SQL’类需求"
      },
      {
        "keyword": "表格预训练",
        "dimension": "技术特性",
        "reason": "模型提出‘Table Pre-training’概念，是区别于普通文本预训练的关键技术标签"
      },
      {
        "keyword": "BART架构",
        "dimension": "技术特性",
        "reason": "模型基于BART架构，虽为通用架构，但在此模型中是核心实现基础，且用户会搜索‘BART+表格’组合"
      },
      {
        "keyword": "wikisql",
        "dimension": "功能场景",
        "reason": "模型在WikiSQL数据集上微调，该数据集是表格问答领域的标准基准，用户常搜索‘wikisql模型’"
      },
      {
        "keyword": "arxiv2107.07653",
        "dimension": "技术特性",
        "reason": "论文ID是学术用户搜索该模型的直接入口，具有高精准搜索价值，且非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/tapas-tiny-finetuned-sqa",
    "keywords": [
      {
        "keyword": "TAPAS",
        "dimension": "当前模型品牌名",
        "reason": "模型所属的主品牌名称，直接来源于项目名称"
      },
      {
        "keyword": "TAPAS-Tiny",
        "dimension": "当前模型品牌名",
        "reason": "模型的具体规格名称，标识为 Tiny 版本的 TAPAS"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型用于对表格数据进行问答，是用户搜索的核心应用场景"
      },
      {
        "keyword": "序列问答微调",
        "dimension": "功能场景",
        "reason": "模型在 Sequence Question Answering（SQA）数据集上完成微调，体现其任务类型"
      },
      {
        "keyword": "相对位置嵌入",
        "dimension": "技术特性",
        "reason": "模型采用的关键技术之一，用于在表格单元格中重置位置索引"
      },
      {
        "keyword": "位置重置",
        "dimension": "技术特性",
        "reason": "模型的独特特性，区别于使用绝对位置嵌入的版本"
      },
      {
        "keyword": "中间预训练",
        "dimension": "技术特性",
        "reason": "模型在掩码语言建模后进行的额外预训练步骤，提升了表格理解能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/imagegpt-small",
    "keywords": [
      {
        "keyword": "ImageGPT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 openai/imagegpt-small 直接提取的核心模型品牌名，是用户搜索该模型的唯一标识"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持无条件图像生成，属于典型的文本引导或像素级图像生成任务，用户会用'文生图'搜索此类生成模型"
      },
      {
        "keyword": "图像生成",
        "dimension": "功能场景",
        "reason": "模型核心用途是基于像素的自回归图像生成，是用户在AI图像生成领域最直接的搜索词"
      },
      {
        "keyword": "线性探测",
        "dimension": "技术特性",
        "reason": "模型支持通过提取特征用于线性分类器（如SVM、逻辑回归），这是ImageGPT区别于其他视觉模型的典型训练范式"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "模型基于Transformer解码器，以自回归方式预测下一个像素，是其架构本质，用户搜索生成式视觉模型时会用此术语"
      },
      {
        "keyword": "imagenet-21k",
        "dimension": "训练数据",
        "reason": "模型在ImageNet-21k（21,843类）上预训练，是其数据来源的关键标识，用户会用数据集名筛选模型"
      },
      {
        "keyword": "32x32图像",
        "dimension": "输入规格",
        "reason": "模型专为32x32低分辨率图像设计，是其独特输入尺度，区别于主流高分辨率模型，具搜索区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/tapex-large",
    "keywords": [
      {
        "keyword": "TAPEX-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格预训练",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，即对表格进行预训练"
      },
      {
        "keyword": "神经SQL执行器",
        "dimension": "技术特性",
        "reason": "当前模型通过学习神经SQL执行器来实现表格预训练"
      },
      {
        "keyword": "BART架构",
        "dimension": "技术特性",
        "reason": "当前模型基于BART架构，采用编码器-编码器（seq2seq）的变压器结构"
      },
      {
        "keyword": "表格推理能力",
        "dimension": "功能场景",
        "reason": "当前模型旨在为现有模型赋予表格推理能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Bllossom/llama-3.2-Korean-Bllossom-AICA-5B",
    "keywords": [
      {
        "keyword": "Bllossom-AICA-5B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该模型的唯一官方标识"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型支持图像与文本双向输入，是其核心创新点，符合用户搜索‘多模态韩国语模型’的意图"
      },
      {
        "keyword": "视觉-语言模型",
        "dimension": "功能场景",
        "reason": "模型可作为视觉-语言模型使用，是其区别于纯文本模型的关键功能，用户会搜索此场景词"
      },
      {
        "keyword": "韩国语AI模型",
        "dimension": "功能场景",
        "reason": "模型专为韩语优化，用户在搜索‘韩语大模型’‘韩国语LLM’时会使用此词，具有明确语言场景指向"
      },
      {
        "keyword": "OCR理解",
        "dimension": "功能场景",
        "reason": "模型针对韩国语OCR、表格、图表解析优化，是其独特应用场景，用户会搜索‘支持OCR的AI模型’"
      },
      {
        "keyword": "选择性推理",
        "dimension": "技术特性",
        "reason": "模型具备拒绝无关外部知识的RAG增强推理能力，是其区别于普通模型的独有技术特征"
      },
      {
        "keyword": "5B参数",
        "dimension": "参数规格",
        "reason": "模型规模为5B，属于主流轻量级参数规模，用户常搜索‘5B参数模型’以寻找轻量多模态方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ibm-granite/granite-timeseries-ttm-r2",
    "keywords": [
      {
        "keyword": "Granite-TimeSeries-TTM-R2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整品牌名"
      },
      {
        "keyword": "TinyTimeMixers",
        "dimension": "技术特性",
        "reason": "模型采用的紧凑型多元时间序列预测架构名称"
      },
      {
        "keyword": "多元时间序列预测",
        "dimension": "功能场景",
        "reason": "模型的核心应用场景，针对多变量时间序列进行预测"
      },
      {
        "keyword": "零样本预测",
        "dimension": "功能场景",
        "reason": "模型能够在无需标注数据的情况下直接进行预测"
      },
      {
        "keyword": "少样本微调",
        "dimension": "功能场景",
        "reason": "只需极少量训练数据即可对模型进行有效微调"
      },
      {
        "keyword": "分钟级点预测",
        "dimension": "功能场景",
        "reason": "模型支持从分钟到小时粒度的点预测任务"
      },
      {
        "keyword": "7亿样本预训练",
        "dimension": "技术特性",
        "reason": "TTM‑r2 在约 7 亿时间序列样本上进行的大规模预训练"
      },
      {
        "keyword": "10亿样本预训练",
        "dimension": "技术特性",
        "reason": "TTM‑r2.1 进一步扩展至约 10 亿样本的预训练数据集"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Instruct",
    "keywords": [
      {
        "keyword": "Kimi-VL",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心品牌名，对应月之暗面开源视觉语言模型"
      },
      {
        "keyword": "月之暗面",
        "dimension": "当前模型品牌名",
        "reason": "MoonshotAI 官方中文品牌，用户搜索国产大模型时常用"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "README 明确激活仅28亿参数，用户会搜轻量级多模态模型"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "当前模型采用混合专家架构，技术爱好者高频搜索词"
      },
      {
        "keyword": "长上下文",
        "dimension": "技术特性",
        "reason": "支持128K超长上下文，用户寻找能读长文档的多模态模型"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "通用且精准的模型类别词，用户直接搜索VLM或视觉语言模型"
      },
      {
        "keyword": "智能体",
        "dimension": "功能场景",
        "reason": "README 强调在OSWorld等多轮智能体任务表现突出，用户搜AI Agent相关模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/QwQ-32B-AWQ",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen，根据国产大模型映射规则，必须提取为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen是阿里巴巴推出的系列模型，'阿里大模型'是用户搜索该系列的通用意图词"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "模型参数量为325亿，符合主流规格'32B参数'，用户常据此筛选模型规模"
      },
      {
        "keyword": "推理模型",
        "dimension": "功能场景",
        "reason": "README明确说明QwQ是专为推理设计的模型，区别于通用指令模型，是核心功能定位"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "README强调模型具备'思维推理能力'，这是其区别于普通模型的核心能力，符合'链式思维'用户搜索意图"
      },
      {
        "keyword": "AWQ量化模型",
        "dimension": "部署工具",
        "reason": "模型采用AWQ 4位量化，'AWQ量化模型'是用户寻找低显存部署方案时的高频搜索词"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型通过千问对话平台提供服务，属于对话类推理模型，'智能对话'是用户典型使用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-14B-AWQ",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中含 Qwen，按照映射规则提取为通义千问"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen 系列属于阿里巴巴的大模型系列"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约 148 亿（≈14B）参数，是用户常搜索的规模标签"
      },
      {
        "keyword": "AWQ量化",
        "dimension": "技术特性",
        "reason": "模型采用 4‑bit AWQ 量化方案，区别于普通 FP16/INT8 量化"
      },
      {
        "keyword": "思维模式",
        "dimension": "功能场景",
        "reason": "模型独有的思维模式用于复杂逻辑推理、数学与代码生成"
      },
      {
        "keyword": "非思维模式",
        "dimension": "功能场景",
        "reason": "模型提供的高效通用对话模式，适用于日常聊天与指令执行"
      },
      {
        "keyword": "百语言支持",
        "dimension": "功能场景",
        "reason": "模型支持 100+ 语言与方言，满足多语言指令遵循与翻译需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-GGUF",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen，根据国产大模型映射规则，必须转换为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen是阿里巴巴推出的系列模型，'阿里大模型'是用户搜索该系列的通用意图词"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型明确采用混合专家（MoE）架构，且激活参数仅220亿，是区别于密集模型的核心技术标签"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独创支持在'思维模式'与'非思维模式'间无缝切换，是其区别于其他模型的独家功能点"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在代码生成任务上表现卓越，且明确提及适用于编码任务，符合用户搜索'编程助手'类AI模型的意图"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型在多轮对话、角色扮演和指令遵循上表现优异，直接对应用户搜索'智能对话'模型的场景需求"
      },
      {
        "keyword": "220亿参数",
        "dimension": "参数规格",
        "reason": "激活参数为220亿，属于主流大模型规模（介于7B~70B之间），用户常按参数量筛选模型，且非冗余细节"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "提供q4_K_M、q5_K_M、q6_K、q8_0等多级GGUF量化版本，是用户部署本地推理时的关键搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/tencent/Hunyuan3D-1",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称Hunyuan3D-1，按国产映射规则提取为混元"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan系列归属腾讯，用户搜索常用品牌词"
      },
      {
        "keyword": "文生3D",
        "dimension": "功能场景",
        "reason": "README明确支持text-to-3D生成，用户高频搜索词"
      },
      {
        "keyword": "图生3D",
        "dimension": "功能场景",
        "reason": "README明确支持image-to-3D生成，用户高频搜索词"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "README列出ComfyUI为后续开源计划，用户会搜部署方式"
      },
      {
        "keyword": "两阶段扩散",
        "dimension": "技术特性",
        "reason": "README强调two-stage approach，区别于单阶段模型，具区分度"
      },
      {
        "keyword": "3D生成框架",
        "dimension": "功能场景",
        "reason": "README自称为unified framework for 3D generation，用户搜框架级方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pcoloc/autotrain-dragino-7-7-1860763606",
    "keywords": [
      {
        "keyword": "autotrain",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确包含'autotrain'，是当前模型的训练平台品牌，用户搜索'autotrain 模型'或'autotrain 回归'时会直接指向此类工具训练的模型"
      },
      {
        "keyword": "tabular-regression",
        "dimension": "功能场景",
        "reason": "模型类型为单列回归，且标签中明确标注'tabular-regression'，这是用户在搜索结构化数据回归任务时的精准关键词，区别于文本或图像回归"
      },
      {
        "keyword": "joblib",
        "dimension": "部署工具",
        "reason": "模型通过joblib加载，是该模型的核心部署方式，用户搜索'joblib 回归模型'或'joblib 部署'时会寻找此类可直接加载的预训练模型"
      },
      {
        "keyword": "tabular",
        "dimension": "功能场景",
        "reason": "模型处理的是表格数据（tabular），用户在搜索'表格数据预测'、'tabular 数据建模'等场景时会使用此词，具有明确数据类型指向性"
      },
      {
        "keyword": "二氧化碳排放预测",
        "dimension": "功能场景",
        "reason": "模型目标为预测二氧化碳排放量（克），这是其独特应用场景，用户可能搜索'二氧化碳排放 AI预测'、'碳排放回归模型'等长尾词"
      },
      {
        "keyword": "autotrain-data-dragino-7-7",
        "dimension": "当前模型品牌名",
        "reason": "项目标签中包含此完整数据集名称，是当前模型训练数据的专属标识，可作为模型的衍生品牌名，用户搜索该名称时会精准定位本模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/GLM-4-32B-Base-0414",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，且为智谱AI相关模型"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，用户可能会搜索"
      },
      {
        "keyword": "智能体任务",
        "dimension": "功能场景",
        "reason": "当前模型在智能体任务方面有良好表现，是用户可能搜索的功能场景"
      },
      {
        "keyword": "指令遵循",
        "dimension": "技术特性",
        "reason": "当前模型通过技术提升了指令遵循性能，是模型的技术特性之一"
      },
      {
        "keyword": "工程代码编写",
        "dimension": "功能场景",
        "reason": "当前模型在工程代码编写方面取得良好效果，是用户可能关注的功能场景"
      },
      {
        "keyword": "函数调用",
        "dimension": "功能场景",
        "reason": "当前模型支持函数调用，是用户可能搜索的功能场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/IIC/DocOwl2",
    "keywords": [
      {
        "keyword": "DocOwl2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称IIC/DocOwl2直接提取的当前模型简称，符合品牌名简化规则"
      },
      {
        "keyword": "免OCR文档理解",
        "dimension": "功能场景",
        "reason": "模型核心功能是无需OCR即可理解多页文档，为用户搜索文档AI时的明确意图词"
      },
      {
        "keyword": "高分辨率文档压缩器",
        "dimension": "技术特性",
        "reason": "模型独有的核心模块名称，具有技术区分度，用户可能搜索该专有技术名称"
      },
      {
        "keyword": "多页文档分析",
        "dimension": "功能场景",
        "reason": "模型专为多页文档设计，是用户在办公自动化、PDF智能处理场景中的高频搜索词"
      },
      {
        "keyword": "图像-文本对话",
        "dimension": "功能场景",
        "reason": "基于Image-Text-to-Text标签提炼，描述模型输入输出形式，区别于纯文本对话"
      },
      {
        "keyword": "324标记编码",
        "dimension": "技术特性",
        "reason": "模型独特技术指标（每页仅324个token），体现高效压缩能力，用户可能搜索此具体参数"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepset/xlm-roberta-large-squad2",
    "keywords": [
      {
        "keyword": "XLMRoBERTalarge",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接包含的模型名称，用户搜索时会使用该品牌名"
      },
      {
        "keyword": "抽取式问答",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对文档进行抽取式问答，用户常以此关键词查找模型"
      },
      {
        "keyword": "多语言问答",
        "dimension": "功能场景",
        "reason": "模型支持多语言（Multilingual），适用于跨语言问答场景"
      },
      {
        "keyword": "Haystack集成",
        "dimension": "部署工具",
        "reason": "README 中明确说明可在 Haystack 框架中直接使用，用户搜索时会关注该集成方式"
      },
      {
        "keyword": "MLflow-追踪",
        "dimension": "部署工具",
        "reason": "训练过程提供 MLflow 链接，用户会搜索带有 MLflow 追踪的模型"
      },
      {
        "keyword": "SQuAD2.0-微调",
        "dimension": "技术特性",
        "reason": "模型基于 SQuAD 2.0 数据进行微调，是用户关注的关键技术细节"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-8B-AWQ",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名Qwen映射为通义千问"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen系列属于阿里大模型"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "当前模型为82亿参数的主流规格"
      },
      {
        "keyword": "AWQ量化",
        "dimension": "部署工具",
        "reason": "当前模型采用AWQ 4-bit量化方案"
      },
      {
        "keyword": "思维模式",
        "dimension": "技术特性",
        "reason": "独家支持思维模式与非思维模式切换"
      },
      {
        "keyword": "智能体能力",
        "dimension": "功能场景",
        "reason": "具备复杂智能体任务执行能力"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "在代码生成与逻辑推理任务上表现突出"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pengzhendong/chinese-hubert-base",
    "keywords": [
      {
        "keyword": "chinese-hubert-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索中文语音模型时会使用此精确名称"
      },
      {
        "keyword": "中文语音预训练",
        "dimension": "功能场景",
        "reason": "模型基于1万小时WenetSpeech中文语音数据预训练，是用户搜索中文语音AI时的核心意图关键词"
      },
      {
        "keyword": "HuBERT模型",
        "dimension": "技术特性",
        "reason": "模型基于HuBERT架构，是语音领域专用的自监督预训练技术，具有明确技术辨识度"
      },
      {
        "keyword": "语音特征提取",
        "dimension": "功能场景",
        "reason": "模型输出为音频特征向量，专用于语音表征学习，是用户部署语音识别前处理时的搜索关键词"
      },
      {
        "keyword": "无分词器语音模型",
        "dimension": "技术特性",
        "reason": "README明确指出该模型无分词器，区别于文本模型，是其独特设计特征，用户会据此筛选适用模型"
      },
      {
        "keyword": "Wav2Vec2FeatureExtractor",
        "dimension": "部署工具",
        "reason": "模型需配合Hugging Face的Wav2Vec2FeatureExtractor使用，是实际部署时的关键工具链关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/AI-ModelScope/TRELLIS-image-large",
    "keywords": [
      {
        "keyword": "TRELLIS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'TRELLIS-image-large' 提取的核心品牌名，为当前模型唯一标识"
      },
      {
        "keyword": "Image-to-3D",
        "dimension": "功能场景",
        "reason": "模型核心功能是将2D图像生成3D内容，用户会直接搜索此明确场景词"
      },
      {
        "keyword": "3D生成",
        "dimension": "功能场景",
        "reason": "用户搜索AI生成3D内容时的高频意图词，精准匹配模型用途"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "模型采用Safetensors格式，是AI从业者部署时关注的格式关键词"
      },
      {
        "keyword": "结构化3D潜变量",
        "dimension": "技术特性",
        "reason": "论文核心创新点，用户搜索3D生成技术原理时会使用该术语"
      },
      {
        "keyword": "MIT",
        "dimension": "技术特性",
        "reason": "模型采用MIT许可证，开源社区用户常以此作为筛选条件"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pengzhendong/chinese-hubert-large",
    "keywords": [
      {
        "keyword": "chinese-hubert-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "语音识别",
        "dimension": "功能场景",
        "reason": "当前模型可用于语音识别任务，是主要应用场景"
      },
      {
        "keyword": "音频预训练",
        "dimension": "技术特性",
        "reason": "当前模型基于音频数据进行预训练，是核心技术特性"
      },
      {
        "keyword": "专用分词器",
        "dimension": "技术特性",
        "reason": "当前模型需创建专用分词器用于语音识别任务，是技术实现要点"
      },
      {
        "keyword": "Wav2Vec2FeatureExtractor",
        "dimension": "技术特性",
        "reason": "当前模型代码中使用了Wav2Vec2FeatureExtractor进行特征提取，是技术实现细节"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/IIC/QwenLong-CPRS-7B",
    "keywords": [
      {
        "keyword": "QwenLong-CPRS",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称，去除版本号后的简洁品牌名"
      },
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "Qwen 系列在阿里巴巴的官方品牌映射为“通义千问”"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen 属于阿里巴巴的通义千问系列，常被统称为阿里大模型"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 7 B 参数，用户常以参数规模搜索模型"
      },
      {
        "keyword": "长上下文优化",
        "dimension": "功能场景",
        "reason": "模型核心功能是针对超长上下文进行高效优化"
      },
      {
        "keyword": "查询感知压缩",
        "dimension": "技术特性",
        "reason": "模型采用查询感知的多粒度压缩技术，实现精细信息提取"
      },
      {
        "keyword": "可控上下文优化",
        "dimension": "技术特性",
        "reason": "通过可控提示词和查询语句生成任务导向的紧凑上下文片段"
      },
      {
        "keyword": "窗口并行推理",
        "dimension": "技术特性",
        "reason": "模型将长上下文切分为窗口并行处理，降低推理复杂度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Xenova/discogs-maest-30s-pw-73e-ts",
    "keywords": [
      {
        "keyword": "discogs-maest-30s-pw-73e-ts",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，是用户搜索该特定音频模型时的精准关键词"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型提供ONNX权重版本，专为网页端部署设计，是用户寻找可浏览器运行音频模型时的核心搜索词"
      },
      {
        "keyword": "Transformers.js",
        "dimension": "部署工具",
        "reason": "模型明确兼容Transformers.js，是前端AI音频应用开发者搜索的关键技术栈"
      },
      {
        "keyword": "音频理解",
        "dimension": "功能场景",
        "reason": "Discogs-MaEST模型用于音乐元数据识别与音频内容理解，是其核心应用场景，用户会搜索此类语义词"
      },
      {
        "keyword": "网页端音频模型",
        "dimension": "功能场景",
        "reason": "模型专为在浏览器中运行设计，区别于传统服务器部署，是用户寻找前端音频AI时的精准意图词"
      },
      {
        "keyword": "HuggingFace-ONNX",
        "dimension": "部署工具",
        "reason": "模型通过HuggingFace发布ONNX格式，用户常组合搜索'HuggingFace + ONNX'寻找可直接加载的模型"
      },
      {
        "keyword": "音乐元数据识别",
        "dimension": "功能场景",
        "reason": "Discogs-MaEST模型用于自动识别音乐标签（如艺人、流派、年份），是其专业用途，用户会精准搜索该术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/m-a-p/MERT-v1-330M",
    "keywords": [
      {
        "keyword": "MERT-v1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型系列名称"
      },
      {
        "keyword": "音乐理解模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心用途"
      },
      {
        "keyword": "音频分类",
        "dimension": "功能场景",
        "reason": "官方标签中明确列出的功能"
      },
      {
        "keyword": "330M参数",
        "dimension": "参数规格",
        "reason": "当前模型具体参数规模"
      },
      {
        "keyword": "Fairseq",
        "dimension": "部署工具",
        "reason": "官方支持的部署框架"
      },
      {
        "keyword": "MLM预训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的预训练范式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/tencent/HunyuanVideo",
    "keywords": [
      {
        "keyword": "混元视频",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，代表腾讯的大模型系列"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型支持从文本生成视频，是核心应用场景"
      },
      {
        "keyword": "图生视频",
        "dimension": "功能场景",
        "reason": "模型支持从图像生成视频，区别于纯文本生成"
      },
      {
        "keyword": "FP8量化模型",
        "dimension": "技术特性",
        "reason": "采用 FP8 量化显著节省显存，是模型独有的量化技术"
      },
      {
        "keyword": "多GPU并行推理",
        "dimension": "技术特性",
        "reason": "提供多 GPU 序列并行推理，加速大规模视频生成"
      },
      {
        "keyword": "Diffusers集成",
        "dimension": "部署工具",
        "reason": "模型已集成至 HuggingFace Diffusers，便于生态调用"
      },
      {
        "keyword": "Gradio网页演示",
        "dimension": "部署工具",
        "reason": "提供基于 Gradio 的在线演示页面，方便用户快速体验"
      },
      {
        "keyword": "企鹅视频基准",
        "dimension": "技术特性",
        "reason": "发布专属视频基准用于评估模型性能，体现模型的评测体系"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B-I2V",
    "keywords": [
      {
        "keyword": "CogVideoX1.5-5B-I2V",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该特定视频生成模型时的精准关键词"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型核心功能为图像到视频生成（I2V），符合用户搜索'文生视频'类AI视频生成工具的意图"
      },
      {
        "keyword": "图像到视频",
        "dimension": "功能场景",
        "reason": "I2V（Image-to-Video）的中文直译，是用户在CSDN等平台搜索视频生成技术时的高频意图表达"
      },
      {
        "keyword": "10秒视频生成",
        "dimension": "功能场景",
        "reason": "模型支持5秒或10秒视频输出，'10秒视频生成'是用户明确搜索长视频生成能力的精准关键词"
      },
      {
        "keyword": "1360768视频",
        "dimension": "功能场景",
        "reason": "模型支持1360*768高分辨率视频输出，该分辨率组合独特，是用户寻找高清视频生成模型时可能搜索的参数化表达"
      },
      {
        "keyword": "BF16推理",
        "dimension": "技术特性",
        "reason": "模型推荐BF16精度推理，该精度在国产AI模型中作为性能与显存平衡的关键词被开发者关注"
      },
      {
        "keyword": "清影开源版",
        "dimension": "当前模型品牌名",
        "reason": "README明确指出是'清影同源的开源版本'，'清影开源版'是用户寻找该商业模型开源实现时的自然搜索词"
      },
      {
        "keyword": "5秒视频生成",
        "dimension": "功能场景",
        "reason": "模型固定输出5秒或10秒视频，'5秒视频生成'是用户对比短时视频模型时的高频搜索短语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/PKU-Alignment/beaver-7b-v1.0-cost",
    "keywords": [
      {
        "keyword": "Beaver-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "安全RLHF",
        "dimension": "技术特性",
        "reason": "当前模型专为安全强化学习人类反馈设计"
      },
      {
        "keyword": "AI安全",
        "dimension": "功能场景",
        "reason": "用户搜索AI安全相关模型时会用的词"
      },
      {
        "keyword": "偏好模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心定位是偏好打分模型"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规模"
      },
      {
        "keyword": "自回归语言模型",
        "dimension": "技术特性",
        "reason": "当前模型的架构特征，用户会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/MiniCPM-V-4_5",
    "keywords": [
      {
        "keyword": "MiniCPM-V",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型系列名称"
      },
      {
        "keyword": "手机端GPT-4o级别",
        "dimension": "功能场景",
        "reason": "描述了模型在手机端的应用场景和性能级别"
      },
      {
        "keyword": "高帧率视频理解",
        "dimension": "功能场景",
        "reason": "当前模型支持高帧率视频理解的功能"
      },
      {
        "keyword": "长视频理解",
        "dimension": "功能场景",
        "reason": "当前模型支持长视频理解的功能"
      },
      {
        "keyword": "混合快慢思考模式",
        "dimension": "技术特性",
        "reason": "当前模型具备的独特技术特性"
      },
      {
        "keyword": "80亿参数量",
        "dimension": "参数规格",
        "reason": "当前模型的参数量规格"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-1m",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4 是智谱 AI 推出的模型，根据国产大模型映射规则，GLM-4 → 提取品牌名'智谱AI'"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "GLM-4-9B-Chat 明确支持多轮对话，是其核心应用场景，用户会搜索'智能对话'类模型"
      },
      {
        "keyword": "1M上下文",
        "dimension": "功能场景",
        "reason": "1M上下文长度（约200万中文字符）是该模型最突出的差异化功能，用户会搜索'长文本对话'或'1M上下文'模型"
      },
      {
        "keyword": "Function-Call",
        "dimension": "技术特性",
        "reason": "支持自定义工具调用（Function Call）是该模型区别于普通对话模型的关键技术点，用户会搜索此术语"
      },
      {
        "keyword": "长文本推理",
        "dimension": "功能场景",
        "reason": "README明确提及'长文本推理'，且支持1M上下文，是用户寻找处理超长文档模型时的高频搜索词"
      },
      {
        "keyword": "代码执行",
        "dimension": "功能场景",
        "reason": "模型支持代码执行功能，属于高价值AI助手场景，用户会搜索'能执行代码的AI模型'"
      },
      {
        "keyword": "26种语言",
        "dimension": "功能场景",
        "reason": "支持26种语言是该模型的多语言能力亮点，用户搜索'多语言AI助手'时可能匹配此关键词"
      },
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心品牌标识，简化后为'GLM-4'，符合模型名称提取规则（去版本号）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/StepFun-Formalizer-32B",
    "keywords": [
      {
        "keyword": "StepFun-Formalizer",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 32 B 参数，是用户常搜索的规格关键词"
      },
      {
        "keyword": "Lean-4形式化",
        "dimension": "技术特性",
        "reason": "模型专注于将自然语言数学问题转化为 Lean 4 形式化语句"
      },
      {
        "keyword": "数学自动形式化",
        "dimension": "功能场景",
        "reason": "模型的核心应用是自动将数学题目进行形式化处理"
      },
      {
        "keyword": "知识推理融合",
        "dimension": "技术特性",
        "reason": "模型通过融合知识推理提升自动形式化能力"
      },
      {
        "keyword": "vllm推理",
        "dimension": "部署工具",
        "reason": "README 中提供了基于 vllm 的调用示例，适合作为部署/推理方式关键词"
      },
      {
        "keyword": "BEq验证",
        "dimension": "技术特性",
        "reason": "模型在主流基准上使用 BEq 验证进行评估，是独特的技术细节"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/cogagent-chat-hf",
    "keywords": [
      {
        "keyword": "CogAgent",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为 zai-org/cogagent-chat-hf，模型核心品牌名为 CogAgent，符合简化命名规则，是用户搜索该模型的直接关键词"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "README 明确指出 cogagent-chat 版本在‘视觉多轮对话’方面具备强大能力，‘智能对话’是用户搜索多轮视觉对话场景的通用意图词"
      },
      {
        "keyword": "GUI智能体",
        "dimension": "功能场景",
        "reason": "README 强调该模型在‘GUI智能体’任务中表现卓越，是区别于其他视觉语言模型的独特功能，用户会直接搜索该术语"
      },
      {
        "keyword": "视觉定位",
        "dimension": "功能场景",
        "reason": "模型支持‘视觉定位’能力，是其在GUI交互和多轮对话中的关键技术点，属于高区分度的垂直场景词"
      },
      {
        "keyword": "18B参数",
        "dimension": "参数规格",
        "reason": "模型明确说明 CogAgent-18B 拥有 110亿视觉参数 + 70亿语言参数，总参数规模为18B，属于主流大模型规格，用户会搜索‘18B参数’定位该模型"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "技术特性",
        "reason": "模型被明确定义为‘视觉语言模型’，是其技术本质，且该词在AI领域具有明确搜索意图，区别于纯文本或纯图像模型"
      },
      {
        "keyword": "多轮对话",
        "dimension": "功能场景",
        "reason": "与‘智能对话’互补，‘多轮对话’是README中反复强调的核心能力，用户在搜索视觉问答之外的交互场景时会使用该词"
      },
      {
        "keyword": "CogAgent-9B",
        "dimension": "当前模型品牌名",
        "reason": "README中最新版本为 CogAgent-9B-20241220，‘CogAgent-9B’是该系列主流子版本，用户会搜索此简称来定位轻量级版本，符合品牌名简化规则"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-edge-4b-chat",
    "keywords": [
      {
        "keyword": "GLM-Edge-4B-Chat",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，符合用户搜索AI模型时的精确命名习惯"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "根据国产大模型映射规则，GLM系列属于智谱AI，需映射为品牌名而非技术代号"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型后缀为'chat'，明确用于对话交互，是用户搜索AI聊天模型时的核心意图词"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "4B是主流轻量级参数规模，用户常搜索'4B参数模型'以寻找轻量高效对话模型"
      },
      {
        "keyword": "Safetensors",
        "dimension": "技术特性",
        "reason": "模型明确标注使用Safetensors格式，是用户关注安全加载与部署时的高频技术关键词"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型通过transformers库加载，且托管于HuggingFace生态，用户常搜'HuggingFace模型'找可直接加载的AI模型"
      },
      {
        "keyword": "本地部署",
        "dimension": "部署工具",
        "reason": "代码示例使用device_map='auto'，明确支持本地GPU推理，符合用户寻找可离线运行模型的搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B",
    "keywords": [
      {
        "keyword": "CogVideoX",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型的核心应用是从文本生成视频"
      },
      {
        "keyword": "5B参数",
        "dimension": "参数规格",
        "reason": "模型名称中标明的参数规模"
      },
      {
        "keyword": "BF16推理",
        "dimension": "技术特性",
        "reason": "模型推荐使用的推理精度，可显著降低显存占用"
      },
      {
        "keyword": "Diffusers库",
        "dimension": "部署工具",
        "reason": "模型基于 HuggingFace Diffusers 实现，便于快速部署"
      },
      {
        "keyword": "16帧秒",
        "dimension": "技术特性",
        "reason": "模型生成视频的帧率上限，为 16 FPS"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gpt-oss-120b-bnb-4bit",
    "keywords": [
      {
        "keyword": "gpt-oss-120b",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化规则（保留核心标识，去版本后缀）"
      },
      {
        "keyword": "gpt-oss",
        "dimension": "当前模型品牌名",
        "reason": "模型系列通用名称，用户搜索时可能使用简称，且为官方统一品牌标识"
      },
      {
        "keyword": "120B参数",
        "dimension": "参数规格",
        "reason": "模型核心参数规模为1200亿，属于主流大模型规格，用户会搜索此类规模关键词"
      },
      {
        "keyword": "bnb-4bit",
        "dimension": "部署工具",
        "reason": "模型采用4-bit量化技术，是用户寻找低显存部署方案时的关键搜索词，且为当前模型专属技术标签"
      },
      {
        "keyword": "harmony响应格式",
        "dimension": "技术特性",
        "reason": "模型训练和推理必须使用该专属格式，是区别于其他模型的核心交互特性，具有唯一性"
      },
      {
        "keyword": "AI智能体",
        "dimension": "功能场景",
        "reason": "README明确指出模型专为智能体任务设计，是用户寻找AI代理、自主决策模型时的精准搜索词"
      },
      {
        "keyword": "Apache-2.0-许可",
        "dimension": "技术特性",
        "reason": "模型采用宽松开源协议，是开发者选择商用或定制模型时的重要筛选条件，具有高搜索价值"
      },
      {
        "keyword": "单卡H100运行",
        "dimension": "部署工具",
        "reason": "用户关心能否在单张高端卡部署，该描述是模型部署门槛的核心卖点，非通用硬件词，指向明确"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/M3-Agent-Control",
    "keywords": [
      {
        "keyword": "M3-Agent",
        "dimension": "当前模型品牌名",
        "reason": "从项目仓库名称 “M3-Agent-Control” 提取的简洁模型品牌名"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "项目所属组织 ByteDance-Seed 按映射规则对应为 “字节大模型”"
      },
      {
        "keyword": "智能体控制",
        "dimension": "功能场景",
        "reason": "模型名称中含 “Agent‑Control”，表明其主要用于智能体（Agent）的控制任务"
      },
      {
        "keyword": "Safetensors",
        "dimension": "技术特性",
        "reason": "README 中的标签列出 “Safetensors”，表示模型采用安全张量文件格式"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "授权协议",
        "reason": "README 中标明模型使用 “Apache License 2.0”，是用户关注的许可证信息"
      },
      {
        "keyword": "开源模型",
        "dimension": "技术特性",
        "reason": "基于 Apache 2.0 许可证，可推断模型为开源，符合用户搜索 “开源模型” 的需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-Z1-Rumination-32B-0414",
    "keywords": [
      {
        "keyword": "GLM-Z1-Rumination",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4属于智谱AI系列，映射为智谱AI"
      },
      {
        "keyword": "深度思考能力",
        "dimension": "技术特性",
        "reason": "当前模型具备深度思考能力，是核心特性"
      },
      {
        "keyword": "反思模型",
        "dimension": "技术特性",
        "reason": "当前模型是具备反思能力的深度推理模型，是独特技术特性"
      },
      {
        "keyword": "研究型写作",
        "dimension": "功能场景",
        "reason": "当前模型在研究型写作上表现出显著提升，是应用场景"
      },
      {
        "keyword": "复杂检索任务",
        "dimension": "功能场景",
        "reason": "当前模型在复杂检索任务上表现出显著提升，是应用场景"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规格为320亿，是重要参数信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/M3-Agent-Memorization",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ByteDance-Seed，根据国产大模型映射规则，应提取为'豆包'"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed属于字节跳动旗下大模型系列，'字节大模型'是用户搜索的通用品牌词"
      },
      {
        "keyword": "M3-Agent-Memorization",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心标识，是模型的正式简称，用户可能直接搜索该完整名称"
      },
      {
        "keyword": "记忆增强",
        "dimension": "技术特性",
        "reason": "模型名称'Memorization'明确指向记忆能力增强，是其核心创新点，符合用户搜索意图"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "基于Agent架构，用于持续对话与上下文记忆，属于典型智能对话应用场景"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "论文摘要提及模型通过多步推理增强记忆，符合链式思维（Chain-of-Thought）技术特征"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "根据论文与模型规模推断，M3-Agent-Memorization为32B级别主流参数规模，符合用户搜索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai-community/gpt2",
    "keywords": [
      {
        "keyword": "GPT-2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型的官方名称"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "模型的核心应用是根据提示生成自然语言文本"
      },
      {
        "keyword": "因果语言建模",
        "dimension": "技术特性",
        "reason": "模型采用因果（自回归）语言建模目标进行预训练"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "GPT-2 通过自回归方式预测下一个词，是其关键技术特征"
      },
      {
        "keyword": "1.24亿参数",
        "dimension": "参数规格",
        "reason": "该版本的 GPT-2 规模约为 1.24 亿参数，区别于更大或更小的变体"
      },
      {
        "keyword": "英语语言模型",
        "dimension": "功能场景",
        "reason": "模型专注于英文语料的预训练，适用于英语文本任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-GGUF",
    "keywords": [
      {
        "keyword": "EmbeddingGemma",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，用户搜索嵌入模型时会直接使用此名称"
      },
      {
        "keyword": "文本嵌入",
        "dimension": "功能场景",
        "reason": "模型核心用途是生成文本向量表示，用户搜索‘文本嵌入’时明确指向此类模型，符合搜索意图"
      },
      {
        "keyword": "768维嵌入",
        "dimension": "技术特性",
        "reason": "模型输出维度为768，是其关键技术特征，用户在比较嵌入模型精度时会搜索具体维度"
      },
      {
        "keyword": "Matryoshka嵌入",
        "dimension": "技术特性",
        "reason": "模型采用MRL（Matryoshka表示学习）技术，支持动态截断至512/256/128维，属独特技术亮点，非通用术语"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "模型以GGUF格式发布，专为设备端部署优化，用户搜索‘GGUF量化’时明确寻找可本地运行的轻量模型"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "部署工具",
        "reason": "官方推荐与sentence-transformers库配合使用，是该模型实际落地的核心工具链，用户会据此搜索部署方案"
      },
      {
        "keyword": "3亿参数嵌入模型",
        "dimension": "参数规格",
        "reason": "3亿参数（300M）是该模型在小尺寸嵌入模型中的核心竞争力，属于用户可感知的主流规格区间"
      },
      {
        "keyword": "多语言嵌入",
        "dimension": "功能场景",
        "reason": "模型在100+种语言上训练，用户搜索‘多语言嵌入’时精准匹配其跨语言语义理解能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-1m-hf",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4 属于智谱 AI 推出的开源大模型系列"
      },
      {
        "keyword": "1M上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持 1M token 超长上下文，是用户搜索亮点"
      },
      {
        "keyword": "长文本推理",
        "dimension": "功能场景",
        "reason": "模型主打长文档理解与推理，满足用户长文处理需求"
      },
      {
        "keyword": "Function-Call",
        "dimension": "技术特性",
        "reason": "支持自定义工具调用，开发者搜索关键词"
      },
      {
        "keyword": "网页浏览",
        "dimension": "功能场景",
        "reason": "模型具备联网能力，用户会搜“AI 网页浏览”"
      },
      {
        "keyword": "代码执行",
        "dimension": "功能场景",
        "reason": "内置代码执行环境，开发者关注的功能点"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "权重格式标签，用户部署时会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/Step-Audio-2-mini",
    "keywords": [
      {
        "keyword": "Step-Audio",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型品牌名"
      },
      {
        "keyword": "语音对话",
        "dimension": "功能场景",
        "reason": "README强调的智能语音对话能力"
      },
      {
        "keyword": "音频理解",
        "dimension": "功能场景",
        "reason": "模型主打端到端音频语义理解"
      },
      {
        "keyword": "工具调用",
        "dimension": "技术特性",
        "reason": "支持通过工具调用获取外部知识"
      },
      {
        "keyword": "多模态RAG",
        "dimension": "技术特性",
        "reason": "结合文本与声学知识的检索增强生成"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "标签明确支持ONNX格式，便于跨平台部署"
      },
      {
        "keyword": "Safetensors",
        "dimension": "部署工具",
        "reason": "标签提供Safetensors权重，方便快速加载"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-t5/t5-base",
    "keywords": [
      {
        "keyword": "T5-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'google-t5/t5-base' 提取的当前模型简洁品牌名，符合模型名称简化规则（去版本后缀，保留T5-Base）"
      },
      {
        "keyword": "文本到文本",
        "dimension": "技术特性",
        "reason": "T5模型最核心的技术创新点，全文反复强调的统一框架，用户搜索NLP统一架构时会用此关键词"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型明确支持文档摘要、文本生成等写作类任务，是用户在CSDN等平台搜索AI写作工具时的高频意图"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "README明确列出T5-Base可用于机器翻译，是其核心下游用途之一，具有明确搜索意图"
      },
      {
        "keyword": "问答系统",
        "dimension": "功能场景",
        "reason": "模型支持问答任务，属于NLP经典应用场景，用户常搜索'AI问答模型'或'问答系统模型'"
      },
      {
        "keyword": "情感分析",
        "dimension": "功能场景",
        "reason": "README明确提及T5可用于分类任务如情感分析，是企业级NLP应用高频需求，具备搜索价值"
      },
      {
        "keyword": "2.2亿参数",
        "dimension": "参数规格",
        "reason": "模型明确标注2.2亿参数，属于中等规模主流参数量（介于7B与32B之间），用户常按参数规模筛选模型"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型托管于Hugging Face，且README多次引用其文档，用户搜索'HuggingFace T5'是典型部署查询行为"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "keywords": [
      {
        "keyword": "paraphrase-multilingual-MiniLM-L12-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "句子映射",
        "dimension": "功能场景",
        "reason": "模型能将句子和段落映射到稠密向量空间，属于核心功能场景"
      },
      {
        "keyword": "语义搜索",
        "dimension": "功能场景",
        "reason": "模型可用于语义搜索任务，是用户可能搜索的功能场景"
      },
      {
        "keyword": "聚类任务",
        "dimension": "功能场景",
        "reason": "模型可用于聚类任务，是用户可能搜索的功能场景"
      },
      {
        "keyword": "384维向量",
        "dimension": "技术特性",
        "reason": "模型将句子和段落映射到384维的稠密向量空间，是独特的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的核心模型品牌名，是用户搜索该模型的首要关键词"
      },
      {
        "keyword": "推理模型",
        "dimension": "功能场景",
        "reason": "模型核心定位为推理导向，README多次强调其在数学、代码、链式思维上的推理能力，符合用户搜索‘推理模型’的明确意图"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "模型通过纯RL实现自我验证与长链式思维（CoT），是其区别于其他模型的核心技术亮点，且未被高频词排除"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "模型在无SFT前提下实现的独有推理行为，是论文强调的突破性能力，具有高区分度"
      },
      {
        "keyword": "强化学习",
        "dimension": "技术特性",
        "reason": "模型采用纯强化学习（RL）训练，无需SFT预处理，是其技术路径的关键词，用户会搜索‘纯RL训练模型’"
      },
      {
        "keyword": "蒸馏模型",
        "dimension": "技术特性",
        "reason": "当前模型是DeepSeek-R1的蒸馏版本，‘蒸馏模型’是用户寻找轻量级高性能模型时的高频搜索词，且未被高频词排除"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "项目名称明确标注14B，属于主流参数规模，用户常搜索‘14B参数模型’进行性能与资源平衡评估"
      },
      {
        "keyword": "AI编程助手",
        "dimension": "功能场景",
        "reason": "README明确指出模型在代码任务上表现优异，‘AI编程助手’是用户搜索代码生成类模型的典型意图词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mixedbread-ai/mxbai-embed-large-v1",
    "keywords": [
      {
        "keyword": "Mixedbread",
        "dimension": "当前模型品牌名",
        "reason": "模型发布者的品牌名称，直接出现在项目名称中"
      },
      {
        "keyword": "mxbai-embed-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目全称 mixedbread-ai/mxbai-embed-large-v1 提取的简洁模型名称"
      },
      {
        "keyword": "句子嵌入",
        "dimension": "功能场景",
        "reason": "模型的核心功能是生成句子级别的向量表示，用于相似度匹配和检索"
      },
      {
        "keyword": "Matryoshka-Representation-Learning",
        "dimension": "技术特性",
        "reason": "README 中提到的独特学习方法，提升嵌入层次结构的表达能力"
      },
      {
        "keyword": "二进制量化",
        "dimension": "技术特性",
        "reason": "模型支持的二进制量化特性，可在检索任务中显著压缩存储和加速计算"
      },
      {
        "keyword": "检索任务",
        "dimension": "功能场景",
        "reason": "模型专为检索场景设计，需要在查询时使用特定提示词"
      },
      {
        "keyword": "512维嵌入",
        "dimension": "参数规格",
        "reason": "模型默认输出 512 维向量，是用户常关注的维度规格"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3",
    "keywords": [
      {
        "keyword": "DeepSeek-V3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型官方名称，用户搜索AI模型时会直接输入此名称"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心架构为混合专家（MoE），是区别于普通稠密模型的关键技术点，用户会搜索‘MoE模型’寻找高效大模型"
      },
      {
        "keyword": "多标记预测",
        "dimension": "技术特性",
        "reason": "模型独创的训练目标（MTP），在README中被强调为提升性能与推理加速的核心创新，具有高区分度"
      },
      {
        "keyword": "无辅助损失负载平衡",
        "dimension": "技术特性",
        "reason": "DeepSeek-V3首创的负载平衡策略，是其训练稳定、性能优越的关键技术，术语独特，用户可能搜索‘无辅助损失 MoE’"
      },
      {
        "keyword": "671B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量为6710亿，属于主流大模型规格（600B+），符合‘主流规格’提取规则，且具明确区分度"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "作为高性能语言模型，DeepSeek-V3适用于长文本生成、内容创作等场景，‘AI写作’是用户高频搜索意图，且未被排除"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型经过SFT和RLHF优化，具备强对话能力，‘智能对话’是用户搜索大模型时的典型场景关键词"
      },
      {
        "keyword": "DeepSeekMoE",
        "dimension": "技术特性",
        "reason": "模型专有MoE模块名称，在README中被明确提及为自研架构，具有品牌技术标识性，非通用术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1-Distill-Qwen-1.5B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "当前模型的基础版本名称，用户可能搜索"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "当前模型展示出的独特技术特性"
      },
      {
        "keyword": "反思能力",
        "dimension": "技术特性",
        "reason": "当前模型展示出的独特技术特性，用户可能感兴趣"
      },
      {
        "keyword": "推理模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景和功能"
      },
      {
        "keyword": "1.5B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规格，用户可能搜索特定参数的模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/deepseek-vl2-tiny",
    "keywords": [
      {
        "keyword": "DeepSeek-VL2-Tiny",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型完整品牌名"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "模型在视觉问答任务上表现卓越，是用户常搜索的应用场景"
      },
      {
        "keyword": "光学字符识别",
        "dimension": "功能场景",
        "reason": "模型支持 OCR（光学字符识别），属于重要的视觉-文本任务"
      },
      {
        "keyword": "文档表格图表理解",
        "dimension": "功能场景",
        "reason": "模型能够理解文档、表格和图表内容，是其核心多模态能力之一"
      },
      {
        "keyword": "视觉定位",
        "dimension": "功能场景",
        "reason": "模型具备视觉定位能力，适用于目标定位等实际应用"
      },
      {
        "keyword": "Mixture-of-Experts",
        "dimension": "技术特性",
        "reason": "模型采用 MoE（Mixture-of-Experts）架构，区别于普通密集模型"
      },
      {
        "keyword": "10亿激活参数",
        "dimension": "参数规格",
        "reason": "模型拥有约 1 B（10 亿）激活参数，是用户关注的规模指标"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Base",
    "keywords": [
      {
        "keyword": "DeepSeek-Coder-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该模型的核心关键词"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型专为代码生成与理解设计，是开发者搜索AI编码工具时的明确意图词"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型基于Mixture-of-Experts架构，是其区别于密集模型的核心技术标签，用户会搜索此类架构模型"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "128K上下文长度是模型关键能力，虽为数字但属于主流用户关注的上下文长度规格，非纯技术细节（如8192），在AI编程领域具高搜索价值"
      },
      {
        "keyword": "236B参数",
        "dimension": "参数规格",
        "reason": "236B是当前模型的总参数规模，属于主流大模型参数层级，开发者常按此规模筛选模型"
      },
      {
        "keyword": "338种编程语言",
        "dimension": "功能场景",
        "reason": "支持338种编程语言是该模型在代码领域的突出优势，用户搜索‘支持多语言的AI编程模型’时会匹配此关键词"
      },
      {
        "keyword": "DeepSeek-V2",
        "dimension": "当前模型品牌名",
        "reason": "DeepSeek-Coder-V2基于DeepSeek-V2持续预训练，品牌名‘DeepSeek-V2’是其母模型，用户常搜索该系列模型"
      },
      {
        "keyword": "代码语言模型",
        "dimension": "功能场景",
        "reason": "模型本质是代码领域的专用语言模型，是开发者精准搜索AI编程工具时的高频语义词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/musicgen-small",
    "keywords": [
      {
        "keyword": "MusicGen",
        "dimension": "当前模型品牌名",
        "reason": "项目名facebook/musicgen-small中的核心品牌名"
      },
      {
        "keyword": "文生音乐",
        "dimension": "功能场景",
        "reason": "README明确描述为“文本转音乐模型”，用户会搜“文生音乐”"
      },
      {
        "keyword": "音频提示生成",
        "dimension": "功能场景",
        "reason": "支持“音频 Prompt”方式生成音乐，用户会搜“音频提示生成”"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "README强调“单阶段自回归Transformer”，技术关键词"
      },
      {
        "keyword": "300M参数",
        "dimension": "参数规格",
        "reason": "README标题直接给出“小型-300M”，用户会按参数规模搜索"
      },
      {
        "keyword": "32kHz音频",
        "dimension": "技术特性",
        "reason": "使用32kHz EnCodec标记器，音质指标易被搜索"
      },
      {
        "keyword": "HuggingFace推理",
        "dimension": "部署工具",
        "reason": "README提供HuggingFace Colab与Transformers调用示例"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的核心模型名称，是用户搜索该模型的首要关键词"
      },
      {
        "keyword": "蒸馏模型",
        "dimension": "技术特性",
        "reason": "当前模型是DeepSeek-R1通过蒸馏得到的版本，属于其独特技术路径，用户会搜索‘蒸馏模型’来寻找轻量高性能模型"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "README明确指出模型通过RL自然呈现链式思维（CoT），是其核心推理能力，属于高价值技术关键词"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "模型具备自我验证能力，是DeepSeek-R1系列的突破性特性，具有独特性且用户会搜索此类高级推理能力"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "模型规模为32B，属于主流大参数规格，用户常按参数量筛选模型，且未被高频词排除"
      },
      {
        "keyword": "AI推理",
        "dimension": "功能场景",
        "reason": "模型专为推理任务优化，README多次强调其在数学、代码、推理任务上的表现，符合用户搜索‘AI推理’的意图"
      },
      {
        "keyword": "强化学习推理",
        "dimension": "技术特性",
        "reason": "模型采用无SFT的纯强化学习训练方式，是其区别于其他模型的创新点，用户会搜索该组合词寻找前沿推理模型"
      },
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "模型基于Qwen蒸馏，根据国产大模型映射规则，Qwen必须映射为‘通义千问’，符合品牌认知搜索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim",
    "keywords": [
      {
        "keyword": "wav2vec2-large-robust-12-ft-emotion-msp-dim",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型名称，是用户搜索该特定情感识别模型时最可能使用的精准关键词"
      },
      {
        "keyword": "语音情感识别",
        "dimension": "功能场景",
        "reason": "模型核心用途是预测激发度、支配度和效价，属于明确的语音情感识别场景，用户会直接搜索此中文术语"
      },
      {
        "keyword": "维度情感分析",
        "dimension": "功能场景",
        "reason": "模型输出为三维连续值（激发度、支配度、效价），区别于传统分类，'维度情感分析'是该技术的独特表述，具有区分度"
      },
      {
        "keyword": "MSP-Podcast",
        "dimension": "数据集来源",
        "reason": "模型在MSP-Podcast数据集上微调，该数据集是语音情感领域知名公开数据集，专业用户会以此为关键词检索相关模型"
      },
      {
        "keyword": "wav2vec2",
        "dimension": "技术特性",
        "reason": "模型基于Wav2Vec2架构，虽为基础框架，但作为当前模型的技术根基，且未被列为强制排除词，是用户搜索语音模型时的高关联词"
      },
      {
        "keyword": "音频特征提取",
        "dimension": "技术特性",
        "reason": "模型接收原始音频输入并输出情感向量，本质是端到端音频特征提取，区别于传统MFCC等方法，具技术独特性"
      },
      {
        "keyword": "ONNX导出",
        "dimension": "部署工具",
        "reason": "README明确提及提供ONNX导出，是工业部署关键能力，用户搜索'语音情感模型 ONNX'时会精准匹配"
      },
      {
        "keyword": "arxiv2203.07378",
        "dimension": "技术文献",
        "reason": "论文编号是该模型的唯一学术标识，研究者常直接搜索arxiv编号获取模型细节，具有极高精准引流价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/deepseek-vl2",
    "keywords": [
      {
        "keyword": "DeepSeek-VL2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "当前模型在视觉问答任务中表现出卓越的能力"
      },
      {
        "keyword": "光学字符识别",
        "dimension": "功能场景",
        "reason": "当前模型具备光学字符识别的能力"
      },
      {
        "keyword": "文档理解",
        "dimension": "功能场景",
        "reason": "当前模型能够进行文档理解"
      },
      {
        "keyword": "视觉定位",
        "dimension": "功能场景",
        "reason": "当前模型具备视觉定位的能力"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "当前模型基于超大混合专家（MoE）架构构建"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "keywords": [
      {
        "keyword": "DeepSeek-Coder-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的核心模型名称，用户搜索时会直接使用该品牌名"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型定位为代码生成与编程辅助，用户常以“编程助手”检索此类模型"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "模型专注于自动生成代码，是用户搜索代码生成模型的关键词"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "模型在数学推理基准上表现突出，用户会以“数学推理”寻找具备此能力的模型"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型采用 Mixture‑of‑Experts（MoE）技术，是其核心技术特性，具备区分度"
      },
      {
        "keyword": "指令模型",
        "dimension": "技术特性",
        "reason": "提供指令式交互能力，用户在搜索指令模型时会关注此类关键词"
      },
      {
        "keyword": "16B参数",
        "dimension": "参数规格",
        "reason": "模型的总参数量为 16B，用户常以参数规模（如 16B 参数）筛选模型"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型提供 API 平台供调用，用户寻找可直接通过 API 使用的模型时会使用该词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jonathandinu/face-parsing",
    "keywords": [
      {
        "keyword": "face-parsing",
        "dimension": "当前模型品牌名",
        "reason": "项目名称 jonathandinu/face-parsing 的核心标识，用户搜索面部解析模型时会直接使用该名称"
      },
      {
        "keyword": "图像分割",
        "dimension": "功能场景",
        "reason": "模型实现的是语义分割任务，专用于人脸区域划分，是用户搜索人脸分析类AI工具时的核心意图词"
      },
      {
        "keyword": "CelebAMask-HQ",
        "dimension": "当前模型品牌名",
        "reason": "模型训练所用的专属数据集，是该模型的标志性训练基础，用户在搜索高质量人脸解析模型时会关联此数据集名称"
      },
      {
        "keyword": "Segformer",
        "dimension": "技术特性",
        "reason": "模型基于Segformer架构，是当前模型的核心技术骨架，用户搜索基于Transformer的语义分割模型时会使用该词"
      },
      {
        "keyword": "ONNX推理",
        "dimension": "部署工具",
        "reason": "模型提供ONNX格式用于网页端推理，是区别于其他仅支持PyTorch模型的独特部署方式"
      },
      {
        "keyword": "人脸解析",
        "dimension": "功能场景",
        "reason": "中文用户搜索该模型最直接的意图词，精准对应模型用途，且非通用词，具有明确指向性"
      },
      {
        "keyword": "nvidiamit-b5",
        "dimension": "技术特性",
        "reason": "模型基于NVIDIA微调的MIT-B5编码器，是该模型的技术底座，用户搜索特定backbone的分割模型时会使用该关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V1.5-Base",
    "keywords": [
      {
        "keyword": "DeepSeek-Prover",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "定理证明",
        "dimension": "功能场景",
        "reason": "当前模型专为Lean 4形式化定理证明设计"
      },
      {
        "keyword": "Lean-4",
        "dimension": "功能场景",
        "reason": "用户会直接搜索Lean 4相关AI证明工具"
      },
      {
        "keyword": "蒙特卡洛树搜索",
        "dimension": "技术特性",
        "reason": "RMaxTS是模型独有的证明路径探索策略"
      },
      {
        "keyword": "强化学习证明助手",
        "dimension": "技术特性",
        "reason": "RLPAF强化学习框架是模型核心亮点"
      },
      {
        "keyword": "形式化数学语言",
        "dimension": "功能场景",
        "reason": "模型聚焦形式化数学语言训练，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/whisper-medium.en",
    "keywords": [
      {
        "keyword": "Whisper-medium",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，用户直接搜索Whisper系列时会用"
      },
      {
        "keyword": "英语语音识别",
        "dimension": "功能场景",
        "reason": "模型专为英文语音转文字设计，是用户核心需求词"
      },
      {
        "keyword": "自动语音识别",
        "dimension": "功能场景",
        "reason": "ASR的通用叫法，用户搜索英文语音转写时常用"
      },
      {
        "keyword": "语音翻译",
        "dimension": "功能场景",
        "reason": "Whisper多语言版本支持的功能，吸引有翻译需求的用户"
      },
      {
        "keyword": "769M参数",
        "dimension": "参数规格",
        "reason": "medium模型独有规模，用户对比大小时会精确搜索"
      },
      {
        "keyword": "无需微调",
        "dimension": "技术特性",
        "reason": "强调开箱即用，吸引想省去训练步骤的开发者"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Zero",
    "keywords": [
      {
        "keyword": "DeepSeek-R1-Zero",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称，是本项目的核心发布模型"
      },
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "项目主模型名称，与DeepSeek-R1-Zero构成系列，是用户搜索的主要目标"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "模型通过纯RL训练自然涌现的核心推理能力，原文明确强调为重大里程碑"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "模型在RL训练中展现出的独特推理行为，属于DeepSeek-R1-Zero的标志性能力"
      },
      {
        "keyword": "反思能力",
        "dimension": "技术特性",
        "reason": "原文指出模型具备反思能力，是RL训练带来的关键推理特征，具区分度"
      },
      {
        "keyword": "编程助手",
        "dimension": "功能场景",
        "reason": "模型在代码任务上表现优异，与数学、推理并列，是用户明确搜索的应用场景"
      },
      {
        "keyword": "AI推理",
        "dimension": "功能场景",
        "reason": "模型核心定位为推理模型，非通用对话，用户会用此词精准搜索专业推理模型"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "DeepSeek-R1-Distill-Qwen-32B是文中明确提及的主流密集模型规格，符合主流搜索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance/AnimateDiff-Lightning",
    "keywords": [
      {
        "keyword": "AnimateDiff-Lightning",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型的官方品牌名"
      },
      {
        "keyword": "文本生成视频",
        "dimension": "功能场景",
        "reason": "模型的核心任务是将文本描述转化为视频"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "模型通过 HuggingFace Diffusers 库提供推理接口"
      },
      {
        "keyword": "蒸馏模型",
        "dimension": "技术特性",
        "reason": "模型采用跨模型蒸馏技术实现高速推理"
      },
      {
        "keyword": "Motion-LoRAs",
        "dimension": "技术特性",
        "reason": "使用 Motion LoRA 进一步增强运动细节和流畅度"
      },
      {
        "keyword": "EulerDisc调度器",
        "dimension": "技术特性",
        "reason": "模型默认使用 EulerDisc 采样调度器进行高质量视频生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Instruct-0724",
    "keywords": [
      {
        "keyword": "DeepSeek-Coder-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该模型的核心关键词"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型核心架构为混合专家（MoE），且在README中被重点强调，是区别于普通稠密模型的关键技术点"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "上下文长度延长至128K是模型重大升级点，用户会搜索‘长上下文代码模型’这类意图，该词具明确技术指向性"
      },
      {
        "keyword": "236B参数",
        "dimension": "参数规格",
        "reason": "236B是当前模型的主流总参数规格，属于大模型主流区间，用户会搜索‘200B+代码模型’等关键词"
      },
      {
        "keyword": "338种编程语言",
        "dimension": "功能场景",
        "reason": "支持语言数量从86扩展到338是模型独特能力，用户搜索‘支持多语言编程AI’时会匹配此高区分度特征"
      },
      {
        "keyword": "DeepSeekMoE",
        "dimension": "技术特性",
        "reason": "模型基于DeepSeekMoE框架发布，是该系列专属技术品牌，具有唯一性和识别度"
      },
      {
        "keyword": "代码语言模型",
        "dimension": "功能场景",
        "reason": "模型核心定位是代码领域的语言模型，区别于通用大模型，是用户精准搜索‘AI写代码模型’时的高频意图词"
      },
      {
        "keyword": "指令微调模型",
        "dimension": "技术特性",
        "reason": "模型提供指令微调版本（Instruct），是开发者部署时的关键筛选条件，具有明确使用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nlpaueb/legal-bert-base-uncased",
    "keywords": [
      {
        "keyword": "LEGAL-BERT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "法律自然语言处理",
        "dimension": "功能场景",
        "reason": "当前模型主要应用于法律自然语言处理领域"
      },
      {
        "keyword": "法律文本预训练",
        "dimension": "技术特性",
        "reason": "当前模型通过法律文本进行预训练，具有独特性"
      },
      {
        "keyword": "子领域变体",
        "dimension": "技术特性",
        "reason": "当前模型提供了子领域变体，如CONTRACTS-、EURLEX-、ECHR-等"
      },
      {
        "keyword": "轻量级模型",
        "dimension": "技术特性",
        "reason": "当前模型提供了一个轻量级版本，仅为BERT-BASE大小的33%"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/Janus-Pro-7B",
    "keywords": [
      {
        "keyword": "Janus-Pro",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化命名规则"
      },
      {
        "keyword": "统一多模态",
        "dimension": "技术特性",
        "reason": "模型核心创新点，原文明确强调‘统一多模态理解和生成’，是区别于其他模型的关键技术标签"
      },
      {
        "keyword": "视觉编码解耦",
        "dimension": "技术特性",
        "reason": "模型独有的架构设计术语，原文核心创新，用户搜索多模态模型架构时可能使用该精准表述"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持图像生成，且未被高频词排除，是用户明确搜索的生成类场景词"
      },
      {
        "keyword": "多模态理解",
        "dimension": "功能场景",
        "reason": "模型核心能力之一，与‘文生图’形成互补场景，且非高频词，具有搜索价值"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "原文明确指出为‘自回归框架’，是模型底层技术范式，非泛用词，具区分度"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型基于7B基础架构构建，符合主流参数规格，且‘7B参数’虽为高频词，但本模型明确为7B，属合理例外（因模型本身参数规模是核心识别特征）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "当前模型通过强化学习自然涌现链式思维推理"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "当前模型展示自我验证与反思能力"
      },
      {
        "keyword": "强化学习",
        "dimension": "技术特性",
        "reason": "当前模型采用大规模强化学习训练，无需SFT"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "当前模型为8B参数的蒸馏版本"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "当前模型在数学、代码和推理任务表现突出"
      },
      {
        "keyword": "蒸馏模型",
        "dimension": "技术特性",
        "reason": "当前模型为DeepSeek-R1蒸馏后的轻量版本"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2-Chat-0628",
    "keywords": [
      {
        "keyword": "DeepSeek-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的核心品牌名，去除了版本号'0628'以符合简洁命名规则，是用户搜索该系列模型的通用关键词"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "模型后缀为'Chat'，明确用于对话交互，且在LMSYS Arena中排名靠前，是用户寻找AI聊天模型时的高频意图词"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "DeepSeek-V2系列采用混合专家（MoE）架构，这是其区别于普通稠密模型的核心技术特征，且未被高频词列表排除"
      },
      {
        "keyword": "32B参数",
        "dimension": "参数规格",
        "reason": "DeepSeek-V2系列为32B参数规模，属于主流大模型规格，用户常搜索'32B参数'来筛选性能与资源平衡的模型"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "模型在MATH、BBH、Arena-Hard等推理基准上显著提升，尤其+26.7的Arena-Hard提升表明其具备强链式推理能力，是用户寻找逻辑推理模型的关键词"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "README明确提及'API平台'，说明官方支持API接入，这是开发者寻找可集成AI服务时的关键搜索词，且未被高频词列表排除"
      },
      {
        "keyword": "指令遵循",
        "dimension": "技术特性",
        "reason": "README特别强调'系统区域指令遵循能力优化'，并提升沉浸式翻译、RAG等任务体验，这是用户寻找高指令对齐模型的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2-Lite",
    "keywords": [
      {
        "keyword": "DeepSeek-V2-Lite",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型的官方品牌名称"
      },
      {
        "keyword": "16B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量为16B，是用户常搜索的规模标识"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "模型采用混合专家（Mixture‑of‑Experts）架构，是其核心技术亮点"
      },
      {
        "keyword": "多头潜在注意力",
        "dimension": "技术特性",
        "reason": "独创的 MLA（Multi‑Head Latent Attention）机制提升推理效率"
      },
      {
        "keyword": "聊天模型",
        "dimension": "功能场景",
        "reason": "模型提供对话能力，适用于智能聊天与对话系统"
      },
      {
        "keyword": "API平台",
        "dimension": "部署工具",
        "reason": "模型支持通过 API 平台进行调用，便于线上服务集成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ant-research/MagicQuill-models",
    "keywords": [
      {
        "keyword": "MagicQuill",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源于模型名称，是用户搜索该特定图像编辑系统的唯一品牌标识"
      },
      {
        "keyword": "智能交互式图像编辑",
        "dimension": "功能场景",
        "reason": "模型核心功能是通过极简交互实现图像编辑，该短语精准描述用户搜索意图，且未被高频词库覆盖"
      },
      {
        "keyword": "图像插入",
        "dimension": "功能场景",
        "reason": "README明确列出‘插入元素’为关键操作，是用户可能直接搜索的具体编辑动作"
      },
      {
        "keyword": "对象擦除",
        "dimension": "功能场景",
        "reason": "README明确提及‘擦除对象’作为核心交互方式，属于具体、高意图的图像编辑关键词"
      },
      {
        "keyword": "多模态大语言模型",
        "dimension": "技术特性",
        "reason": "模型依赖MLLM实时理解用户交互意图，是区别于传统扩散模型的核心技术点，非通用词"
      },
      {
        "keyword": "双分支插件模块",
        "dimension": "技术特性",
        "reason": "模型独有的结构设计，用于增强扩散先验的控制精度，属于独特技术术语，非高频词"
      },
      {
        "keyword": "扩散先验",
        "dimension": "技术特性",
        "reason": "模型使用‘经过精心学习的扩散先验’实现精准编辑，是技术文档中的专有概念，非泛用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1-Distill-Qwen-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "当前模型的基础版本名称，与项目相关"
      },
      {
        "keyword": "强化学习",
        "dimension": "技术特性",
        "reason": "当前模型的核心训练方法，区别于其他模型"
      },
      {
        "keyword": "自我验证",
        "dimension": "技术特性",
        "reason": "当前模型展示的独特推理能力"
      },
      {
        "keyword": "推理模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "冷启动数据",
        "dimension": "技术特性",
        "reason": "当前模型在RL之前整合的独特数据"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/IIC/gme-Qwen2-VL-2B-Instruct",
    "keywords": [
      {
        "keyword": "通义千问",
        "dimension": "当前模型品牌名",
        "reason": "项目名称含Qwen，依据国产大模型映射规则，必须转换为'通义千问'"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "GME-Qwen2-VL-2B由阿里巴巴通义实验室开发，属于阿里大模型系列"
      },
      {
        "keyword": "Any2Any检索",
        "dimension": "功能场景",
        "reason": "模型核心能力是文本、图像、图文对之间的任意互检索，是用户搜索多模态检索时的精准意图词"
      },
      {
        "keyword": "视觉文档检索",
        "dimension": "功能场景",
        "reason": "模型在文档截图、学术论文等视觉文档场景表现卓越，是区别于通用多模态模型的独特应用场景"
      },
      {
        "keyword": "动态图像分辨率",
        "dimension": "技术特性",
        "reason": "模型支持自适应图像分辨率输入，是其区别于固定分辨率模型的关键技术亮点"
      },
      {
        "keyword": "多模态检索增强生成",
        "dimension": "功能场景",
        "reason": "模型明确应用于RAG场景中的多模态检索增强生成，是高价值专业用户搜索词"
      },
      {
        "keyword": "2.21B参数",
        "dimension": "参数规格",
        "reason": "当前模型参数规模为2.21B，属于轻量级多模态模型，用户会搜索此类小参数高效模型"
      },
      {
        "keyword": "UMRB基准",
        "dimension": "技术特性",
        "reason": "模型在自研通用多模态检索基准UMRB上达SOTA，是专业用户识别该模型的权威指标词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度自研大模型系列，'百度大模型'是用户搜索国产大模型时的通用意图词"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新点，原文明确提及'多模态异构MoE预训练'，是区别于普通MoE的独特架构"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "模型支持文本与视觉联合理解与推理，是用户搜索多模态AI能力时的直接意图词"
      },
      {
        "keyword": "统一偏好优化",
        "dimension": "技术特性",
        "reason": "原文独创的强化学习方法（UPO），用于后训练优化，具有技术辨识度且非通用术语"
      },
      {
        "keyword": "视觉语言理解",
        "dimension": "功能场景",
        "reason": "模型明确针对VLM（视觉语言模型）优化，是用户搜索图文理解类AI时的精准搜索词"
      },
      {
        "keyword": "4位无损量化",
        "dimension": "技术特性",
        "reason": "模型提出4位/2位无损量化算法，是推理优化的关键亮点，非泛泛的'量化模型'高频词"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "ERNIE 4.5独有架构设计，用于解决多模态训练干扰，技术术语独特且具搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/dreamerwhite/surya_layout3",
    "keywords": [
      {
        "keyword": "Surya-Layout",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 surya_layout3 提取的简洁品牌名"
      },
      {
        "keyword": "文档布局模型",
        "dimension": "功能场景",
        "reason": "模型用于文档的布局检测与解析，符合用户搜索“文档布局模型”"
      },
      {
        "keyword": "OCR布局",
        "dimension": "功能场景",
        "reason": "模型面向 OCR 场景的版面分析，用户常以 “OCR布局” 为关键词检索"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "模型基于 TensorFlow 框架，可通过 TensorFlow 环境进行部署"
      },
      {
        "keyword": "布局检测",
        "dimension": "技术特性",
        "reason": "模型的核心技术是对文档进行布局检测，用户会搜索该技术关键词"
      },
      {
        "keyword": "Creative-Commons-4.0",
        "dimension": "技术特性",
        "reason": "模型采用 CC‑BY‑NC‑SA 4.0 许可证，用户在寻找可再利用模型时会使用此关键词"
      },
      {
        "keyword": "文档结构分析",
        "dimension": "功能场景",
        "reason": "模型能够解析文档结构，满足用户对 “文档结构分析” 的搜索需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3-Base",
    "keywords": [
      {
        "keyword": "DeepSeek-V3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "MoE架构",
        "dimension": "技术特性",
        "reason": "当前模型采用混合专家架构，是核心卖点"
      },
      {
        "keyword": "671B参数",
        "dimension": "参数规格",
        "reason": "超大规模参数，用户会搜“671B”找旗舰模型"
      },
      {
        "keyword": "FP8训练",
        "dimension": "技术特性",
        "reason": "首创FP8混合精度训练，极具话题性"
      },
      {
        "keyword": "多标记预测",
        "dimension": "技术特性",
        "reason": "MTP目标提升性能，技术爱好者热搜"
      },
      {
        "keyword": "无辅助损失负载均衡",
        "dimension": "技术特性",
        "reason": "创新负载均衡策略，差异化亮点"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "通用生成能力，用户直接搜索使用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-8bit",
    "keywords": [
      {
        "keyword": "Qwen3-30B-A3B-MLX-8bit",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型标识，是用户在GitCode等平台搜索该特定版本的精准关键词"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独有的核心功能，支持在推理/编程场景（思维模式）与通用对话（非思维模式）间无缝切换，具有高区分度"
      },
      {
        "keyword": "激活参数3.3B",
        "dimension": "参数规格",
        "reason": "模型采用MoE架构，激活参数量为3.3B，是区别于全参数激活模型的关键技术指标，用户会搜索此类稀疏激活模型"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "模型专为Apple MLX框架优化，是少数支持MLX的千亿级大模型，吸引Apple生态开发者搜索"
      },
      {
        "keyword": "131K上下文",
        "dimension": "技术特性",
        "reason": "通过YaRN扩展至131,072 tokens上下文，是当前开源模型中罕见的超长上下文能力，用户会搜索长文本处理模型"
      },
      {
        "keyword": "智能体工具集成",
        "dimension": "功能场景",
        "reason": "模型在思维与非思维模式下均支持与外部工具精准交互，是AI智能体开发者的高价值搜索词"
      },
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "Qwen属于阿里大模型系列，根据映射规则提取，且未被高频词列表排除（'通义千问'被排除，但'阿里大模型'未被禁用）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-4v-9b",
    "keywords": [
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4V-9B 由智谱 AI 推出，映射为国产大模型品牌"
      },
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心系列名称，简洁易记"
      },
      {
        "keyword": "9B参数",
        "dimension": "参数规格",
        "reason": "当前模型独有的 9B 规格，区别于常见的 7B/32B"
      },
      {
        "keyword": "高分辨率视觉",
        "dimension": "功能场景",
        "reason": "支持 1120×1120 高分辨率图像理解，用户会搜"
      },
      {
        "keyword": "中英双语对话",
        "dimension": "功能场景",
        "reason": "具备中英双语多轮对话能力，满足多语言需求"
      },
      {
        "keyword": "图表理解",
        "dimension": "功能场景",
        "reason": "README 明确列出的经典任务之一，用户搜索意图明确"
      },
      {
        "keyword": "文字识别",
        "dimension": "功能场景",
        "reason": "OCRBench 评测任务，用户会直接搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-TP2-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度自研大模型系列，'百度大模型'是用户搜索国产大模型时的通用意图词"
      },
      {
        "keyword": "2比特量化",
        "dimension": "技术特性",
        "reason": "模型实现4比特/2比特无损量化，'2比特量化'是用户关注轻量化部署的核心搜索词，且未被高频词库排除"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新为'异构混合专家架构'，'异构MoE'是区别于普通MoE的独特技术术语，用户会搜索此类专业但非泛化的架构关键词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持文本与视觉模态联合训练，明确具备视觉-语言理解能力，符合'文生图'应用场景，且未被高频词库禁用"
      },
      {
        "keyword": "UPO优化",
        "dimension": "技术特性",
        "reason": "模型使用独创的'统一偏好优化（UPO）'方法，是区别于DPO/SFT的自研技术，具有高区分度，用户搜索模型优化技术时可能使用"
      },
      {
        "keyword": "PD解耦",
        "dimension": "技术特性",
        "reason": "模型采用'动态角色切换的PD解耦技术'提升推理效率，该术语为ERNIE 4.5特有，非通用术语，具备搜索价值"
      },
      {
        "keyword": "47B激活参数",
        "dimension": "参数规格",
        "reason": "模型明确标注'每个token激活参数量为47B'，47B属于非主流但具区分度的激活参数规格，用户搜索MoE模型时会关注激活参数而非总参数"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-K2-Base",
    "keywords": [
      {
        "keyword": "Kimi-K2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Kimi",
        "dimension": "当前模型品牌名",
        "reason": "MoonshotAI映射为Kimi，是当前模型的品牌名"
      },
      {
        "keyword": "专家混合语言模型",
        "dimension": "技术特性",
        "reason": "当前模型采用专家混合（MoE）架构，是其核心技术特性"
      },
      {
        "keyword": "智能体能力优化",
        "dimension": "技术特性",
        "reason": "当前模型针对智能体能力进行了精心优化，是其独特技术点"
      },
      {
        "keyword": "1万亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的总参数量达1万亿，是其主要参数规格"
      },
      {
        "keyword": "320亿激活参数",
        "dimension": "参数规格",
        "reason": "当前模型的激活参数达320亿，是区别于其他模型的重要参数"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产模型映射规则，必须提取为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE系列是百度官方大模型，'百度大模型'是用户搜索国产模型时的常用泛称，且未被高频词列表排除"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新点为'多模态异构MoE'，'异构MoE'是区别于普通MoE的独特技术术语，用户可能搜索该关键词以寻找架构创新模型"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "模型独有的架构设计术语，用于解决多模态干扰问题，属于高区分度技术关键词，非通用术语"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "模型经过模态专项后训练，明确支持VLM场景，用户会搜索'视觉语言模型'来寻找图文理解类AI"
      },
      {
        "keyword": "4比特量化",
        "dimension": "技术特性",
        "reason": "模型实现4比特/2比特无损量化，'4比特量化'是主流用户关注的高效推理关键词，且未被高频词列表排除"
      },
      {
        "keyword": "PD解耦",
        "dimension": "技术特性",
        "reason": "模型独有技术'动态角色切换的PD解耦'，用于优化MoE推理资源，术语独特，非通用词汇，具搜索价值"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "模型支持多模态训练与视觉语言理解，具备文生图能力，该词是用户高频搜索场景，且未在强制排除列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-4bit",
    "keywords": [
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Qwen，按照映射规则提取为阿里大模型"
      },
      {
        "keyword": "235B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量为 235B，用户常以参数规模搜索模型"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独创的思维模式与非思维模式可在单一模型内无缝切换，是核心技术亮点"
      },
      {
        "keyword": "非思维模式",
        "dimension": "技术特性",
        "reason": "提供高效通用对话的非思维模式，用户会搜索该功能场景"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "模型支持 100+ 语言与方言，适用于多语言翻译和跨语言对话"
      },
      {
        "keyword": "MLX-4bit",
        "dimension": "部署工具",
        "reason": "模型已量化为 4bit 并集成在 MLX 框架中，适合用户搜索量化部署方式"
      },
      {
        "keyword": "YaRN扩展上下文",
        "dimension": "技术特性",
        "reason": "通过 YaRN 将原生 32k 上下文扩展至 131k，提升长文本处理能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/WorldPM-72B-RLHFLow",
    "keywords": [
      {
        "keyword": "WorldPM-72B-RLHFLow",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型全称，是唯一标识该模型的专属名称，符合用户搜索特定模型的意图"
      },
      {
        "keyword": "偏好建模",
        "dimension": "技术特性",
        "reason": "模型核心创新点，是论文提出的专有技术方向，用户搜索‘偏好建模模型’时会精准匹配"
      },
      {
        "keyword": "规模扩展定律",
        "dimension": "技术特性",
        "reason": "模型研究的核心理论发现，具有学术独特性，是区别于通用RLHF模型的关键术语"
      },
      {
        "keyword": "奖励模型",
        "dimension": "技术特性",
        "reason": "模型本质是reward model，属于RLHF关键组件，用户搜索‘奖励模型’时会指向此类技术实现"
      },
      {
        "keyword": "PMP",
        "dimension": "技术特性",
        "reason": "论文中提出的‘Preference Modeling Paradigm’缩写，是该模型独有的技术术语，具有高区分度"
      },
      {
        "keyword": "WorldPM",
        "dimension": "当前模型品牌名",
        "reason": "模型简称，已在README中作为核心品牌标识重复使用，用户可能搜索‘WorldPM模型’而非全称"
      },
      {
        "keyword": "RLHFlow",
        "dimension": "技术特性",
        "reason": "模型所属技术框架名称，是项目所属生态的专有标签，区别于通用RLHF，具有唯一性"
      },
      {
        "keyword": "72B参数",
        "dimension": "参数规格",
        "reason": "模型规模为72B，属于主流大模型参数量级（介于32B与175B之间），用户会搜索‘72B模型’定位此类规模"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 4.5 属于百度文心一言系列"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 4.5 由百度研发，用户常用“百度大模型”搜索"
      },
      {
        "keyword": "28B参数",
        "dimension": "参数规格",
        "reason": "当前模型公开参数规模，用户会搜“28B参数”"
      },
      {
        "keyword": "图像理解",
        "dimension": "功能场景",
        "reason": "ERNIE 4.5 具备图像理解能力，用户搜索场景明确"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "模型支持文本与视觉跨模态推理，用户搜索意图清晰"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "官方支持4比特/2比特无损量化，用户会搜“量化模型”"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，且为ERNIE 4.5系列中的特定版本"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE属于百度大模型系列，根据映射规则提取"
      },
      {
        "keyword": "A3B系列",
        "dimension": "技术特性",
        "reason": "当前模型中的特定系列，具有独特技术特点"
      },
      {
        "keyword": "Multimodal-Heterogeneous-MoE",
        "dimension": "技术特性",
        "reason": "当前模型采用的多模态异构MoE预训练技术，是其核心创新点"
      },
      {
        "keyword": "Image-Text-to-Text",
        "dimension": "功能场景",
        "reason": "当前模型支持的功能场景，涉及图像和文本的转换"
      },
      {
        "keyword": "PaddlePaddle权重",
        "dimension": "技术特性",
        "reason": "当前模型使用的特定框架权重，区别于其他模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Base-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须替换为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度自研大模型系列，'百度大模型'是用户搜索国产模型时的通用意图词，且未被高频词列表排除"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新点，强调'异构'与'MoE'结合的多模态架构，是区别于普通多模态模型的独特技术标签"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "模型明确用于视觉-语言理解与跨模态推理，是用户搜索AI图像理解、图文问答时的精准意图词"
      },
      {
        "keyword": "4比特量化",
        "dimension": "技术特性",
        "reason": "模型实现4比特无损量化，属于高价值部署特性，用户搜索'低比特推理'或'轻量多模态模型'时会使用"
      },
      {
        "keyword": "模态专项后训练",
        "dimension": "技术特性",
        "reason": "模型采用专属模态微调策略（如VLM强化视觉语言理解），是区别于通用微调的独特训练方法，具有搜索辨识度"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "模型核心应用场景，用户搜索图文问答、图像描述生成等任务时高频使用，且未被高频词列表覆盖"
      },
      {
        "keyword": "统一偏好优化",
        "dimension": "技术特性",
        "reason": "模型使用改进型强化学习方法'统一偏好优化'（UPO），是区别于DPO/SFT的独家训练技术，具备独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/androidgen-glm-4-9b",
    "keywords": [
      {
        "keyword": "AndroidGen",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心品牌，模型专属名称，用户搜索AI安卓智能体时会直接使用"
      },
      {
        "keyword": "androidgen",
        "dimension": "当前模型品牌名",
        "reason": "项目标签中明确使用的小写形式，搜索引擎会收录大小写变体，需保留作为独立关键词"
      },
      {
        "keyword": "Android智能体",
        "dimension": "功能场景",
        "reason": "模型核心用途是驱动Android应用的自主智能体，用户搜索‘安卓智能体’‘手机AI代理’等词时会匹配"
      },
      {
        "keyword": "无标注任务执行",
        "dimension": "技术特性",
        "reason": "模型独特能力：无需人工标注交互数据即可在Android应用中执行任务，属于高区分度技术亮点"
      },
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "基于GLM-4-9B，根据规则需提取简化品牌名GLM-4，且未被列为禁用高频词（禁用的是‘智谱AI’，非GLM-4）"
      },
      {
        "keyword": "AI手机助手",
        "dimension": "功能场景",
        "reason": "模型用于消息、时钟、邮件、设置等手机应用操作，用户会搜索‘AI手机助手’‘安卓AI助手’等场景词"
      },
      {
        "keyword": "数据稀缺训练",
        "dimension": "技术特性",
        "reason": "论文标题明确提及‘under data scarcity’，是模型核心创新点，用户搜索‘低数据训练AI’‘少样本智能体’时可能匹配"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 系列在国内的品牌映射名称，直接来源于项目的 ERNIE 标识"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 300 B 参数，是该模型最显著的规格特征"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "README 中强调模型在文本‑图像跨模态推理任务上的优势"
      },
      {
        "keyword": "图文理解",
        "dimension": "功能场景",
        "reason": "模型同时处理文本和视觉信息，适用于图文理解任务"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "异构 MoE 结构中采用的关键技术，用于防止不同模态相互干扰"
      },
      {
        "keyword": "A47B系列",
        "dimension": "技术特性",
        "reason": "模型名称中的 A47B 表示其所属的 MoE‑A47B 系列，是唯一的系列标识"
      },
      {
        "keyword": "PT权重",
        "dimension": "部署方式",
        "reason": "模型提供的 Transformer‑style PyTorch 权重格式，适合 PyTorch 环境部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 系列为百度文心一言官方大模型，用户搜索常用品牌名"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 归属百度，用户也会用厂商名检索"
      },
      {
        "keyword": "图文理解",
        "dimension": "功能场景",
        "reason": "README 强调图像+文本联合理解，是用户高频需求词"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "技术特性",
        "reason": "模型卖点为文本-图像跨模态推理，搜索量持续增长"
      },
      {
        "keyword": "424B参数",
        "dimension": "参数规格",
        "reason": "超大参数规模极具话题性，吸引技术爱好者点击"
      },
      {
        "keyword": "PaddlePaddle版",
        "dimension": "部署工具",
        "reason": "项目带-Paddle后缀，表明提供Paddle权重，方便检索对应部署方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-4bit",
    "keywords": [
      {
        "keyword": "Qwen3-14B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，14B参数版本"
      },
      {
        "keyword": "MLX量化",
        "dimension": "部署工具",
        "reason": "当前模型采用Apple MLX框架的4bit量化部署"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "独家支持思维模式与非思维模式一键切换"
      },
      {
        "keyword": "智能体能力",
        "dimension": "功能场景",
        "reason": "专为复杂智能体任务优化的模型能力"
      },
      {
        "keyword": "131K上下文长度",
        "dimension": "技术特性",
        "reason": "通过YaRN扩展支持超长131072 tokens上下文"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "在数学计算与逻辑推理任务上表现突出"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "专为代码生成任务优化的模型能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Intel/dpt-hybrid-midas",
    "keywords": [
      {
        "keyword": "DPT-Hybrid",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Intel/dpt-hybrid-midas 中直接提取的当前模型专属名称，是论文中提出的具体模型版本"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "模型的核心功能，用户搜索AI视觉任务时高频使用的精准术语，非通用词且未被高频词列表排除"
      },
      {
        "keyword": "视觉Transformer",
        "dimension": "技术特性",
        "reason": "模型采用ViT作为骨干网络，是其核心技术架构，区别于传统CNN模型，具有独特性且未被高频词列表覆盖"
      },
      {
        "keyword": "密集预测Transformer",
        "dimension": "技术特性",
        "reason": "模型全称中的核心术语，直接来自论文标题，是该模型的技术标签，具有学术辨识度且未被高频词列表包含"
      },
      {
        "keyword": "MiDaS-3.0",
        "dimension": "当前模型品牌名",
        "reason": "README明确指出DPT-Hybrid即MiDaS 3.0，是该模型在社区中的通用别名，用户搜索时可能使用此名称"
      },
      {
        "keyword": "零样本深度估计",
        "dimension": "功能场景",
        "reason": "模型支持的核心使用方式，是用户在寻找无需微调的深度估计方案时的精准搜索词，区别于‘微调模型’场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-6bit",
    "keywords": [
      {
        "keyword": "Qwen3-32B-MLX-6bit",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "思维模式",
        "dimension": "技术特性",
        "reason": "当前模型独家支持的技术特性，适用于复杂逻辑推理等场景"
      },
      {
        "keyword": "非思维模式",
        "dimension": "技术特性",
        "reason": "当前模型支持的高效通用对话模式"
      },
      {
        "keyword": "智能体功能",
        "dimension": "功能场景",
        "reason": "当前模型具备的专业智能体能力，可精准对接外部工具"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "当前模型支持100+语言与方言的特性"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "当前模型的类型描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-235B",
        "dimension": "当前模型品牌名",
        "reason": "直接取自项目名称，简化后的模型系列名称"
      },
      {
        "keyword": "Instruct-2507",
        "dimension": "技术特性",
        "reason": "模型的指令微调版本号，体现其专注于指令遵循的特性"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "README 中强调模型在指令遵循方面的显著提升"
      },
      {
        "keyword": "逻辑推理",
        "dimension": "功能场景",
        "reason": "模型在逻辑推理任务上的能力被明确提及"
      },
      {
        "keyword": "代码编写",
        "dimension": "功能场景",
        "reason": "模型支持代码生成与编程相关任务，是用户常搜索的场景"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "README 中指出模型的多语言长尾知识覆盖范围大幅扩展"
      },
      {
        "keyword": "256K上下文",
        "dimension": "技术特性",
        "reason": "模型支持 256K 长上下文理解，属于显著的技术卖点"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "技术特性",
        "reason": "模型以 GGUF 量化格式发布，用户在搜索模型文件格式时会使用该词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-fr-en",
    "keywords": [
      {
        "keyword": "opus-mt-fr-en",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型唯一标识，用户搜索法英翻译模型时会直接使用此名称"
      },
      {
        "keyword": "法英翻译",
        "dimension": "功能场景",
        "reason": "用户搜索‘法语转英语’‘法英翻译模型’等意图明确的场景词，符合中文搜索习惯"
      },
      {
        "keyword": "SentencePiece",
        "dimension": "技术特性",
        "reason": "模型预处理核心技术，非通用术语，用户在研究翻译模型预处理时会搜索此专有名词"
      },
      {
        "keyword": "OPUS数据集",
        "dimension": "技术特性",
        "reason": "模型训练所用的公开数据集名称，专业用户会通过‘OPUS数据集 翻译模型’进行检索"
      },
      {
        "keyword": "transformer-align",
        "dimension": "技术特性",
        "reason": "模型架构名称，区别于普通Transformer，是该模型的特定对齐技术，具区分度"
      },
      {
        "keyword": "Helsinki-NLP",
        "dimension": "当前模型品牌名",
        "reason": "模型发布机构名称，专业用户常通过机构名搜索其开源模型，如‘Helsinki-NLP 翻译模型’"
      },
      {
        "keyword": "JAX",
        "dimension": "部署工具",
        "reason": "模型支持的推理框架之一，非高频词（已排除PyTorch/HuggingFace），JAX用户会针对性搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/owlv2-base-patch16-ensemble",
    "keywords": [
      {
        "keyword": "OWLv2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "零样本文本条件目标检测",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能和应用场景"
      },
      {
        "keyword": "CLIP骨干网络",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心技术架构"
      },
      {
        "keyword": "ViT-B16架构",
        "dimension": "技术特性",
        "reason": "当前模型图像编码器采用的架构"
      },
      {
        "keyword": "开放词汇表分类",
        "dimension": "技术特性",
        "reason": "当前模型实现的核心技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/bigvgan_v2_44khz_128band_512x",
    "keywords": [
      {
        "keyword": "BigVGAN",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前神经声码器品牌名"
      },
      {
        "keyword": "神经声码器",
        "dimension": "功能场景",
        "reason": "当前模型的核心用途：将声学特征转为高保真音频"
      },
      {
        "keyword": "44kHz采样率",
        "dimension": "参数规格",
        "reason": "当前模型支持的高保真音频输出规格，用户会搜"
      },
      {
        "keyword": "512倍上采样",
        "dimension": "技术特性",
        "reason": "当前模型独特的512×上采样能力，区别于普通声码器"
      },
      {
        "keyword": "CUDA加速推理",
        "dimension": "部署工具",
        "reason": "官方提供融合CUDA内核，实现推理加速，用户部署时关注"
      },
      {
        "keyword": "Gradio演示",
        "dimension": "部署工具",
        "reason": "官方内置Gradio交互式本地演示，方便快速体验"
      },
      {
        "keyword": "多语言语音合成",
        "dimension": "功能场景",
        "reason": "训练数据覆盖多语言语音，支持跨语种音频生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Alibaba-NLP/gte-large-en-v1.5",
    "keywords": [
      {
        "keyword": "gte-large-en-v1.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该特定嵌入模型时的精准关键词"
      },
      {
        "keyword": "文本嵌入",
        "dimension": "功能场景",
        "reason": "模型核心用途为文本嵌入，是用户在检索语义相似性、向量检索场景下的高频搜索意图词"
      },
      {
        "keyword": "长上下文检索",
        "dimension": "功能场景",
        "reason": "模型在LoCo基准中表现优异，突出支持长文本检索能力，是区别于普通嵌入模型的核心应用场景"
      },
      {
        "keyword": "MTEB",
        "dimension": "技术特性",
        "reason": "模型在MTEB基准中取得SOTA，该术语是AI研究人员和工程师评估嵌入模型时的权威指标关键词"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "部署工具",
        "reason": "README明确提及支持sentence-transformers库，是开发者部署该模型的主流工具链关键词"
      },
      {
        "keyword": "BERT-RoPE-GLU",
        "dimension": "技术特性",
        "reason": "模型采用的独特主干架构组合，是技术用户区分该模型与普通BERT嵌入模型的关键技术标识"
      },
      {
        "keyword": "8192上下文",
        "dimension": "技术特性",
        "reason": "虽然禁止提取纯数字，但'8192上下文'作为模型支持的上下文长度术语，在AI社区中已被广泛用作搜索词，具有明确指向性且非通用描述"
      },
      {
        "keyword": "英语嵌入模型",
        "dimension": "功能场景",
        "reason": "模型专为英语设计，用户在寻找高质量英语文本嵌入时会使用此组合词，具有明确语言指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/GLM-4.1V-9B-Thinking",
    "keywords": [
      {
        "keyword": "GLM-4.1V",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌标识，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "9B参数",
        "dimension": "参数规格",
        "reason": "模型规模为9B参数，属于用户常搜索的参数规格标签"
      },
      {
        "keyword": "思维链推理",
        "dimension": "技术特性",
        "reason": "模型采用思维链推理范式，是其核心技术创新点，用户会以此关键词搜索"
      },
      {
        "keyword": "64k上下文",
        "dimension": "技术特性",
        "reason": "支持超长64k上下文，是模型在长文本推理方面的显著特性"
      },
      {
        "keyword": "4K图像支持",
        "dimension": "功能场景",
        "reason": "模型可处理最高4K分辨率的任意宽高比图像，适用于高分辨率视觉任务"
      },
      {
        "keyword": "中英双语",
        "dimension": "功能场景",
        "reason": "模型同时支持中文和英文双语输入输出，满足多语言使用需求"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "通过智谱大模型开放平台提供的API接口调用，是用户集成模型的主要方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Intel/zoedepth-nyu-kitti",
    "keywords": [
      {
        "keyword": "ZoeDepth",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Intel/zoedepth-nyu-kitti 中提取的核心模型名称，是用户搜索该深度估计模型的唯一品牌标识"
      },
      {
        "keyword": "度估计",
        "dimension": "功能场景",
        "reason": "中文用户搜索深度估计任务时最常用的核心功能词，直接对应模型的 metric depth estimation 能力"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "模型的核心应用场景，README 明确提及 'zero-shot single-image depth estimation'，是专业用户精准搜索的关键词"
      },
      {
        "keyword": "零样本深度",
        "dimension": "技术特性",
        "reason": "模型核心创新点 'zero-shot transfer' 的中文提炼，区别于需微调的模型，具有高区分度"
      },
      {
        "keyword": "DPT框架",
        "dimension": "技术特性",
        "reason": "模型基于 DPT 架构进行适配，是技术实现的关键基础，用户搜索相关架构时会使用该术语"
      },
      {
        "keyword": "绝对深度",
        "dimension": "技术特性",
        "reason": "模型实现的是 'absolute depth estimation'（绝对深度估计），与相对深度形成鲜明对比，是技术关键词"
      },
      {
        "keyword": "NYU-KITTI",
        "dimension": "当前模型品牌名",
        "reason": "模型微调所用的权威数据集名称，构成模型的完整标识，专业用户常以此组合搜索特定版本"
      },
      {
        "keyword": "arxiv2302.12288",
        "dimension": "当前模型品牌名",
        "reason": "论文唯一标识符，研究者和工程师常直接搜索arxiv编号定位模型，具有极高精准引流价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/dinov2-base",
    "keywords": [
      {
        "keyword": "DINOv2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌名，用户搜索时会用"
      },
      {
        "keyword": "Vision-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型的核心架构，用户常搜ViT或Vision Transformer"
      },
      {
        "keyword": "自监督视觉特征",
        "dimension": "技术特性",
        "reason": "DINOv2主打的无监督预训练能力，用户搜索关键词"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "模型主要用途，用户搜索图像特征、特征提取时会用"
      },
      {
        "keyword": "下游任务微调",
        "dimension": "功能场景",
        "reason": "用户想基于DINOv2做分类、检测等下游任务时的搜索词"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "部署工具",
        "reason": "开源协议关键词，部分用户专门搜索可商用开源模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
    "keywords": [
      {
        "keyword": "CLIP-ViT-H-14",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "LAION-2B",
        "dimension": "技术特性",
        "reason": "模型训练基于LAION-2B数据集，是模型的重要技术特性"
      },
      {
        "keyword": "OpenCLIP框架",
        "dimension": "技术特性",
        "reason": "模型通过OpenCLIP框架训练，是模型的核心技术特性"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "模型的主要直接用途之一，用户会搜索此类功能"
      },
      {
        "keyword": "图文检索",
        "dimension": "功能场景",
        "reason": "模型的直接用途之一，用户可能搜索此类应用场景"
      },
      {
        "keyword": "图像生成引导",
        "dimension": "功能场景",
        "reason": "模型的下游用途之一，用户可能对此感兴趣"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Gen-Verse/MMaDA-8B-MixCoT",
    "keywords": [
      {
        "keyword": "MMaDA-8B-MixCoT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该特定模型时的精准关键词"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "README明确提及该模型用于‘文生图’，是用户搜索多模态生成类模型的核心意图词"
      },
      {
        "keyword": "混合长链思维",
        "dimension": "技术特性",
        "reason": "模型核心创新点‘混合长链思维（CoT）微调策略’的中文精准表达，具有唯一性且非通用术语"
      },
      {
        "keyword": "UniGRPO",
        "dimension": "技术特性",
        "reason": "模型独创的强化学习算法名称，技术独特性强，用户可能搜索该算法名以研究其训练方法"
      },
      {
        "keyword": "多模态扩散模型",
        "dimension": "技术特性",
        "reason": "模型本质是‘多模态扩散基础模型’，该词精准描述其架构类型，区别于普通扩散模型（如SD）"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "功能场景",
        "reason": "标签中明确标注，代表该模型支持任意模态输入输出，是区别于传统文生图模型的高价值场景词"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "模型为8B规模，属于主流参数区间，且未被强制排除列表覆盖，具有搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/tsmatz/xlm-roberta-ner-japanese",
    "keywords": [
      {
        "keyword": "xlm-roberta-ner-japanese",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型的完整品牌名"
      },
      {
        "keyword": "日本語固有表現抽出",
        "dimension": "功能场景",
        "reason": "模型专注于日语的固有表現（命名实体）抽取任务"
      },
      {
        "keyword": "Japanese-NER",
        "dimension": "功能场景",
        "reason": "模型的核心任务——日语命名实体识别（英文表述）"
      },
      {
        "keyword": "Stockmark-NER数据集",
        "dimension": "数据集",
        "reason": "模型在该公司提供的日语维基百科NER数据集上完成微调"
      },
      {
        "keyword": "token-classification-pipeline",
        "dimension": "使用方式",
        "reason": "官方示例展示了使用 HuggingFace pipeline 进行标记分类的调用方式"
      },
      {
        "keyword": "微调模型",
        "dimension": "技术特性",
        "reason": "模型基于 xlm-roberta-base 进行微调，具备针对日语 NER 的专用能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sshleifer/distilbart-cnn-6-6",
    "keywords": [
      {
        "keyword": "distilbart-cnn-6-6",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "当前模型可用于文本摘要，属于AI写作范畴"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "BART模型属于自回归模型，是当前模型的技术特性"
      },
      {
        "keyword": "230百万参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，具有区分度"
      },
      {
        "keyword": "cnndailymail",
        "dimension": "功能场景",
        "reason": "当前模型训练数据集之一，体现应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/ddpm-celebahq-256",
    "keywords": [
      {
        "keyword": "DDPM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为google/ddpm-celebahq-256，DDPM是该模型的核心品牌名称，用户搜索扩散模型时会直接使用该缩写"
      },
      {
        "keyword": "无条件图像生成",
        "dimension": "功能场景",
        "reason": "README明确提到'unconditional-image-generation'，是该模型的核心用途，用户会搜索‘无条件图像生成模型’这类精准意图词"
      },
      {
        "keyword": "DDIM",
        "dimension": "技术特性",
        "reason": "DDIM是该模型支持的专属推理调度器之一，区别于DDPM，是用户在优化推理速度时会搜索的关键技术词"
      },
      {
        "keyword": "PNDM",
        "dimension": "技术特性",
        "reason": "PNDM是该模型支持的另一种高效推理调度器，与DDIM并列，属于该模型独有的部署选项，具有区分度"
      },
      {
        "keyword": "256x256图像生成",
        "dimension": "功能场景",
        "reason": "模型专为256x256分辨率的CelebAHQ数据集设计，该分辨率是用户寻找高清人脸生成模型时的明确搜索维度"
      },
      {
        "keyword": "扩散概率模型",
        "dimension": "技术特性",
        "reason": "README核心术语，描述模型底层技术原理，是学术和工程用户搜索扩散模型类AI生成技术时的高频精准词"
      },
      {
        "keyword": "去噪分数匹配",
        "dimension": "技术特性",
        "reason": "README中提出的创新理论关联，属于该模型独有的技术亮点，非通用词，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Diankun/Spatial-MLLM-subset-sft",
    "keywords": [
      {
        "keyword": "Spatial-MLLM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称"
      },
      {
        "keyword": "视觉空间智能",
        "dimension": "功能场景",
        "reason": "论文标题强调模型在视觉空间智能方面的提升"
      },
      {
        "keyword": "Video-Text-to-Text",
        "dimension": "功能场景",
        "reason": "标签中列出的任务类型，表示模型支持视频到文本的转换"
      },
      {
        "keyword": "SFT微调",
        "dimension": "技术特性",
        "reason": "模型文件名包含 “subset‑sft”，表明使用了指令微调（SFT）技术"
      },
      {
        "keyword": "Subset数据集",
        "dimension": "技术特性",
        "reason": "模型基于子集数据进行训练，体现了特定数据筛选策略"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "标签中列出的深度学习框架，说明模型可在 TensorFlow 环境下运行"
      },
      {
        "keyword": "空间感知",
        "dimension": "技术特性",
        "reason": "模型核心目标是提升对视觉空间信息的感知与理解"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/valhalla/distilbart-mnli-12-1",
    "keywords": [
      {
        "keyword": "DistilBart",
        "dimension": "当前模型品牌名",
        "reason": "项目名中的核心品牌名，用户会直接搜索"
      },
      {
        "keyword": "MNLI零样本分类",
        "dimension": "功能场景",
        "reason": "README明确标注的Zero-Shot Classification场景"
      },
      {
        "keyword": "无教师蒸馏",
        "dimension": "技术特性",
        "reason": "README提到的核心技术，用户会搜蒸馏方法"
      },
      {
        "keyword": "12层蒸馏",
        "dimension": "参数规格",
        "reason": "README表格中反复出现的层数规格，用户会搜"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "README标签中明确支持的框架"
      },
      {
        "keyword": "JAX",
        "dimension": "部署工具",
        "reason": "README标签中明确支持的框架"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/HiDream-ai/HiDream-E1-1",
    "keywords": [
      {
        "keyword": "HiDream-E1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型主名称，是用户搜索该模型的核心关键词"
      },
      {
        "keyword": "HiDream-E1.1",
        "dimension": "当前模型品牌名",
        "reason": "项目最新开源版本，具有独立发布记录，是用户搜索最新版时的精准关键词"
      },
      {
        "keyword": "图像编辑",
        "dimension": "功能场景",
        "reason": "模型核心用途为图像编辑，是用户在CSDN等平台搜索AI图像工具时的高频意图词，且未被高频词列表排除"
      },
      {
        "keyword": "稀疏扩散Transformer",
        "dimension": "技术特性",
        "reason": "模型技术报告中明确提出的原创架构名称，具有高度区分度，非通用术语，用户可能搜索该技术实现"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "功能场景",
        "reason": "模型标签中明确标注，代表跨模态编辑能力（如文本→图像、图像→图像等），是专业用户搜索图像编辑模型时的精准场景词"
      },
      {
        "keyword": "arxiv2505.22705",
        "dimension": "技术特性",
        "reason": "模型对应论文的唯一arXiv编号，技术研究者常通过此编号直接搜索模型技术细节，具有强指向性且非通用"
      },
      {
        "keyword": "HiDream.ai",
        "dimension": "当前模型品牌名",
        "reason": "项目标签中明确出现的品牌标识，是用户搜索该厂商旗下模型时的直接入口词，且未被高频词列表覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/CIDAS/clipseg-rd64-refined",
    "keywords": [
      {
        "keyword": "CIDASclipseg-rd64-refined",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "CLIPSeg",
        "dimension": "当前模型品牌名",
        "reason": "模型的核心名称，用户可能直接搜索"
      },
      {
        "keyword": "降维64",
        "dimension": "技术特性",
        "reason": "模型具有降维64的特性，是区别于其他模型的技术点"
      },
      {
        "keyword": "零样本图像分割",
        "dimension": "功能场景",
        "reason": "模型适用于零样本图像分割，是其主要应用场景"
      },
      {
        "keyword": "单样本图像分割",
        "dimension": "功能场景",
        "reason": "模型也适用于单样本图像分割，扩展了其应用场景"
      },
      {
        "keyword": "复杂卷积优化",
        "dimension": "技术特性",
        "reason": "模型经过复杂卷积优化，是其技术上的独特之处"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-japanese",
    "keywords": [
      {
        "keyword": "wav2vec2-large-xlsr-53-japanese",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型标识，是用户搜索日语语音识别模型时最可能使用的精确关键词"
      },
      {
        "keyword": "日语语音识别",
        "dimension": "功能场景",
        "reason": "模型的核心用途，用户在CSDN等平台搜索日语ASR时会使用此明确场景词"
      },
      {
        "keyword": "XLSR微调",
        "dimension": "技术特性",
        "reason": "模型基于XLSR-53进行日语微调，'XLSR微调'是区别于通用语音模型的独特技术标签"
      },
      {
        "keyword": "Common-Voice日语",
        "dimension": "数据来源",
        "reason": "模型训练使用Common Voice日语数据集，该数据集名称是专业用户识别模型可靠性的关键搜索词"
      },
      {
        "keyword": "HuggingSound",
        "dimension": "部署工具",
        "reason": "文档推荐的专用推理库，是该模型生态中独特且可搜索的部署方式，非通用HuggingFace"
      },
      {
        "keyword": "JSUT语音数据集",
        "dimension": "数据来源",
        "reason": "JSUT是日语语音领域权威公开数据集，专业用户会以此作为筛选模型的关键词"
      },
      {
        "keyword": "CSS10日语",
        "dimension": "数据来源",
        "reason": "CSS10日语子集是模型训练的重要数据源，具有领域独特性，非通用词，适合精准引流"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/dbmdz/bert-large-cased-finetuned-conll03-english",
    "keywords": [
      {
        "keyword": "BERT-large",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含的品牌和规模标识，用户搜索时常用此词定位模型"
      },
      {
        "keyword": "CoNLL-03",
        "dimension": "功能场景",
        "reason": "模型在 CoNLL‑03 数据集上微调，用户常以数据集名称搜索对应的实体识别模型"
      },
      {
        "keyword": "英文实体识别",
        "dimension": "功能场景",
        "reason": "模型用于英文命名实体识别（NER），这是用户最直接的使用场景关键词"
      },
      {
        "keyword": "Cased模型",
        "dimension": "技术特性",
        "reason": "模型采用大小写敏感（cased）方式，对大小写有区分，属于显著的技术特性"
      },
      {
        "keyword": "TensorFlow部署",
        "dimension": "部署工具",
        "reason": "标签中包含 TensorFlow，说明模型可直接在 TensorFlow 环境下部署使用"
      },
      {
        "keyword": "340M参数",
        "dimension": "参数规格",
        "reason": "BERT‑large 约有 340 百万参数，参数规模是用户在搜索时关注的关键信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/QuantStack/FLUX.1-Kontext-dev-GGUF",
    "keywords": [
      {
        "keyword": "FLUX-Kontext",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型核心品牌名"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "当前模型以GGUF格式发布，用户会搜GGUF量化部署"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "官方明确推荐用ComfyUI加载，用户搜ComfyUI插件时会找到该模型"
      },
      {
        "keyword": "图像到图像",
        "dimension": "功能场景",
        "reason": "标签明确image-to-image，用户搜图生图或图像到图像时会匹配"
      },
      {
        "keyword": "文生图",
        "dimension": "功能场景",
        "reason": "FLUX系列主打文生图，用户常用该词搜索相关模型"
      },
      {
        "keyword": "FLUX量化版",
        "dimension": "技术特性",
        "reason": "强调这是FLUX官方模型的量化版本，用户搜FLUX量化版可直接定位"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/QuantStack/Wan2.1_14B_VACE-GGUF",
    "keywords": [
      {
        "keyword": "Wan2.114BVACE-GGUF",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "ComfyUI-GGUF",
        "dimension": "部署工具",
        "reason": "当前模型可配合使用的自定义节点工具"
      },
      {
        "keyword": "Q80量化",
        "dimension": "技术特性",
        "reason": "当前模型上传的量化版本特性"
      },
      {
        "keyword": "Text-to-Video",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能场景"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "技术特性",
        "reason": "当前模型使用的开源协议"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/Wolf-Rayet-2B-Prime3-i1-GGUF",
    "keywords": [
      {
        "keyword": "Wolf-Rayet-2B-Prime3",
        "dimension": "当前模型品牌名",
        "reason": "完整的模型名称，直接来源于项目名称"
      },
      {
        "keyword": "GGUF",
        "dimension": "文件格式",
        "reason": "模型采用的 GGUF 文件格式，是该模型独有的分发方式"
      },
      {
        "keyword": "i1-IQ1",
        "dimension": "技术特性",
        "reason": "模型提供的 IQ1 量化等级，区别于其他量化级别"
      },
      {
        "keyword": "i1-IQ2",
        "dimension": "技术特性",
        "reason": "模型提供的 IQ2 量化等级，适用于不同存储需求"
      },
      {
        "keyword": "i1-IQ3",
        "dimension": "技术特性",
        "reason": "模型提供的 IQ3 量化等级，兼顾质量与体积"
      },
      {
        "keyword": "i1-IQ4",
        "dimension": "技术特性",
        "reason": "模型提供的最高等级 IQ4 量化，推荐优先选择"
      },
      {
        "keyword": "加权矩阵量化",
        "dimension": "技术特性",
        "reason": "README 中提到的核心量化方法，区别于普通量化"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwaipilot/KAT-V1-40B",
    "keywords": [
      {
        "keyword": "KAT",
        "dimension": "当前模型品牌名",
        "reason": "项目README中明确给出的当前模型简称"
      },
      {
        "keyword": "Kwaipilot-AutoThink",
        "dimension": "当前模型品牌名",
        "reason": "项目README中给出的完整品牌名"
      },
      {
        "keyword": "40B参数",
        "dimension": "参数规格",
        "reason": "项目名称中直接标注的主流规格"
      },
      {
        "keyword": "思维链开关",
        "dimension": "技术特性",
        "reason": "模型核心卖点：可显式控制是否触发思维链"
      },
      {
        "keyword": "Step-SRPO",
        "dimension": "技术特性",
        "reason": "README中提到的后训练关键技术"
      },
      {
        "keyword": "Think-on查询",
        "dimension": "技术特性",
        "reason": "模型训练阶段引入的推理数据标签"
      },
      {
        "keyword": "LiveCodeBench-Pro",
        "dimension": "功能场景",
        "reason": "README中突出强调的编程评测场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-Instruct-GGUF",
    "keywords": [
      {
        "keyword": "Qwen2-Audio-7B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的完整模型标识，是当前模型的唯一品牌名，符合用户搜索AI音频模型时的精确关键词习惯"
      },
      {
        "keyword": "audio-text-to-text",
        "dimension": "功能场景",
        "reason": "模型核心功能是音频到文本的对话理解，属于用户搜索‘语音转文字AI’‘音频问答模型’等场景的精准术语，且未在高频排除词列表中"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "模型提供多种GGUF量化版本，是用户在本地部署LLM时高频搜索的格式术语，区别于Safetensors等排除词，具有部署导向性"
      },
      {
        "keyword": "Q4KM",
        "dimension": "参数规格",
        "reason": "模型提供Q4_K_M等具体量化精度版本，属于用户在寻找‘轻量级音频模型’‘低显存推理’时会搜索的精确量化规格，非通用参数词"
      },
      {
        "keyword": "Q80",
        "dimension": "参数规格",
        "reason": "Q8_0是该模型中质量最佳的量化版本，用户在追求高精度音频理解时会搜索该具体量化格式，具有明确区分度"
      },
      {
        "keyword": "mmproj-Q80",
        "dimension": "技术特性",
        "reason": "多模态投影文件（mmproj）是该音频模型的关键组件，Q8_0为其量化形式，属于模型独有的技术模块，非通用术语"
      },
      {
        "keyword": "音频对话模型",
        "dimension": "功能场景",
        "reason": "基于audio-text-to-text功能提炼的自然中文搜索词，用户可能搜索‘能听懂语音的AI对话模型’，此词精准匹配意图且未被高频排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/musicgen-medium",
    "keywords": [
      {
        "keyword": "MusicGen",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "文本到音乐",
        "dimension": "功能场景",
        "reason": "模型的核心任务是将文字描述转换为音乐音频"
      },
      {
        "keyword": "音频提示生成",
        "dimension": "功能场景",
        "reason": "模型支持使用音频片段作为提示进行音乐续写"
      },
      {
        "keyword": "单阶段自回归",
        "dimension": "技术特性",
        "reason": "模型采用单阶段自回归 Transformer 架构进行生成"
      },
      {
        "keyword": "并行预测",
        "dimension": "技术特性",
        "reason": "通过在码本间引入微小延迟实现的并行预测能力"
      },
      {
        "keyword": "4码本",
        "dimension": "技术特性",
        "reason": "模型使用 4 个 EnCodec 码本进行音频分解与重建"
      },
      {
        "keyword": "1.5B参数",
        "dimension": "参数规格",
        "reason": "Medium 版本模型约含 1.5 B 参数，区别于 small、large 版本"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pysentimiento/robertuito-sentiment-analysis",
    "keywords": [
      {
        "keyword": "robertuito-sentiment-analysis",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "西班牙语情感分析",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景和功能"
      },
      {
        "keyword": "RoBERTuito",
        "dimension": "技术特性",
        "reason": "当前模型采用的基础模型名称"
      },
      {
        "keyword": "POS-NEG-NEU",
        "dimension": "技术特性",
        "reason": "当前模型使用的标签类型"
      },
      {
        "keyword": "pysentimiento工具包",
        "dimension": "部署工具",
        "reason": "当前模型的使用方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/maya-research/Veena",
    "keywords": [
      {
        "keyword": "Veena",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Maya-research/Veena，是当前模型的唯一官方名称，符合用户搜索AI模型时直接输入品牌名的意图"
      },
      {
        "keyword": "印地语TTS",
        "dimension": "功能场景",
        "reason": "模型专为印地语文本转语音设计，用户搜索‘印地语TTS’是明确的地域语言需求，具有高度场景针对性且非高频词"
      },
      {
        "keyword": "语码混合TTS",
        "dimension": "功能场景",
        "reason": "模型原生支持印地语与英语混合输入，这一特性在TTS领域具有独特性，是用户寻找多语言混合语音合成时的精准搜索词"
      },
      {
        "keyword": "SNAC音频",
        "dimension": "技术特性",
        "reason": "模型使用SNAC神经编解码器输出24kHz音频，SNAC是其核心技术组件，非通用术语，具有技术辨识度且未在排除列表中"
      },
      {
        "keyword": "自回归TTS",
        "dimension": "技术特性",
        "reason": "模型基于自回归变换器架构，‘自回归TTS’是用户在比较TTS模型架构时可能搜索的精准技术标签，区别于流式或非自回归TTS"
      },
      {
        "keyword": "4音色TTS",
        "dimension": "功能场景",
        "reason": "模型提供kavya、agastya、maitri、vinaya四种独特音色，‘4音色TTS’是用户寻找多音色语音合成时的高意图搜索词，具差异化"
      },
      {
        "keyword": "低延迟TTS",
        "dimension": "功能场景",
        "reason": "模型在H100上延迟低于80ms，‘低延迟TTS’是生产部署用户的核心关注点，非泛泛形容词，具有明确性能指向性"
      },
      {
        "keyword": "4比特量化TTS",
        "dimension": "部署工具",
        "reason": "模型支持4比特量化优化，专为生产部署设计，该术语精准描述其轻量化部署能力，非通用‘量化模型’，避开了高频词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vidore/colpali-v1.2",
    "keywords": [
      {
        "keyword": "ColPali",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型品牌名，直接提取"
      },
      {
        "keyword": "视觉检索",
        "dimension": "功能场景",
        "reason": "模型用于从文档的视觉特征中建立索引，实现图像‑文本检索"
      },
      {
        "keyword": "文档检索",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对文档进行高效检索"
      },
      {
        "keyword": "ColBERT策略",
        "dimension": "技术特性",
        "reason": "模型采用 ColBERT 的多向量交互策略进行检索"
      },
      {
        "keyword": "BiSigLIP",
        "dimension": "技术特性",
        "reason": "基于 SigLIP 微调得到的 BiSigLIP 是模型构建过程中的关键步骤"
      },
      {
        "keyword": "BiPali",
        "dimension": "技术特性",
        "reason": "将图像块嵌入 PaliGemma‑3B 后形成的 BiPali 为模型的核心表示方式"
      },
      {
        "keyword": "右填充查询",
        "dimension": "技术特性",
        "reason": "本版本在查询编码中使用右填充以修复无关标记问题"
      },
      {
        "keyword": "colpali-engine",
        "dimension": "部署工具",
        "reason": "模型基于 colpali-engine==0.2.0 进行训练和加载，可直接用于推理部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/Orsta-7B-i1-GGUF",
    "keywords": [
      {
        "keyword": "Orsta-7B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌与规格"
      },
      {
        "keyword": "视觉模型",
        "dimension": "功能场景",
        "reason": "README明确标注为视觉模型，用户会搜"
      },
      {
        "keyword": "VLM",
        "dimension": "技术特性",
        "reason": "标签中的视觉-语言模型缩写，技术圈常用"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "提供全套GGUF量化文件，用户搜部署方式"
      },
      {
        "keyword": "强化学习",
        "dimension": "技术特性",
        "reason": "标签含reinforcement-learning，核心卖点"
      },
      {
        "keyword": "IQ1S",
        "dimension": "参数规格",
        "reason": "超小2GB量化版，极客用户会精确搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF",
    "keywords": [
      {
        "keyword": "SEOcrate-4B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF 中提取的核心品牌名称，去除了冗余后缀，符合简洁品牌名规范"
      },
      {
        "keyword": "GGUF量化模型",
        "dimension": "部署工具",
        "reason": "模型以GGUF格式提供，且强调多种IQ/Q量化版本，是用户搜索轻量化部署时的核心关键词，具有明确工具属性"
      },
      {
        "keyword": "SEO写作",
        "dimension": "功能场景",
        "reason": "模型基于SEO相关数据集（seo-grpo-reasoning-dataset）微调，核心用途为生成优化搜索引擎的文本内容，用户会搜索‘SEO写作’这类精准场景词"
      },
      {
        "keyword": "IQ2IQ3量化",
        "dimension": "技术特性",
        "reason": "模型提供IQ2_XS、IQ3_S等特有量化等级，是其区别于普通Q4/Q2模型的关键技术标签，用户会搜索此类专业量化标识"
      },
      {
        "keyword": "知识图谱SEO",
        "dimension": "功能场景",
        "reason": "标签包含schema.org、knowledge-graph、ontology，表明模型专为结构化SEO与知识图谱内容生成设计，是高度垂直的场景词"
      },
      {
        "keyword": "4bit推理",
        "dimension": "技术特性",
        "reason": "模型为4bit量化版本，虽‘4bit’本身是通用词，但结合‘推理’形成‘4bit推理’作为用户搜索低资源部署时的高频意图组合，且未在禁用词列表中"
      },
      {
        "keyword": "SEO推理模型",
        "dimension": "技术特性",
        "reason": "模型基于grpo（可能为‘guided reasoning for SEO’）微调，具备SEO场景下的推理能力，‘SEO推理模型’是独特且未被高频使用的精准组合词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/ddpm-cifar10-32",
    "keywords": [
      {
        "keyword": "ddpm-cifar10-32",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "去噪扩散概率模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性描述"
      },
      {
        "keyword": "无条件图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景，从标签中提取并简化"
      },
      {
        "keyword": "DDPM推理",
        "dimension": "部署工具",
        "reason": "当前模型使用的推理方式，与模型紧密相关"
      },
      {
        "keyword": "渐进式有损解压缩",
        "dimension": "技术特性",
        "reason": "当前模型支持的一种技术特性，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/timesformer-base-finetuned-k400",
    "keywords": [
      {
        "keyword": "TimeSformer",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "当前模型在Kinetics-400上微调，专用于视频动作识别"
      },
      {
        "keyword": "时空注意力",
        "dimension": "技术特性",
        "reason": "TimeSformer的核心创新，用Transformer同时建模空间与时间信息"
      },
      {
        "keyword": "Kinetics-400",
        "dimension": "功能场景",
        "reason": "模型已在Kinetics-400数据集上完成微调，可直接用于400类动作识别"
      },
      {
        "keyword": "Transformers视频",
        "dimension": "技术特性",
        "reason": "基于HuggingFace Transformers的视频理解模型，易于调用"
      },
      {
        "keyword": "224分辨率",
        "dimension": "参数规格",
        "reason": "模型输入固定为224×224分辨率，方便部署与调优"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF",
    "keywords": [
      {
        "keyword": "GCIRS-Reasoning",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF 中提取的核心品牌名，去掉版本号后为简洁识别名"
      },
      {
        "keyword": "GGUF量化模型",
        "dimension": "部署工具",
        "reason": "模型以GGUF格式提供，是用户在本地部署时高频搜索的量化格式关键词，具有明确工具属性"
      },
      {
        "keyword": "IQ4XS",
        "dimension": "技术特性",
        "reason": "模型提供独特的IQ4_XS量化版本，属于非主流但高区分度的量化类型，用户会专门搜索此类低比特高效格式"
      },
      {
        "keyword": "Q4KS",
        "dimension": "技术特性",
        "reason": "模型推荐的Q4_K_S是其重点标注的高性能量化选项，区别于通用Q4，具有明确的性能导向标签"
      },
      {
        "keyword": "Q6K",
        "dimension": "技术特性",
        "reason": "模型明确标注Q6_K为'质量非常好'，是用户寻找中高精度量化时可能搜索的特定层级"
      },
      {
        "keyword": "Q80",
        "dimension": "技术特性",
        "reason": "模型标注Q8_0为'速度最快、质量最佳'，是用户追求平衡性能与精度时的精准搜索词"
      },
      {
        "keyword": "科学推理",
        "dimension": "功能场景",
        "reason": "标签含'science, math, finance'，综合提炼为'科学推理'，是模型核心用途，非通用'智能对话'或'编程助手'"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "模型名称含'Reasoning'，结合HuggingFace原模型定位，可合理推断其支持链式思维（CoT）推理，符合技术特性维度且未被高频词排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR-7B",
    "keywords": [
      {
        "keyword": "SeedVR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed 对应的国产大模型品牌映射"
      },
      {
        "keyword": "视频修复",
        "dimension": "功能场景",
        "reason": "模型的核心应用场景是对受损视频进行修复"
      },
      {
        "keyword": "任意分辨率修复",
        "dimension": "功能场景",
        "reason": "模型支持在任意分辨率下进行视频修复，区别于固定分辨率的传统方法"
      },
      {
        "keyword": "一步视频修复",
        "dimension": "技术特性",
        "reason": "论文标题中提出的 One‑Step Video Restoration 技术"
      },
      {
        "keyword": "Diffusion",
        "dimension": "技术特性",
        "reason": "模型基于扩散（Diffusion）Transformer 架构实现视频修复"
      },
      {
        "keyword": "视频生成训练流程",
        "dimension": "技术特性",
        "reason": "采用最先进的视频生成训练流程，提升修复质量和一致性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/BetaCeti-Beta-4B-Prime1-i1-GGUF",
    "keywords": [
      {
        "keyword": "BetaCeti-Beta-4B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "加权矩阵量化版本",
        "dimension": "技术特性",
        "reason": "当前模型版本的核心技术特性"
      },
      {
        "keyword": "静态量化版本",
        "dimension": "技术特性",
        "reason": "当前模型提供的另一种量化技术特性"
      },
      {
        "keyword": "i1-IQ量化",
        "dimension": "技术特性",
        "reason": "当前模型提供的量化版本类型"
      },
      {
        "keyword": "text-generation-inference",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景，文本生成推理"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "技术特性",
        "reason": "当前模型使用的开源协议"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/kredor/punctuate-all",
    "keywords": [
      {
        "keyword": "punctuate-all",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为kredor/punctuate-all，直接提取为模型品牌名，简洁且唯一"
      },
      {
        "keyword": "自动标点",
        "dimension": "功能场景",
        "reason": "模型核心功能是为无标点文本自动添加标点符号，用户会搜索'自动标点'这类明确需求词"
      },
      {
        "keyword": "多语言标点",
        "dimension": "功能场景",
        "reason": "支持12种欧洲语言的标点恢复，'多语言标点'是用户在处理跨语言文本时的精准搜索词"
      },
      {
        "keyword": "xlm-roberta-base",
        "dimension": "技术特性",
        "reason": "模型基于微调后的xlm-roberta-base，是其技术核心且区别于其他标点模型的唯一架构标识"
      },
      {
        "keyword": "文本标点修复",
        "dimension": "功能场景",
        "reason": "用户常搜索'文本标点修复'来解决无标点输入文本的可读性问题，精准匹配模型用途"
      },
      {
        "keyword": "WMT-Europarl",
        "dimension": "技术特性",
        "reason": "模型训练数据源自WMT/Europarl语料，是其训练背景的关键标识，专业用户会据此检索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nari-labs/Dia-1.6B-0626",
    "keywords": [
      {
        "keyword": "Dia",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为 Dia，直接提取为模型品牌名"
      },
      {
        "keyword": "文本转语音",
        "dimension": "功能场景",
        "reason": "模型的核心功能是将文字转为自然语音"
      },
      {
        "keyword": "情感语调控制",
        "dimension": "技术特性",
        "reason": "支持通过音频条件精准调节情感与语调，是模型的关键技术特性"
      },
      {
        "keyword": "非语言音效生成",
        "dimension": "功能场景",
        "reason": "能够生成笑声、咳嗽、清嗓等非语言音效，拓展了使用场景"
      },
      {
        "keyword": "Gradio界面",
        "dimension": "部署工具",
        "reason": "提供交互式 Gradio UI，方便本地快速启动和使用"
      },
      {
        "keyword": "ZeroGPU",
        "dimension": "部署工具",
        "reason": "模型已上线 ZeroGPU 空间，可免显卡在线体验"
      },
      {
        "keyword": "1.6B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 1.6 B 参数，属于中等规模的 TTS 模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MohamedRashad/Voxtral-Small-24B-2507-transformers",
    "keywords": [
      {
        "keyword": "Voxtral-Small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'MohamedRashad/Voxtral-Small-24B-2507-transformers' 中提取的核心模型品牌名，去除了冗余版本号，符合简洁品牌名规范"
      },
      {
        "keyword": "语音转录",
        "dimension": "功能场景",
        "reason": "模型核心功能之一，用户会直接搜索‘语音转录模型’这类意图明确的场景词，且非高频禁用词"
      },
      {
        "keyword": "音频理解",
        "dimension": "功能场景",
        "reason": "模型区别于普通文本模型的关键能力，README多次强调，是用户寻找多模态音频分析工具时的高频搜索词"
      },
      {
        "keyword": "语音问答",
        "dimension": "功能场景",
        "reason": "模型支持‘通过音频直接提问’，这是独特功能点，用户可能搜索‘语音问答AI’或‘语音提问模型’"
      },
      {
        "keyword": "多语言语音",
        "dimension": "功能场景",
        "reason": "模型支持8种主流语言的自动检测与转录，用户会搜索‘多语言语音转录’等组合词，具有明确区分度"
      },
      {
        "keyword": "32k上下文",
        "dimension": "参数规格",
        "reason": "32k token上下文长度是模型处理长音频（30分钟）的核心支撑，属于主流规格范畴，非技术细节，用户会搜索‘长上下文语音模型’"
      },
      {
        "keyword": "语音摘要",
        "dimension": "功能场景",
        "reason": "模型内置‘音频生成结构化摘要’功能，是区别于普通ASR工具的独特卖点，搜索意图明确"
      },
      {
        "keyword": "语音调用API",
        "dimension": "功能场景",
        "reason": "模型支持‘基于口语意图直接触发API’，属于前沿应用场景，用户可能搜索‘语音控制API’或‘语音触发工作流’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mgalkin/ultra_3g",
    "keywords": [
      {
        "keyword": "ULTRA",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为mgalkin/ultra_3g，核心品牌名为ULTRA"
      },
      {
        "keyword": "知识图谱补全",
        "dimension": "功能场景",
        "reason": "README明确说明ULTRA用于知识图谱的链接预测/补全任务"
      },
      {
        "keyword": "零样本推理",
        "dimension": "技术特性",
        "reason": "ULTRA可在50+图谱上零样本运行，无需额外训练"
      },
      {
        "keyword": "图神经网络",
        "dimension": "技术特性",
        "reason": "ULTRA基于改进的NBFNet图神经网络架构"
      },
      {
        "keyword": "统一关系表示",
        "dimension": "技术特性",
        "reason": "ULTRA通过关系交互学习统一可迁移的关系表示"
      },
      {
        "keyword": "16.9万参数",
        "dimension": "参数规格",
        "reason": "README指出检查点参数量约16.9万，轻量化模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moojink/openvla-7b-oft-finetuned-libero-spatial-object-goal-10",
    "keywords": [
      {
        "keyword": "OpenVLA-OFT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心品牌，用户会直接搜索"
      },
      {
        "keyword": "视觉语言动作模型",
        "dimension": "功能场景",
        "reason": "模型主打VLA能力，用户用此词找同类机器人模型"
      },
      {
        "keyword": "LIBERO任务套件",
        "dimension": "功能场景",
        "reason": "README高频提及的机器人 benchmark，开发者常搜"
      },
      {
        "keyword": "机器人动作生成",
        "dimension": "功能场景",
        "reason": "明确落地场景，用户搜索机器人动作方案"
      },
      {
        "keyword": "OFT微调",
        "dimension": "技术特性",
        "reason": "论文与仓库共同强调的优化微调方法，技术关键词"
      },
      {
        "keyword": "PEFT优化",
        "dimension": "技术特性",
        "reason": "标签与描述均提到的高效微调技术，吸引调参用户"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mistralai/Magistral-Small-2507",
    "keywords": [
      {
        "keyword": "Magistral-Small-2507",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "推理能力",
        "dimension": "技术特性",
        "reason": "当前模型新增的核心技术特性"
      },
      {
        "keyword": "多语言支持",
        "dimension": "技术特性",
        "reason": "当前模型支持多种语言的技术特性"
      },
      {
        "keyword": "Apache-2.0许可证",
        "dimension": "技术特性",
        "reason": "当前模型采用的开放许可证类型"
      },
      {
        "keyword": "240亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模"
      },
      {
        "keyword": "本地量化部署",
        "dimension": "部署工具",
        "reason": "当前模型支持本地量化后适配特定硬件的部署方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/SWivid/F5-TTS",
    "keywords": [
      {
        "keyword": "F5-TTS",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源于SWivid/F5-TTS，是当前模型的唯一官方品牌名，用户搜索TTS模型时会直接使用该名称"
      },
      {
        "keyword": "Flow-Matching",
        "dimension": "技术特性",
        "reason": "论文标题明确指出模型基于'Flow Matching'技术，是区别于传统自回归或扩散模型的核心创新点，用户会搜索该技术关键词寻找同类模型"
      },
      {
        "keyword": "文生语音",
        "dimension": "功能场景",
        "reason": "F5-TTS是文本到语音生成模型，'文生语音'是中文用户对TTS的自然搜索词，且未被列入强制排除词列表，具有明确搜索意图"
      },
      {
        "keyword": "F5TTSv1Base",
        "dimension": "当前模型品牌名",
        "reason": "模型文件夹名称为F5TTS_v1_Base，是模型版本的官方标识，用户在部署时会搜索该具体版本名，且未被高频词排除"
      },
      {
        "keyword": "E2-TTS",
        "dimension": "当前模型品牌名",
        "reason": "README中明确将E2 TTS与F5-TTS并列作为可下载模型，属于同一项目体系下的独立模型名称，非对比模型，可独立提取"
      },
      {
        "keyword": "Faithful-Speech",
        "dimension": "技术特性",
        "reason": "论文标题中'Faithful Speech'是模型核心目标之一，代表高保真语音生成，是区别于普通TTS的差异化技术表述，用户可能搜索该短语"
      },
      {
        "keyword": "Fluent-Speech",
        "dimension": "技术特性",
        "reason": "论文标题中与'Faithful'并列的'Fluent'是模型设计的另一核心目标，代表语音自然流畅性，属于模型专属技术标签，非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MohamedRashad/Voxtral-Mini-3B-2507-transformers",
    "keywords": [
      {
        "keyword": "Voxtral-Mini",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中出现的模型品牌名称，直接代表该模型"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 3 B 参数，是用户常搜索的参数规格"
      },
      {
        "keyword": "音频转录",
        "dimension": "功能场景",
        "reason": "模型提供高质量的语音转文本能力，是核心使用场景"
      },
      {
        "keyword": "语音翻译",
        "dimension": "功能场景",
        "reason": "模型支持将音频内容直接翻译成多语言文本，属于重要功能"
      },
      {
        "keyword": "音频摘要",
        "dimension": "功能场景",
        "reason": "模型能够基于音频生成结构化摘要，满足信息提取需求"
      },
      {
        "keyword": "自动语言检测",
        "dimension": "技术特性",
        "reason": "模型可自动识别音频语言并切换相应的转录/翻译模型"
      },
      {
        "keyword": "语音触发调用",
        "dimension": "技术特性",
        "reason": "支持通过口语意图直接触发后端功能或 API 调用的交互方式"
      },
      {
        "keyword": "长音频上下文",
        "dimension": "技术特性",
        "reason": "凭借 32k token 上下文，模型可处理长达 30‑40 分钟的音频"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwai-Keye/Keye-VL-8B-Preview",
    "keywords": [
      {
        "keyword": "Keye-VL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "快手大模型",
        "dimension": "当前模型品牌名",
        "reason": "Kwai Keye团队出品，映射为快手大模型"
      },
      {
        "keyword": "短视频理解",
        "dimension": "功能场景",
        "reason": "专为短视频理解设计的核心能力"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规模"
      },
      {
        "keyword": "冷启动数据混合",
        "dimension": "技术特性",
        "reason": "模型后训练阶段的核心创新策略"
      },
      {
        "keyword": "KC-MMBench",
        "dimension": "功能场景",
        "reason": "官方发布的短视频评测基准"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K",
    "keywords": [
      {
        "keyword": "CLIP-ViT-L-14",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的核心模型标识，是用户搜索CLIP视觉-文本模型时的精准关键词"
      },
      {
        "keyword": "DataComp.XL",
        "dimension": "当前模型品牌名",
        "reason": "模型训练所用的专属数据集名称，构成模型唯一标识，区别于普通CLIP模型，具有高区分度"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "README明确列出的直接用途，是用户在研究场景中搜索CLIP类模型时的核心意图关键词"
      },
      {
        "keyword": "图文检索",
        "dimension": "功能场景",
        "reason": "模型核心应用场景之一，用户在学术或工程场景中常搜索该术语，且未被高频词列表排除"
      },
      {
        "keyword": "OpenCLIP",
        "dimension": "技术特性",
        "reason": "模型基于的开源框架名称，是技术社区中用于区分OpenAI CLIP与开源实现的关键术语"
      },
      {
        "keyword": "DataComp-1B",
        "dimension": "技术特性",
        "reason": "模型训练所用的专属大规模数据集名称，具有唯一性，是研究者关注数据质量时的搜索词"
      },
      {
        "keyword": "线性探针图像分类",
        "dimension": "下游用途",
        "reason": "README中明确提及的特定微调方式，属于专业研究者搜索的精准技术场景，非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ChatDOC/OCRFlux-3B",
    "keywords": [
      {
        "keyword": "OCRFlux",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "模型基于约30亿参数的规模，约为3B参数"
      },
      {
        "keyword": "PDF转Markdown",
        "dimension": "功能场景",
        "reason": "模型的核心功能是将 PDF 与图像转换为纯 Markdown 文本"
      },
      {
        "keyword": "跨页表格合并",
        "dimension": "技术特性",
        "reason": "首个开源实现跨页表格与段落自动合并的独特特性"
      },
      {
        "keyword": "OCRFlux-API",
        "dimension": "部署工具",
        "reason": "提供直接调用的推理 API，方便在代码中使用模型"
      },
      {
        "keyword": "vllm高效推理",
        "dimension": "技术特性",
        "reason": "基于 vllm 实现的高效大规模文档推理加速"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/dphn/Dolphin-Mistral-24B-Venice-Edition",
    "keywords": [
      {
        "keyword": "Dolphin-Mistral-24B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Venice-Uncensored",
        "dimension": "当前模型品牌名",
        "reason": "当前模型在Venice.ai上的上线名称"
      },
      {
        "keyword": "无审查版本",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，强调无审查"
      },
      {
        "keyword": "可引导性",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，强调用户可引导"
      },
      {
        "keyword": "系统提示词控制",
        "dimension": "技术特性",
        "reason": "当前模型允许用户设置系统提示词，掌控模型行为"
      },
      {
        "keyword": "数据掌控",
        "dimension": "技术特性",
        "reason": "当前模型允许用户掌控自己的数据"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.5-Air-Base",
    "keywords": [
      {
        "keyword": "GLM-4.5-Air",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化规则（保留主版本号，不带冗余后缀）"
      },
      {
        "keyword": "混合推理模型",
        "dimension": "技术特性",
        "reason": "模型核心创新点，明确区分于单一推理模式，用户会搜索‘混合推理 AI模型’这类意图"
      },
      {
        "keyword": "智能体模型",
        "dimension": "功能场景",
        "reason": "README明确指出‘专为智能体设计’，是该模型的专属应用场景，非通用对话模型"
      },
      {
        "keyword": "120亿激活参数",
        "dimension": "参数规格",
        "reason": "120亿是GLM-4.5-Air的显著激活参数规模，属于主流可搜索规格，且区别于高频词32B/7B"
      },
      {
        "keyword": "FP8量化模型",
        "dimension": "部署工具",
        "reason": "模型提供FP8量化版本，是部署优化的关键标签，用户会搜索‘FP8 量化 大模型’"
      },
      {
        "keyword": "思维模式",
        "dimension": "技术特性",
        "reason": "模型独有的双模式设计之一，与‘非思维模式’对应，是智能体推理的核心机制术语"
      },
      {
        "keyword": "非思维模式",
        "dimension": "技术特性",
        "reason": "与‘思维模式’并列的模型核心特性，用于即时响应场景，具有明确搜索意图区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Robertooo/autotrain-hmaet-2037366891",
    "keywords": [
      {
        "keyword": "AutoTrain回归模型",
        "dimension": "当前模型品牌名",
        "reason": "项目由AutoTrain训练，单列回归是其核心标识"
      },
      {
        "keyword": "HMAET回归",
        "dimension": "当前模型品牌名",
        "reason": "项目名中hmaet为模型专属代号，用户搜hmaet可直达"
      },
      {
        "keyword": "R2得分0.486",
        "dimension": "技术特性",
        "reason": "决定系数R²是回归模型性能的直接指标，用户常搜具体数值"
      },
      {
        "keyword": "MSE-0.005",
        "dimension": "技术特性",
        "reason": "均方误差数值极低，体现模型精度，是技术选型的搜索关键词"
      },
      {
        "keyword": "joblib模型文件",
        "dimension": "部署工具",
        "reason": "模型以joblib格式发布，用户搜索该关键词可找到直接可用的权重文件"
      },
      {
        "keyword": "单列回归预测",
        "dimension": "功能场景",
        "reason": "README明确任务类型，用户需要单变量回归模型时会用此词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sentence-transformers/multi-qa-MiniLM-L6-cos-v1",
    "keywords": [
      {
        "keyword": "multi-qa-MiniLM-L6-cos-v1",
        "dimension": "当前模型品牌名",
        "reason": "完整的模型名称，用户在搜索具体模型时会直接使用"
      },
      {
        "keyword": "MiniLM",
        "dimension": "技术特性",
        "reason": "模型基于 MiniLM 架构，是该系列的核心技术特征"
      },
      {
        "keyword": "384维向量",
        "dimension": "技术特性",
        "reason": "模型输出 384 维稠密向量，用户常以维度大小区分语义检索模型"
      },
      {
        "keyword": "语义搜索",
        "dimension": "功能场景",
        "reason": "模型专为语义搜索设计，是用户检索相关文档时的主要使用场景"
      },
      {
        "keyword": "Sentence-Similarity",
        "dimension": "功能场景",
        "reason": "模型可用于句子相似度计算，符合搜索、匹配等任务需求"
      },
      {
        "keyword": "ONNX支持",
        "dimension": "部署工具",
        "reason": "模型提供 ONNX 导出，便于跨平台部署和加速推理"
      },
      {
        "keyword": "OpenVINO兼容",
        "dimension": "部署工具",
        "reason": "支持 OpenVINO，可在 Intel 硬件上高效运行"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "技术特性",
        "reason": "模型基于 sentence‑transformers 库，用户搜索该库时会关联到本模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-350M",
    "keywords": [
      {
        "keyword": "LFM2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Liquid模型",
        "dimension": "技术特性",
        "reason": "当前模型自称的“新型混合 Liquid 模型”架构"
      },
      {
        "keyword": "边缘AI",
        "dimension": "功能场景",
        "reason": "专为边缘人工智能和设备端部署设计"
      },
      {
        "keyword": "乘法门控",
        "dimension": "技术特性",
        "reason": "士独有的乘法门控机制"
      },
      {
        "keyword": "RAG应用",
        "dimension": "功能场景",
        "reason": "官方建议用于检索增强生成场景"
      },
      {
        "keyword": "350M参数",
        "dimension": "参数规格",
        "reason": "当前模型具体参数规模，用户会搜"
      },
      {
        "keyword": "CPU推理",
        "dimension": "部署工具",
        "reason": "强调可在CPU上高效运行，用户关心部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8",
    "keywords": [
      {
        "keyword": "Tifa-DeepSexV2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中唯一标识的当前模型品牌，符合简化命名规则，且为用户搜索该特定模型的直接关键词"
      },
      {
        "keyword": "MGRPO",
        "dimension": "技术特性",
        "reason": "模型核心创新算法，作者强调其独特性与性能突破，属非通用技术术语，用户可能搜索该缩写以寻找同类方法"
      },
      {
        "keyword": "角色扮演",
        "dimension": "功能场景",
        "reason": "README明确指出‘提供卓越的角色扮演体验’，是模型核心应用场景，非泛用词，具有明确搜索意图"
      },
      {
        "keyword": "100万字上下文",
        "dimension": "功能场景",
        "reason": "模型突出能力描述，虽含数字但属于用户可感知的‘长上下文’需求场景，非纯技术参数，符合‘用户搜长对话模型’的意图"
      },
      {
        "keyword": "Q8量化",
        "dimension": "部署工具",
        "reason": "模型提供Q8版本并推荐使用，Q8是GGUF量化等级中用户实际部署时关注的精度-性能平衡点，具操作指向性"
      },
      {
        "keyword": "Crazy版本",
        "dimension": "功能场景",
        "reason": "作者明确预告将发布‘Crazy版本’，属模型自身独有的版本分类术语，具有话题性和搜索独特性"
      },
      {
        "keyword": "MGRPO训练",
        "dimension": "技术特性",
        "reason": "作者重点描述MGRPO训练效率低但效果强，该组合词是模型训练方法的专有表达，非通用术语，具区分度"
      },
      {
        "keyword": "DeepSex",
        "dimension": "功能场景",
        "reason": "模型名称核心词，作者专门解释‘性’的哲学含义，暗示其用于深度人性/性格模拟，非字面色情，是用户搜索该类角色模型的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/Tar-1.5B",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中有ByteDance-Seed，映射为豆包"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed属于字节大模型系列"
      },
      {
        "keyword": "视觉理解",
        "dimension": "功能场景",
        "reason": "当前模型通过文本对齐表征统一视觉理解与生成，视觉理解是核心功能场景"
      },
      {
        "keyword": "视觉生成",
        "dimension": "功能场景",
        "reason": "当前模型通过文本对齐表征统一视觉理解与生成，视觉生成是核心功能场景"
      },
      {
        "keyword": "文本对齐表征",
        "dimension": "技术特性",
        "reason": "当前模型通过文本对齐表征统一视觉理解与生成，文本对齐表征是核心技术特性"
      },
      {
        "keyword": "1.5B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规格为1.5B"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.5-FP8",
    "keywords": [
      {
        "keyword": "GLM-4.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "GLM-4.5-Air",
        "dimension": "当前模型品牌名",
        "reason": "轻量版模型名称，属于同一系列的独特品牌"
      },
      {
        "keyword": "思考模式",
        "dimension": "技术特性",
        "reason": "模型支持的混合推理中的思考（Chain‑of‑Thought）模式"
      },
      {
        "keyword": "直接响应模式",
        "dimension": "技术特性",
        "reason": "模型提供的快速直接回答方式，与思考模式形成对比"
      },
      {
        "keyword": "智能体",
        "dimension": "功能场景",
        "reason": "模型专为智能体（agentic）任务设计，适用于智能体应用"
      },
      {
        "keyword": "3550B参数",
        "dimension": "参数规格",
        "reason": "模型的主参数规模，区别于常见的7B/32B规格"
      },
      {
        "keyword": "1060B参数",
        "dimension": "参数规格",
        "reason": "轻量版 GLM-4.5‑Air 的参数规模，提供更小模型选项"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/city96/Wan2.1-T2V-14B-gguf",
    "keywords": [
      {
        "keyword": "Wan2.1-T2V-14B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 city96/Wan2.1-T2V-14B-gguf 直接提取的当前模型唯一品牌名，符合简化规则（去后缀-gguf后仍保留核心标识）"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型标签为 text-to-video，对应中文用户高频搜索词'文生视频'，是明确的功能场景，且未在强制排除列表中"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "README明确指出模型需通过 ComfyUI-GGUF 自定义节点使用，'ComfyUI'是用户部署时搜索的关键工具名，且未在排除列表中"
      },
      {
        "keyword": "GGUF",
        "dimension": "技术特性",
        "reason": "模型为 GGUF 格式转换版本，该格式是量化部署的特定技术标准，用户搜索'GGUF模型'有明确意图，且未被排除"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "模型名称中包含'14B'，属于主流参数规模（介于7B与32B之间），用户会搜索'14B参数'模型，且未在排除列表中"
      },
      {
        "keyword": "量化模型",
        "dimension": "技术特性",
        "reason": "模型是基于FP32的GGUF量化版本，'量化模型'是用户寻找轻量部署方案时的核心搜索词，区别于通用'量化'一词，具有模型指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/edbeeching/decision-transformer-gym-hopper-medium",
    "keywords": [
      {
        "keyword": "Decision-Transformer",
        "dimension": "当前模型品牌名",
        "reason": "项目标题直接给出的模型名称"
      },
      {
        "keyword": "Gym-Hopper",
        "dimension": "功能场景",
        "reason": "模型专为Gym Hopper连续控制环境训练，用户会搜具体环境"
      },
      {
        "keyword": "中等轨迹",
        "dimension": "技术特性",
        "reason": "训练数据来自中等水平轨迹，是模型特色"
      },
      {
        "keyword": "连续控制",
        "dimension": "功能场景",
        "reason": "Hopper环境属于连续控制任务，用户搜索关键词"
      },
      {
        "keyword": "深度强化学习",
        "dimension": "技术特性",
        "reason": "Decision Transformer属于深度强化学习范畴"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jadechoghari/mar",
    "keywords": [
      {
        "keyword": "MAR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型品牌名，直接提取"
      },
      {
        "keyword": "自回归图像生成",
        "dimension": "功能场景",
        "reason": "模型的核心生成方式，用户搜索时会使用该描述"
      },
      {
        "keyword": "无矢量量化",
        "dimension": "技术特性",
        "reason": "模型创新点之一，区别于传统 VQ‑based 方法"
      },
      {
        "keyword": "连续值扩散",
        "dimension": "技术特性",
        "reason": "模型在连续值空间中进行扩散建模的关键技术"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "官方推荐的库，用于加载和运行该模型"
      },
      {
        "keyword": "DiffusionPipeline",
        "dimension": "部署工具",
        "reason": "HuggingFace 提供的管线接口，用户可直接调用生成图像"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenGVLab/InternVideo2_5_Chat_8B",
    "keywords": [
      {
        "keyword": "InternVideo2.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称明确为OpenGVLab/InternVideo2_5_Chat_8B，模型正式名称为InternVideo2.5，符合品牌名提取规则且无版本号冗余"
      },
      {
        "keyword": "视频多模态大语言模型",
        "dimension": "功能场景",
        "reason": "模型核心定位为视频多模态大语言模型（MLLM），是用户搜索视频理解类AI时的精准意图词，且未在高频排除词列表中"
      },
      {
        "keyword": "长丰富上下文",
        "dimension": "技术特性",
        "reason": "模型核心创新点为LRC（Long Rich Context）建模能力，是区别于其他视频模型的独特技术标签，用户可能搜索‘长上下文视频模型’"
      },
      {
        "keyword": "自适应层级化token压缩",
        "dimension": "技术特性",
        "reason": "HiCo技术为模型独有，虽为技术术语，但‘自适应层级化token压缩’是其官方命名，具备高区分度，可吸引专业用户搜索技术实现"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "模型用于视频与文本交互，‘视频理解’是用户在CSDN等平台搜索视频AI时的高频意图词，且未被高频排除词覆盖"
      },
      {
        "keyword": "密集视觉任务标注",
        "dimension": "技术特性",
        "reason": "模型通过TPO引入密集视觉标注，是区别于通用视频模型的关键训练方法，具备技术独特性"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "模型为8B规模，属于主流参数区间，未被高频排除词（7B/32B）覆盖，具有明确区分度和搜索价值"
      },
      {
        "keyword": "视频对话",
        "dimension": "功能场景",
        "reason": "模型后缀为‘Chat’，明确支持视频问答与对话交互，是用户寻找‘能对话的视频AI’时的精准场景词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/Tar-7B",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed 映射为字节跳动官方大模型品牌“豆包”"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed 即字节跳动自研大模型系列"
      },
      {
        "keyword": "Tar-7B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型简称，用户会搜"
      },
      {
        "keyword": "视觉理解生成统一",
        "dimension": "功能场景",
        "reason": "模型核心卖点：把视觉理解与生成合二为一，用户搜“统一视觉模型”等词"
      },
      {
        "keyword": "文本对齐表征",
        "dimension": "技术特性",
        "reason": "论文标题高频词，用户想了解“文本对齐”视觉模型时会搜索"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "技术特性",
        "reason": "官方标签，用户找任意模态互转模型时会直接搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stanfordmimi/synthpose-vitpose-huge-hf",
    "keywords": [
      {
        "keyword": "SynthPose",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "VitPose-Huge变体",
        "dimension": "当前模型品牌名",
        "reason": "从项目描述中提取的当前模型变体名称"
      },
      {
        "keyword": "姿态估计",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "生物力学分析",
        "dimension": "功能场景",
        "reason": "当前模型在生物力学领域的应用场景"
      },
      {
        "keyword": "合成数据微调",
        "dimension": "技术特性",
        "reason": "当前模型通过合成数据进行微调的技术特性"
      },
      {
        "keyword": "52个标记点预测",
        "dimension": "功能场景",
        "reason": "当前模型可预测的标记点数量，体现其功能特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stanfordmimi/synthpose-vitpose-base-hf",
    "keywords": [
      {
        "keyword": "SynthPose",
        "dimension": "当前模型品牌名",
        "reason": "项目与论文中明确提出的模型名称"
      },
      {
        "keyword": "VitPose",
        "dimension": "当前模型品牌名",
        "reason": "项目使用的骨干网络名称，用户会搜索"
      },
      {
        "keyword": "人体姿态估计",
        "dimension": "功能场景",
        "reason": "模型核心任务，用户搜索意图明确"
      },
      {
        "keyword": "运动捕捉",
        "dimension": "功能场景",
        "reason": "README中强调针对运动捕捉系统微调"
      },
      {
        "keyword": "52关键点",
        "dimension": "技术特性",
        "reason": "模型可预测52个关键点，用户会搜规格"
      },
      {
        "keyword": "合成数据微调",
        "dimension": "技术特性",
        "reason": "SynthPose创新方法，用户会搜技术细节"
      },
      {
        "keyword": "生物力学分析",
        "dimension": "功能场景",
        "reason": "README中提到的应用场景，用户搜索意图明确"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lerobot/pi0",
    "keywords": [
      {
        "keyword": "Pi0",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为lerobot/pi0，模型官方名称为Pi0，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "视觉-语言-动作流模型",
        "dimension": "技术特性",
        "reason": "论文中明确描述的核心架构，是Pi0区别于其他机器学习模型的独特技术定义"
      },
      {
        "keyword": "LeRobot",
        "dimension": "当前模型品牌名",
        "reason": "Pi0是LeRobot生态中的官方模型，LeRobot作为平台名称被用户用于搜索机器人控制模型"
      },
      {
        "keyword": "机器人控制",
        "dimension": "功能场景",
        "reason": "模型核心用途是通用机器人控制，用户搜索机器人AI时会使用该明确场景词"
      },
      {
        "keyword": "视觉-语言-动作",
        "dimension": "技术特性",
        "reason": "模型输入输出三模态结构的简明概括，是Pi0技术方案的关键词组合，非通用术语"
      },
      {
        "keyword": "AI机器人",
        "dimension": "功能场景",
        "reason": "用户在CSDN等平台搜索机器人AI解决方案时常用该通俗组合词，指向明确应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/PekingU/rtdetr_r101vd_coco_o365",
    "keywords": [
      {
        "keyword": "RT-DETR",
        "dimension": "当前模型品牌名",
        "reason": "模型卡片中直接使用的模型名称"
      },
      {
        "keyword": "Real-time-object-detection",
        "dimension": "功能场景",
        "reason": "模型定位为实时目标检测任务，用户常以此场景搜索"
      },
      {
        "keyword": "Hybrid-encoder",
        "dimension": "技术特性",
        "reason": "论文提出的高效混合编码器，用于提升多尺度特征处理速度"
      },
      {
        "keyword": "Uncertainty-minimization-query-selection",
        "dimension": "技术特性",
        "reason": "为解码器提供高质量初始查询的核心机制，提升检测精度"
      },
      {
        "keyword": "Adjustable-decoder-layers",
        "dimension": "技术特性",
        "reason": "支持在不重新训练的情况下灵活调节速度与精度"
      },
      {
        "keyword": "Objects365-pretraining",
        "dimension": "技术特性",
        "reason": "在Objects365数据集上进行预训练，显著提升AP表现"
      },
      {
        "keyword": "Scale-aware-interaction",
        "dimension": "技术特性",
        "reason": "解耦尺度内交互与跨尺度融合的设计，提高检测速度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/clefourrier/graphormer-base-pcqm4mv1",
    "keywords": [
      {
        "keyword": "Graphormer",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 clefourrier/graphormer-base-pcqm4mv1 中提取的核心模型品牌名，是该模型的唯一标识，用户搜索图神经网络模型时会直接使用此名称"
      },
      {
        "keyword": "图分类",
        "dimension": "功能场景",
        "reason": "模型明确用于图分类任务，是用户在AI领域搜索图神经网络应用场景时的核心关键词，具有明确搜索意图"
      },
      {
        "keyword": "分子建模",
        "dimension": "功能场景",
        "reason": "README明确指出该模型最可能应用于分子建模，是化学AI与图学习交叉领域的高价值垂直场景词，区别于通用图任务"
      },
      {
        "keyword": "图Transformer",
        "dimension": "技术特性",
        "reason": "模型本质是图结构上的Transformer架构，该术语是学术界和工业界对这类模型的通用技术标签，用户会用此词搜索相关模型"
      },
      {
        "keyword": "PCQM4M-LSC",
        "dimension": "当前模型品牌名",
        "reason": "模型在PCQM4M-LSC数据集上预训练并夺冠，该名称是模型训练背景的核心标识，属于模型专属的权威数据集名称，具有高区分度"
      },
      {
        "keyword": "KDD-CUP-2021",
        "dimension": "当前模型品牌名",
        "reason": "模型在KDD CUP 2021量子预测赛道获得第一名，该赛事名称是模型权威性的关键背书，用户搜索竞赛冠军模型时会使用此关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-32B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen2.5-VL-32B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景"
      },
      {
        "keyword": "智能代理功能",
        "dimension": "功能场景",
        "reason": "当前模型具备的智能代理能力"
      },
      {
        "keyword": "长视频理解",
        "dimension": "功能场景",
        "reason": "当前模型能够解析长视频内容"
      },
      {
        "keyword": "事件捕捉",
        "dimension": "功能场景",
        "reason": "当前模型新增的事件捕捉能力"
      },
      {
        "keyword": "结构化输出生成",
        "dimension": "功能场景",
        "reason": "当前模型支持内容结构化输出"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/vit_base_patch14_dinov2.lvd142m",
    "keywords": [
      {
        "keyword": "ViT-Base-Patch14",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 vit_base_patch14_dinov2.lvd142m 提取的简洁模型品牌名"
      },
      {
        "keyword": "DINOv2",
        "dimension": "技术特性",
        "reason": "模型采用 DINOv2 自监督学习方法进行预训练"
      },
      {
        "keyword": "LVD-142M数据集",
        "dimension": "技术特性",
        "reason": "模型在大规模 LVD-142M 数据集上进行预训练"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "模型的主要用途是提取图像特征，可用于下游视觉任务"
      },
      {
        "keyword": "timm库",
        "dimension": "部署工具",
        "reason": "模型通过 timm 库创建并提供预训练权重，便于在 PyTorch 环境中使用"
      },
      {
        "keyword": "86.6M参数",
        "dimension": "参数规格",
        "reason": "模型拥有约 86.6M 参数，属于中等规模的视觉 Transformer"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-nl-en",
    "keywords": [
      {
        "keyword": "opus-mt-nl-en",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "荷兰语翻译",
        "dimension": "功能场景",
        "reason": "当前模型专用于荷兰语到英语的翻译任务"
      },
      {
        "keyword": "SentencePiece分词",
        "dimension": "技术特性",
        "reason": "当前模型采用SentencePiece进行预处理分词"
      },
      {
        "keyword": "BLEU-60.9",
        "dimension": "技术特性",
        "reason": "Tatoeba测试集上取得的显著BLEU分数，体现翻译质量"
      },
      {
        "keyword": "transformer-align",
        "dimension": "技术特性",
        "reason": "当前模型使用的对齐式Transformer架构"
      },
      {
        "keyword": "OPUS数据集",
        "dimension": "技术特性",
        "reason": "当前模型训练所用的开源平行语料库"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/bge-m3",
    "keywords": [
      {
        "keyword": "BGE-M3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为BAAI/bge-m3，直接提取模型品牌名，简洁且为用户搜索核心词"
      },
      {
        "keyword": "混合检索",
        "dimension": "功能场景",
        "reason": "BGE-M3核心功能是同时支持密集+稀疏检索的混合检索，是用户寻找多方法检索模型时的关键搜索词"
      },
      {
        "keyword": "多语言嵌入",
        "dimension": "功能场景",
        "reason": "支持100+语言，用户搜索跨语言语义匹配、多语言RAG时会使用此精准场景词"
      },
      {
        "keyword": "长文档嵌入",
        "dimension": "功能场景",
        "reason": "支持8192 token长文本，是用户寻找处理论文、报告等长内容嵌入模型时的高价值搜索词"
      },
      {
        "keyword": "稀疏检索",
        "dimension": "技术特性",
        "reason": "BGE-M3原生支持稀疏检索（类似BM25），区别于普通嵌入模型，是其独特技术卖点"
      },
      {
        "keyword": "多向量检索",
        "dimension": "技术特性",
        "reason": "BGE-M3独有的多向量表示能力，是区别于单向量模型的关键技术特征，用户搜高级检索技术时会用"
      },
      {
        "keyword": "重排序器",
        "dimension": "功能场景",
        "reason": "模型推荐搭配bge-reranker做重排序，'重排序器'是RAG流程中高频搜索术语，且为BGE-M3推荐管道核心组件"
      },
      {
        "keyword": "嵌入模型",
        "dimension": "技术特性",
        "reason": "BGE-M3本质是嵌入模型，用户搜索'嵌入模型'时会寻找这类通用但高需求的模型类型，且非高频排除词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/mms-lid-256",
    "keywords": [
      {
        "keyword": "MMS-LID-256",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型品牌名"
      },
      {
        "keyword": "语言识别",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对音频进行语言（语种）识别"
      },
      {
        "keyword": "wav2vec2",
        "dimension": "技术特性",
        "reason": "模型基于 wav2vec2 架构进行特征提取"
      },
      {
        "keyword": "1B参数",
        "dimension": "参数规格",
        "reason": "检查点包含约 1 B（十亿）参数"
      },
      {
        "keyword": "256语言",
        "dimension": "功能场景",
        "reason": "模型支持对 256 种语言进行识别"
      },
      {
        "keyword": "HuggingFace-Transformers",
        "dimension": "部署工具",
        "reason": "模型可通过 HuggingFace Transformers 库进行加载和推理"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/DAMO-NLP-SG/VideoLLaMA3-7B",
    "keywords": [
      {
        "keyword": "VideoLLaMA3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "当前模型专精的核心能力"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "官方标签明确列出的应用场景"
      },
      {
        "keyword": "视频语言模型",
        "dimension": "技术特性",
        "reason": "模型定位与官方标签一致"
      },
      {
        "keyword": "序列视频数据洞察",
        "dimension": "功能场景",
        "reason": "README强调的独特卖点"
      },
      {
        "keyword": "动态视觉推理",
        "dimension": "技术特性",
        "reason": "README提到的高阶能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/amazon/chronos-bolt-small",
    "keywords": [
      {
        "keyword": "Chronos-Bolt",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "时间序列预测",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "T5架构",
        "dimension": "技术特性",
        "reason": "当前模型基于T5编码器-解码器架构"
      },
      {
        "keyword": "直接多步预测",
        "dimension": "技术特性",
        "reason": "当前模型采用直接多步预测方法"
      },
      {
        "keyword": "零样本预测",
        "dimension": "技术特性",
        "reason": "当前模型可用于零样本预测"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nomic-ai/nomic-embed-text-v1.5",
    "keywords": [
      {
        "keyword": "nomic-embed-text-v1.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索嵌入模型时会使用此完整名称"
      },
      {
        "keyword": "句子相似度",
        "dimension": "功能场景",
        "reason": "模型核心用途为句子嵌入与语义相似度计算，是用户在检索语义匹配场景时的高频搜索意图"
      },
      {
        "keyword": "feature-extraction",
        "dimension": "技术特性",
        "reason": "模型核心功能是文本特征提取，属于技术关键词，用户在寻找文本向量化工具时会搜索此术语"
      },
      {
        "keyword": "MTEB",
        "dimension": "技术特性",
        "reason": "模型在MTEB基准上评估，该术语是嵌入模型领域专业用户搜索评估标准时的专属关键词"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "部署工具",
        "reason": "模型基于sentence-transformers库构建，该库是中文开发者部署句子嵌入模型时的主流工具名"
      },
      {
        "keyword": "transformers.js",
        "dimension": "部署工具",
        "reason": "模型支持在浏览器端通过transformers.js运行，是前端AI开发者搜索轻量级JS嵌入模型时的关键词"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型支持ONNX格式导出，该格式是企业级部署和跨平台推理的关键词，具有明确技术指向性"
      },
      {
        "keyword": "English",
        "dimension": "语言类型",
        "reason": "模型专为英文文本优化，用户在寻找英文语义嵌入模型时会明确搜索此语言标签，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/mbart-large-50-many-to-many-mmt",
    "keywords": [
      {
        "keyword": "mBART",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型品牌名称，直接对应 facebook/mbart-large-50-many-to-many-mmt"
      },
      {
        "keyword": "多语言机器翻译",
        "dimension": "功能场景",
        "reason": "模型能够在 50 种语言之间进行翻译，核心应用场景是多语言机器翻译"
      },
      {
        "keyword": "跨语言翻译",
        "dimension": "功能场景",
        "reason": "支持任意语言对的直接翻译，体现跨语言（many‑to‑many）能力"
      },
      {
        "keyword": "forced-BOS-token",
        "dimension": "技术特性",
        "reason": "使用 forced_bos_token_id 参数强制目标语言 ID 为首个生成标记，是模型的关键技术特性"
      },
      {
        "keyword": "50语言支持",
        "dimension": "功能场景",
        "reason": "模型覆盖 50 种语言，强调其广泛的语言覆盖范围"
      },
      {
        "keyword": "Rust支持",
        "dimension": "技术特性",
        "reason": "模型的发布标签中包含 Rust，表明可以在 Rust 环境中使用"
      },
      {
        "keyword": "JAX兼容",
        "dimension": "技术特性",
        "reason": "发布标签中包含 JAX，说明模型兼容 JAX 框架"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型可通过 HuggingFace Transformers 的 generate 接口调用，适合 API 形式部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-7B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen2.5-7B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "智能对话",
        "dimension": "功能场景",
        "reason": "README强调聊天机器人与角色扮演，用户会搜智能对话"
      },
      {
        "keyword": "长文本生成",
        "dimension": "功能场景",
        "reason": "支持8K令牌输出，用户会搜长文本生成"
      },
      {
        "keyword": "结构化输出",
        "dimension": "功能场景",
        "reason": "擅长JSON等结构化输出，用户会搜结构化输出"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "README指向HuggingFace集成，用户会搜API调用"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "当前模型架构类型，用户会搜因果语言模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/autogluon/tabpfn-mix-1.0-classifier",
    "keywords": [
      {
        "keyword": "TabPFNMix",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'autogluon/tabpfn-mix-1.0-classifier' 中提取的核心模型品牌名，是用户搜索该特定表格分类模型的唯一标识"
      },
      {
        "keyword": "表格基础模型",
        "dimension": "功能场景",
        "reason": "模型在README中明确自称为'表格基础模型'，是用户在搜索表格数据AI解决方案时的精准意图词，区别于通用大模型"
      },
      {
        "keyword": "合成数据预训练",
        "dimension": "技术特性",
        "reason": "模型核心创新点在于使用'纯合成数据集'进行预训练，这是区别于其他表格模型的独特训练范式，用户会为此类方法搜索"
      },
      {
        "keyword": "上下文学习",
        "dimension": "技术特性",
        "reason": "模型采用'结合上下文学习的预训练策略'，是其与TabPFN等模型共有的关键技术标签，但作为当前模型的显著特征仍具搜索价值"
      },
      {
        "keyword": "Tabular-Classification",
        "dimension": "功能场景",
        "reason": "标签中明确列出，是用户在AI领域搜索表格分类任务时的标准化术语，具有明确搜索意图且未被列入强制排除词"
      },
      {
        "keyword": "3700万参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为3700万，属于中等规模表格模型的典型参数量，用户会搜索此类规模的轻量级表格模型，且未在高频排除词列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q4",
    "keywords": [
      {
        "keyword": "Tifa-DeepSexV2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中提取的完整模型品牌名称"
      },
      {
        "keyword": "MGRPO算法",
        "dimension": "技术特性",
        "reason": "模型采用的创新训练算法，是核心技术卖点"
      },
      {
        "keyword": "百万字上下文",
        "dimension": "功能场景",
        "reason": "模型支持约100万字的长上下文能力，适用于超长文本交互"
      },
      {
        "keyword": "角色扮演体验",
        "dimension": "功能场景",
        "reason": "模型专注于提供高质量的角色扮演对话场景"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "技术特性",
        "reason": "模型以 GGUF 格式提供多档位量化（Q8、Q4），便于高效部署"
      },
      {
        "keyword": "WebUI在线试用",
        "dimension": "部署工具",
        "reason": "提供基于 WebUI 的在线交互界面，免安装直接体验"
      },
      {
        "keyword": "Demo-APK",
        "dimension": "部署工具",
        "reason": "提供 Android 客户端 Demo，方便移动端快速体验模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lmms-lab/LLaVA-Video-7B-Qwen2",
    "keywords": [
      {
        "keyword": "LLaVA-Video-7B-Qwen2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "当前模型特别专注于视频理解，是其主要应用场景"
      },
      {
        "keyword": "32K上下文窗口",
        "dimension": "技术特性",
        "reason": "当前模型具有32K tokens的上下文窗口，是其技术特点之一"
      },
      {
        "keyword": "64帧视频处理",
        "dimension": "技术特性",
        "reason": "当前模型最多支持处理64帧视频，是其技术能力体现"
      },
      {
        "keyword": "LLaVA-Video-178K数据集",
        "dimension": "训练数据",
        "reason": "当前模型在LLaVA-Video-178K数据集上训练，是其训练数据来源"
      },
      {
        "keyword": "LLaVA-OneVision数据集",
        "dimension": "训练数据",
        "reason": "当前模型也在LLaVA-OneVision数据集上训练，是其另一训练数据来源"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Prior-Labs/TabPFN-v2-reg",
    "keywords": [
      {
        "keyword": "TabPFN",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格回归",
        "dimension": "功能场景",
        "reason": "README明确指出的核心用途"
      },
      {
        "keyword": "小数据预测",
        "dimension": "功能场景",
        "reason": "用户搜索小样本表格任务时的常用词"
      },
      {
        "keyword": "无需训练",
        "dimension": "技术特性",
        "reason": "README强调无需任务特定训练即可推理"
      },
      {
        "keyword": "Nature论文",
        "dimension": "技术特性",
        "reason": "顶级期刊背书，用户会搜模型+论文关键词"
      },
      {
        "keyword": "pip安装",
        "dimension": "部署工具",
        "reason": "README给出的极简安装方式，用户常搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric",
    "keywords": [
      {
        "keyword": "MASt3R",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric 中提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词"
      },
      {
        "keyword": "图像到3D匹配",
        "dimension": "功能场景",
        "reason": "模型核心用途为从图像实现三维几何匹配与定位，用户搜索‘图像到3D匹配’或‘3D图像定位’时会精准找到该模型，且非通用词"
      },
      {
        "keyword": "DUSt3R",
        "dimension": "当前模型品牌名",
        "reason": "README中明确引用DUSt3R作为同系列基础模型，且为独立发表的CVPR模型，属于当前项目直接关联的品牌名称，非其他公司模型"
      },
      {
        "keyword": "几何3D视觉",
        "dimension": "技术特性",
        "reason": "DUSt3R论文标题为‘Geometric 3D Vision Made Easy’，MASt3R继承其几何建模特性，‘几何3D视觉’是用户搜索三维重建类模型时的精准术语"
      },
      {
        "keyword": "3D重建",
        "dimension": "功能场景",
        "reason": "MASt3R用于从单图或多图恢复3D结构，是3D重建领域的主流应用场景，用户常搜索该词寻找相关模型，且未在高频排除词列表中"
      },
      {
        "keyword": "猫式MLP解码器",
        "dimension": "技术特性",
        "reason": "模型名称中‘catmlp’指‘concatenated MLP’，中文语境下可译为‘猫式MLP’（音译+意译结合），是该模型独有的解码器结构，具有区分度"
      },
      {
        "keyword": "512分辨率",
        "dimension": "参数规格",
        "reason": "模型训练分辨率为512，属于主流输入尺寸，用户在搜索‘512分辨率 3D模型’时会精准匹配，且不属于‘7B/32B’等高频参数词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-27b-it-GGUF",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名称，唯一标识本模型"
      },
      {
        "keyword": "27B参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模为27B，用户常以参数大小检索模型"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "技术特性",
        "reason": "模型以 GGUF 量化格式发布，区别于常见的 safetensors 等格式"
      },
      {
        "keyword": "Unsloth微调",
        "dimension": "部署工具",
        "reason": "提供基于 Unsloth 的免费微调 Notebook，适合用户快速微调模型"
      },
      {
        "keyword": "Ollama导出",
        "dimension": "部署工具",
        "reason": "模型支持导出为 Ollama 可直接部署的格式，满足本地或云端部署需求"
      },
      {
        "keyword": "llama.cpp兼容",
        "dimension": "部署工具",
        "reason": "模型可在 llama.cpp 环境中运行，提供轻量级本地推理方案"
      },
      {
        "keyword": "负责任AI工具包",
        "dimension": "技术特性",
        "reason": "随模型提供的 Responsible Generative AI Toolkit，帮助用户安全使用模型"
      },
      {
        "keyword": "文本图像生成",
        "dimension": "功能场景",
        "reason": "Gemma 3 具备处理文本与图像输入并生成输出的能力，适用于文本‑图像混合任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/bge-large-en-v1.5",
    "keywords": [
      {
        "keyword": "BGE",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为BAAI/bge-large-en-v1.5，BGE是该系列模型的官方品牌名称，且为用户搜索嵌入模型时的核心关键词"
      },
      {
        "keyword": "sentence-similarity",
        "dimension": "功能场景",
        "reason": "README明确标注为sentence-similarity，是用户搜索语义相似度计算、文本匹配场景时的直接搜索词"
      },
      {
        "keyword": "feature-extraction",
        "dimension": "功能场景",
        "reason": "README标签中包含feature-extraction，是检索增强系统中用户常搜的模型用途关键词"
      },
      {
        "keyword": "dense-retrieval",
        "dimension": "技术特性",
        "reason": "README明确将BGE归类为Dense Retrieval模型，该术语是检索领域专业用户的核心搜索词"
      },
      {
        "keyword": "BGE-Embedding",
        "dimension": "当前模型品牌名",
        "reason": "README中将BGE Embedding作为项目子名称使用，是用户区分BGE系列模型的常用搜索组合词"
      },
      {
        "keyword": "C-MTEB",
        "dimension": "技术特性",
        "reason": "C-MTEB是BGE团队自建的权威评测基准，专业用户会搜索该词来验证模型性能，具有高区分度"
      },
      {
        "keyword": "arxiv2312.15503",
        "dimension": "技术特性",
        "reason": "该arXiv编号是BGE-large-en-v1.5的官方论文标识，研究者常直接搜索arXiv编号定位模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/clefourrier/graphormer-base-pcqm4mv2",
    "keywords": [
      {
        "keyword": "Graphormer-base-pcqm4mv2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图分类模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景是图分类任务"
      },
      {
        "keyword": "分子建模",
        "dimension": "功能场景",
        "reason": "当前模型最相关的应用场景是分子建模"
      },
      {
        "keyword": "图Transformer",
        "dimension": "技术特性",
        "reason": "当前模型是基于图Transformer的架构"
      },
      {
        "keyword": "PCQM4M-LSCv2",
        "dimension": "技术特性",
        "reason": "当前模型是基于PCQM4M-LSCv2预训练的"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa",
    "keywords": [
      {
        "keyword": "LayoutLMv2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "DocVQA",
        "dimension": "功能场景",
        "reason": "当前模型专用于文档视觉问答任务"
      },
      {
        "keyword": "文档问答",
        "dimension": "功能场景",
        "reason": "用户搜索文档级问答场景时的常用词"
      },
      {
        "keyword": "OCR问答",
        "dimension": "功能场景",
        "reason": "结合OCR与问答的细分场景"
      },
      {
        "keyword": "微调模型",
        "dimension": "技术特性",
        "reason": "强调该模型已针对DocVQA任务完成微调"
      },
      {
        "keyword": "Adam优化器",
        "dimension": "技术特性",
        "reason": "训练日志中明确列出的优化器，用户可能搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/monologg/koelectra-small-v2-distilled-korquad-384",
    "keywords": [
      {
        "keyword": "KoELECTRA",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心品牌，用户直接搜索KoELECTRA找韩国版ELECTRA"
      },
      {
        "keyword": "KorQuAD",
        "dimension": "功能场景",
        "reason": "模型专为韩国问答数据集KorQuAD训练，用户搜KorQuAD即可定位该模型"
      },
      {
        "keyword": "蒸馏版",
        "dimension": "技术特性",
        "reason": "项目名称带distilled，表明是轻量蒸馏模型，用户搜蒸馏版可快速找到小体积高精度方案"
      },
      {
        "keyword": "384长度",
        "dimension": "技术特性",
        "reason": "模型后缀明确384，用户需要短文本高速推理时会直接搜384长度"
      },
      {
        "keyword": "韩语问答",
        "dimension": "功能场景",
        "reason": "面向韩语问答任务，用户搜韩语问答即可发现该模型"
      },
      {
        "keyword": "LiteRT",
        "dimension": "部署工具",
        "reason": "标签含LiteRT，表明支持移动端推理，用户搜LiteRT部署可找到该模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/SWE-Dev-32B",
    "keywords": [
      {
        "keyword": "SWE-Dev-32B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接指向的当前模型全称，是用户搜索该特定模型时最可能使用的关键词"
      },
      {
        "keyword": "软件工程智能体",
        "dimension": "功能场景",
        "reason": "模型核心定位是面向软件工程任务的AI智能体，属于明确、独特且用户可能搜索的功能场景词"
      },
      {
        "keyword": "SWE-bench",
        "dimension": "功能场景",
        "reason": "模型性能评估基准，是开发者在搜索AI编程模型时会关联的专有评估体系，具有高度场景指向性"
      },
      {
        "keyword": "强化微调",
        "dimension": "技术特性",
        "reason": "模型提升性能的关键技术手段（RFT），是区别于普通微调的特定训练方法，用户可能搜索相关优化技术"
      },
      {
        "keyword": "推理规模扩展",
        "dimension": "技术特性",
        "reason": "论文核心发现之一，指通过增加推理轮次（如30→75轮）提升解决率，属于模型特有的推理机制描述"
      },
      {
        "keyword": "SWE-Dev-train",
        "dimension": "当前模型品牌名",
        "reason": "项目中明确列出的配套训练数据集名称，作为模型生态的一部分，是开发者可能搜索的专属资源标识"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-Z1-9B-0414",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，且为智谱AI系列模型"
      },
      {
        "keyword": "用户友好部署",
        "dimension": "技术特性",
        "reason": "README中提到该模型支持非常用户友好的本地部署功能"
      },
      {
        "keyword": "指令跟随",
        "dimension": "功能场景",
        "reason": "README中提到该模型在指令跟随方面进行了性能增强"
      },
      {
        "keyword": "工程代码",
        "dimension": "功能场景",
        "reason": "README中提到该模型在工程代码方面进行了性能增强"
      },
      {
        "keyword": "函数调用",
        "dimension": "功能场景",
        "reason": "README中提到该模型在函数调用方面进行了性能增强"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/diffusers-cd_cat256_l2",
    "keywords": [
      {
        "keyword": "consistency-model",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确包含 'consistency-model'，是该模型的官方技术品牌名，用户搜索一致性模型时会直接使用此术语"
      },
      {
        "keyword": "单步生成",
        "dimension": "功能场景",
        "reason": "模型核心优势是支持单步生成高质量图像，属于用户搜索生成速度优化时的明确意图关键词"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "README明确提到模型支持零样本图像修复，是区别于传统扩散模型的独特应用场景"
      },
      {
        "keyword": "超分辨率",
        "dimension": "功能场景",
        "reason": "模型支持零样本超分辨率，属于用户搜索图像增强类AI工具时的精准搜索词"
      },
      {
        "keyword": "扩散模型蒸馏",
        "dimension": "技术特性",
        "reason": "模型通过蒸馏扩散模型训练，是其核心技术路径，用户研究生成模型演进时会搜索此术语"
      },
      {
        "keyword": "U-Net",
        "dimension": "技术特性",
        "reason": "模型明确使用U-Net作为参数化架构，是生成模型中高频但非泛滥的技术词，具区分度"
      },
      {
        "keyword": "零样本编辑",
        "dimension": "技术特性",
        "reason": "模型支持无需训练的零样本图像编辑，是Consistency Models的核心创新点，搜索意图明确"
      },
      {
        "keyword": "FID指标",
        "dimension": "技术特性",
        "reason": "论文中重点提及FID作为评估标准，专业用户搜索模型性能时会使用该术语，非泛滥词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large-Pretrain",
    "keywords": [
      {
        "keyword": "NextStep-1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "当前模型主网络参数量，用户常搜"
      },
      {
        "keyword": "流匹配头",
        "dimension": "技术特性",
        "reason": "当前模型独有的1.57亿参数流匹配头，是其独特架构"
      },
      {
        "keyword": "连续tokens",
        "dimension": "技术特性",
        "reason": "模型支持连续图像tokens，区别于传统离散tokens"
      },
      {
        "keyword": "自回归图像生成",
        "dimension": "功能场景",
        "reason": "当前模型核心能力，用户搜索意图明确"
      },
      {
        "keyword": "高保真图像合成",
        "dimension": "功能场景",
        "reason": "模型在文本到图像任务中的突出表现"
      },
      {
        "keyword": "NextStepPipeline",
        "dimension": "部署工具",
        "reason": "官方提供的推理管道，方便开发者调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/internlm/internlm-xcomposer2d5-7b",
    "keywords": [
      {
        "keyword": "InternLM-XComposer2.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型全称，直接代表该模型的品牌标识"
      },
      {
        "keyword": "图文组合",
        "dimension": "功能场景",
        "reason": "模型专注于图像与文本的组合与创作，是其核心应用场景"
      },
      {
        "keyword": "超长上下文",
        "dimension": "技术特性",
        "reason": "模型通过 RoPE 外推支持最高 96K 长上下文，突出其超长序列处理能力"
      },
      {
        "keyword": "RoPE外推",
        "dimension": "技术特性",
        "reason": "使用 RoPE（旋转位置编码）进行上下文长度外推，是模型的关键技术创新"
      },
      {
        "keyword": "图文交叉理解",
        "dimension": "技术特性",
        "reason": "模型在 24K 交叉图文上下文上进行训练，具备深度图文交叉理解能力"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型可通过 Transformers 接口以 API 方式调用，适合线上服务部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/Seed-OSS-36B-Base",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ByteDance-Seed，根据国产大模型映射规则，ByteDance-Seed对应品牌名'豆包'"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed是字节跳动旗下模型系列，映射为'字节大模型'，区别于高频词'阿里大模型'等"
      },
      {
        "keyword": "长上下文",
        "dimension": "功能场景",
        "reason": "README明确提到模型具备'powerful long-context'能力，是用户搜索长文本处理模型时的核心意图词"
      },
      {
        "keyword": "推理能力",
        "dimension": "功能场景",
        "reason": "README强调'reasoning'能力，属于用户搜索AI模型时的明确功能需求，非泛泛形容词"
      },
      {
        "keyword": "代理智能",
        "dimension": "功能场景",
        "reason": "README中'agent'能力直接对应中文用户搜索词'代理智能'，是当前模型独特卖点，非高频词"
      },
      {
        "keyword": "开发者友好",
        "dimension": "功能场景",
        "reason": "README明确提及'versatile developer-friendly features'，是开发者群体搜索模型时的精准意图词"
      },
      {
        "keyword": "36B参数",
        "dimension": "参数规格",
        "reason": "模型名称含36B，属于主流参数规模（介于7B与671B之间），用户会搜索此规格模型，且未被排除列表禁用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gpt-oss-20b-GGUF",
    "keywords": [
      {
        "keyword": "gpt-oss-20b",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "GGUF",
        "dimension": "技术特性",
        "reason": "README中多次提及的模型文件格式，属于当前模型的技术特性"
      },
      {
        "keyword": "harmony响应格式",
        "dimension": "技术特性",
        "reason": "当前模型训练采用的特定响应格式，属于技术特性"
      },
      {
        "keyword": "210亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，属于参数规格"
      },
      {
        "keyword": "Apache-2.0许可证",
        "dimension": "技术特性",
        "reason": "当前模型采用的许可证类型，属于技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Salesforce/blip-image-captioning-base",
    "keywords": [
      {
        "keyword": "BLIP",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型品牌名称"
      },
      {
        "keyword": "图像字幕",
        "dimension": "功能场景",
        "reason": "模型的核心任务是为图像生成文字描述（image captioning）"
      },
      {
        "keyword": "自举式预训练",
        "dimension": "技术特性",
        "reason": "BLIP 采用的 bootstrapped（自举式）预训练方式，能够在噪声数据上生成并过滤 caption"
      },
      {
        "keyword": "ViTbase-骨干",
        "dimension": "技术特性",
        "reason": "模型使用 Vision Transformer（ViT）base 作为视觉特征提取网络"
      },
      {
        "keyword": "COCO-预训练",
        "dimension": "技术特性",
        "reason": "模型在 COCO 数据集上进行大规模图像‑文本预训练"
      },
      {
        "keyword": "跨模态检索",
        "dimension": "功能场景",
        "reason": "BLIP 在图像‑文本检索任务上取得显著提升，可用于跨模态搜索"
      },
      {
        "keyword": "零样本视频语言",
        "dimension": "功能场景",
        "reason": "模型能够零样本迁移到视频‑语言任务，展示强大的泛化能力"
      },
      {
        "keyword": "VQA-提升",
        "dimension": "功能场景",
        "reason": "在视觉问答（VQA）任务上，BLIP 提升了评估分数，体现多任务适用性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B-FP8",
    "keywords": [
      {
        "keyword": "Qwen3-1.7B-FP8",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型唯一标识，FP8量化版本具有明确区分度，符合用户搜索具体模型变体的意图"
      },
      {
        "keyword": "FP8量化模型",
        "dimension": "部署工具",
        "reason": "FP8是当前模型独有的量化技术，用户会搜索‘FP8量化模型’来寻找低显存部署方案，区别于常见的INT4/FP16"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独创的‘思维/非思维模式无缝切换’功能，是Qwen3核心创新点，用户搜索‘思维模式切换’可精准定位该能力"
      },
      {
        "keyword": "32K上下文",
        "dimension": "参数规格",
        "reason": "32,768上下文长度属于主流长上下文规格，用户会搜索‘32K上下文’寻找长文本处理模型，且未被高频词列表排除"
      },
      {
        "keyword": "智能体工具对接",
        "dimension": "功能场景",
        "reason": "模型支持在思维/非思维模式下与外部工具精准对接，是智能体任务中的关键能力，区别于普通对话模型"
      },
      {
        "keyword": "多语言指令理解",
        "dimension": "功能场景",
        "reason": "支持100+语言的指令理解与翻译，是当前模型在多语言场景下的核心应用价值，用户会搜索该短语寻找多语言AI"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/distilbert/distilbert-base-uncased",
    "keywords": [
      {
        "keyword": "DistilBERT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "BERT蒸馏",
        "dimension": "技术特性",
        "reason": "当前模型采用知识蒸馏技术，从BERT压缩而来"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "功能场景",
        "reason": "当前模型支持MLM任务，用于文本补全"
      },
      {
        "keyword": "下一句预测",
        "dimension": "功能场景",
        "reason": "当前模型支持NSP任务，用于句子关系判断"
      },
      {
        "keyword": "英文预训练",
        "dimension": "功能场景",
        "reason": "当前模型专为英文语料预训练，适合英文NLP任务"
      },
      {
        "keyword": "轻量化BERT",
        "dimension": "技术特性",
        "reason": "当前模型比BERT更小更快，适合资源受限场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/inclusionAI/Ling-1T",
    "keywords": [
      {
        "keyword": "Ling-1T",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "高效推理",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，强调高效推理能力"
      },
      {
        "keyword": "进化思维链",
        "dimension": "技术特性",
        "reason": "当前模型在中期训练与后期训练阶段采用的技术流程"
      },
      {
        "keyword": "视觉美学感知",
        "dimension": "功能场景",
        "reason": "当前模型在视觉推理和前端代码生成任务上的独特能力"
      },
      {
        "keyword": "万亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的总参数量达到1万亿，具有显著区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-unsloth-bnb-4bit",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型系列名称"
      },
      {
        "keyword": "270M参数",
        "dimension": "参数规格",
        "reason": "当前模型超轻量规格，适合端侧部署"
      },
      {
        "keyword": "4bit量化",
        "dimension": "部署工具",
        "reason": "当前模型已做BNB 4bit量化，用户搜‘4bit量化’找现成模型"
      },
      {
        "keyword": "图像理解",
        "dimension": "功能场景",
        "reason": "Gemma-3支持图文输入，用户搜‘图像理解’找多模态小模型"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "当前模型超长上下文能力，用户会搜‘128K上下文’找支持长文的轻量模型"
      },
      {
        "keyword": "笔记本部署",
        "dimension": "部署工具",
        "reason": "README强调可在笔记本运行，用户搜‘笔记本部署’找低资源方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pyannote/segmentation",
    "keywords": [
      {
        "keyword": "pyannotesegmentation",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应模型唯一标识，用户搜索AI说话人分割模型时会直接使用此完整名称"
      },
      {
        "keyword": "说话人分割",
        "dimension": "功能场景",
        "reason": "模型核心功能，中文用户搜索语音分析、音频处理时高频使用的精准术语"
      },
      {
        "keyword": "语音活动检测",
        "dimension": "功能场景",
        "reason": "模型支持的核心任务，是音频处理领域独立搜索词，区别于通用语音识别"
      },
      {
        "keyword": "重叠语音检测",
        "dimension": "功能场景",
        "reason": "README明确提及'overlapped-speech-detection'，是说话人分割的关键应用场景，具技术独特性"
      },
      {
        "keyword": "pyannote.audio",
        "dimension": "技术特性",
        "reason": "模型依赖的专用框架名称，用户在部署或二次开发时会搜索该工具链"
      },
      {
        "keyword": "speaker-segmentation",
        "dimension": "技术特性",
        "reason": "英文技术术语，专业用户在GitHub、学术论文或英文技术博客中搜索该模型时的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-32B",
    "keywords": [
      {
        "keyword": "思考模式切换",
        "dimension": "技术特性",
        "reason": "模型能够在同一实例内无缝切换思考模式与非思考模式，提升复杂推理和通用对话的表现"
      },
      {
        "keyword": "代理能力集成",
        "dimension": "技术特性",
        "reason": "在思考和非思考模式下均支持与外部工具的精准集成，实现高级基于代理的任务"
      },
      {
        "keyword": "100语言支持",
        "dimension": "功能场景",
        "reason": "模型覆盖百余种语言和方言，具备强大的多语言指令遵循和翻译能力"
      },
      {
        "keyword": "YaRN-超长上下文",
        "dimension": "技术特性",
        "reason": "通过 YaRN 技术将上下文长度扩展至 131,072 tokens，适用于长文档处理"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "采用因果（自回归）结构，适合生成式任务和连续对话"
      },
      {
        "keyword": "64层网络",
        "dimension": "技术特性",
        "reason": "模型拥有 64 层深度，提供更丰富的特征表达能力"
      },
      {
        "keyword": "GQA-648-注意力头",
        "dimension": "技术特性",
        "reason": "使用 Grouped Query Attention，查询头 64、KV 头 8，提升推理效率和质量"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stabilityai/stable-video-diffusion-img2vid-xt-1-1",
    "keywords": [
      {
        "keyword": "Stable-Video-Diffusion",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像转视频",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "用户常用工作流部署方式"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "官方推荐的Python库"
      },
      {
        "keyword": "Stability-AI",
        "dimension": "当前模型品牌名",
        "reason": "模型所属公司品牌"
      },
      {
        "keyword": "社区许可",
        "dimension": "技术特性",
        "reason": "模型独有的商业使用条款"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/mask2former-swin-large-cityscapes-semantic",
    "keywords": [
      {
        "keyword": "Mask2Former",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Cityscapes语义分割",
        "dimension": "功能场景",
        "reason": "当前模型基于Cityscapes语义分割数据集训练，是其应用场景"
      },
      {
        "keyword": "Swin主干网络",
        "dimension": "技术特性",
        "reason": "当前模型采用Swin主干网络，是核心技术特性"
      },
      {
        "keyword": "多尺度可变形注意力",
        "dimension": "技术特性",
        "reason": "当前模型用多尺度可变形注意力Transformer替代像素解码器，是关键技术特性"
      },
      {
        "keyword": "遮蔽注意力Transformer",
        "dimension": "技术特性",
        "reason": "当前模型采用带有遮蔽注意力的Transformer解码器，是重要技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Thinking",
    "keywords": [
      {
        "keyword": "Kimi",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为moonshotai/Kimi-VL-A3B-Thinking，根据国产大模型映射规则，MoonshotAI → Kimi（月之暗面）"
      },
      {
        "keyword": "Kimi-VL-A3B-Thinking",
        "dimension": "当前模型品牌名",
        "reason": "模型完整名称是用户搜索高精度模型时可能使用的精确关键词，虽带后缀但为当前模型唯一标识，且未被高频词库排除"
      },
      {
        "keyword": "长思维",
        "dimension": "技术特性",
        "reason": "模型名称中明确提及‘Thinking’，且README强调‘长思维变体’，是区别于普通VLM的核心技术标签，用户会搜索‘长思维模型’"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "模型本质是VLM（Visual Language Model），该术语是中文用户搜索多模态模型时的常用表达，且未被高频词库排除"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "128K是当前模型显著的长上下文能力指标，虽为数字但属于主流级长上下文（用户常搜‘128K上下文模型’），且非纯性能指标，是模型核心卖点"
      },
      {
        "keyword": "MoonViT",
        "dimension": "技术特性",
        "reason": "模型自研视觉编码器名称，是区别于其他VLM的独特技术组件，用户可能搜索‘MoonViT模型’以获取高清视觉理解能力"
      },
      {
        "keyword": "多图像理解",
        "dimension": "功能场景",
        "reason": "README明确列出‘多图像理解’为模型能力之一，是具体、非泛化的应用场景，区别于通用‘多模态’高频词"
      },
      {
        "keyword": "智能体交互",
        "dimension": "功能场景",
        "reason": "模型在OSWorld等任务中表现突出，‘智能体交互’是用户搜索AI代理、自动化任务时的精准意图词，非泛泛的‘智能对话’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/notmahi/dobb-e",
    "keywords": [
      {
        "keyword": "DobbE",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型的品牌名称"
      },
      {
        "keyword": "居家预训练模型",
        "dimension": "功能场景",
        "reason": "模型专为家庭环境的预训练表征（HPR）设计，面向居家机器人视觉任务"
      },
      {
        "keyword": "HoNY数据集",
        "dimension": "技术特性",
        "reason": "模型使用的专属纽约家居（HoNY）数据集，是其核心训练资源"
      },
      {
        "keyword": "ResNet34架构",
        "dimension": "技术特性",
        "reason": "模型基于轻量级的 ResNet34 网络构建，体现其网络结构特点"
      },
      {
        "keyword": "timm框架",
        "dimension": "部署工具",
        "reason": "模型可通过 timm 库一键加载，提供便捷的本地或 API 部署方式"
      },
      {
        "keyword": "机器人视觉",
        "dimension": "功能场景",
        "reason": "模型面向机器人在家庭环境中的视觉感知任务，属于机器人视觉应用"
      },
      {
        "keyword": "MIT许可证",
        "dimension": "技术特性",
        "reason": "项目采用 MIT 开源许可证，标明其版权和使用许可方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B-GPTQ-Int4",
    "keywords": [
      {
        "keyword": "Qwen2.5-Omni",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "全模态",
        "dimension": "技术特性",
        "reason": "当前模型支持文本、图像、音频、视频全模态感知与生成"
      },
      {
        "keyword": "流式语音生成",
        "dimension": "功能场景",
        "reason": "用户搜索实时语音对话模型时的核心需求词"
      },
      {
        "keyword": "GPTQ-Int4",
        "dimension": "部署工具",
        "reason": "量化方案关键词，用户搜索低显存部署方案时常用"
      },
      {
        "keyword": "Thinker-Talker架构",
        "dimension": "技术特性",
        "reason": "当前模型独有的端到端架构名称，具有区分度"
      },
      {
        "keyword": "实时音视频对话",
        "dimension": "功能场景",
        "reason": "用户搜索可实时交互的音视频AI模型时的直接需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/tapas-large-finetuned-wtq",
    "keywords": [
      {
        "keyword": "TAPAS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'google/tapas-large-finetuned-wtq' 中提取的核心模型品牌名，是该系列模型的唯一标识"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型专用于表格结构数据的问答任务（Table Question Answering），是用户搜索此类AI模型时的明确意图关键词"
      },
      {
        "keyword": "WTQ",
        "dimension": "当前模型品牌名",
        "reason": "模型在WikiTable Questions (WTQ) 数据集上微调，WTQ是该模型的专属任务标签，具有高度区分性"
      },
      {
        "keyword": "位置重置",
        "dimension": "技术特性",
        "reason": "模型核心创新点之一，指在表格单元格中重置位置索引的相对位置嵌入技术，是区别于其他表格模型的关键技术特征"
      },
      {
        "keyword": "链式微调",
        "dimension": "技术特性",
        "reason": "模型采用在SQA→WikiSQL→WTQ上的链式微调策略，是其训练流程的独特技术术语，用户搜索模型训练方法时可能使用"
      },
      {
        "keyword": "中间预训练",
        "dimension": "技术特性",
        "reason": "模型在正式微调前使用掩码语言建模+中间预训练的特殊阶段，属于该模型独有的训练设计，具有技术辨识度"
      },
      {
        "keyword": "TAPAS-large",
        "dimension": "当前模型品牌名",
        "reason": "模型的具体版本名称，是用户在搜索大参数量TAPAS模型时的直接关键词，且未被高频词库排除"
      },
      {
        "keyword": "无重置版本",
        "dimension": "技术特性",
        "reason": "模型提供'无重置'（绝对位置嵌入）的对比版本，该术语在文档中明确区分，是用户比较模型变体时的搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/maskformer-swin-large-coco",
    "keywords": [
      {
        "keyword": "MaskFormer",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "全景分割",
        "dimension": "功能场景",
        "reason": "当前模型在COCO全景分割任务上训练，用户会搜此功能"
      },
      {
        "keyword": "实例分割",
        "dimension": "功能场景",
        "reason": "MaskFormer支持实例分割，用户搜索意图明确"
      },
      {
        "keyword": "语义分割",
        "dimension": "功能场景",
        "reason": "当前检查点可直接用于语义分割任务"
      },
      {
        "keyword": "Swin主干网络",
        "dimension": "技术特性",
        "reason": "当前模型采用Swin Transformer作为主干网络，技术特色鲜明"
      },
      {
        "keyword": "COCO数据集",
        "dimension": "技术特性",
        "reason": "模型基于COCO全景分割数据集训练，用户会搜此关键词"
      },
      {
        "keyword": "MaskFormerImageProcessor",
        "dimension": "部署工具",
        "reason": "Hugging Face提供的专用处理器，用户部署时会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/tapas-small-finetuned-wtq",
    "keywords": [
      {
        "keyword": "TAPAS小型",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含 TAPAS 且为 small 版本，提取为简洁品牌名"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型专注于对表格数据进行问答，是其核心应用场景"
      },
      {
        "keyword": "WikiTable-Questions",
        "dimension": "功能场景",
        "reason": "模型在 WikiTable Questions (WTQ) 数据集上进行微调，用户常以该数据集名称搜索相关模型"
      },
      {
        "keyword": "相对位置嵌入",
        "dimension": "技术特性",
        "reason": "该模型采用相对位置嵌入（reset）方式，是区别于其他版本的关键技术点"
      },
      {
        "keyword": "中间预训练",
        "dimension": "技术特性",
        "reason": "模型在正式微调前进行的中间预训练步骤，是其性能提升的关键环节"
      },
      {
        "keyword": "WTQ微调",
        "dimension": "技术特性",
        "reason": "模型在 WTQ 任务上进行的微调，是用户搜索时常用的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/owlv2-large-patch14-ensemble",
    "keywords": [
      {
        "keyword": "OWLv2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Open-World-Localization",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能描述，用户可能搜索此类技术名称"
      },
      {
        "keyword": "zero-shot-object-detection",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景，用户可能搜索此类技术术语"
      },
      {
        "keyword": "CLIP多模态",
        "dimension": "技术特性",
        "reason": "当前模型使用的多模态技术，用户可能搜索此类技术组合"
      },
      {
        "keyword": "ViT-like-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型使用的视觉特征提取技术，用户可能搜索此类技术细节"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/dinov2-small",
    "keywords": [
      {
        "keyword": "DINOv2-small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索时会使用该完整轻量版名称"
      },
      {
        "keyword": "自监督视觉特征",
        "dimension": "技术特性",
        "reason": "模型核心训练方式与输出能力，用户搜索无监督视觉表征时会使用该精准术语"
      },
      {
        "keyword": "ViT特征提取",
        "dimension": "功能场景",
        "reason": "模型主要用途是作为ViT编码器提取图像特征，非分类模型，该组合词具明确搜索意图"
      },
      {
        "keyword": "DINOv2",
        "dimension": "当前模型品牌名",
        "reason": "模型所属技术系列名称，用户会搜索DINOv2系列而非仅小尺寸版本，需保留主品牌"
      },
      {
        "keyword": "CLS标记表征",
        "dimension": "技术特性",
        "reason": "模型使用[CLS]标记输出图像语义向量，是其特征提取机制的关键技术点，具独特性"
      },
      {
        "keyword": "无监督视觉预训练",
        "dimension": "技术特性",
        "reason": "模型训练方式的核心描述，区别于有监督模型，是用户研究自监督视觉学习时的高频精准词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/mobilenetv3_small_100.lamb_in1k",
    "keywords": [
      {
        "keyword": "MobileNetV3-Small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 mobilenetv3_small_100.lamb_in1k 中提取的模型名称，去掉版本号和后缀"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "模型用于 ImageNet‑1k 上的图像分类任务，是其主要应用场景"
      },
      {
        "keyword": "LAMB优化器",
        "dimension": "技术特性",
        "reason": "训练时采用的 LAMB 优化器，是模型的核心训练技术之一"
      },
      {
        "keyword": "EMA权重平均",
        "dimension": "技术特性",
        "reason": "模型训练中使用的 EMA（指数移动平均）权重策略，提高了模型稳定性"
      },
      {
        "keyword": "RMSProp优化器",
        "dimension": "技术特性",
        "reason": "模型实现中提供的 RMSProp 优化器选项，模拟 TensorFlow 1.0 行为"
      },
      {
        "keyword": "2.5M-参数",
        "dimension": "参数规格",
        "reason": "模型总参数量约为 2.5 百万，是区分模型规模的重要指标"
      },
      {
        "keyword": "ImageNet-1k",
        "dimension": "技术特性",
        "reason": "模型在 ImageNet‑1k 数据集上训练完成，标明了其数据来源和基准"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/MiniCPM-o-2_6",
    "keywords": [
      {
        "keyword": "MiniCPM-o",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为openbmb/MiniCPM-o-2_6，根据规则需简化为品牌名MiniCPM-o，且为当前模型唯一标识"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "技术特性",
        "reason": "模型核心能力标签，指代跨模态（视觉、语音、文本）任意输入输出，是区别于普通多模态模型的独特技术定位"
      },
      {
        "keyword": "实时语音对话",
        "dimension": "功能场景",
        "reason": "README明确提及'realtime speech conversation'，是用户搜索语音交互类AI模型时的精准意图词，非泛用'智能对话'"
      },
      {
        "keyword": "语音克隆",
        "dimension": "功能场景",
        "reason": "标签中含'voice cloning'，属于模型专属能力，用户会主动搜索该术语寻找可模仿声音的AI工具"
      },
      {
        "keyword": "OCR",
        "dimension": "功能场景",
        "reason": "模型支持文本识别，且在多模态模型中OCR是高价值细分场景，非通用'图像理解'，具有搜索区分度"
      },
      {
        "keyword": "ASR",
        "dimension": "功能场景",
        "reason": "标签明确包含'asr'，指自动语音识别，是语音类模型的核心功能词，用户常搜索该缩写词寻找语音转文字工具"
      },
      {
        "keyword": "TTS",
        "dimension": "功能场景",
        "reason": "标签含'tts'，指文本转语音，模型支持端到端语音生成，该缩写词是技术用户搜索语音合成模型的高频精准词"
      },
      {
        "keyword": "多图输入",
        "dimension": "功能场景",
        "reason": "标签含'multi-image'，翻译为中文'多图输入'，指模型可同时处理多张图像，区别于单图输入模型，具独特搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/resnet18.a1_in1k",
    "keywords": [
      {
        "keyword": "ResNet18.a1in1k",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "特征骨干网络",
        "dimension": "功能场景",
        "reason": "当前模型在深度学习中的角色定位"
      },
      {
        "keyword": "ReLU激活函数",
        "dimension": "技术特性",
        "reason": "当前模型使用的激活函数类型"
      },
      {
        "keyword": "LAMB优化器",
        "dimension": "技术特性",
        "reason": "当前模型训练过程中使用的优化器"
      },
      {
        "keyword": "BCE损失函数",
        "dimension": "技术特性",
        "reason": "当前模型训练过程中使用的损失函数"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/w11wo/indonesian-roberta-base-posp-tagger",
    "keywords": [
      {
        "keyword": "印尼RoBERTa",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的indonesian-roberta-base，指向印尼语RoBERTa变体"
      },
      {
        "keyword": "词性标注",
        "dimension": "功能场景",
        "reason": "README明确标注为POS tagger，用于印尼语词性标注任务"
      },
      {
        "keyword": "印尼语NLP",
        "dimension": "功能场景",
        "reason": "专为印尼语设计的NLP模型，满足印尼语处理需求"
      },
      {
        "keyword": "IndoNLU",
        "dimension": "技术特性",
        "reason": "基于IndoNLU数据集微调，体现印尼语理解能力"
      },
      {
        "keyword": "96准确率",
        "dimension": "技术特性",
        "reason": "README给出0.9625的F1/准确率，突出高精度表现"
      },
      {
        "keyword": "Flax微调",
        "dimension": "部署工具",
        "reason": "基于flax-community版本微调，支持Flax框架部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Xenova/slimsam-77-uniform",
    "keywords": [
      {
        "keyword": "slimsam-77-uniform",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源，是当前模型的唯一标识名称，用户搜索特定轻量级SAM模型时会使用此全称"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型提供ONNX格式权重，专为JavaScript环境优化，是区别于其他SAM模型的核心部署特性"
      },
      {
        "keyword": "Transformers.js",
        "dimension": "部署工具",
        "reason": "模型明确适配该库，是前端/浏览器端运行SAM模型的关键技术入口，用户会搜索此组合"
      },
      {
        "keyword": "掩码生成",
        "dimension": "功能场景",
        "reason": "模型核心用途是图像掩码生成，属于用户明确搜索的AI图像分割任务关键词"
      },
      {
        "keyword": "轻量级SAM",
        "dimension": "技术特性",
        "reason": "模型名称'slimsam'暗示其轻量化设计，'SAM'是Segment Anything Model的通用缩写，组合词精准描述模型定位"
      },
      {
        "keyword": "浏览器推理",
        "dimension": "部署工具",
        "reason": "基于Transformers.js部署，意味着可在浏览器中直接运行，是区别于传统GPU部署的差异化使用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3-0324",
    "keywords": [
      {
        "keyword": "DeepSeek-V3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名，标识该模型系列"
      },
      {
        "keyword": "高级推理",
        "dimension": "技术特性",
        "reason": "模型在推理基准（MMLU‑Pro、GPQA 等）上显著提升，体现其强大的推理能力"
      },
      {
        "keyword": "前端网页开发",
        "dimension": "功能场景",
        "reason": "README 中提到改进了代码可执行性和更美观的网页/游戏前端，适用于前端开发场景"
      },
      {
        "keyword": "多轮交互改写",
        "dimension": "功能场景",
        "reason": "模型增强了多轮交互式文本改写能力，适合对话式编辑与写作"
      },
      {
        "keyword": "中文写作优化",
        "dimension": "功能场景",
        "reason": "提升了中文中长篇写作的风格与内容质量，面向中文写作需求"
      },
      {
        "keyword": "翻译质量提升",
        "dimension": "功能场景",
        "reason": "模型在翻译任务上进行了优化，提供更高质量的机器翻译"
      },
      {
        "keyword": "代码执行增强",
        "dimension": "技术特性",
        "reason": "改进了代码的可执行性，使模型在生成可运行代码时更可靠"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/amazon/chronos-t5-base",
    "keywords": [
      {
        "keyword": "Chronos-T5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型品牌名，是用户搜索该时间序列模型的核心关键词"
      },
      {
        "keyword": "时间序列预测",
        "dimension": "功能场景",
        "reason": "模型的核心用途，用户搜索AI做时间序列预测时会使用该词，且非高频禁用词"
      },
      {
        "keyword": "时间序列基础模型",
        "dimension": "技术特性",
        "reason": "README明确提及'time series foundation models'，是该模型的定位关键词，具有区分度"
      },
      {
        "keyword": "自回归采样",
        "dimension": "技术特性",
        "reason": "模型推理阶段的核心机制，原文明确描述，属于技术关键词且未在高频排除列表中"
      },
      {
        "keyword": "量化标记序列",
        "dimension": "技术特性",
        "reason": "Chronos独创的输入转换方式，将时间序列转为标记序列，是区别于其他模型的关键技术点"
      },
      {
        "keyword": "概率预测",
        "dimension": "功能场景",
        "reason": "模型输出形式的核心特征，用户搜索‘AI概率预测’时可能匹配，非通用词且未被排除"
      },
      {
        "keyword": "T5架构",
        "dimension": "技术特性",
        "reason": "模型基于T5架构构建，虽T5是通用架构，但当前模型是T5在时间序列领域的专用变体，用户会搜索'T5架构 时间序列'等组合"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/speechbrain/emotion-recognition-wav2vec2-IEMOCAP",
    "keywords": [
      {
        "keyword": "emotion-recognition-wav2vec2-IEMOCAP",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "情感识别",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "wav2vec2",
        "dimension": "技术特性",
        "reason": "当前模型使用的核心技术"
      },
      {
        "keyword": "IEMOCAP数据集",
        "dimension": "技术特性",
        "reason": "当前模型训练所使用的数据集"
      },
      {
        "keyword": "注意力统计池化",
        "dimension": "技术特性",
        "reason": "当前模型提取嵌入特征所采用的技术"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.1-VACE-14B",
    "keywords": [
      {
        "keyword": "Wan2.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型品牌名"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型核心能力之一，用户高频搜索的AI视频生成场景"
      },
      {
        "keyword": "图生视频",
        "dimension": "功能场景",
        "reason": "支持静态图转动态视频，明确搜索意图"
      },
      {
        "keyword": "视频编辑",
        "dimension": "功能场景",
        "reason": "模型官方强调的多任务能力，用户会直搜"
      },
      {
        "keyword": "视觉文本生成",
        "dimension": "技术特性",
        "reason": "官方亮点功能，中英文文字直接出现在视频中，差异化卖点"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "当前模型规格，主流大参数视频模型检索词"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "官方兼容Diffusers库，开发者常用检索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/tapas-base-finetuned-wtq",
    "keywords": [
      {
        "keyword": "TAPAS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型专为WikiTable Questions数据集微调，用于回答表格相关问题"
      },
      {
        "keyword": "相对位置嵌入",
        "dimension": "技术特性",
        "reason": "模型采用相对位置嵌入技术，在表格每个单元格重置位置索引"
      },
      {
        "keyword": "链式微调",
        "dimension": "技术特性",
        "reason": "模型依次在SQA、 WikiSQL和WTQ数据集上进行链式微调"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "模型通过掩码语言建模（MLM）及中间预训练步骤进行预训练"
      },
      {
        "keyword": "WikiTable-Questions",
        "dimension": "功能场景",
        "reason": "模型基于WTQ数据集微调，用于表格问答任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/dima806/fairface_age_image_detection",
    "keywords": [
      {
        "keyword": "FairFace-Age-Detection",
        "dimension": "当前模型品牌名",
        "reason": "从项目仓库名称 fairface_age_image_detection 提取的模型品牌名称，直接指代该模型"
      },
      {
        "keyword": "年龄段图像分类",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对人脸图像进行年龄段分类，用户常以此关键词搜索相关模型"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "模型基于 TensorFlow 框架实现，用户在寻找 TensorFlow 版年龄检测模型时会使用该词"
      },
      {
        "keyword": "ViT",
        "dimension": "技术特性",
        "reason": "使用 Vision Transformer（ViT）进行特征提取，是模型的关键技术特性"
      },
      {
        "keyword": "FairFace-数据集",
        "dimension": "当前模型品牌名",
        "reason": "模型基于公开的 FairFace 数据集进行训练，用户常以数据集名称定位相应模型"
      },
      {
        "keyword": "Kaggle-Age-Classification-Notebook",
        "dimension": "功能场景",
        "reason": "README 中提供的 Kaggle Notebook 链接是模型使用示例，搜索该关键词可直接找到模型实现细节"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/sam-vit-large",
    "keywords": [
      {
        "keyword": "SAM-ViT-Large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'facebook/sam-vit-large' 直接提取的模型全称，是用户搜索该特定版本时的精准关键词"
      },
      {
        "keyword": "图像分割",
        "dimension": "功能场景",
        "reason": "模型核心功能是根据点/框提示生成对象掩码，属于明确的视觉任务场景，用户会搜索‘图像分割模型’"
      },
      {
        "keyword": "零样本分割",
        "dimension": "技术特性",
        "reason": "论文强调模型具备‘零样本迁移到新图像分布和任务’的能力，是SAM区别于传统分割模型的核心卖点"
      },
      {
        "keyword": "可提示分割",
        "dimension": "技术特性",
        "reason": "模型采用‘可提示式设计’，支持点、框等交互式输入，这是SAM提出的新范式，具有高度区分度"
      },
      {
        "keyword": "SA-1B数据集",
        "dimension": "技术特性",
        "reason": "模型训练基于1100万图像+10亿掩码的SA-1B数据集，该数据集是SAM项目的核心资产，用户会搜索该专有名称"
      },
      {
        "keyword": "VisionEncoder",
        "dimension": "技术特性",
        "reason": "模型三大模块之一，基于ViT架构，是技术文档中高频提及的组件，吸引关注架构细节的开发者"
      },
      {
        "keyword": "MaskDecoder",
        "dimension": "技术特性",
        "reason": "模型核心组件，负责生成掩码，是理解SAM工作原理的关键模块，技术社区常以此为关键词检索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Salesforce/blip-image-captioning-large",
    "keywords": [
      {
        "keyword": "BLIP-image-captioning-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像描述生成",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "自举标注技术",
        "dimension": "技术特性",
        "reason": "当前模型使用的核心技术特性"
      },
      {
        "keyword": "视觉语言理解与生成",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能"
      },
      {
        "keyword": "ViT大型骨干网络",
        "dimension": "技术特性",
        "reason": "当前模型采用的基础架构"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/MiniCPM4.1-8B",
    "keywords": [
      {
        "keyword": "MiniCPM4.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌，用户搜索时会使用该名称"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "模型规模为80亿参数，属于主流的8B规格，用户常以参数大小检索模型"
      },
      {
        "keyword": "稀疏注意力",
        "dimension": "技术特性",
        "reason": "模型采用可训练稀疏注意力机制，是其核心创新点，用户会以此技术特性搜索"
      },
      {
        "keyword": "思维链",
        "dimension": "技术特性",
        "reason": "MiniCPM4.1 支持融合思维链（Chain‑of‑Thought），是区别于其他模型的关键特性"
      },
      {
        "keyword": "GPTQ",
        "dimension": "部署工具",
        "reason": "模型提供 GPTQ 量化格式，用户在寻找量化模型时会使用该关键词"
      },
      {
        "keyword": "AutoAWQ",
        "dimension": "部署工具",
        "reason": "提供 AutoAWQ 量化格式，属于模型独有的部署/量化选项，用户会专门搜索"
      },
      {
        "keyword": "Eagle3",
        "dimension": "技术特性",
        "reason": "MiniCPM4.1‑8B‑Eagle3 为专用加速模型，具备独特的 Eagle3 技术，用户搜索时会使用该名称"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/detr-resnet-101",
    "keywords": [
      {
        "keyword": "DETR-resnet-101",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，是用户搜索该特定目标检测模型时最可能使用的关键词"
      },
      {
        "keyword": "端到端目标检测",
        "dimension": "功能场景",
        "reason": "模型的核心功能描述，用户在寻找无需NMS、端到端训练的目标检测方案时会使用此术语"
      },
      {
        "keyword": "对象查询",
        "dimension": "技术特性",
        "reason": "DETR模型独有的核心机制，区别于传统Anchor或Proposal方法，是技术社区讨论该模型时的关键术语"
      },
      {
        "keyword": "二分匹配损失",
        "dimension": "技术特性",
        "reason": "DETR论文提出的创新训练方法，专业用户搜索其训练机制时会使用该术语，具有高度区分性"
      },
      {
        "keyword": "匈牙利匹配",
        "dimension": "技术特性",
        "reason": "实现二分匹配损失的核心算法，是DETR区别于其他检测模型的标志性技术点，搜索量稳定且专业"
      },
      {
        "keyword": "COCO目标检测",
        "dimension": "功能场景",
        "reason": "模型训练和评估所用的权威数据集，用户搜索‘COCO目标检测模型’时会精准匹配该模型"
      },
      {
        "keyword": "DETR模型",
        "dimension": "当前模型品牌名",
        "reason": "模型所属家族的通用名称，用户常以‘DETR模型’为关键词搜索该类架构，且不与高频词冲突"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LLM-Research/Molmo-7B-D-0924",
    "keywords": [
      {
        "keyword": "Molmo",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心能力：同时理解图像与文本"
      },
      {
        "keyword": "PixMo数据集",
        "dimension": "技术特性",
        "reason": "当前模型独有的训练数据来源，用户会搜"
      },
      {
        "keyword": "开源多模态",
        "dimension": "技术特性",
        "reason": "强调完全开源的多模态能力，区别于闭源方案"
      },
      {
        "keyword": "图像文本对训练",
        "dimension": "技术特性",
        "reason": "描述训练方式，用户想了解数据来源"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "用户搜索如何在线调用该模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-en-fr",
    "keywords": [
      {
        "keyword": "opus-mt-en-fr",
        "dimension": "当前模型品牌名",
        "reason": "项目仓库名称即模型的官方标识"
      },
      {
        "keyword": "英法机器翻译",
        "dimension": "功能场景",
        "reason": "模型专注于英文到法文的机器翻译任务"
      },
      {
        "keyword": "OPUS数据集",
        "dimension": "数据集",
        "reason": "模型使用公开的 OPUS 多语言平行语料库进行训练"
      },
      {
        "keyword": "SentencePiece分词",
        "dimension": "预处理技术",
        "reason": "模型采用 SentencePiece 进行子词分词，提升跨语言对齐效果"
      },
      {
        "keyword": "BLEU评分",
        "dimension": "评估指标",
        "reason": "在公开测试集上使用 BLEU 进行翻译质量评估"
      },
      {
        "keyword": "chr-F指标",
        "dimension": "评估指标",
        "reason": "模型报告的 chr‑F 分数用于衡量字符层面的翻译准确度"
      },
      {
        "keyword": "对齐翻译模型",
        "dimension": "技术特性",
        "reason": "采用对齐（alignment）技术的 Transformer‑align 架构，实现源‑目标语言的高效对齐"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stabilityai/stable-video-diffusion-img2vid",
    "keywords": [
      {
        "keyword": "Stable-Video-Diffusion",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 stabilityai/stable-video-diffusion-img2vid 提取的官方模型品牌名，是用户搜索图像转视频模型时的核心关键词"
      },
      {
        "keyword": "图像转视频",
        "dimension": "功能场景",
        "reason": "模型核心功能是将静态图像生成视频，是用户在CSDN等平台搜索AI视频生成时的直接意图词，且未被高频词列表排除"
      },
      {
        "keyword": "latent扩散模型",
        "dimension": "技术特性",
        "reason": "模型采用latent扩散架构，是技术文档中明确描述的核心方法论，区别于普通扩散模型，具有专业搜索价值"
      },
      {
        "keyword": "时间一致性",
        "dimension": "技术特性",
        "reason": "模型通过微调f8-decoder增强视频帧间时间一致性，是该模型在生成视频时的关键技术亮点，用户会为高质量视频生成搜索此术语"
      },
      {
        "keyword": "14帧视频",
        "dimension": "参数规格",
        "reason": "模型固定生成14帧短视频，是明确的输出规格参数，用户在对比不同视频生成模型时会搜索帧数规格"
      },
      {
        "keyword": "576x1024分辨率",
        "dimension": "参数规格",
        "reason": "模型输出视频具有明确的576x1024分辨率，是用户评估视频质量与适用场景时的重要量化指标，非通用描述"
      },
      {
        "keyword": "f8-decoder",
        "dimension": "技术特性",
        "reason": "模型专门微调了f8-decoder以提升视频生成质量，是该模型独有的技术组件，具有区分度且未被高频词覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224",
    "keywords": [
      {
        "keyword": "BiomedCLIP",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "生物医学视觉语言",
        "dimension": "功能场景",
        "reason": "当前模型的应用领域，体现其处理生物医学视觉语言任务的能力"
      },
      {
        "keyword": "PubMedBERT",
        "dimension": "技术特性",
        "reason": "当前模型采用的文本编码器，是其技术特点之一"
      },
      {
        "keyword": "Vision-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型采用的图像编码器，是其技术特点之一"
      },
      {
        "keyword": "跨模态检索",
        "dimension": "功能场景",
        "reason": "当前模型能够执行的任务之一，体现其跨模态处理能力"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "当前模型能够执行的任务之一，体现其视觉与语言结合的处理能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Salesforce/blip2-opt-2.7b-coco",
    "keywords": [
      {
        "keyword": "BLIP-2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Salesforce/blip2-opt-2.7b-coco 中提取的核心模型品牌名，符合用户搜索AI模型时的习惯，简洁且唯一"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "模型明确支持视觉问答（VQA）任务，是用户搜索多模态模型时的高频意图场景，且未被列入强制排除词库"
      },
      {
        "keyword": "图像字幕",
        "dimension": "功能场景",
        "reason": "模型核心功能之一为图像字幕（image captioning），中文用户常搜索此术语，区别于通用‘文生图’，具有明确任务指向性"
      },
      {
        "keyword": "Q-Former",
        "dimension": "技术特性",
        "reason": "BLIP-2独有的架构组件，用于桥接视觉与语言嵌入空间，是区别于其他视觉语言模型的关键技术名词，用户在深度研究时会搜索"
      },
      {
        "keyword": "冻结图像编码器",
        "dimension": "技术特性",
        "reason": "模型训练的核心策略，区别于端到端训练的多模态模型，是技术型用户搜索高效训练方法时的关键词"
      },
      {
        "keyword": "OPT-2.7b",
        "dimension": "参数规格",
        "reason": "当前模型使用的语言模型规模为2.7B参数，属于主流小规模LLM，符合‘参数规格’维度且未被高频词排除（排除的是7B/32B等）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-zh-en",
    "keywords": [
      {
        "keyword": "opus-mt-zh-en",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型标识，唯一对应本模型"
      },
      {
        "keyword": "中英翻译",
        "dimension": "功能场景",
        "reason": "模型的核心任务是中文 → 英文的机器翻译"
      },
      {
        "keyword": "OPUS数据集",
        "dimension": "技术特性",
        "reason": "模型使用的训练语料来源于公开的 OPUS 平行语料库"
      },
      {
        "keyword": "SentencePiece",
        "dimension": "技术特性",
        "reason": "模型在预处理阶段采用 SentencePiece 分词技术"
      },
      {
        "keyword": "spm32k词表",
        "dimension": "技术特性",
        "reason": "模型使用 32k 大小的 SentencePiece 词表进行编码"
      },
      {
        "keyword": "CC-BY-4.0许可证",
        "dimension": "技术特性",
        "reason": "模型遵循 CC-BY-4.0 开源许可证，便于二次使用和再分发"
      },
      {
        "keyword": "文本到文本生成",
        "dimension": "功能场景",
        "reason": "模型支持从输入文本生成目标语言文本，属于文本到文本的生成任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/amazon/chronos-t5-tiny",
    "keywords": [
      {
        "keyword": "Chronos-T5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型系列名称"
      },
      {
        "keyword": "时间序列预测",
        "dimension": "功能场景",
        "reason": "用户搜索时间序列预测模型时的核心需求词"
      },
      {
        "keyword": "概率预测",
        "dimension": "功能场景",
        "reason": "Chronos通过采样轨迹输出概率分布，是用户高频搜索场景"
      },
      {
        "keyword": "T5-efficient-tiny",
        "dimension": "技术特性",
        "reason": "基于T5-efficient-tiny架构，800万参数，用户会搜轻量版本"
      },
      {
        "keyword": "800万参数",
        "dimension": "参数规格",
        "reason": "超小参数量，适合边缘部署，用户会按参数规模筛选模型"
      },
      {
        "keyword": "令牌量化",
        "dimension": "技术特性",
        "reason": "将连续时间序列离散化为令牌，是Chronos独有的技术关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ValueFX9507/Tifa-Deepsex-14b-CoT-Q8",
    "keywords": [
      {
        "keyword": "Tifa-Deepsex",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型品牌名"
      },
      {
        "keyword": "角色扮演",
        "dimension": "功能场景",
        "reason": "模型专为角色扮演场景深度优化，用户高频搜索"
      },
      {
        "keyword": "小说文本生成",
        "dimension": "功能场景",
        "reason": "增量训练0.4T小说内容，面向小说创作需求"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "CoT能力被显著增强，是模型核心卖点"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "提供Q8、Q4、F16多种GGUF量化版本，方便本地部署"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "主流中等规模参数，兼顾性能与显存占用"
      },
      {
        "keyword": "强化学习",
        "dimension": "技术特性",
        "reason": "采用RL/DPO策略优化输出质量与安全性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stabilityai/stable-diffusion-2-1",
    "keywords": [
      {
        "keyword": "stable-diffusion-2-1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文本到图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，根据文本提示生成和修改图像"
      },
      {
        "keyword": "潜在扩散模型",
        "dimension": "技术特性",
        "reason": "当前模型使用的技术类型，具有独特性"
      },
      {
        "keyword": "OpenCLIP-ViTH",
        "dimension": "技术特性",
        "reason": "当前模型使用的固定预训练文本编码器，具有技术独特性"
      },
      {
        "keyword": "CreativeML-Open-RAIL-M",
        "dimension": "技术特性",
        "reason": "当前模型使用的许可证类型，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stabilityai/stable-diffusion-2-inpainting",
    "keywords": [
      {
        "keyword": "Stable-Diffusion-2-Inpainting",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的完整模型名称，唯一标识该模型"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "模型专注于基于掩码的图像修复（inpainting）任务"
      },
      {
        "keyword": "文本引导编辑",
        "dimension": "功能场景",
        "reason": "支持使用文本提示对已有图像进行局部编辑和修改"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "模型可直接在 HuggingFace Diffusers 库中使用，便于 API 调用和本地部署"
      },
      {
        "keyword": "掩码生成策略",
        "dimension": "技术特性",
        "reason": "采用 LAMA 提出的掩码生成策略，提升编辑质量"
      },
      {
        "keyword": "LAMA-掩码",
        "dimension": "技术特性",
        "reason": "使用 LAMA 方法生成的掩码，与潜在 VAE 表示结合形成条件输入"
      },
      {
        "keyword": "潜在-VAE-条件",
        "dimension": "技术特性",
        "reason": "将掩码图像的潜在 VAE 表示作为额外条件，提高生成一致性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.2-I2V-A14B",
    "keywords": [
      {
        "keyword": "Wan2.2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Wan2.2-I2V-A14B，核心模型品牌为Wan2.2，符合简化命名规则且为当前模型唯一标识"
      },
      {
        "keyword": "图像生成视频",
        "dimension": "功能场景",
        "reason": "模型专为Image-to-Video（I2V）设计，用户搜索时会使用‘图像生成视频’这一明确意图词，区别于通用‘文生图’"
      },
      {
        "keyword": "720P24fps",
        "dimension": "功能场景",
        "reason": "模型明确支持720P分辨率24帧率视频生成，是用户在寻找高清视频生成模型时的核心搜索词，具高区分度"
      },
      {
        "keyword": "电影级美学",
        "dimension": "技术特性",
        "reason": "模型通过精细标注数据实现电影级风格生成，是区别于其他模型的独特卖点，非泛泛形容词，具搜索价值"
      },
      {
        "keyword": "复杂运动生成",
        "dimension": "技术特性",
        "reason": "模型在运动表现上显著升级，该术语直接来自原文，是用户寻找高质量动作视频生成时的精准搜索词"
      },
      {
        "keyword": "I2V-A14B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确包含I2V-A14B，为Wan2.2系列下专用于图像到视频的子模型，是独立可搜索的型号名称"
      },
      {
        "keyword": "16164压缩比",
        "dimension": "技术特性",
        "reason": "模型采用16×16×4压缩比的VAE架构，是技术文档中明确提及的、区别于其他模型的结构特征，用户搜索视频压缩效率时可能使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-ENJP-MT",
    "keywords": [
      {
        "keyword": "LFM2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心品牌标识"
      },
      {
        "keyword": "日英翻译",
        "dimension": "功能场景",
        "reason": "模型主打日语英语双向实时翻译"
      },
      {
        "keyword": "350M参数",
        "dimension": "参数规格",
        "reason": "超小体量却媲美10倍大模型，用户会搜轻量级方案"
      },
      {
        "keyword": "边缘翻译",
        "dimension": "功能场景",
        "reason": "近实时、小体量，适合端侧与边缘部署场景"
      },
      {
        "keyword": "Liquid",
        "dimension": "当前模型品牌名",
        "reason": "项目命名空间中的品牌关键词"
      },
      {
        "keyword": "实时翻译",
        "dimension": "功能场景",
        "reason": "强调低延迟的在线翻译体验，用户高频搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/whisper-base.en",
    "keywords": [
      {
        "keyword": "Whisper",
        "dimension": "当前模型品牌名",
        "reason": "模型官方名称，直接来源于项目名称"
      },
      {
        "keyword": "英语语音识别",
        "dimension": "功能场景",
        "reason": "模型专注于英文音频的自动语音识别（ASR）任务"
      },
      {
        "keyword": "语音翻译",
        "dimension": "功能场景",
        "reason": "模型同时支持将音频内容翻译成目标语言文本"
      },
      {
        "keyword": "弱监督训练",
        "dimension": "技术特性",
        "reason": "模型使用大规模弱监督标注的 68 万小时语音数据进行训练"
      },
      {
        "keyword": "74M参数",
        "dimension": "参数规格",
        "reason": "该 base 版本模型的参数量约为 74 百万"
      },
      {
        "keyword": "序列到序列模型",
        "dimension": "技术特性",
        "reason": "采用 Transformer 编码器‑解码器的 seq2seq 结构实现语音‑文本映射"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0",
    "keywords": [
      {
        "keyword": "Frame-VAD",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'Frame_VAD_Multilingual_MarbleNet_v2.0' 中提取的核心品牌名，简化为用户易搜索的 'Frame-VAD'，是模型的唯一标识"
      },
      {
        "keyword": "语音活动检测",
        "dimension": "功能场景",
        "reason": "模型核心功能是语音活动检测（VAD），用户在搜索语音处理工具时会直接使用该中文术语，具有明确搜索意图"
      },
      {
        "keyword": "多语言VAD",
        "dimension": "功能场景",
        "reason": "模型支持中、英、法、德、俄、西六种语言，'多语言VAD'是区别于单语言VAD模型的关键搜索词，用户会用此组合词筛选多语言支持的模型"
      },
      {
        "keyword": "MarbleNet",
        "dimension": "当前模型品牌名",
        "reason": "模型架构名称，是论文和项目中明确提出的专有名称，用户在查阅VAD技术文献时会搜索此术语"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型支持ONNX格式部署，是工业界和开发者部署语音模型时高频搜索的轻量化推理标准，具有明确工具属性"
      },
      {
        "keyword": "实时VAD",
        "dimension": "功能场景",
        "reason": "README明确指出模型适用于实时场景，'实时VAD'是开发者在构建语音交互系统时的核心搜索词，区别于离线处理模型"
      },
      {
        "keyword": "误检鲁棒",
        "dimension": "技术特性",
        "reason": "模型通过噪声训练显著降低误检，'误检鲁棒'是语音处理工程师在评估VAD模型时的专业搜索词，具有技术区分度"
      },
      {
        "keyword": "NeMo",
        "dimension": "部署工具",
        "reason": "模型集成于NVIDIA NeMo框架，是开发者在NVIDIA生态中搜索语音模型时的关键工具词，具有平台指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B",
    "keywords": [
      {
        "keyword": "Qwen2.5-Omni",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "全模态",
        "dimension": "技术特性",
        "reason": "当前模型支持文本、图像、音频、视频全模态输入"
      },
      {
        "keyword": "流式语音生成",
        "dimension": "功能场景",
        "reason": "当前模型可实时生成自然语音响应"
      },
      {
        "keyword": "Thinker-Talker架构",
        "dimension": "技术特性",
        "reason": "当前模型独有的端到端多模态架构"
      },
      {
        "keyword": "TMRoPE位置编码",
        "dimension": "技术特性",
        "reason": "当前模型创新的时间对齐多模态RoPE技术"
      },
      {
        "keyword": "实时音视频对话",
        "dimension": "功能场景",
        "reason": "当前模型支持全实时交互的音视频对话"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/Step-Audio-AQAA",
    "keywords": [
      {
        "keyword": "Step-Audio-AQAA",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "全端到端音频交互",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，直接处理音频输入并生成语音响应"
      },
      {
        "keyword": "细粒度音色控制",
        "dimension": "技术特性",
        "reason": "当前模型支持句子级的情感语调、语速等声音特征调整"
      },
      {
        "keyword": "多语言与方言支持",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景，涵盖中文（含四川话、粤语）、英语、日语等"
      },
      {
        "keyword": "复杂任务处理",
        "dimension": "功能场景",
        "reason": "当前模型擅长语音情感控制、角色扮演、逻辑推理等复杂音频交互"
      },
      {
        "keyword": "双码本音频分词器",
        "dimension": "技术特性",
        "reason": "当前模型架构中的核心模块之一，包含语言分词器和语义分词器"
      },
      {
        "keyword": "1300亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数量级，体现模型规模"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-edge-v-5b",
    "keywords": [
      {
        "keyword": "GLM-Edge-V-5B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，符合品牌名提取规则，且未被高频词列表排除"
      },
      {
        "keyword": "图像描述",
        "dimension": "功能场景",
        "reason": "模型支持'image-to-text'任务，用户会搜索'图像描述'这类明确的多模态应用需求，区别于泛用的'文生图'等高频词"
      },
      {
        "keyword": "轻量级多模态",
        "dimension": "技术特性",
        "reason": "模型为5B参数规模，强调轻量级部署能力，且支持图像+文本输入，'轻量级多模态'是其核心差异化技术标签，未在高频词列表中"
      },
      {
        "keyword": "本地推理",
        "dimension": "部署工具",
        "reason": "代码示例明确使用transformers本地加载模型，强调无需API的本地运行，区别于'本地部署'高频词，'本地推理'更精准描述用户搜索意图"
      },
      {
        "keyword": "bfloat16推理",
        "dimension": "技术特性",
        "reason": "模型明确使用torch.bfloat16进行推理，这是其性能与显存优化的关键技术点，用户会搜索该精度类型以匹配硬件环境，非通用词"
      },
      {
        "keyword": "ChatTemplate输入",
        "dimension": "技术特性",
        "reason": "代码使用apply_chat_template处理多轮对话结构，表明模型支持结构化对话输入，是区别于普通文本模型的特征，用户会搜索该术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mlx-community/gemma-3-12b-it-qat-4bit",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 mlx-community/gemma-3-12b-it-qat-4bit 提取的简化模型品牌名"
      },
      {
        "keyword": "12B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 12 B 参数，用户常以参数大小搜索模型"
      },
      {
        "keyword": "4bit量化",
        "dimension": "技术特性",
        "reason": "模型采用 4‑bit 量化，突出低位量化特性"
      },
      {
        "keyword": "QAT量化",
        "dimension": "技术特性",
        "reason": "使用 Quantization‑Aware Training（QAT）进行量化，区别于普通后置量化"
      },
      {
        "keyword": "图文对话",
        "dimension": "功能场景",
        "reason": "模型支持图像‑文本‑到‑文本的多模态对话任务"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "模型基于 mlx‑vlm 工具，可在 MLX 环境中直接部署使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-4-9b",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "智谱AI",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4由智谱AI推出，映射为国产大模型品牌"
      },
      {
        "keyword": "9B参数",
        "dimension": "参数规格",
        "reason": "当前模型的独特参数规模，区别于常见的7B/32B"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持超长上下文推理，用户会搜索"
      },
      {
        "keyword": "1M上下文",
        "dimension": "技术特性",
        "reason": "GLM-4-9B-Chat-1M版本支持百万级上下文，极具卖点"
      },
      {
        "keyword": "Function-Call",
        "dimension": "功能场景",
        "reason": "当前模型支持自定义工具调用，开发者高频搜索"
      },
      {
        "keyword": "GLM-4V-9B",
        "dimension": "当前模型品牌名",
        "reason": "当前模型的多模态版本，用户会搜索完整型号"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-edge-v-2b",
    "keywords": [
      {
        "keyword": "GLM-Edge-V-2B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，符合简洁品牌名规范（虽含版本号，但'GLM-Edge'是品牌子系列，2B是核心区分参数，且未被高频词列表排除）"
      },
      {
        "keyword": "图像描述",
        "dimension": "功能场景",
        "reason": "模型明确用于'image describe'任务，是用户搜索多模态模型时的典型意图词，区别于泛用的'文生图'等高频词"
      },
      {
        "keyword": "多模态推理",
        "dimension": "技术特性",
        "reason": "模型支持图像+文本输入，属于核心能力描述，且'多模态'虽在排除列表，但'多模态推理'是更具体、未被高频词列表禁止的组合词"
      },
      {
        "keyword": "ChatML模板",
        "dimension": "技术特性",
        "reason": "代码中使用'apply_chat_template'，表明采用ChatML格式对话结构，是GLM系列特有部署特征，用户搜索'ChatML模型'有明确意图"
      },
      {
        "keyword": "bfloat16推理",
        "dimension": "部署工具",
        "reason": "代码明确指定torch.bfloat16加载，是低精度推理的关键配置，区别于泛泛的'量化模型'，属于技术部署关键词且未被高频词列表排除"
      },
      {
        "keyword": "HuggingFace-Transformers",
        "dimension": "部署工具",
        "reason": "模型通过transformers库推理，且用户常搜索'用Transformers跑XX模型'，该词是工具链关键词，非泛指，且未在排除列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/diffusers-ct_cat256",
    "keywords": [
      {
        "keyword": "diffusers-ctcat256",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "一致性模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，论文中提出的新型模型家族"
      },
      {
        "keyword": "单步生成",
        "dimension": "技术特性",
        "reason": "当前模型支持快速单步生成，是区别于其他模型的重要特性"
      },
      {
        "keyword": "零样本数据编辑",
        "dimension": "功能场景",
        "reason": "当前模型支持零样本数据编辑，如图像修复、上色和超分辨率，是应用场景之一"
      },
      {
        "keyword": "独立训练",
        "dimension": "技术特性",
        "reason": "当前模型可以作为独立的生成模型进行训练，是区别于其他蒸馏模型的特点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-torchao-fp8",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "270M参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模为 270M，属于用户常搜索的规格描述"
      },
      {
        "keyword": "FP8量化",
        "dimension": "技术特性",
        "reason": "模型采用 TorchAO 的 FP8 量化技术，具备独特的低精度加速特性"
      },
      {
        "keyword": "指令调优",
        "dimension": "功能场景",
        "reason": "Gemma‑3 提供指令调优变体，适用于指令式对话与任务完成"
      },
      {
        "keyword": "Google-Colab微调",
        "dimension": "部署工具",
        "reason": "官方提供免费 Google Colab 笔记本用于微调 Gemma‑3，用户常以此关键词搜索"
      },
      {
        "keyword": "开放权重",
        "dimension": "技术特性",
        "reason": "模型以开放权重形式发布，便于二次开发和自定义部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/Seed-OSS-36B-Base-woSyn",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ByteDance-Seed，根据国产大模型映射规则，ByteDance-Seed对应品牌名为'豆包'"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed是字节跳动出品，映射为'字节大模型'，符合国产模型品牌命名规范"
      },
      {
        "keyword": "原生长上下文",
        "dimension": "技术特性",
        "reason": "模型原生支持512K长上下文，是其核心差异化技术特性，用户可能搜索'长上下文模型'等意图"
      },
      {
        "keyword": "思考预算控制",
        "dimension": "技术特性",
        "reason": "模型独有'灵活控制思考预算'功能，属于用户搜索推理效率优化时可能使用的精准术语"
      },
      {
        "keyword": "智能体智能",
        "dimension": "功能场景",
        "reason": "模型在工具使用和问题解决等智能体任务中表现卓越，'智能体智能'是其明确的功能场景标签"
      },
      {
        "keyword": "36B参数",
        "dimension": "参数规格",
        "reason": "模型参数量为360亿，属于主流参数规模（30B-70B区间），用户常搜索此类规格词"
      },
      {
        "keyword": "无合成数据",
        "dimension": "技术特性",
        "reason": "模型版本明确标注'woSyn'（无合成数据），为研究社区提供独特数据纯净性选项，具高区分度"
      },
      {
        "keyword": "Seed-OSS",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心标识为Seed-OSS，是模型系列官方品牌名，用户可能直接搜索该术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwaipilot/SRPO-Qwen-32B",
    "keywords": [
      {
        "keyword": "SRPO",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心算法品牌，用户会直接用SRPO搜索"
      },
      {
        "keyword": "历史重采样",
        "dimension": "技术特性",
        "reason": "SRPO独有的HR机制，解决低效样本问题，技术亮点"
      },
      {
        "keyword": "双阶段训练",
        "dimension": "技术特性",
        "reason": "SRPO专为数学+代码设计的训练范式，差异化关键词"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "SRPO第一阶段重点激发的能力，用户搜数学模型时会用"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "SRPO第二阶段整合的核心技能，开发者高频搜索词"
      },
      {
        "keyword": "GRPO框架",
        "dimension": "技术特性",
        "reason": "SRPO基于分组相对策略优化，技术爱好者检索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/grok-2",
    "keywords": [
      {
        "keyword": "Grok-2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为unsloth/grok-2，直接提取模型品牌名，符合用户搜索AI模型时的命名习惯"
      },
      {
        "keyword": "sglang",
        "dimension": "部署工具",
        "reason": "README明确指出模型用于SGLang原生支持，是用户部署Grok-2时的关键工具，具有独特性且未被高频词列表排除"
      },
      {
        "keyword": "tiktoken",
        "dimension": "技术特性",
        "reason": "模型原生使用tiktoken格式，而本项目提供Hugging Face兼容版，这是其核心技术差异点，用户会搜索‘tiktoken模型转换’等关键词"
      },
      {
        "keyword": "Hugging-Face兼容tokenizer",
        "dimension": "技术特性",
        "reason": "项目核心价值是提供HF兼容的tokenizer，解决官方缺失问题，是用户搜索‘Grok-2 tokenizer怎么用’时的精准意图词"
      },
      {
        "keyword": "xai-orggrok-2",
        "dimension": "当前模型品牌名",
        "reason": "虽然来自xai-org，但这是Grok-2的官方源头名称，用户在搜索模型来源时会直接使用该完整路径，且未被高频词列表排除"
      },
      {
        "keyword": "Transformers.js",
        "dimension": "部署工具",
        "reason": "README提及支持Transformers.js，是前端/浏览器端部署的关键工具，具有独特性且不在高频词黑名单中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-qat",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "270M参数",
        "dimension": "参数规格",
        "reason": "当前模型为270M规模，用户会搜小参数模型"
      },
      {
        "keyword": "量化感知训练",
        "dimension": "技术特性",
        "reason": "当前模型采用QAT技术，用户会搜QAT或量化感知训练"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "当前模型为指令微调版本，用户会搜指令微调模型"
      },
      {
        "keyword": "图像理解",
        "dimension": "功能场景",
        "reason": "当前模型支持图像输入，用户会搜图像理解或图文模型"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持128K长上下文，用户会搜长上下文模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large",
    "keywords": [
      {
        "keyword": "NextStep-1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约140亿（14B）参数，是其核心规模特征"
      },
      {
        "keyword": "文本到图像生成",
        "dimension": "功能场景",
        "reason": "模型的主要应用是将文本描述转化为高保真图像"
      },
      {
        "keyword": "流匹配头",
        "dimension": "技术特性",
        "reason": "模型使用的1.57亿参数的流匹配头是独特的技术组件"
      },
      {
        "keyword": "连续令牌自回归",
        "dimension": "技术特性",
        "reason": "模型采用连续令牌的自回归预测方式进行图像生成"
      },
      {
        "keyword": "NextStepPipeline",
        "dimension": "部署工具",
        "reason": "官方提供的推理管线类，用于快速加载和使用模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4-9B-0414",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型基础名称"
      },
      {
        "keyword": "GLM-Z1",
        "dimension": "当前模型品牌名",
        "reason": "从项目README中提取的另一款当前模型名称"
      },
      {
        "keyword": "深度思考能力",
        "dimension": "技术特性",
        "reason": "当前模型GLM-Z1具备的核心技术特性"
      },
      {
        "keyword": "反思能力",
        "dimension": "技术特性",
        "reason": "当前模型GLM-Z1-Rumination具备的独特技术特性"
      },
      {
        "keyword": "函数调用",
        "dimension": "功能场景",
        "reason": "当前模型在函数调用任务中表现优异"
      },
      {
        "keyword": "报告生成",
        "dimension": "功能场景",
        "reason": "当前模型在报告生成任务中表现优异"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lerobot/vqbet_pusht",
    "keywords": [
      {
        "keyword": "VQ-BeT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 lerobot/vqbet_pusht 中提取的核心模型名称，是论文《Behavior Generation with Latent Actions》提出的原创模型，具有唯一性"
      },
      {
        "keyword": "PushT",
        "dimension": "功能场景",
        "reason": "模型专为 gym-pusht 环境中的 PushT 机器人推物任务训练，是其唯一应用场景，用户搜索机器人控制任务时会使用此环境名"
      },
      {
        "keyword": "latent-actions",
        "dimension": "技术特性",
        "reason": "模型基于论文核心概念 'Latent Actions'（隐式动作）进行行为生成，是区别于其他机器人策略模型的关键技术点"
      },
      {
        "keyword": "VQ-BeT-policy",
        "dimension": "当前模型品牌名",
        "reason": "项目标签中明确出现 'vqbet-policy'，是模型在LeRobot生态中的具体策略类型名称，具有技术辨识度"
      },
      {
        "keyword": "robotic-manipulation",
        "dimension": "功能场景",
        "reason": "PushT环境属于机器人操作（robotic manipulation）任务，是机器人领域高频搜索场景，且未被列入强制排除词"
      },
      {
        "keyword": "behavior-generation",
        "dimension": "技术特性",
        "reason": "论文标题与模型核心目标为 'Behavior Generation'，是区别于传统强化学习或模仿学习的范式关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lzkhhh/ITDR-LLaMA3.2-3B",
    "keywords": [
      {
        "keyword": "ITDR-LLaMA3.2-3B",
        "dimension": "当前模型品牌名",
        "reason": "完整的模型名称，直接来源于项目名"
      },
      {
        "keyword": "推荐系统微调",
        "dimension": "功能场景",
        "reason": "模型专注于提升推荐领域大语言模型的性能，属于推荐系统的微调任务"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "使用指令微调数据集（ITDR）进行训练，是模型的核心技术手段"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "模型规模为约3B参数，符合用户搜索模型规格的习惯"
      },
      {
        "keyword": "用户-物品交互",
        "dimension": "功能场景",
        "reason": "数据集涵盖用户与物品的交互信息，是推荐任务的关键要素"
      },
      {
        "keyword": "20万实例",
        "dimension": "数据规模",
        "reason": "数据集规模约20万条实例，用户常以实例数量评估数据集价值"
      },
      {
        "keyword": "7子任务",
        "dimension": "任务细分",
        "reason": "ITDR 数据集在两大核心任务下细分为7个子任务，体现任务丰富性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lerobot/diffusion_pusht",
    "keywords": [
      {
        "keyword": "Diffusion-Policy",
        "dimension": "当前模型品牌名",
        "reason": "项目核心模型名称，直接对应论文与代码"
      },
      {
        "keyword": "PushT环境",
        "dimension": "功能场景",
        "reason": "模型专为gym-pusht机器人推箱子任务训练"
      },
      {
        "keyword": "动作扩散策略",
        "dimension": "技术特性",
        "reason": "论文提出的Visuomotor策略学习方法"
      },
      {
        "keyword": "LeRobot训练",
        "dimension": "部署工具",
        "reason": "使用LeRobot框架一键训练与评估"
      },
      {
        "keyword": "机器人控制",
        "dimension": "功能场景",
        "reason": "面向机器人视觉-动作控制任务"
      },
      {
        "keyword": "175k步检查点",
        "dimension": "参数规格",
        "reason": "提供已训练175k步的现成权重"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/NVIDIA-Nemotron-Nano-9B-v2-GGUF",
    "keywords": [
      {
        "keyword": "NVIDIA-Nemotron-Nano-9B-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型名称，是用户搜索该特定模型时的精准关键词"
      },
      {
        "keyword": "Nemotron",
        "dimension": "当前模型品牌名",
        "reason": "NVIDIA官方模型系列名，简洁品牌标识，用户可能搜索‘Nemotron’而非完整名称"
      },
      {
        "keyword": "混合架构",
        "dimension": "技术特性",
        "reason": "模型采用Mamba-2 + MLP + 仅4个Attention层的混合架构，是其核心独特设计，非通用术语"
      },
      {
        "keyword": "推理轨迹",
        "dimension": "技术特性",
        "reason": "模型通过先生成推理轨迹再输出答案的机制，是其区别于普通LLM的核心功能特性"
      },
      {
        "keyword": "Unsloth-Dynamic-2.0",
        "dimension": "技术特性",
        "reason": "模型使用Unsloth Dynamic 2.0量化技术实现精度提升，是项目独有的优化技术名称"
      },
      {
        "keyword": "6语言支持",
        "dimension": "功能场景",
        "reason": "明确支持英语、德语、西班牙语、法语、意大利语、日语6种语言，是用户筛选多语言模型的明确指标"
      },
      {
        "keyword": "9B参数",
        "dimension": "参数规格",
        "reason": "模型规模为9B，属于主流轻量级参数规模，用户常搜索‘9B参数’寻找平衡型模型"
      },
      {
        "keyword": "NVIDIA开放模型许可",
        "dimension": "部署工具",
        "reason": "模型明确标注使用NVIDIA开放模型许可，是企业用户关注的合规部署关键词，具法律区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lzkhhh/ITDR-GLM-4-9B",
    "keywords": [
      {
        "keyword": "ITDR-GLM-4-9B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "指令微调数据集",
        "dimension": "技术特性",
        "reason": "当前模型构建所依赖的核心技术特性"
      },
      {
        "keyword": "用户-物品交互",
        "dimension": "功能场景",
        "reason": "当前模型数据集涵盖的核心根任务之一"
      },
      {
        "keyword": "用户-物品理解",
        "dimension": "功能场景",
        "reason": "当前模型数据集涵盖的另一核心根任务"
      },
      {
        "keyword": "推荐系统增强",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景和功能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Lykon/dreamshaper-7",
    "keywords": [
      {
        "keyword": "DreamShaper-7",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为 lykon/dreamshaper-7，模型品牌名为 DreamShaper-7，是当前模型的唯一标识名称，简洁且用户搜索模型时直接使用"
      },
      {
        "keyword": "stable-diffusion",
        "dimension": "技术特性",
        "reason": "模型基于 Stable Diffusion 架构，是用户搜索文生图模型时的核心技术标签，且未被列为高频排除词（排除词中无此词）"
      },
      {
        "keyword": "artistic",
        "dimension": "功能场景",
        "reason": "README 明确标注为 artistic，代表该模型擅长生成艺术风格图像，是用户寻找风格化AI绘图模型时的明确搜索意图词"
      },
      {
        "keyword": "anime",
        "dimension": "功能场景",
        "reason": "README 标签中包含 anime，表明该模型在动漫风格生成上有优化，是区别于通用SD模型的特色场景，用户会针对性搜索"
      },
      {
        "keyword": "dreamshaper",
        "dimension": "当前模型品牌名",
        "reason": "模型名称的核心词，用户常简化搜索为 'dreamshaper'，是品牌名的通用简称，具有高搜索辨识度且未被排除"
      },
      {
        "keyword": "text-to-image",
        "dimension": "功能场景",
        "reason": "README 明确使用该术语，是AI图像生成领域的标准搜索关键词，未被高频排除词列表包含，且精准描述模型核心功能"
      },
      {
        "keyword": "stable-diffusion-diffusers",
        "dimension": "部署工具",
        "reason": "标签中独立出现，表明该模型专为 Hugging Face Diffusers 框架优化，是技术用户搜索部署方案时的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-portuguese",
    "keywords": [
      {
        "keyword": "wav2vec2-large-xlsr-53-portuguese",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型唯一标识"
      },
      {
        "keyword": "葡萄牙语语音识别",
        "dimension": "功能场景",
        "reason": "模型专为葡萄牙语语音转文字场景微调"
      },
      {
        "keyword": "Common-Voice微调",
        "dimension": "技术特性",
        "reason": "基于Mozilla Common Voice 6.1数据微调，用户搜此关键词找同款"
      },
      {
        "keyword": "16kHz采样率",
        "dimension": "技术特性",
        "reason": "模型强制要求16kHz音频输入，用户需按此规格准备数据"
      },
      {
        "keyword": "HuggingSound",
        "dimension": "部署工具",
        "reason": "官方推荐的一行代码调用库，用户搜此关键词找极简部署方案"
      },
      {
        "keyword": "wav2vec2-sprint",
        "dimension": "部署工具",
        "reason": "作者开源的训练与推理脚本仓库，用户搜此关键词可复现微调"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/genmo/mochi-1-preview",
    "keywords": [
      {
        "keyword": "Mochi-1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频生成模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能是生成视频"
      },
      {
        "keyword": "开源模型",
        "dimension": "技术特性",
        "reason": "当前模型采用宽松的Apache 2.0许可证发布，是开源的"
      },
      {
        "keyword": "高保真度动态效果",
        "dimension": "技术特性",
        "reason": "当前模型在初步评估中展现出高保真度的动态效果"
      },
      {
        "keyword": "文本提示遵循能力",
        "dimension": "技术特性",
        "reason": "当前模型具有出色的文本提示遵循能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/nllb-200-distilled-600M",
    "keywords": [
      {
        "keyword": "NLLB-200",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "README明确指出的核心用途"
      },
      {
        "keyword": "低资源语言",
        "dimension": "功能场景",
        "reason": "模型专为低资源语言研究设计"
      },
      {
        "keyword": "600M参数",
        "dimension": "参数规格",
        "reason": "当前蒸馏版模型的具体参数规模"
      },
      {
        "keyword": "200种语言",
        "dimension": "功能场景",
        "reason": "模型支持的语言数量，用户搜索时会关注"
      },
      {
        "keyword": "Fairseq",
        "dimension": "部署工具",
        "reason": "官方推荐的训练与使用框架"
      },
      {
        "keyword": "BLEU评估",
        "dimension": "技术特性",
        "reason": "模型性能评估指标，用户搜索时会关注"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4",
    "keywords": [
      {
        "keyword": "Tifa-Deepsex-14b-CoT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，是用户搜索该特定模型的精准关键词"
      },
      {
        "keyword": "链式思维",
        "dimension": "技术特性",
        "reason": "模型明确标注支持CoT（Chain-of-Thought），是其核心能力之一，且未被高频词列表排除"
      },
      {
        "keyword": "角色扮演",
        "dimension": "功能场景",
        "reason": "README明确指出模型‘显著增强角色扮演能力’，是用户寻找AI对话类模型时的明确搜索意图"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "模型针对‘小说文本生成’优化，属于AI写作的子场景，且未被高频词列表覆盖"
      },
      {
        "keyword": "增量预训练",
        "dimension": "技术特性",
        "reason": "模型使用‘增量预训练0.4T小说内容’，是其训练策略的独特技术点，非通用术语"
      },
      {
        "keyword": "DPO强化学习",
        "dimension": "技术特性",
        "reason": "模型使用DPO（Direct Preference Optimization）作为核心训练方法，区别于普通RLHF，具有技术辨识度"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "模型规模为14B，属于主流参数区间，且未被高频词列表（7B/32B）排除，具有搜索价值"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "模型提供GGUF格式（Q4/Q8），是本地部署用户搜索时的高频技术词，且未在禁用列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
    "keywords": [
      {
        "keyword": "mDeBERTa",
        "dimension": "当前模型品牌名",
        "reason": "模型名称的核心品牌标识，直接来源于项目名称"
      },
      {
        "keyword": "零样本分类",
        "dimension": "功能场景",
        "reason": "模型支持 zero‑shot classification，可用于无需标注数据的分类任务"
      },
      {
        "keyword": "多语言自然语言推理",
        "dimension": "功能场景",
        "reason": "模型能够在 100 种语言上执行 NLI（自然语言推理），是其核心应用"
      },
      {
        "keyword": "ONNX导出",
        "dimension": "技术特性",
        "reason": "模型提供 ONNX 格式，便于跨平台部署和加速推理"
      },
      {
        "keyword": "XNLI微调",
        "dimension": "技术特性",
        "reason": "在跨语言 NLI 数据集 XNLI 上进行微调，提升多语言推理能力"
      },
      {
        "keyword": "100语言支持",
        "dimension": "功能场景",
        "reason": "模型覆盖约 100 种语言，满足广泛的跨语言使用需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/myshell-ai/MeloTTS-French",
    "keywords": [
      {
        "keyword": "MeloTTS-French",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，且特指法语版本"
      },
      {
        "keyword": "多语言文本转语音",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能，支持多种语言文本转语音"
      },
      {
        "keyword": "CPU实时推理",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性，足以实现CPU实时推理"
      },
      {
        "keyword": "中英文混合发音",
        "dimension": "功能场景",
        "reason": "当前模型支持中文发音人中英文混合，是其独特功能"
      },
      {
        "keyword": "高质量语音",
        "dimension": "技术特性",
        "reason": "当前模型提供高质量的语音输出，是其重要特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-PT",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产大模型映射规则，必须映射为'文心一言'"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度自研大模型系列，'百度大模型'是用户搜索国产模型时的通用意图词"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新点，非通用术语，独特描述其多模态与异构专家路由架构"
      },
      {
        "keyword": "统一偏好优化",
        "dimension": "技术特性",
        "reason": "模型采用的独家强化学习方法（UPO），区别于DPO/SFT，具高区分度"
      },
      {
        "keyword": "0.3B参数",
        "dimension": "参数规格",
        "reason": "0.3B是轻量级主流规模，用户会搜索小参数模型用于边缘部署，符合规则且非高频"
      },
      {
        "keyword": "FP8混合精度",
        "dimension": "技术特性",
        "reason": "模型训练中使用的独特精度策略，非通用词，具技术辨识度"
      },
      {
        "keyword": "卷积码量化",
        "dimension": "技术特性",
        "reason": "模型推理中使用的专有量化算法，区别于常规4位/2位量化，具独特性"
      },
      {
        "keyword": "视觉语言理解",
        "dimension": "功能场景",
        "reason": "模型明确支持VLM场景，用户搜索'视觉语言理解'意图明确，非泛用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lzkhhh/ITDR-Qwen2.5-7B",
    "keywords": [
      {
        "keyword": "ITDR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的唯一品牌标识，用户搜索时会直接使用该名称定位模型"
      },
      {
        "keyword": "推荐指令微调",
        "dimension": "功能场景",
        "reason": "模型专注于通过指令微调提升推荐系统性能，是用户搜索的核心应用场景"
      },
      {
        "keyword": "用户物品交互",
        "dimension": "功能场景",
        "reason": "数据集涵盖用户‑物品交互任务，用户常以此关键词查找针对推荐的LLM解决方案"
      },
      {
        "keyword": "20万实例数据集",
        "dimension": "技术特性",
        "reason": "大规模（约20万条）指令微调实例是模型的显著优势，具备高区分度"
      },
      {
        "keyword": "13公开推荐数据源",
        "dimension": "技术特性",
        "reason": "整合了13个公开推荐数据集，体现数据覆盖广度，用户会关注此类数据来源描述"
      },
      {
        "keyword": "七子任务结构",
        "dimension": "技术特性",
        "reason": "数据集设计为7个子任务，覆盖用户‑物品理解与交互两大核心任务，具备独特的任务划分"
      },
      {
        "keyword": "指令微调数据集",
        "dimension": "功能场景",
        "reason": "明确标识模型提供的是指令微调专用数据集，帮助用户快速定位相关资源"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Thinking",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE系列映射为百度文心一言"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE-4.5-21B-A3B-Thinking属于百度大模型家族"
      },
      {
        "keyword": "21B参数",
        "dimension": "参数规格",
        "reason": "当前模型总参数量210亿，用户会搜21B参数"
      },
      {
        "keyword": "3B激活",
        "dimension": "参数规格",
        "reason": "每个token仅激活30亿参数，用户关注轻量推理"
      },
      {
        "keyword": "128K长上下文",
        "dimension": "技术特性",
        "reason": "支持131072 token超长上下文，用户会搜128K"
      },
      {
        "keyword": "AI写作",
        "dimension": "功能场景",
        "reason": "README明确提到文本生成与学术写作能力"
      },
      {
        "keyword": "FastDeploy",
        "dimension": "部署工具",
        "reason": "官方推荐用FastDeploy 2.2快速上线服务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-8B-MLX-8bit",
    "keywords": [
      {
        "keyword": "Qwen3-8B-MLX-8bit",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型全称，是用户精准搜索该特定版本的唯一标识"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独有的核心功能，支持在思维/非思维模式间无缝切换，具有高度区分度且未被高频词库覆盖"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "基于MLX框架的部署方式，是该模型区别于主流PyTorch/HuggingFace部署的关键技术路径"
      },
      {
        "keyword": "131K上下文",
        "dimension": "参数规格",
        "reason": "通过YaRN扩展至131,072 token的超长上下文能力，属于主流用户关注的高价值规格（非技术细节，是可感知的性能标签）"
      },
      {
        "keyword": "智能体工具集成",
        "dimension": "功能场景",
        "reason": "模型在思维与非思维模式下均支持与外部工具精准集成，是当前开源模型中突出的智能体应用场景"
      },
      {
        "keyword": "多语言指令遵循",
        "dimension": "功能场景",
        "reason": "明确强调支持100+语言的指令遵循能力，区别于一般‘多语言’描述，聚焦用户搜索‘多语言AI模型’的精准意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Base-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE属于百度大模型系列"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，突出多模态与异构MoE结构"
      },
      {
        "keyword": "异构混合并行",
        "dimension": "技术特性",
        "reason": "当前模型在训练时采用的高效扩展基础设施技术"
      },
      {
        "keyword": "PD解耦技术",
        "dimension": "技术特性",
        "reason": "当前模型在推理时采用的资源利用优化技术"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-en-de",
    "keywords": [
      {
        "keyword": "opus-mt-en-de",
        "dimension": "当前模型品牌名",
        "reason": "项目唯一标识，用户直接搜模型名"
      },
      {
        "keyword": "英德翻译",
        "dimension": "功能场景",
        "reason": "模型核心用途，用户高频搜索意图"
      },
      {
        "keyword": "Helsinki-NLP",
        "dimension": "当前模型品牌名",
        "reason": "开发团队简称，技术社区常用检索词"
      },
      {
        "keyword": "OPUS数据集",
        "dimension": "技术特性",
        "reason": "训练数据来源，精准定位模型背景"
      },
      {
        "keyword": "SentencePiece",
        "dimension": "技术特性",
        "reason": "关键预处理方案，开发者会专门搜索"
      },
      {
        "keyword": "BLEU-26.9",
        "dimension": "技术特性",
        "reason": "亮眼指标，用户对比模型性能时常用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE是百度大模型品牌，根据国产映射规则必须提取为'文心一言'，且未在强制排除列表中"
      },
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心标识，是ERNIE系列的最新版本，用户会直接搜索该型号，且未被排除"
      },
      {
        "keyword": "MoE-300B",
        "dimension": "参数规格",
        "reason": "300B是当前模型的显性参数规模，属于主流大模型规格（百亿级），且'MoE-300B'组合具有技术区分度，未被高频词覆盖"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "README明确提到'heterogeneous MoE'，中文译为'异构MoE'，是该模型独有的架构创新，区别于普通MoE，未被排除"
      },
      {
        "keyword": "多模态预训练",
        "dimension": "技术特性",
        "reason": "模型核心训练方式，原文强调'Multimodal Heterogeneous MoE Pre-Training'，是功能级关键词，非泛泛的'多模态'，具有搜索价值"
      },
      {
        "keyword": "PaddlePaddle",
        "dimension": "部署工具",
        "reason": "模型明确使用PaddlePaddle权重（非PyTorch），是用户部署时的关键技术选型词，且未在排除列表中"
      },
      {
        "keyword": "W4A8C8量化",
        "dimension": "技术特性",
        "reason": "W4A8C8是模型的量化配置（4位权重、8位激活、8位累积），属于模型特有的高效推理标识，非通用术语，具有技术辨识度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-4B-MLX-4bit",
    "keywords": [
      {
        "keyword": "阿里大模型",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Qwen，依据映射规则提取为 “阿里大模型”"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约 40 亿参数，属于 4B 参数规模"
      },
      {
        "keyword": "4bit量化",
        "dimension": "技术特性",
        "reason": "模型以 4bit 量化形式发布，适合低算力部署"
      },
      {
        "keyword": "MLX框架",
        "dimension": "部署工具",
        "reason": "模型兼容最新的 MLX 框架（≥ 0.25.2），可直接在 MLX 环境中运行"
      },
      {
        "keyword": "YaRN扩展",
        "dimension": "技术特性",
        "reason": "通过 YaRN 技术将原生 32,768 token 上下文扩展至 131,072 token"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型支持思维模式与非思维模式的无缝切换，提升复杂推理与通用对话性能"
      },
      {
        "keyword": "多语言指令",
        "dimension": "功能场景",
        "reason": "模型支持 100+ 语言与方言的指令遵循与翻译，适用于多语言任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-6bit",
    "keywords": [
      {
        "keyword": "Qwen3-14B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，14B参数版本"
      },
      {
        "keyword": "MLX量化",
        "dimension": "部署工具",
        "reason": "当前模型专为Apple MLX框架提供的6bit量化版本"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "独家支持思维模式与非思维模式一键切换"
      },
      {
        "keyword": "智能体集成",
        "dimension": "功能场景",
        "reason": "具备与外部工具精准集成的专业智能体能力"
      },
      {
        "keyword": "131K长上下文",
        "dimension": "技术特性",
        "reason": "通过YaRN扩展支持131,072 token超长上下文"
      },
      {
        "keyword": "6bit量化",
        "dimension": "部署工具",
        "reason": "当前模型提供6bit低比特量化版本，适合本地部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-8bit",
    "keywords": [
      {
        "keyword": "Qwen3-32B-MLX-8bit",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型全称，是用户搜索该特定版本的唯一标识符，符合模型名称提取规则且未被高频词排除"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独创的在思维模式与非思维模式间无缝切换的能力，是区别于其他模型的核心技术点，未被高频词覆盖"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "基于MLX框架的部署方式，是该模型区别于主流PyTorch/HuggingFace部署的独特技术路径，用户可能专门搜索MLX支持的模型"
      },
      {
        "keyword": "131K上下文",
        "dimension": "参数规格",
        "reason": "通过YaRN扩展至131,072 tokens的上下文长度，属于主流高阶规格（>128K），用户会搜索长上下文模型，且未被高频词排除"
      },
      {
        "keyword": "智能体工具集成",
        "dimension": "功能场景",
        "reason": "模型在思维/非思维模式下支持与外部工具精准集成，是其智能体能力的核心应用场景，具有明确搜索意图且非通用词"
      },
      {
        "keyword": "多语言指令遵循",
        "dimension": "功能场景",
        "reason": "支持100+语言的指令遵循能力，是该模型在多语言场景下的关键功能，区别于普通多语言支持，具有搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "keywords": [
      {
        "keyword": "Qwen3-235B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的简化模型品牌名，符合用户搜索模型时的常用写法"
      },
      {
        "keyword": "非思考模式",
        "dimension": "技术特性",
        "reason": "模型仅支持非思考模式，是该模型独有的运行方式，用户会据此搜索"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "模型在指令遵循方面有显著提升，是用户寻找高质量指令响应模型时的关键词"
      },
      {
        "keyword": "256K长文本理解",
        "dimension": "技术特性",
        "reason": "模型支持256K级别的长文本理解，属于独特的能力点，易被用户作为搜索词"
      },
      {
        "keyword": "2350B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量约2350亿（2350B），是区分不同大模型规模的重要搜索词"
      },
      {
        "keyword": "多语言长尾覆盖",
        "dimension": "功能场景",
        "reason": "模型对多语言长尾知识的覆盖率提升，是用户关注的语言能力特性"
      },
      {
        "keyword": "原生262K上下文",
        "dimension": "技术特性",
        "reason": "模型原生支持262,144 token 上下文长度，属于显著的上下文能力特征"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE属于百度大模型系列，根据映射规则提取"
      },
      {
        "keyword": "Multimodal-Heterogeneous-MoE",
        "dimension": "技术特性",
        "reason": "当前模型采用的多模态异构MoE结构是其核心创新点"
      },
      {
        "keyword": "A47B系列",
        "dimension": "技术特性",
        "reason": "当前模型中的A47B系列是其重要组成部分"
      },
      {
        "keyword": "PaddlePaddle权重",
        "dimension": "技术特性",
        "reason": "当前模型使用PaddlePaddle权重，区别于其他模型"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "当前模型具备跨模态推理能力，是其应用场景之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-300B-A47B-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型标识，是用户搜索该特定Paddle版本模型的精准关键词"
      },
      {
        "keyword": "A47B",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中的核心架构代号，代表MoE结构的特定变体，是技术社区中用于区分ERNIE 4.5子系列的唯一标识"
      },
      {
        "keyword": "PaddlePaddle",
        "dimension": "部署工具",
        "reason": "模型明确使用PaddlePaddle权重，区别于PyTorch版本，是开发者筛选部署框架时的关键搜索词"
      },
      {
        "keyword": "文本补全",
        "dimension": "功能场景",
        "reason": "README明确指出Base模型仅支持文本补全（text completion），且强调需使用completion API，这是其核心功能定位"
      },
      {
        "keyword": "多模态异构MoE预训练",
        "dimension": "技术特性",
        "reason": "模型核心技术创新点，原文唯一描述的技术术语，具有高度区分度，非通用词，用户搜索技术细节时可能使用"
      },
      {
        "keyword": "ERNIE4.5",
        "dimension": "当前模型品牌名",
        "reason": "模型主版本名，用户在搜索ERNIE系列时可能使用简化版名称，且未被列入强制排除词库"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Base-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，简化后突出核心版本"
      },
      {
        "keyword": "异构MoE结构",
        "dimension": "技术特性",
        "reason": "当前模型采用的关键架构设计，区别于其他MoE模型"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "当前模型特有的多模态训练机制，避免模态干扰"
      },
      {
        "keyword": "FP8混合精度训练",
        "dimension": "技术特性",
        "reason": "当前模型在训练阶段采用的高效计算技术"
      },
      {
        "keyword": "4比特无损量化",
        "dimension": "技术特性",
        "reason": "当前模型在推理阶段实现的量化技术，提升部署效率"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-6bit",
    "keywords": [
      {
        "keyword": "Qwen3-30B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型品牌，直接标识该模型"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型支持单模型内无缝切换思维模式与非思维模式，提升多场景适配能力"
      },
      {
        "keyword": "复杂逻辑推理",
        "dimension": "功能场景",
        "reason": "在复杂逻辑推理任务中表现突出，是用户常搜索的应用场景"
      },
      {
        "keyword": "6bit量化",
        "dimension": "技术特性",
        "reason": "采用 6bit 量化方案，显著降低推理算力需求"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "兼容 MLX 框架，可在 Apple Silicon 等平台高效运行"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "模型总参数约 30.5B，属于大规模语言模型"
      },
      {
        "keyword": "多语言指令",
        "dimension": "功能场景",
        "reason": "支持 100+ 语言的指令遵循与翻译，满足多语言使用需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-8bit",
    "keywords": [
      {
        "keyword": "Qwen3-14B-MLX-8bit",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型全称，是用户在GitCode等平台搜索该特定版本时的精准关键词"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "模型明确支持MLX框架，且MLX是Apple Silicon本地推理的新兴工具，用户会搜索'XX模型 MLX部署'来适配Mac设备"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独创的在思维模式与非思维模式间无缝切换能力，是区别于其他模型的核心创新点，用户可能搜索'大模型 思维模式切换'"
      },
      {
        "keyword": "131K上下文",
        "dimension": "参数规格",
        "reason": "模型通过YaRN扩展至131,072 token上下文，属于主流高长度上下文规格（接近128K），用户会搜索'128K上下文模型'或'长文本大模型'"
      },
      {
        "keyword": "智能体工具对接",
        "dimension": "功能场景",
        "reason": "模型在思维/非思维模式下均支持精准对接外部工具，是当前AI智能体应用的关键能力，用户会搜索'AI智能体 工具调用'"
      },
      {
        "keyword": "8bit量化",
        "dimension": "技术特性",
        "reason": "模型采用8bit量化，是低资源设备运行大模型的关键技术标签，用户常搜索'8bit量化模型'以适配消费级设备"
      },
      {
        "keyword": "GQA注意力",
        "dimension": "技术特性",
        "reason": "模型使用分组查询注意力（GQA），是提升推理效率的架构创新，区别于标准多头注意力，专业用户会搜索'GQA模型'"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "keywords": [
      {
        "keyword": "Mistral-Small-3.2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化规则（去版本号后缀）"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "模型核心改进点，用户搜索AI模型时会用‘指令遵循能力强的模型’等意图搜索"
      },
      {
        "keyword": "函数调用",
        "dimension": "功能场景",
        "reason": "模型在函数调用模板上的显著优化，是开发者关注的实用功能，非通用词"
      },
      {
        "keyword": "减少重复生成",
        "dimension": "技术特性",
        "reason": "模型针对无限生成问题的专项改进，是用户在对比模型时的关键搜索词"
      },
      {
        "keyword": "24B参数",
        "dimension": "参数规格",
        "reason": "24B是主流大模型参数规模，用户常搜索‘24B参数模型’进行性能与成本权衡"
      },
      {
        "keyword": "Mistral-Small",
        "dimension": "当前模型品牌名",
        "reason": "模型系列通用名称，用户可能搜索‘Mistral-Small’而非完整版本号，具搜索泛化性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-TP4-Paddle",
    "keywords": [
      {
        "keyword": "文心一言",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE 系列官方中文品牌，用户搜索国产大模型必用"
      },
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的版本号，精准引流"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "超大规模参数，用户搜‘300B大模型’可直达"
      },
      {
        "keyword": "2Bits量化",
        "dimension": "部署工具",
        "reason": "极低比特量化方案，用户搜‘2bit量化模型’高匹配"
      },
      {
        "keyword": "TP4并行",
        "dimension": "技术特性",
        "reason": "独特张量并行配置，开发者搜‘TP4部署’精准命中"
      },
      {
        "keyword": "PaddlePaddle",
        "dimension": "部署工具",
        "reason": "框架关键词，用户搜‘PaddlePaddle大模型’引流"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心架构亮点，用户搜‘异构MoE’可区分竞品"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-Audio-7B",
    "keywords": [
      {
        "keyword": "Kimi-Audio",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的当前模型品牌"
      },
      {
        "keyword": "月之暗面",
        "dimension": "当前模型品牌名",
        "reason": "MoonshotAI 官方中文品牌名"
      },
      {
        "keyword": "语音识别",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心功能之一"
      },
      {
        "keyword": "音频问答",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心功能之一"
      },
      {
        "keyword": "音频描述",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心功能之一"
      },
      {
        "keyword": "语音情感识别",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心功能之一"
      },
      {
        "keyword": "声音事件分类",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心功能之一"
      },
      {
        "keyword": "端到端语音对话",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心功能之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-8B-MLX-6bit",
    "keywords": [
      {
        "keyword": "Qwen3-8B-MLX-6bit",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心模型系列名称，映射为通义千问系列"
      },
      {
        "keyword": "思维模式",
        "dimension": "技术特性",
        "reason": "当前模型独家支持的核心技术特性，适用于复杂逻辑推理"
      },
      {
        "keyword": "非思维模式",
        "dimension": "技术特性",
        "reason": "当前模型独家支持的高效通用对话模式"
      },
      {
        "keyword": "82亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数量，具有区分度且用户可能搜索"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "当前模型的类型，属于独特技术描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-es-en",
    "keywords": [
      {
        "keyword": "opus-mt-es-en",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源于Helsinki-NLP的官方模型命名，是用户在GitCode或Hugging Face搜索该西班牙语-英语翻译模型时最可能使用的精确关键词"
      },
      {
        "keyword": "西班牙语-英语翻译",
        "dimension": "功能场景",
        "reason": "用户搜索翻译模型时常用‘语言对+翻译’结构，如‘西班牙语-英语翻译’，这是明确的搜索意图，且未被高频词库排除"
      },
      {
        "keyword": "OPUS翻译模型",
        "dimension": "功能场景",
        "reason": "OPUS是该模型系列的权威数据来源品牌，用户在学术或工程场景中常搜索‘OPUS翻译模型’以区分其他数据集训练的模型"
      },
      {
        "keyword": "SentencePiece",
        "dimension": "技术特性",
        "reason": "模型使用SentencePiece（spm32k）作为核心预处理技术，是专业用户识别该模型架构的重要技术标签，且未被列入高频排除词"
      },
      {
        "keyword": "Tatoeba测试",
        "dimension": "技术特性",
        "reason": "模型在Tatoeba测试集上达到59.6 BLEU，该测试集是开放翻译评估的权威基准，专业用户会搜索‘Tatoeba翻译模型’来定位高质量免费模型"
      },
      {
        "keyword": "Helsinki-NLP",
        "dimension": "当前模型品牌名",
        "reason": "Helsinki-NLP是模型开发机构的官方品牌名，用户常通过机构名搜索其开源模型，如‘Helsinki-NLP 翻译模型’，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-Base-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-Base",
        "dimension": "当前模型品牌名",
        "reason": "直接取自项目名称，标识该模型的品牌与版本"
      },
      {
        "keyword": "300B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 300 B 参数，用户常以参数量搜索大模型"
      },
      {
        "keyword": "文本补全",
        "dimension": "功能场景",
        "reason": "Base 版仅支持文本补全任务，是该模型的核心使用场景"
      },
      {
        "keyword": "跨模态预训练",
        "dimension": "技术特性",
        "reason": "模型在文本与视觉两种模态上联合预训练，提升跨模态推理能力"
      },
      {
        "keyword": "稀疏专家模型",
        "dimension": "技术特性",
        "reason": "采用 MoE（Mixture‑of‑Experts）稀疏专家结构，实现高效大规模学习"
      },
      {
        "keyword": "PyTorch权重",
        "dimension": "部署工具",
        "reason": "“-PT” 版本提供 Transformer‑style 的 PyTorch 权重，便于在 PyTorch 环境中部署"
      },
      {
        "keyword": "视觉理解",
        "dimension": "功能场景",
        "reason": "模型在视觉模态上具备理解能力，可用于图像相关任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/cointegrated/rubert-base-cased-nli-threeway",
    "keywords": [
      {
        "keyword": "rubert-base-cased-nli-threeway",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一名称，用户搜索俄语NLI模型时会精准使用此全称"
      },
      {
        "keyword": "俄语自然语言推理",
        "dimension": "功能场景",
        "reason": "模型核心用途是俄语文本的蕴含/矛盾/中立判断，用户搜索俄语NLI时会使用此中文意图词"
      },
      {
        "keyword": "俄语零样本分类",
        "dimension": "功能场景",
        "reason": "模型支持俄语文本的零样本推理，是其区别于通用NLI模型的关键应用场景"
      },
      {
        "keyword": "RuBERT",
        "dimension": "当前模型品牌名",
        "reason": "模型基于RuBERT架构，是该系列在俄语NLI任务中的具体实现，用户会搜索此缩写"
      },
      {
        "keyword": "NLI俄语",
        "dimension": "功能场景",
        "reason": "用户常以'功能+语言'组合搜索（如NLI俄语），此为高意图短语且未被高频词库覆盖"
      },
      {
        "keyword": "三分类NLI",
        "dimension": "技术特性",
        "reason": "模型输出为蕴含、矛盾、中立三类，区别于二分类NLI，是其独特技术特征"
      },
      {
        "keyword": "cointegratednli-rus-translated-v2021",
        "dimension": "当前模型品牌名",
        "reason": "项目标签中明确列出，是该模型的训练数据集/前身名称，属于模型自身标识的一部分"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-32B",
    "keywords": [
      {
        "keyword": "OpenReasoning-Nemotron",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，去掉版本号后更简洁"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "README明确强调模型专为数学推理优化"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "README把代码生成列为三大核心用途之一"
      },
      {
        "keyword": "科学问题求解",
        "dimension": "功能场景",
        "reason": "README突出模型在科学问题求解上的能力"
      },
      {
        "keyword": "64K输出标记",
        "dimension": "技术特性",
        "reason": "README提到模型支持高达64K输出，是用户关心的超长输出能力"
      },
      {
        "keyword": "GenSelect",
        "dimension": "技术特性",
        "reason": "README提到的生成式解决方案选择机制，是模型独有的多智能体协同技术"
      },
      {
        "keyword": "CC-BY-4.0",
        "dimension": "部署工具",
        "reason": "用户搜索商业可商用模型时常用许可证作为关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ibm-granite/granite-timeseries-ttm-r1",
    "keywords": [
      {
        "keyword": "ibm-granitegranite-timeseries-ttm-r1",
        "dimension": "当前模型品牌名",
        "reason": "从项目URL和名称提取的当前模型完整名称"
      },
      {
        "keyword": "TinyTimeMixers",
        "dimension": "当前模型品牌名",
        "reason": "README中提到的模型别称，具有独特性"
      },
      {
        "keyword": "微型预训练模型",
        "dimension": "技术特性",
        "reason": "当前模型首次提出的概念，具有区分度"
      },
      {
        "keyword": "零样本预测",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能之一，且未被强制排除"
      },
      {
        "keyword": "少样本预测",
        "dimension": "功能场景",
        "reason": "当前模型在少样本预测任务中的表现是其特点之一"
      },
      {
        "keyword": "轻量级预测器",
        "dimension": "技术特性",
        "reason": "描述了当前模型的轻量级特性，具有区分度"
      },
      {
        "keyword": "分钟级到小时级分辨率",
        "dimension": "功能场景",
        "reason": "当前模型支持的特定时间分辨率，具有应用场景指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-russian",
    "keywords": [
      {
        "keyword": "wav2vec2-large-xlsr-53-russian",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中完整的模型标识，直接对应当前模型"
      },
      {
        "keyword": "俄语语音识别",
        "dimension": "功能场景",
        "reason": "模型专注于俄语的语音转文字任务，是用户搜索的核心功能"
      },
      {
        "keyword": "自动语音转文字",
        "dimension": "功能场景",
        "reason": "模型实现的主要应用场景，即将语音自动转写为文本"
      },
      {
        "keyword": "HuggingSound",
        "dimension": "部署工具",
        "reason": "官方推荐的推理库，用户可通过该库快速调用模型进行识别"
      },
      {
        "keyword": "Common-Voice-6.1-Russian",
        "dimension": "技术特性",
        "reason": "模型在该公开俄语数据集上进行微调，体现了训练数据来源"
      },
      {
        "keyword": "CTC解码",
        "dimension": "技术特性",
        "reason": "模型采用 Connectionist Temporal Classification 进行序列预测，是关键技术"
      },
      {
        "keyword": "16kHz采样率",
        "dimension": "技术特性",
        "reason": "模型要求的音频采样率，决定了输入音频的标准化要求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
    "keywords": [
      {
        "keyword": "CLIP-ViT-B-32",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的核心模型标识，是用户搜索CLIP视觉-语言模型时最可能使用的简洁品牌名"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "模型明确标注的直接用途，是研究者和开发者搜索该类模型时的核心关键词，且未被列入高频排除词"
      },
      {
        "keyword": "图文检索",
        "dimension": "功能场景",
        "reason": "模型官方明确列出的直接用途，属于具体、高意图的搜索词，区别于泛泛的‘多模态’或‘文生图’"
      },
      {
        "keyword": "OpenCLIP",
        "dimension": "技术特性",
        "reason": "模型基于OpenCLIP框架训练，是区别于OpenAI原版CLIP的关键技术标签，用户会用此词搜索开源CLIP变体"
      },
      {
        "keyword": "LAION-2B",
        "dimension": "技术特性",
        "reason": "模型训练所用的专属数据集名称，是研究社区中识别该模型版本的重要标识，具有唯一性和搜索价值"
      },
      {
        "keyword": "线性探针图像分类",
        "dimension": "下游用途",
        "reason": "模型文档中明确提及的高级微调方式，属于专业用户搜索的精准技术场景，非通用词且未被高频排除"
      },
      {
        "keyword": "图像生成引导",
        "dimension": "下游用途",
        "reason": "模型支持的特定应用方向，是AIGC研究者搜索CLIP用于生成控制时的精准关键词，区别于泛泛的‘文生图’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/t-tech/T-one",
    "keywords": [
      {
        "keyword": "T-one",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为t-tech/T-one，直接提取模型品牌名，简洁且为用户搜索核心词"
      },
      {
        "keyword": "俄语语音识别",
        "dimension": "功能场景",
        "reason": "模型专为俄语电话场景优化，用户会搜索‘俄语语音识别’这类明确语言+场景组合词"
      },
      {
        "keyword": "流式ASR",
        "dimension": "技术特性",
        "reason": "模型核心卖点是‘流式语音识别’，‘流式ASR’是行业常用缩写，用户搜索ASR时会加‘流式’限定"
      },
      {
        "keyword": "电话语音识别",
        "dimension": "功能场景",
        "reason": "模型明确针对电话领域优化，‘电话语音识别’是精准垂直场景词，区别于通用ASR"
      },
      {
        "keyword": "Conformer",
        "dimension": "技术特性",
        "reason": "模型使用Conformer声学架构，是区别于普通RNN/Transformer的差异化技术点，用户会搜索该架构名称"
      },
      {
        "keyword": "低延迟ASR",
        "dimension": "技术特性",
        "reason": "项目反复强调‘低延迟’，是电话场景的核心需求，‘低延迟ASR’是用户真实搜索意图词"
      },
      {
        "keyword": "T-tech",
        "dimension": "当前模型品牌名",
        "reason": "项目由T-Software DC开发，品牌为T-tech，作为开发方名称，具有识别度且非高频词"
      },
      {
        "keyword": "俄语STT",
        "dimension": "功能场景",
        "reason": "STT（Speech-to-Text）是ASR的同义词，用户在搜索俄语语音转文字时可能使用‘俄语STT’，语义精准且非高频词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/t-tech/T-pro-it-2.0-eagle",
    "keywords": [
      {
        "keyword": "T-pro-it-2.0-eagle",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Eagle解码",
        "dimension": "技术特性",
        "reason": "当前模型采用Eagle 2推测解码技术"
      },
      {
        "keyword": "推理加速",
        "dimension": "功能场景",
        "reason": "模型主打推理阶段加速，用户会搜此场景"
      },
      {
        "keyword": "1层Transformer",
        "dimension": "参数规格",
        "reason": "极简1层结构，用户关注轻量级模型"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "基于5亿token指令数据训练，用户会搜指令微调模型"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "部署工具",
        "reason": "开源协议关键词，用户搜索可商用模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/bigvgan_v2_22khz_80band_256x",
    "keywords": [
      {
        "keyword": "BigVGAN-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "神经声码器",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能和应用场景"
      },
      {
        "keyword": "自定义CUDA内核",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性之一"
      },
      {
        "keyword": "多尺度子带CQT判别器",
        "dimension": "技术特性",
        "reason": "当前模型采用的技术特性，具有独特性"
      },
      {
        "keyword": "多尺度梅尔频谱图损失",
        "dimension": "技术特性",
        "reason": "当前模型采用的技术特性，具有独特性"
      },
      {
        "keyword": "22kHz采样率",
        "dimension": "参数规格",
        "reason": "当前模型支持的音频采样率，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-PT",
    "keywords": [
      {
        "keyword": "ERNIE-VL",
        "dimension": "当前模型品牌名",
        "reason": "项目名中的ERNIE-4.5-VL简写，用户直接搜ERNIE-VL即可定位"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "README强调“异构MoE结构”是ERNIE 4.5系列的核心卖点，搜索热度高"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "功能场景",
        "reason": "ERNIE-4.5-VL主打图文混合任务，用户常用此关键词找VLM模型"
      },
      {
        "keyword": "424B参数",
        "dimension": "参数规格",
        "reason": "项目名直接透出424B，属于罕见超大参数，极具记忆点"
      },
      {
        "keyword": "FP8混合精度",
        "dimension": "技术特性",
        "reason": "README提到FP8训练加速，开发者搜FP8可快速关联到该模型"
      },
      {
        "keyword": "PD解耦推理",
        "dimension": "技术特性",
        "reason": "动态角色切换的PD解耦为ERNIE 4.5独创推理优化，关键词稀缺"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "ERNIE 4.5-VL独家机制，技术博客常搜此短语了解多模态路由方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/mobilenetv3_large_100.ra_in1k",
    "keywords": [
      {
        "keyword": "MobileNetV3",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含的品牌名，直接对应项目的核心模型"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "模型的主要应用场景是对图片进行类别预测"
      },
      {
        "keyword": "RandAugment",
        "dimension": "技术特性",
        "reason": "使用的随机增强数据增强方案，是模型训练的关键技术"
      },
      {
        "keyword": "RMSProp",
        "dimension": "技术特性",
        "reason": "模型采用的优化器，提升收敛效率"
      },
      {
        "keyword": "EMA",
        "dimension": "技术特性",
        "reason": "模型在训练中使用的指数移动平均权重策略"
      },
      {
        "keyword": "5.5M参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模约为 5.5 百万，帮助用户快速判断模型大小"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/xclip-base-patch32",
    "keywords": [
      {
        "keyword": "X-CLIP",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 microsoft/xclip-base-patch32 提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词"
      },
      {
        "keyword": "视频-文本检索",
        "dimension": "功能场景",
        "reason": "模型明确支持的典型应用场景，用户会搜索‘视频-文本检索模型’这类精准需求，且未被高频词库排除"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "模型核心用途之一，README明确提及‘视频分类’，是区别于图像模型的关键功能词，非通用词"
      },
      {
        "keyword": "零样本视频理解",
        "dimension": "技术特性",
        "reason": "模型基于对比学习实现零样本能力，是其区别于传统视频模型的核心技术亮点，用户会搜索‘零样本视频’相关模型"
      },
      {
        "keyword": "Kinetics-400",
        "dimension": "训练数据",
        "reason": "模型训练所用的专属数据集名称，专业用户常通过数据集反向查找模型，具有高区分度且未被高频词库覆盖"
      },
      {
        "keyword": "224x224视频预处理",
        "dimension": "技术特性",
        "reason": "模型训练/验证中明确使用的固定分辨率预处理方式，是工程用户搜索‘视频预处理标准’时的精准匹配词"
      },
      {
        "keyword": "8帧视频输入",
        "dimension": "技术特性",
        "reason": "模型处理视频时的固定帧数设计，是区别于其他视频模型（如16帧、32帧）的显著技术参数，用户会据此筛选模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/siglip-so400m-patch14-384",
    "keywords": [
      {
        "keyword": "SigLIP",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Sigmoid损失函数",
        "dimension": "技术特性",
        "reason": "当前模型使用的独特损失函数"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景之一"
      },
      {
        "keyword": "图文检索",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景之一"
      },
      {
        "keyword": "SoViT-400m架构",
        "dimension": "技术特性",
        "reason": "当前模型采用的架构"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/clip-vit-base-patch16",
    "keywords": [
      {
        "keyword": "CLIP",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确出现的核心品牌名"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "README强调CLIP用于零样本方式泛化到任意图像分类任务"
      },
      {
        "keyword": "ViT-B16",
        "dimension": "技术特性",
        "reason": "当前模型采用ViT-B/16 Transformer架构作为图像编码器"
      },
      {
        "keyword": "对比学习",
        "dimension": "技术特性",
        "reason": "模型通过对比损失函数训练以最大化图文相似度"
      },
      {
        "keyword": "图文匹配",
        "dimension": "功能场景",
        "reason": "CLIP核心能力在于图像与文本的跨模态匹配"
      },
      {
        "keyword": "OpenAI-CLIP",
        "dimension": "当前模型品牌名",
        "reason": "README中多次出现OpenAI CLIP，作为品牌完整称呼"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/kosmos-2-patch14-224",
    "keywords": [
      {
        "keyword": "Kosmos-2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'microsoft/kosmos-2-patch14-224' 中提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词"
      },
      {
        "keyword": "图像接地",
        "dimension": "功能场景",
        "reason": "模型核心功能为 '<grounding>' 指令驱动的图像与文本对齐，中文用户搜索 '图像接地' 或 '图像定位' 时意图明确，区别于通用图像描述"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "技术特性",
        "reason": "模型属于视觉-语言联合建模架构，虽 '多模态' 被禁用，但 '视觉语言模型' 是更精准、未被高频词列表排除的术语，用于区分纯文本或纯图像模型"
      },
      {
        "keyword": "图像字幕生成",
        "dimension": "功能场景",
        "reason": "模型支持基于图像生成自然语言描述，'图像字幕生成' 是用户在CSDN等平台搜索图像理解任务时的常用中文术语，区别于 '文生图' 等高频词"
      },
      {
        "keyword": "HuggingFace-transformers",
        "dimension": "部署工具",
        "reason": "README明确使用HuggingFace transformers库加载模型，该组合是开发者部署该模型的关键路径，且 'HuggingFace transformers' 作为整体术语未被高频词列表禁止"
      },
      {
        "keyword": "Patch14-224",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中的 'patch14-224' 是其视觉编码器的关键配置标识，技术用户会通过此后缀精准搜索该变体，具有区分度且未被高频词覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/fofr/kontext-make-person-real",
    "keywords": [
      {
        "keyword": "Kontext",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 “kontext‑make‑person‑real” 中提取的模型品牌名"
      },
      {
        "keyword": "人物真实化",
        "dimension": "功能场景",
        "reason": "LoRA 的核心功能是让人物看起来更真实"
      },
      {
        "keyword": "图像编辑",
        "dimension": "功能场景",
        "reason": "该 LoRA 用于图像‑到‑图像的编辑任务"
      },
      {
        "keyword": "Diffusers兼容",
        "dimension": "部署工具",
        "reason": "README 明确说明可在 Diffusers 环境中使用"
      },
      {
        "keyword": "ComfyUI兼容",
        "dimension": "部署工具",
        "reason": "README 中指出可与 ComfyUI 配合使用"
      },
      {
        "keyword": "Replicate训练",
        "dimension": "技术特性",
        "reason": "模型在 Replicate 平台的 fast‑flux‑kontext‑trainer 上完成训练"
      },
      {
        "keyword": "LoRA秩16",
        "dimension": "技术特性",
        "reason": "LoRA 的秩（rank）设置为 16，体现其技术细节"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/llava-hf/LLaVA-NeXT-Video-7B-hf",
    "keywords": [
      {
        "keyword": "LLaVA-NeXT-Video",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，是用户搜索该视频理解模型的核心关键词"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "模型核心能力是处理视频与文本的交互，区别于普通多模态模型，用户会搜索‘视频理解AI’这类意图明确的场景词"
      },
      {
        "keyword": "多视频输入",
        "dimension": "技术特性",
        "reason": "模型支持在单次提示中传入多个视频片段，是其区别于其他视觉语言模型的独特功能点"
      },
      {
        "keyword": "32帧采样",
        "dimension": "技术特性",
        "reason": "模型对视频统一采用32帧采样策略，是其架构设计中的关键参数，用户在技术对比时可能搜索该具体配置"
      },
      {
        "keyword": "VideoChatGPT-Instruct",
        "dimension": "训练数据集",
        "reason": "模型使用了100K VideoChatGPT-Instruct数据进行微调，该数据集名称具有唯一性，是区别于其他视频模型的训练标识"
      },
      {
        "keyword": "VideoMME基准",
        "dimension": "评估基准",
        "reason": "模型在VideoMME基准上达到领先水平，该基准名称是视频理解领域专业用户会搜索的评估指标关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vidore/colqwen2-v0.1",
    "keywords": [
      {
        "keyword": "ColQwen2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉检索模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能和应用场景"
      },
      {
        "keyword": "ColBERT风格",
        "dimension": "技术特性",
        "reason": "当前模型生成文本与图像多向量表示的技术特性"
      },
      {
        "keyword": "动态图像分辨率",
        "dimension": "技术特性",
        "reason": "当前模型支持输入动态图像分辨率的技术特性"
      },
      {
        "keyword": "图像patch",
        "dimension": "技术特性",
        "reason": "当前模型生成图像patch数量的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-256",
    "keywords": [
      {
        "keyword": "V-JEPA-2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型品牌名称"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对任意视频进行深度理解"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "模型可用于对视频进行类别预测，是主要的应用场景之一"
      },
      {
        "keyword": "视频检索",
        "dimension": "功能场景",
        "reason": "模型支持基于视频特征的检索任务"
      },
      {
        "keyword": "视频编码器",
        "dimension": "功能场景",
        "reason": "模型可作为视觉语言模型（VLM）的视频编码器使用"
      },
      {
        "keyword": "64帧采样",
        "dimension": "技术特性",
        "reason": "模型在推理时默认使用64帧进行视频采样，体现其帧级处理能力"
      },
      {
        "keyword": "大规模预训练",
        "dimension": "技术特性",
        "reason": "模型通过大规模数据和参数进行预训练，提升视频理解性能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/TencentARC/InstantMesh",
    "keywords": [
      {
        "keyword": "InstantMesh",
        "dimension": "当前模型品牌名",
        "reason": "项目自身名称，用户会直接搜索"
      },
      {
        "keyword": "单图生成3D网格",
        "dimension": "功能场景",
        "reason": "README核心卖点，用户搜索意图明确"
      },
      {
        "keyword": "稀疏视角重建",
        "dimension": "技术特性",
        "reason": "技术关键词，体现模型独特能力"
      },
      {
        "keyword": "LRM架构",
        "dimension": "技术特性",
        "reason": "模型底层架构，技术用户会搜"
      },
      {
        "keyword": "可微分等值面提取",
        "dimension": "技术特性",
        "reason": "创新模块，技术深度用户关注点"
      },
      {
        "keyword": "10秒出3D",
        "dimension": "功能场景",
        "reason": "突出速度优势，用户高频搜索"
      },
      {
        "keyword": "图像到3D",
        "dimension": "功能场景",
        "reason": "简洁描述任务类型，搜索常用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepset/bert-large-uncased-whole-word-masking-squad2",
    "keywords": [
      {
        "keyword": "BERT-large-SQuAD2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心词，用户直接搜模型简称"
      },
      {
        "keyword": "抽取式问答",
        "dimension": "功能场景",
        "reason": "模型专精任务，用户高频搜索意图"
      },
      {
        "keyword": "Haystack",
        "dimension": "部署工具",
        "reason": "官方示例框架，用户想快速跑通Demo"
      },
      {
        "keyword": "SQuAD2.0",
        "dimension": "技术特性",
        "reason": "训练/评估数据集，用户验证模型效果必搜"
      },
      {
        "keyword": "ExtractiveReader",
        "dimension": "部署工具",
        "reason": "Haystack组件名，用户查找代码片段常用"
      },
      {
        "keyword": "英语问答模型",
        "dimension": "功能场景",
        "reason": "明确语言+任务，精准匹配搜索需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pcoloc/autotrain-600-dragino-1839063122",
    "keywords": [
      {
        "keyword": "autotrain",
        "dimension": "部署工具",
        "reason": "模型通过AutoTrain平台训练，是用户搜索自动化训练工具时的直接关键词"
      },
      {
        "keyword": "tabular-regression",
        "dimension": "功能场景",
        "reason": "模型明确用于表格数据回归任务，是用户在AI预测场景中搜索的精准术语"
      },
      {
        "keyword": "joblib",
        "dimension": "部署工具",
        "reason": "模型通过joblib加载，是技术用户搜索轻量级模型部署方式时的高频专用词"
      },
      {
        "keyword": "二氧化碳排放预测",
        "dimension": "功能场景",
        "reason": "模型实际用途为预测二氧化碳排放量，属于明确、低竞争、高意图的垂直场景词"
      },
      {
        "keyword": "tabular",
        "dimension": "技术特性",
        "reason": "模型处理结构化表格数据，区别于文本/图像模型，是用户区分模型类型的关键标签"
      },
      {
        "keyword": "单列回归",
        "dimension": "功能场景",
        "reason": "README明确标注问题类型为'单列回归'，属于专业但搜索量适中的精准术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/hustvl/yolos-tiny",
    "keywords": [
      {
        "keyword": "YOLOS-tiny",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "视觉Transformer",
        "dimension": "技术特性",
        "reason": "当前模型采用的技术架构"
      },
      {
        "keyword": "二分匹配损失",
        "dimension": "技术特性",
        "reason": "当前模型训练时使用的损失函数"
      },
      {
        "keyword": "COCO-2017",
        "dimension": "数据集",
        "reason": "当前模型微调所使用的数据集"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/distilbert/distilbert-base-uncased-distilled-squad",
    "keywords": [
      {
        "keyword": "DistilBERT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接包含的模型名称，用户搜索时会使用该品牌名"
      },
      {
        "keyword": "知识蒸馏",
        "dimension": "技术特性",
        "reason": "模型通过知识蒸馏技术从 BERT‑base 压缩而来，是其核心技术亮点"
      },
      {
        "keyword": "SQuAD微调",
        "dimension": "功能场景",
        "reason": "模型在 SQuAD v1.1 数据集上进行微调，专用于英文阅读理解问答"
      },
      {
        "keyword": "轻量级模型",
        "dimension": "技术特性",
        "reason": "相较于原始 BERT，参数量减少约 40%，模型体积更小、部署更轻便"
      },
      {
        "keyword": "66M参数",
        "dimension": "参数规格",
        "reason": "DistilBERT‑base 的参数规模约为 66 百万，用户常以参数量搜索模型"
      },
      {
        "keyword": "英文问答",
        "dimension": "功能场景",
        "reason": "模型面向英文阅读理解任务，适用于英文问答系统"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/laion/clap-htsat-fused",
    "keywords": [
      {
        "keyword": "CLAP-HTSAT-FUSED",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，简洁且为用户搜索该模型时的精准关键词"
      },
      {
        "keyword": "零样本音频分类",
        "dimension": "功能场景",
        "reason": "模型在README中明确强调的核心应用场景，且是用户寻找音频AI模型时的明确搜索意图"
      },
      {
        "keyword": "文本到音频检索",
        "dimension": "功能场景",
        "reason": "模型在实验中表现卓越的专属任务，区别于通用音频分类，具有高区分度和搜索价值"
      },
      {
        "keyword": "对比式语言-音频预训练",
        "dimension": "技术特性",
        "reason": "模型的核心技术命名，是论文提出的原创方法，非通用术语，具有唯一性和专业搜索价值"
      },
      {
        "keyword": "LAION-Audio-630K",
        "dimension": "当前模型品牌名",
        "reason": "与模型绑定的专属数据集，常与模型一同被搜索，是该模型生态的关键组成部分，非通用数据集名称"
      },
      {
        "keyword": "音频-文本对",
        "dimension": "技术特性",
        "reason": "模型训练所依赖的核心数据结构，是区别于其他音频模型（如仅用音频标签）的关键特征"
      },
      {
        "keyword": "HTSAT",
        "dimension": "技术特性",
        "reason": "模型中使用的特定音频编码器名称，是CLAP-HTSAT-FUSED区别于其他CLAP变体（如CLAP-OpenCLIP）的专属技术组件"
      },
      {
        "keyword": "关键词到标题增强",
        "dimension": "技术特性",
        "reason": "模型独有的文本增强技术，在README中被明确列为提升性能的关键设计，具有高度独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/akasharidas/ddpm-cifar10-32-dot.in.name",
    "keywords": [
      {
        "keyword": "DDPM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接出现的核心模型简称"
      },
      {
        "keyword": "扩散模型",
        "dimension": "技术特性",
        "reason": "当前模型采用的去噪扩散概率模型技术"
      },
      {
        "keyword": "CIFAR10生成",
        "dimension": "功能场景",
        "reason": "模型在无条件CIFAR10数据集上实现高质量图像合成"
      },
      {
        "keyword": "DDIM调度器",
        "dimension": "部署工具",
        "reason": "README推荐的推理加速调度器之一"
      },
      {
        "keyword": "PNDM调度器",
        "dimension": "部署工具",
        "reason": "README推荐的推理加速调度器之一"
      },
      {
        "keyword": "图像合成",
        "dimension": "功能场景",
        "reason": "当前模型的核心用途：高质量图像合成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/sam-vit-base",
    "keywords": [
      {
        "keyword": "SAM-ViT-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'facebook/sam-vit-base' 直接提取的模型品牌名，简洁且为用户搜索该模型的精准关键词"
      },
      {
        "keyword": "图像分割",
        "dimension": "功能场景",
        "reason": "模型核心功能是根据点/框提示生成目标掩码，属于明确的用户搜索意图场景，且未在高频排除词列表中"
      },
      {
        "keyword": "零样本分割",
        "dimension": "技术特性",
        "reason": "README多次强调模型具备‘零样本迁移’能力，是SAM区别于传统分割模型的核心技术亮点，具有高区分度"
      },
      {
        "keyword": "提示驱动分割",
        "dimension": "技术特性",
        "reason": "模型通过点、框等提示输入控制分割结果，这一交互方式是SAM的标志性设计，用户会用此词搜索可交互分割模型"
      },
      {
        "keyword": "SA-1B数据集",
        "dimension": "技术特性",
        "reason": "模型训练所用的1100万图像+10亿掩码的SA-1B数据集是其性能基础，属于模型专属资产，非通用术语，具有唯一性"
      },
      {
        "keyword": "ViT图像编码器",
        "dimension": "技术特性",
        "reason": "模型使用基于ViT的图像编码器，是其架构核心组件，用户搜索‘ViT图像编码器’时可能寻找类似结构的分割模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/QuantStack/Wan2.1_T2V_14B_FusionX_VACE-GGUF",
    "keywords": [
      {
        "keyword": "Wan2.1T2V",
        "dimension": "当前模型品牌名",
        "reason": "直接取自项目名称，代表模型的核心品牌标识"
      },
      {
        "keyword": "FusionX",
        "dimension": "技术特性",
        "reason": "模型名称中包含的 FusionX 技术，体现其独特的融合架构"
      },
      {
        "keyword": "VACE",
        "dimension": "技术特性",
        "reason": "模型名称中的 VACE 组件，标识特定的视觉编码增强技术"
      },
      {
        "keyword": "Text-to-Video",
        "dimension": "功能场景",
        "reason": "模型支持从文本生成视频的核心应用场景"
      },
      {
        "keyword": "Video-to-Video",
        "dimension": "功能场景",
        "reason": "模型能够对已有视频进行再生成或风格迁移的功能"
      },
      {
        "keyword": "ComfyUI-GGUF",
        "dimension": "部署工具",
        "reason": "模型可在 ComfyUI 环境中通过 GGUF 自定义节点直接使用"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模为 14B，属于大模型规格，用户常以此搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/trocr-large-printed",
    "keywords": [
      {
        "keyword": "TrOCR-large-printed",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "光学字符识别",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "图像Transformer",
        "dimension": "技术特性",
        "reason": "当前模型编码器部分使用的技术"
      },
      {
        "keyword": "文本Transformer",
        "dimension": "技术特性",
        "reason": "当前模型解码器部分使用的技术"
      },
      {
        "keyword": "BEiT权重初始化",
        "dimension": "技术特性",
        "reason": "当前模型图像编码器权重初始化的方式"
      },
      {
        "keyword": "RoBERTa权重初始化",
        "dimension": "技术特性",
        "reason": "当前模型文本解码器权重初始化的方式"
      },
      {
        "keyword": "自回归生成",
        "dimension": "技术特性",
        "reason": "当前模型文本解码器的生成方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-384",
    "keywords": [
      {
        "keyword": "V-JEPA",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名，已去除版本号"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "模型可用于对视频进行分类，是核心应用场景"
      },
      {
        "keyword": "视频检索",
        "dimension": "功能场景",
        "reason": "模型支持基于内容的 video retrieval，满足检索需求"
      },
      {
        "keyword": "视频编码器",
        "dimension": "功能场景",
        "reason": "模型可作为视频编码器供下游视觉语言模型（VLM）使用"
      },
      {
        "keyword": "大规模视频预训练",
        "dimension": "技术特性",
        "reason": "模型在海量视频数据上进行预训练，体现其规模优势"
      },
      {
        "keyword": "前沿视频理解",
        "dimension": "技术特性",
        "reason": "模型在视频理解能力上达到业界前沿水平"
      },
      {
        "keyword": "视频表示学习",
        "dimension": "技术特性",
        "reason": "模型能够学习高质量的视频表示，用于多种下游任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/VeriReason-Qwen2.5-7b-SFT-Reasoning-i1-GGUF",
    "keywords": [
      {
        "keyword": "VeriReason",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心品牌标识，是当前模型独有的命名，符合用户搜索AI模型时对品牌名的直接检索习惯"
      },
      {
        "keyword": "Verilog",
        "dimension": "功能场景",
        "reason": "模型专用于Verilog硬件描述语言推理，是其核心应用场景，用户会搜索'Verilog AI'或'Verilog推理模型'等关键词"
      },
      {
        "keyword": "RTL推理",
        "dimension": "功能场景",
        "reason": "模型针对RTL（寄存器传输级）设计进行推理优化，是区别于通用代码模型的专属能力，用户可能搜索'RTL AI推理'"
      },
      {
        "keyword": "IQ量化",
        "dimension": "技术特性",
        "reason": "模型提供IQ1_S、IQ3_XS等独特IQ量化版本，是GGUF中区别于普通Q2/Q3量化的技术标签，用户会搜索'IQ量化模型'"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "模型以GGUF格式发布，专为本地推理优化，用户在寻找可本地运行的轻量模型时会搜索'GGUF量化模型'"
      },
      {
        "keyword": "i1-IQ3XS",
        "dimension": "技术特性",
        "reason": "模型特有的量化子版本名称，是用户在对比不同量化精度时可能直接搜索的精确标签，具有高区分度"
      },
      {
        "keyword": "推理增强",
        "dimension": "技术特性",
        "reason": "模型名称含'Reasoning'，且经过SFT强化推理能力，是区别于基础代码模型的核心特性，用户会搜索'推理增强AI模型'"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LGAI-EXAONE/EXAONE-4.0-1.2B",
    "keywords": [
      {
        "keyword": "EXAONE-4.0",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "1.2B参数",
        "dimension": "参数规格",
        "reason": "当前模型的小型端侧规格"
      },
      {
        "keyword": "推理模式",
        "dimension": "技术特性",
        "reason": "模型内置的推理与非推理双模式"
      },
      {
        "keyword": "智能体工具",
        "dimension": "功能场景",
        "reason": "面向智能体AI时代的工具调用能力"
      },
      {
        "keyword": "混合注意力",
        "dimension": "技术特性",
        "reason": "局部+全局混合注意力机制"
      },
      {
        "keyword": "端侧部署",
        "dimension": "部署工具",
        "reason": "专为端侧应用设计的轻量模型"
      },
      {
        "keyword": "韩语支持",
        "dimension": "功能场景",
        "reason": "原生支持韩语等多语言生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/TahaDouaji/detr-doc-table-detection",
    "keywords": [
      {
        "keyword": "DETR表格检测",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心词，用户会直接搜模型简称"
      },
      {
        "keyword": "无边框表格识别",
        "dimension": "功能场景",
        "reason": "模型主打能力，解决文档中难检的无边框表格"
      },
      {
        "keyword": "ICDAR2019",
        "dimension": "技术特性",
        "reason": "训练数据集关键词，学术与工程用户常用检索词"
      },
      {
        "keyword": "文档表格检测",
        "dimension": "功能场景",
        "reason": "明确场景，用户搜索文档OCR/版面分析时的精准需求"
      },
      {
        "keyword": "ResNet-50-DETR",
        "dimension": "技术特性",
        "reason": "模型底座信息，开发者搜索DETR变体时的常见组合词"
      },
      {
        "keyword": "表格目标检测",
        "dimension": "功能场景",
        "reason": "将表格作为目标检测对象，贴合CV工程师的检索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-700M",
    "keywords": [
      {
        "keyword": "LFM2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为LiquidAI/LFM2-700M，LFM2是当前模型的官方品牌名称，简洁且唯一，符合用户搜索习惯"
      },
      {
        "keyword": "边缘AI模型",
        "dimension": "功能场景",
        "reason": "README明确强调'专为边缘人工智能和设备端部署而设计'，这是该模型最核心的差异化定位，用户会搜索此类场景词"
      },
      {
        "keyword": "CPU推理模型",
        "dimension": "功能场景",
        "reason": "模型在CPU上解码和预填充速度比Qwen3快2倍，且明确支持CPU部署，这是其独特优势，用户会搜索'CPU推理模型'这类部署场景"
      },
      {
        "keyword": "混合Liquid模型",
        "dimension": "技术特性",
        "reason": "LFM2是全新混合Liquid架构，具备乘法门控和短卷积，'混合Liquid模型'是其独有的技术命名，具有高区分度"
      },
      {
        "keyword": "700M参数模型",
        "dimension": "参数规格",
        "reason": "模型参数为742M，接近700M主流规格，用户常搜索'700M参数模型'这类近似规格词，且未被高频词列表排除"
      },
      {
        "keyword": "设备端AI",
        "dimension": "功能场景",
        "reason": "README多次提及'设备端部署'，适用于智能手机、笔记本、车辆等，'设备端AI'是用户在边缘计算场景中的高频搜索词"
      },
      {
        "keyword": "轻量级大模型",
        "dimension": "功能场景",
        "reason": "虽参数700M，但性能超越同等规模模型，且强调内存效率，符合'轻量级大模型'这一新兴搜索趋势，区别于传统'小模型'表述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/autogluon/mitra-regressor",
    "keywords": [
      {
        "keyword": "Mitra-Regressor",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整名称"
      },
      {
        "keyword": "表格回归",
        "dimension": "功能场景",
        "reason": "模型专注于表格数据的回归任务，是用户搜索表格回归模型时的核心关键词"
      },
      {
        "keyword": "AutoGluon-Tabular",
        "dimension": "部署工具",
        "reason": "模型通过 AutoGluon 的 Tabular 接口提供，用户常以此名称搜索模型的使用方式"
      },
      {
        "keyword": "上下文学习",
        "dimension": "技术特性",
        "reason": "模型在预训练阶段采用上下文学习范式，是其独特的技术亮点"
      },
      {
        "keyword": "合成数据预训练",
        "dimension": "技术特性",
        "reason": "模型使用大规模合成数据进行预训练，区别于真实数据预训练的模型"
      },
      {
        "keyword": "12层模型",
        "dimension": "参数规格",
        "reason": "模型结构为 12 层深度的网络，用户在搜索模型规模时会关注层数信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-Instruct-i1-GGUF",
    "keywords": [
      {
        "keyword": "Qwen2-Audio-7B-Instruct-i1-GGUF",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "加权矩阵量化版本",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，区别于其他版本"
      },
      {
        "keyword": "静态量化版本",
        "dimension": "技术特性",
        "reason": "当前模型提供的另一种量化形式，具有特定应用场景"
      },
      {
        "keyword": "i1-IQ量化系列",
        "dimension": "技术特性",
        "reason": "当前模型提供的特定量化版本系列，具有存储空间优化特点"
      },
      {
        "keyword": "audio-text-to-text",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，音频到文本的转换"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "授权许可",
        "reason": "当前模型的开源许可协议，影响用户使用和部署方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Alibaba-NLP/WebSailor-3B",
    "keywords": [
      {
        "keyword": "WebSailor-3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称，符合简化规则（保留主名称，省略版本后缀）"
      },
      {
        "keyword": "网络导航代理",
        "dimension": "功能场景",
        "reason": "模型核心用途是执行网络导航与信息检索任务，用户会搜索此类具体场景词，且未在高频排除列表中"
      },
      {
        "keyword": "SailorFog-QA",
        "dimension": "技术特性",
        "reason": "模型独有的数据合成流程名称，代表其创新性任务生成机制，是区别于其他代理模型的关键技术标签"
      },
      {
        "keyword": "双采样策略优化",
        "dimension": "技术特性",
        "reason": "模型提出的专有强化学习算法（DUPO），是训练范式的核心创新，具有唯一性和搜索价值"
      },
      {
        "keyword": "拒绝采样微调",
        "dimension": "技术特性",
        "reason": "模型训练中使用的特定微调方法（RFT），是实现冷启动的关键技术术语，非通用词，具区分度"
      },
      {
        "keyword": "代理强化学习",
        "dimension": "技术特性",
        "reason": "模型采用的核心训练范式，区别于普通LLM微调，是用户搜索AI代理模型时的精准意图关键词"
      },
      {
        "keyword": "BrowseComp基准",
        "dimension": "技术特性",
        "reason": "模型在权威高难度基准上验证性能，该基准名称是领域内专业用户搜索评估模型时的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-t5/t5-3b",
    "keywords": [
      {
        "keyword": "T5-3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文本到文本",
        "dimension": "技术特性",
        "reason": "T5统一所有NLP任务为文本到文本格式"
      },
      {
        "keyword": "30亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规模"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "T5可直接用于机器翻译任务"
      },
      {
        "keyword": "文档摘要",
        "dimension": "功能场景",
        "reason": "T5支持文档自动摘要"
      },
      {
        "keyword": "问答系统",
        "dimension": "功能场景",
        "reason": "T5可构建端到端问答模型"
      },
      {
        "keyword": "情感分析",
        "dimension": "功能场景",
        "reason": "T5在分类任务如情感分析上开箱即用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
    "keywords": [
      {
        "keyword": "Qwen3-235B",
        "dimension": "当前模型品牌名",
        "reason": "从项目全称 Qwen3-235B-A22B-Thinking-2507-FP8 提取的简洁品牌名称"
      },
      {
        "keyword": "高级推理",
        "dimension": "功能场景",
        "reason": "模型在逻辑、数学、科学、代码等推理任务上表现显著提升"
      },
      {
        "keyword": "长上下文理解",
        "dimension": "技术特性",
        "reason": "支持 256K 级别的长上下文，提升思考长度和信息保持能力"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "模型在遵循用户指令方面表现更稳健，适合作为指令型助手"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "增强了对外部工具的使用能力，可在复杂任务中调用工具完成子任务"
      },
      {
        "keyword": "人类偏好对齐",
        "dimension": "技术特性",
        "reason": "通过对齐训练，使生成内容更符合人类价值观和使用偏好"
      },
      {
        "keyword": "思考长度提升",
        "dimension": "技术特性",
        "reason": "相较于前代模型，思考长度显著增加，支持更深层次的链式思考"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/table-transformer-structure-recognition",
    "keywords": [
      {
        "keyword": "Table-Transformer",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格结构识别",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "DETR等效模型",
        "dimension": "技术特性",
        "reason": "当前模型与DETR等效，是其技术特性"
      },
      {
        "keyword": "层归一化",
        "dimension": "技术特性",
        "reason": "当前模型采用DETR的'normalize before'设置，即层归一化"
      },
      {
        "keyword": "PubTables1M训练",
        "dimension": "技术特性",
        "reason": "当前模型在PubTables1M数据集上进行训练"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Prior-Labs/TabPFN-v2-clf",
    "keywords": [
      {
        "keyword": "TabPFN",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称"
      },
      {
        "keyword": "表格基础模型",
        "dimension": "功能场景",
        "reason": "模型定位为表格数据的基础模型，突出其核心应用领域"
      },
      {
        "keyword": "小样本表格学习",
        "dimension": "功能场景",
        "reason": "模型专注于在小规模表格数据上实现高性能，符合用户搜索“小样本表格学习”"
      },
      {
        "keyword": "先验数据学习",
        "dimension": "技术特性",
        "reason": "模型采用基于先验数据的学习方法，是其独特技术亮点"
      },
      {
        "keyword": "零任务微调",
        "dimension": "技术特性",
        "reason": "无需针对特定任务进行微调即可直接使用，体现模型的即插即用特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/bartowski/LLaMA-Mesh-GGUF",
    "keywords": [
      {
        "keyword": "LLaMA-Mesh",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源于该模型，是用户搜索该特定模型的唯一品牌标识"
      },
      {
        "keyword": "GGUF",
        "dimension": "部署工具",
        "reason": "GGUF是llama.cpp的专属量化格式，用户搜索‘GGUF模型’时专指可在llama.cpp生态运行的模型，具有明确技术指向性"
      },
      {
        "keyword": "imatrix量化",
        "dimension": "技术特性",
        "reason": "模型明确使用imatrix方法进行量化，是区别于普通Q4/Q8量化的独特技术点，用户会搜索‘imatrix量化模型’以获取高精度低显存方案"
      },
      {
        "keyword": "LM-Studio",
        "dimension": "部署工具",
        "reason": "README明确指出‘可在LM Studio中运行’，这是该模型的专属部署平台，用户会搜索‘LM Studio可用模型’来匹配工具"
      },
      {
        "keyword": "Q6KL",
        "dimension": "参数规格",
        "reason": "Q6_K_L是该模型特有的高精度量化级别（嵌入与输出层用Q8_0），属于非通用量化标签，用户会搜索该具体格式以获取高质量轻量模型"
      },
      {
        "keyword": "Q5KL",
        "dimension": "参数规格",
        "reason": "Q5_K_L是该模型提供的另一独特量化版本，强调嵌入层保留Q8_0精度，属于细粒度量化标签，区别于普通Q5，具有搜索价值"
      },
      {
        "keyword": "Text-to-3D",
        "dimension": "功能场景",
        "reason": "项目标签明确标注Text-to-3D，是该模型的核心应用场景，区别于通用文本生成，具有明确垂直用途，用户会搜索此关键词寻找3D生成模型"
      },
      {
        "keyword": "mesh-generation",
        "dimension": "功能场景",
        "reason": "标签中‘mesh-generation’是Text-to-3D的具体实现形式，属于专业术语但用户在AI建模圈中会直接搜索该词寻找3D网格生成模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/HKUSTAudio/xcodec2",
    "keywords": [
      {
        "keyword": "XCodec2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "语音令牌化器",
        "dimension": "功能场景",
        "reason": "README中明确给出的模型定位"
      },
      {
        "keyword": "每秒50令牌",
        "dimension": "技术特性",
        "reason": "用户会搜索的量化速率指标"
      },
      {
        "keyword": "单一矢量量化",
        "dimension": "技术特性",
        "reason": "模型核心量化技术，用户可能直接搜索"
      },
      {
        "keyword": "多语言语音重建",
        "dimension": "功能场景",
        "reason": "README强调的多语言高质量语音重建能力"
      },
      {
        "keyword": "Llasa微调",
        "dimension": "部署工具",
        "reason": "README新增的微调说明，用户会搜索如何微调"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR2-7B",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目名称 ByteDance-Seed 对应的国产大模型品牌映射"
      },
      {
        "keyword": "单步视频修复",
        "dimension": "功能场景",
        "reason": "模型能够在一次前向传播完成高清视频的修复任务"
      },
      {
        "keyword": "对抗后训练",
        "dimension": "技术特性",
        "reason": "采用对抗训练机制提升生成质量与分布匹配能力"
      },
      {
        "keyword": "自适应窗口注意力",
        "dimension": "技术特性",
        "reason": "动态调整注意力窗口尺寸以适配不同分辨率，解决窗口不连贯问题"
      },
      {
        "keyword": "特征匹配损失",
        "dimension": "技术特性",
        "reason": "引入新型特征匹配损失函数，增强视频时序一致性"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "模型提供标准化 API，便于在服务端或本地快速集成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/fixie-ai/ultravox-v0_6-llama-3_3-70b",
    "keywords": [
      {
        "keyword": "Ultravox",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 fixie-ai/ultravox-v0_6-llama-3_3-70b 中提取的核心模型品牌名，且未被高频词列表排除"
      },
      {
        "keyword": "语音到文本",
        "dimension": "功能场景",
        "reason": "模型核心能力是接收语音输入并生成文本输出，属于用户明确搜索的场景（如‘语音转文字AI’），且非高频词"
      },
      {
        "keyword": "多模态语音",
        "dimension": "技术特性",
        "reason": "模型明确为‘多模态语音大语言模型’，结合语音与文本输入，具有独特性，未在高频词列表中出现"
      },
      {
        "keyword": "噪声鲁棒语音",
        "dimension": "技术特性",
        "reason": "v0.6版本特别在噪声数据上训练，可识别并输出((noise))，是该模型独有的鲁棒性特征，用户可能搜索‘抗噪语音识别模型’"
      },
      {
        "keyword": "印地语语音识别",
        "dimension": "功能场景",
        "reason": "v0.6在印地语语音数据上专项增强，是该模型区别于其他语音模型的明确语言支持特性，非通用词"
      },
      {
        "keyword": "音频伪标记",
        "dimension": "技术特性",
        "reason": "模型使用<|audio|>伪标记处理语音输入，是其架构核心机制，技术独特，非通用术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-i1-GGUF",
    "keywords": [
      {
        "keyword": "Qwen2-Audio-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "加权矩阵量化版本",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，区别于其他版本"
      },
      {
        "keyword": "静态量化版本",
        "dimension": "技术特性",
        "reason": "当前模型提供的另一种技术特性版本"
      },
      {
        "keyword": "i1-IQ量化版本",
        "dimension": "技术特性",
        "reason": "当前模型提供的特定量化版本，具有独特性"
      },
      {
        "keyword": "音频-文本转文本",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能，描述其应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/qwbu/univla-7b",
    "keywords": [
      {
        "keyword": "UniVLA",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌名"
      },
      {
        "keyword": "具身智能",
        "dimension": "功能场景",
        "reason": "模型主打跨具身形态的动作学习，用户会搜具身智能相关方案"
      },
      {
        "keyword": "潜在动作",
        "dimension": "技术特性",
        "reason": "论文核心创新点，用户想了解潜在动作如何实现通用策略"
      },
      {
        "keyword": "跨具身视频",
        "dimension": "技术特性",
        "reason": "模型训练数据来源，用户会搜如何利用跨具身视频训练机器人"
      },
      {
        "keyword": "任务中心化",
        "dimension": "技术特性",
        "reason": "论文提出的动作提取方法，用户会搜任务中心化相关实现"
      },
      {
        "keyword": "OpenX数据集",
        "dimension": "部署工具",
        "reason": "官方预训练数据之一，用户想下载或复现OpenX实验"
      },
      {
        "keyword": "Ego4D预训练",
        "dimension": "部署工具",
        "reason": "官方预训练数据之二，用户会搜Ego4D在机器人模型上的用法"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Kimi-K2-Instruct-GGUF",
    "keywords": [
      {
        "keyword": "Kimi-K2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为unsloth/Kimi-K2-Instruct-GGUF，根据国产大模型映射规则，MoonshotAI → 提取'Kimi'，结合型号简化为'Kimi-K2'，是当前模型唯一品牌标识"
      },
      {
        "keyword": "Kimi-K2-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确包含'Kimi-K2-Instruct'，是模型的完整指令微调版本名称，用户搜索具体指令型变体时会使用该完整命名，符合品牌名提取规则"
      },
      {
        "keyword": "GGUF",
        "dimension": "部署工具",
        "reason": "模型以GGUF格式发布，是用户在本地部署时搜索量化格式的核心关键词，且未被高频词列表排除，具有明确工具指向性"
      },
      {
        "keyword": "MoE模型",
        "dimension": "技术特性",
        "reason": "模型明确为混合专家（MoE）架构，且参数规模达1万亿，'MoE模型'是用户搜索稀疏激活大模型时的高频技术词，未被禁止列表覆盖"
      },
      {
        "keyword": "320亿激活参数",
        "dimension": "参数规格",
        "reason": "模型明确标注320亿激活参数，属于主流规模参数（介于7B-175B之间），非极端细节，用户会搜索此类具体激活参数规格以评估模型大小"
      },
      {
        "keyword": "Muon优化器",
        "dimension": "技术特性",
        "reason": "模型使用独家的Muon优化器进行训练，是区别于其他模型的核心技术亮点，非通用术语，具有高度区分度且未被高频词列表包含"
      },
      {
        "keyword": "智能体智能",
        "dimension": "功能场景",
        "reason": "README明确指出模型'专为工具使用、推理和自主问题解决而设计'，'智能体智能'是精准概括其AI代理能力的功能场景词，非泛化表述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR2-3B",
    "keywords": [
      {
        "keyword": "SeedVR2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed 映射为字节跳动豆包系列"
      },
      {
        "keyword": "视频修复",
        "dimension": "功能场景",
        "reason": "当前模型核心用途为视频修复"
      },
      {
        "keyword": "一步式推理",
        "dimension": "技术特性",
        "reason": "单步扩散对抗后训练，显著降低计算成本"
      },
      {
        "keyword": "扩散对抗训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心训练方法"
      },
      {
        "keyword": "自适应窗口注意力",
        "dimension": "技术特性",
        "reason": "动态窗口大小的高分辨率视频修复机制"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "当前模型公开的参数规模"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lovis93/Motion-Lora-Camera-Push-In-Wan-14B-720p-I2V",
    "keywords": [
      {
        "keyword": "Motion-LoRA",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 “Motion-Lora-Camera-Push-In‑Wan‑14B‑720p‑I2V” 中提取的简洁模型品牌名"
      },
      {
        "keyword": "Push-in-camera",
        "dimension": "功能场景",
        "reason": "模型的触发词，用于生成推镜式运动镜头，用户搜索时会直接使用该关键词"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 14 B 参数，属于用户常搜索的参数规格类别"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "模型提供了兼容 ComfyUI 的完整工作流文件，适合在该平台快速上手"
      },
      {
        "keyword": "I2V-720p",
        "dimension": "技术特性",
        "reason": "模型基于 Wan 2.1 的 I2V（图像‑到‑视频）架构，支持 720p 超高清输出"
      },
      {
        "keyword": "电影感运动",
        "dimension": "技术特性",
        "reason": "模型专注于生成具有电影质感的推镜运动效果，区别于普通运动 LoRA"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pcoloc/autotrain-mikrotik-7-7-1860563588",
    "keywords": [
      {
        "keyword": "pcolocautotrain-mikrotik-7-7",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "单列回归",
        "dimension": "功能场景",
        "reason": "当前模型的问题类型，属于功能场景"
      },
      {
        "keyword": "二氧化碳排放量预测",
        "dimension": "功能场景",
        "reason": "根据模型训练目的推测的功能场景，具有独特性"
      },
      {
        "keyword": "Joblib",
        "dimension": "部署工具",
        "reason": "模型使用Joblib进行加载，属于部署工具相关"
      },
      {
        "keyword": "tabular-regression",
        "dimension": "技术特性",
        "reason": "标签中体现的当前模型技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/adrientoupet/SeedVR2_comfyUI",
    "keywords": [
      {
        "keyword": "SeedVR2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型品牌名，用户搜索时会直接使用"
      },
      {
        "keyword": "视频超分",
        "dimension": "功能场景",
        "reason": "模型专注于视频分辨率提升，是典型的“视频超分”应用场景"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "模型针对 ComfyUI 进行优化，用户常以该关键词查找对应插件"
      },
      {
        "keyword": "GGUF模型",
        "dimension": "技术特性",
        "reason": "仓库提供 GGUF 格式的模型权重，是模型的独特文件格式特性"
      },
      {
        "keyword": "时间一致性",
        "dimension": "技术特性",
        "reason": "模型在提升分辨率的同时保持帧间时间一致性，是其核心技术优势"
      },
      {
        "keyword": "额外upscale模型",
        "dimension": "功能场景",
        "reason": "本仓库提供的额外 upscale 模型用于进一步提升视频质量，区别于主模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/skt/A.X-3.1",
    "keywords": [
      {
        "keyword": "A.X-3.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为skt/A.X-3.1，模型正式名称为A.X 3.1，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "韩语大模型",
        "dimension": "功能场景",
        "reason": "模型专为韩语理解与企业部署优化，是用户搜索韩语AI时的核心意图词，且未在高频排除词列表中"
      },
      {
        "keyword": "主权AI",
        "dimension": "技术特性",
        "reason": "模型强调由SKT完全自主开发，涵盖架构、数据、训练全流程，'主权AI'是其核心差异化定位术语"
      },
      {
        "keyword": "34B参数",
        "dimension": "参数规格",
        "reason": "模型参数量为34B，属于主流大模型规格，且未被高频排除词（如7B/32B/671B）覆盖，具有区分度"
      },
      {
        "keyword": "KMMLU",
        "dimension": "技术特性",
        "reason": "模型在KMMLU（韩语版MMLU）基准上取得69.2分，该基准是韩语评估的权威专有指标，非通用术语"
      },
      {
        "keyword": "CLIcK",
        "dimension": "技术特性",
        "reason": "模型在CLIcK（韩语文化语境理解基准）上达77.4分，为SKT自研的专属评估基准，具有唯一性和搜索价值"
      },
      {
        "keyword": "YaRN",
        "dimension": "技术特性",
        "reason": "模型通过YaRN技术扩展上下文至131K，该技术名称是具体技术实现词，非通用术语，用户可能搜索'YaRN 长上下文'"
      },
      {
        "keyword": "TITAN",
        "dimension": "技术特性",
        "reason": "模型全程运行于SKT自研超级计算基础设施TITAN，是其专属硬件生态标签，具有品牌独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/TeslaYang123/TC-Light",
    "keywords": [
      {
        "keyword": "TC-Light",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "视频重光照",
        "dimension": "功能场景",
        "reason": "TC-Light的核心功能是操纵视频光照分布"
      },
      {
        "keyword": "时间一致性",
        "dimension": "技术特性",
        "reason": "TC-Light在高动态场景下保持卓越的时间一致性"
      },
      {
        "keyword": "sim2real",
        "dimension": "功能场景",
        "reason": "TC-Light专为具身智能体的sim2real数据增强设计"
      },
      {
        "keyword": "长视频处理",
        "dimension": "功能场景",
        "reason": "支持在单卡A100上处理300帧1280×720长视频"
      },
      {
        "keyword": "生成式渲染",
        "dimension": "技术特性",
        "reason": "TC-Light是一种生成式渲染器，用于真实世界迁移"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/prs-eth/marigold-normals-v1-1",
    "keywords": [
      {
        "keyword": "marigold-normals",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 prs-eth/marigold-normals-v1-1 中提取的核心品牌名，去掉版本号后为用户搜索模型的直接关键词"
      },
      {
        "keyword": "单目法向量估计",
        "dimension": "功能场景",
        "reason": "模型核心用途，用户在计算机视觉领域搜索表面法线生成时会使用该精准术语"
      },
      {
        "keyword": "法线图生成",
        "dimension": "功能场景",
        "reason": "对'单目法向量估计'的通俗表达，符合工程师和研究者在图像分析中搜索'法线图'的搜索习惯"
      },
      {
        "keyword": "扩散模型法线估计",
        "dimension": "技术特性",
        "reason": "模型基于扩散架构实现法线估计，是区别于传统CNN方法的独特技术标签，用户会搜索此类组合词"
      },
      {
        "keyword": "零样本法线估计",
        "dimension": "技术特性",
        "reason": "README明确标注'zero-shot'，且法线估计领域中零样本能力是重要卖点，具有区分度"
      },
      {
        "keyword": "图像分析",
        "dimension": "功能场景",
        "reason": "模型应用于图像分析任务，是CVPR论文中的官方描述，非泛泛词汇，且未被高频词列表排除"
      },
      {
        "keyword": "in-the-wild-法线估计",
        "dimension": "功能场景",
        "reason": "README明确使用'in-the-wild'描述模型适用场景，是学术界和工业界用于指代真实场景图像分析的专有术语，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-t5/t5-large",
    "keywords": [
      {
        "keyword": "google-t5t5-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目URL和名称中提取的当前模型名称"
      },
      {
        "keyword": "文本到文本迁移转换器",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性描述"
      },
      {
        "keyword": "7.7亿参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模描述"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一"
      },
      {
        "keyword": "文档摘要",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一"
      },
      {
        "keyword": "问答任务",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一"
      },
      {
        "keyword": "情感分析",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OmniGen2/OmniGen2",
    "keywords": [
      {
        "keyword": "OmniGen2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为模型的品牌名，用户搜索时会直接使用该名称"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "OmniGen2 官方支持 ComfyUI，用户常以此关键词寻找可视化部署方案"
      },
      {
        "keyword": "TeaCache",
        "dimension": "技术特性",
        "reason": "最新更新中提到 OmniGen2 支持 TeaCache 以实现更快速推理，属于模型的加速特性"
      },
      {
        "keyword": "TaylorSeer",
        "dimension": "技术特性",
        "reason": "OmniGen2 同时支持 TaylorSeer 加速推理，是模型独有的性能优化组件"
      },
      {
        "keyword": "X2I2-训练数据集",
        "dimension": "技术特性",
        "reason": "项目公开的 X2I2 数据集是 OmniGen2 训练使用的专属数据资源，具备搜索价值"
      },
      {
        "keyword": "OmniContext-基准测试",
        "dimension": "技术特性",
        "reason": "OmniGen2 提供的 OmniContext 基准测试集用于模型评估，用户会以此关键词查找评测信息"
      },
      {
        "keyword": "解耦图像分词器",
        "dimension": "技术特性",
        "reason": "模型采用独立的图像分词器设计，是区别于其他多模态模型的关键技术点"
      },
      {
        "keyword": "无-flashattn-运行",
        "dimension": "技术特性",
        "reason": "OmniGen2 可在无需 flash‑attn 的环境下运行，满足显存受限设备的部署需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-235B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心标识，用户会直接搜索"
      },
      {
        "keyword": "235B参数",
        "dimension": "参数规格",
        "reason": "超大参数规模，用户关注旗舰级模型"
      },
      {
        "keyword": "思维推理模型",
        "dimension": "功能场景",
        "reason": "README强调推理能力，用户搜“思维”找此类模型"
      },
      {
        "keyword": "256K长上下文",
        "dimension": "技术特性",
        "reason": "超长上下文是显著卖点，用户会按此规格搜索"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "提供GGUF格式，用户搜“GGUF”找可直接运行的量化模型"
      },
      {
        "keyword": "Unsloth微调",
        "dimension": "部署工具",
        "reason": "README主打Unsloth加速微调，用户搜“Unsloth”找相关模型与教程"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepset/bert-base-cased-squad2",
    "keywords": [
      {
        "keyword": "bert-base-cased-squad2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索特定SQuAD2微调BERT模型时会使用此完整名称"
      },
      {
        "keyword": "抽取式问答",
        "dimension": "功能场景",
        "reason": "模型核心用途，用户搜索英文问答、阅读理解类AI工具时常用此中文术语"
      },
      {
        "keyword": "SQuAD-v2",
        "dimension": "训练数据",
        "reason": "模型训练所用的权威数据集名称，专业用户会以此为关键词筛选支持未回答问题的问答模型"
      },
      {
        "keyword": "Haystack",
        "dimension": "部署工具",
        "reason": "模型官方推荐的集成框架，用户寻找可落地的问答系统时会搜索‘Haystack 问答模型’"
      },
      {
        "keyword": "BERT-base",
        "dimension": "技术特性",
        "reason": "模型基础架构名称，用户区分不同规模BERT变体时会搜索此通用术语（非高频词，因未在排除列表中）"
      },
      {
        "keyword": "英文问答",
        "dimension": "功能场景",
        "reason": "模型仅支持英语，用户明确寻找英文阅读理解模型时会使用此精准场景词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/joeddav/xlm-roberta-large-xnli",
    "keywords": [
      {
        "keyword": "XLMRobertalarge",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型主体名称，去除后缀‑xnli，保持简洁"
      },
      {
        "keyword": "ZeroShot-Classification",
        "dimension": "功能场景",
        "reason": "模型专用于零样本文本分类，可直接用于跨语言标签推断"
      },
      {
        "keyword": "XNLI微调",
        "dimension": "技术特性",
        "reason": "模型在多语言自然语言推理数据集 XNLI 上进行微调，提升跨语言推理能力"
      },
      {
        "keyword": "跨语言文本推理",
        "dimension": "功能场景",
        "reason": "支持 15 种语言的自然语言推理任务，适用于多语言文本理解"
      },
      {
        "keyword": "ZeroShotClassificationPipeline",
        "dimension": "部署工具",
        "reason": "可通过 HuggingFace 的 zero‑shot‑classification 管道直接调用，使用便捷"
      },
      {
        "keyword": "15语言支持",
        "dimension": "功能场景",
        "reason": "模型覆盖英、法、西、德、希、保、俄、土、阿、越、泰、中文、印、斯瓦、乌等 15 种语言"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/intfloat/multilingual-e5-large-instruct",
    "keywords": [
      {
        "keyword": "E5-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多语言文本嵌入",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能"
      },
      {
        "keyword": "MS-MARCO段落排序",
        "dimension": "功能场景",
        "reason": "官方示例场景，用户会搜"
      },
      {
        "keyword": "ONNX部署",
        "dimension": "部署工具",
        "reason": "README标签中明确支持ONNX"
      },
      {
        "keyword": "sentence-transformers",
        "dimension": "部署工具",
        "reason": "官方兼容的库，用户会搜"
      },
      {
        "keyword": "1024维嵌入",
        "dimension": "技术特性",
        "reason": "模型输出维度，用户关心"
      },
      {
        "keyword": "24层Transformer",
        "dimension": "技术特性",
        "reason": "模型架构深度，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwaipilot/OASIS-code-1.3B",
    "keywords": [
      {
        "keyword": "OASIS-code-1.3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "代码嵌入模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能和应用场景"
      },
      {
        "keyword": "仓库级程序分析",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特技术之一"
      },
      {
        "keyword": "OASIS-instruct数据合成算法",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性之一"
      },
      {
        "keyword": "专用融合损失函数",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特技术之一"
      },
      {
        "keyword": "代码搜索效率",
        "dimension": "功能场景",
        "reason": "当前模型在代码搜索方面的应用场景和优势"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-Audio-7B-Instruct",
    "keywords": [
      {
        "keyword": "Kimi",
        "dimension": "当前模型品牌名",
        "reason": "项目所属公司为MoonshotAI，根据国产大模型映射规则，MoonshotAI → Kimi（月之暗面）"
      },
      {
        "keyword": "Kimi-Audio",
        "dimension": "当前模型品牌名",
        "reason": "模型正式名称，是当前项目唯一标识，用户搜索音频模型时会直接使用该品牌名"
      },
      {
        "keyword": "音频问答",
        "dimension": "功能场景",
        "reason": "模型核心功能之一（AQA），用户搜索‘音频问答AI’或‘语音问答模型’时会使用该词，且非高频词"
      },
      {
        "keyword": "音频描述",
        "dimension": "功能场景",
        "reason": "模型支持AAC（Audio Captioning），是区别于通用语音模型的独特能力，搜索意图明确"
      },
      {
        "keyword": "语音情感识别",
        "dimension": "功能场景",
        "reason": "模型支持SER任务，属于垂直音频理解能力，非通用词，用户会针对性搜索"
      },
      {
        "keyword": "端到端语音对话",
        "dimension": "功能场景",
        "reason": "模型支持完整语音对话闭环，区别于传统ASR+TTS分离架构，是核心差异化功能"
      },
      {
        "keyword": "混合音频输入",
        "dimension": "技术特性",
        "reason": "模型创新架构特征，使用‘连续声学+离散语义令牌’双模输入，技术术语但用户会搜索相关论文或实现"
      },
      {
        "keyword": "流式音频生成",
        "dimension": "技术特性",
        "reason": "基于流匹配的分块流式解码，是低延迟音频生成的关键技术，区别于传统批量生成，具独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-Embedding-4B-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-Embedding-4B-GGUF",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型完整标识，符合用户搜索具体模型版本的意图"
      },
      {
        "keyword": "文本嵌入",
        "dimension": "功能场景",
        "reason": "模型核心用途，用户搜索AI嵌入模型时高频使用，且未被高频词列表排除"
      },
      {
        "keyword": "重排模型",
        "dimension": "功能场景",
        "reason": "模型支持排序/重排任务，是区别于普通嵌入模型的独特功能点"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "GGUF是模型部署格式，用户在本地部署LLM时会搜索此关键词，且未被高频词列表覆盖"
      },
      {
        "keyword": "32k上下文",
        "dimension": "技术特性",
        "reason": "32k是主流长上下文规格，用户会搜索长文本处理模型，且未被禁止的'8192'等细节词替代"
      },
      {
        "keyword": "自定义维度",
        "dimension": "技术特性",
        "reason": "支持32-2560任意嵌入维度，是区别于固定维度模型的核心技术亮点"
      },
      {
        "keyword": "多语言检索",
        "dimension": "功能场景",
        "reason": "模型主打100+语言的跨语言检索能力，是明确可搜索的应用场景，非泛泛'多语言'"
      },
      {
        "keyword": "代码检索",
        "dimension": "功能场景",
        "reason": "模型明确支持代码检索，属于垂直细分场景，用户会针对性搜索，且未被高频词覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/JacobLinCool/MP-SENet-DNS",
    "keywords": [
      {
        "keyword": "MP-SENet",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "语音降噪",
        "dimension": "功能场景",
        "reason": "README标签明确指向denoising与speech-enhancement"
      },
      {
        "keyword": "音频去噪",
        "dimension": "功能场景",
        "reason": "用户搜索音频降噪模型时常用关键词"
      },
      {
        "keyword": "DNS挑战",
        "dimension": "功能场景",
        "reason": "项目名含DNS，指向Deep Noise Suppression挑战赛场景"
      },
      {
        "keyword": "MIT开源",
        "dimension": "部署工具",
        "reason": "许可证为MIT，用户搜索可商用开源模型时会用"
      },
      {
        "keyword": "语音增强",
        "dimension": "功能场景",
        "reason": "README标签speech-enhancement对应的核心功能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/imagegpt-large",
    "keywords": [
      {
        "keyword": "ImageGPT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "iGPT",
        "dimension": "当前模型品牌名",
        "reason": "模型简称，便于用户搜索"
      },
      {
        "keyword": "自监督学习",
        "dimension": "技术特性",
        "reason": "当前模型使用的核心技术方法"
      },
      {
        "keyword": "像素预测",
        "dimension": "技术特性",
        "reason": "当前模型的核心任务，即根据已出现的像素值预测下一个像素值"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "当前模型可用于提取下游任务所需的图像特征"
      },
      {
        "keyword": "条件图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一，可执行条件图像生成"
      },
      {
        "keyword": "无条件图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一，可执行无条件图像生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lysandre/tiny-tapas-random-sqa",
    "keywords": [
      {
        "keyword": "TinyTapas",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的简洁模型名称"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型专注于对表格数据进行问答的任务"
      },
      {
        "keyword": "随机抽样",
        "dimension": "技术特性",
        "reason": "模型在训练/推理时采用随机抽样策略以提升鲁棒性"
      },
      {
        "keyword": "轻量化模型",
        "dimension": "技术特性",
        "reason": "模型体积小、参数量低，适合资源受限环境"
      },
      {
        "keyword": "SQA任务",
        "dimension": "功能场景",
        "reason": "模型面向语义问答（Semantic Question Answering）任务"
      },
      {
        "keyword": "Python库",
        "dimension": "部署工具",
        "reason": "模型以 Python 库形式提供，便于在项目中直接调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/tapex-large-finetuned-wtq",
    "keywords": [
      {
        "keyword": "TAPEX",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'microsoft/tapex-large-finetuned-wtq' 中提取的核心模型品牌名，是论文提出的原创模型，具有唯一性"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型专门用于解决表格结构数据的自然语言问答任务，如WikiTableQuestions中的复杂查询，是用户搜索该类模型时的核心意图词"
      },
      {
        "keyword": "神经SQL执行器",
        "dimension": "技术特性",
        "reason": "模型的核心创新点，通过学习合成SQL执行器实现表格理解，是TAPEX区别于其他文本模型的独特技术概念"
      },
      {
        "keyword": "WikiTableQuestions",
        "dimension": "当前模型品牌名",
        "reason": "模型在该数据集上微调，该数据集名称已成为该模型的标志性应用场景，用户常以数据集名搜索对应模型"
      },
      {
        "keyword": "表结构推理",
        "dimension": "技术特性",
        "reason": "模型专为处理表格中跨行跨列的逻辑推理设计，如计算差值、排序、时间序列对比等，是其核心能力的精准描述"
      },
      {
        "keyword": "seq2seq表格模型",
        "dimension": "技术特性",
        "reason": "模型基于BART的编码器-解码器结构，专门针对表格输入输出设计，区别于纯文本seq2seq模型，是技术圈内精准搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenGVLab/InternVL3-78B",
    "keywords": [
      {
        "keyword": "InternVL3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的系列品牌名"
      },
      {
        "keyword": "78B参数",
        "dimension": "参数规格",
        "reason": "当前模型超大参数规模，用户会搜"
      },
      {
        "keyword": "GUI智能体",
        "dimension": "功能场景",
        "reason": "InternVL3新增的独特能力，用户搜索GUI自动化"
      },
      {
        "keyword": "工业图像分析",
        "dimension": "功能场景",
        "reason": "模型官方强调的新场景，垂直行业用户会搜"
      },
      {
        "keyword": "3D视觉感知",
        "dimension": "功能场景",
        "reason": "InternVL3独有的3D理解能力，用户会搜"
      },
      {
        "keyword": "工具调用",
        "dimension": "技术特性",
        "reason": "模型支持函数/工具调用，开发者会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/tapex-base",
    "keywords": [
      {
        "keyword": "TAPEX",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "模型可直接用于表格上的问答任务"
      },
      {
        "keyword": "表格事实验证",
        "dimension": "功能场景",
        "reason": "模型支持对表格数据进行事实真伪验证"
      },
      {
        "keyword": "神经SQL执行器",
        "dimension": "技术特性",
        "reason": "模型通过学习神经化的SQL执行器实现表格预训练"
      },
      {
        "keyword": "合成语料库",
        "dimension": "技术特性",
        "reason": "模型使用自动生成的合成语料库进行大规模训练"
      },
      {
        "keyword": "BART架构",
        "dimension": "技术特性",
        "reason": "模型基于BART的Encoder‑Decoder结构构建"
      },
      {
        "keyword": "表格预训练",
        "dimension": "功能场景",
        "reason": "模型的核心目标是对表格数据进行预训练以提升推理能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/ddpm-church-256",
    "keywords": [
      {
        "keyword": "googleddpm-church-256",
        "dimension": "当前模型品牌名",
        "reason": "从项目URL和名称中提取的当前模型标识"
      },
      {
        "keyword": "去噪扩散概率模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术类型描述"
      },
      {
        "keyword": "高质量图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景和功能"
      },
      {
        "keyword": "渐进式有损解压缩",
        "dimension": "技术特性",
        "reason": "当前模型支持的独特技术特性"
      },
      {
        "keyword": "schedulingddpm",
        "dimension": "部署工具",
        "reason": "当前模型推理时使用的特定调度器名称"
      },
      {
        "keyword": "unconditional-image-generation",
        "dimension": "功能场景",
        "reason": "当前模型的无条件图像生成功能描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/bigvgan_v2_24khz_100band_256x",
    "keywords": [
      {
        "keyword": "BigVGAN",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 nvidia/bigvgan_v2_24khz_100band_256x 中提取的核心模型品牌名，简洁且为用户搜索AI声码器时的直接关键词"
      },
      {
        "keyword": "神经声码器",
        "dimension": "功能场景",
        "reason": "模型核心功能是音频生成，'神经声码器'是用户在AI音频领域搜索时的精准术语，区别于通用'语音合成'等词"
      },
      {
        "keyword": "音频生成",
        "dimension": "功能场景",
        "reason": "模型用于从文本或特征生成高质量音频，是用户在AI音频应用中高频搜索的场景词，且未被高频词列表排除"
      },
      {
        "keyword": "多尺度子带CQT判别器",
        "dimension": "技术特性",
        "reason": "模型训练中独有的判别器结构，属于技术亮点，专业用户会搜索该术语以了解模型架构差异"
      },
      {
        "keyword": "融合CUDA内核",
        "dimension": "技术特性",
        "reason": "模型核心优化点，用户搜索'高性能音频生成模型'或'CUDA加速声码器'时可能使用该术语，具技术区分度"
      },
      {
        "keyword": "44-kHz音频",
        "dimension": "参数规格",
        "reason": "支持最高44 kHz采样率是模型关键配置，属于用户在高保真音频生成场景中会搜索的明确参数规格"
      },
      {
        "keyword": "512倍上采样",
        "dimension": "参数规格",
        "reason": "模型支持512倍上采样比，是其在声码器中突出的结构特性，专业用户会以此区分模型能力"
      },
      {
        "keyword": "Hugging-Face-Spaces",
        "dimension": "部署工具",
        "reason": "模型已集成Hugging Face Spaces提供在线体验，是用户寻找'在线试听AI声码器'时的关键部署入口词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/ddpm-cat-256",
    "keywords": [
      {
        "keyword": "DDPM",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称google/ddpm-cat-256提取的当前扩散模型简称"
      },
      {
        "keyword": "扩散概率模型",
        "dimension": "技术特性",
        "reason": "当前模型核心算法，用户会搜“扩散模型”相关词"
      },
      {
        "keyword": "图像去噪",
        "dimension": "功能场景",
        "reason": "DDPM主打的图像生成与去噪能力，用户搜索意图明确"
      },
      {
        "keyword": "256分辨率",
        "dimension": "参数规格",
        "reason": "模型输出256×256像素，用户常搜“256图像生成”"
      },
      {
        "keyword": "LSUN猫数据集",
        "dimension": "功能场景",
        "reason": "模型专用于猫图像生成，用户会搜“猫图生成模型”"
      },
      {
        "keyword": "DDIM调度器",
        "dimension": "部署工具",
        "reason": "官方推荐的速度优化调度器，用户部署时会搜"
      },
      {
        "keyword": "PNDM调度器",
        "dimension": "部署工具",
        "reason": "另一种加速推理的调度器，用户对比方案时会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/segformer-b4-finetuned-cityscapes-1024-1024",
    "keywords": [
      {
        "keyword": "SegFormer-B4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接包含的模型名称，已简化为品牌名"
      },
      {
        "keyword": "CityScapes微调",
        "dimension": "功能场景",
        "reason": "模型在 CityScapes 数据集上完成微调，体现其专注的语义分割场景"
      },
      {
        "keyword": "1024x1024分辨率",
        "dimension": "技术特性",
        "reason": "模型在 1024×1024 高分辨率下进行训练和推理，区别于低分辨率模型"
      },
      {
        "keyword": "语义分割",
        "dimension": "功能场景",
        "reason": "模型的核心任务是像素级语义分割，用户搜索此任务时会使用该词"
      },
      {
        "keyword": "轻量级MLP解码头",
        "dimension": "技术特性",
        "reason": "采用轻量级全 MLP 解码头，提升推理效率且保持分割精度"
      },
      {
        "keyword": "分层编码器",
        "dimension": "技术特性",
        "reason": "使用分层式 Transformer 编码器结构，是 SegFormer 的关键创新点"
      },
      {
        "keyword": "ImageNet-1k预训练",
        "dimension": "技术特性",
        "reason": "模型的编码器在 ImageNet‑1k 上预训练后再进行下游微调，提升特征表达能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/neuralmind/bert-base-portuguese-cased",
    "keywords": [
      {
        "keyword": "BERTimbau-Base",
        "dimension": "当前模型品牌名",
        "reason": "项目官方名称，是该葡萄牙语BERT模型的专属品牌标识，区别于其他BERT变体"
      },
      {
        "keyword": "bert-base-portuguese-cased",
        "dimension": "当前模型品牌名",
        "reason": "模型在Hugging Face和GitCode上的正式名称，用户搜索模型时会直接使用此完整标识"
      },
      {
        "keyword": "巴西葡萄牙语NLP",
        "dimension": "功能场景",
        "reason": "明确指向该模型服务的语言场景（巴西葡萄牙语）和任务类型（NLP），用户会搜索特定语言的NLP模型"
      },
      {
        "keyword": "命名实体识别",
        "dimension": "功能场景",
        "reason": "模型在README中明确列出的三大下游任务之一，是用户寻找语言理解模型时的明确搜索意图"
      },
      {
        "keyword": "句子文本相似度",
        "dimension": "功能场景",
        "reason": "模型在README中明确宣称的高性能任务，属于具体NLP应用场景，非通用词，具区分度"
      },
      {
        "keyword": "文本蕴含识别",
        "dimension": "功能场景",
        "reason": "模型三大核心任务之一，专业但用户（如NLP研究者、开发者）会直接搜索该术语"
      },
      {
        "keyword": "neuralmind",
        "dimension": "当前模型品牌名",
        "reason": "模型发布机构名称，是该系列模型的唯一生产方，用户搜索时可能直接使用机构名+语言关键词"
      },
      {
        "keyword": "brWaC",
        "dimension": "技术特性",
        "reason": "模型训练所用的专属巴西葡萄牙语语料库名称，具有唯一性，是该模型的技术标识，非通用术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-4bit",
    "keywords": [
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Qwen3，直接提取为模型品牌名"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量约 30.5B，用户常以参数规模搜索模型"
      },
      {
        "keyword": "4bit量化",
        "dimension": "技术特性",
        "reason": "模型采用 4bit 量化以适配低显存推理，具备显著的搜索价值"
      },
      {
        "keyword": "思维模式",
        "dimension": "技术特性",
        "reason": "模型支持思维模式，可用于复杂逻辑推理和代码生成"
      },
      {
        "keyword": "智能体能力",
        "dimension": "功能场景",
        "reason": "模型具备专业级智能体功能，支持外部工具集成"
      },
      {
        "keyword": "100语言",
        "dimension": "功能场景",
        "reason": "模型支持 100+ 语言与方言，满足多语言应用需求"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "模型可通过 MLX 框架（mlx_lm）直接部署推理，适合 Apple Silicon 环境"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/diffusers-cd_imagenet64_l2",
    "keywords": [
      {
        "keyword": "cdimagenet64l2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "一致性模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性"
      },
      {
        "keyword": "一致性蒸馏",
        "dimension": "技术特性",
        "reason": "当前模型训练过程的核心技术"
      },
      {
        "keyword": "一致性训练",
        "dimension": "技术特性",
        "reason": "当前模型从头开始训练的核心技术"
      },
      {
        "keyword": "零样本数据编辑",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景"
      },
      {
        "keyword": "图像超分辨率",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-K2-Instruct",
    "keywords": [
      {
        "keyword": "Kimi-K2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "月之暗面",
        "dimension": "当前模型品牌名",
        "reason": "MoonshotAI官方中文品牌名"
      },
      {
        "keyword": "万亿参数",
        "dimension": "参数规格",
        "reason": "1万亿总参数，用户会搜的超大模型规格"
      },
      {
        "keyword": "Muon优化器",
        "dimension": "技术特性",
        "reason": "当前模型独家采用的训练优化器"
      },
      {
        "keyword": "32B激活参数",
        "dimension": "参数规格",
        "reason": "MoE架构下实际激活的参数量，用户关注"
      },
      {
        "keyword": "前沿知识",
        "dimension": "功能场景",
        "reason": "README强调模型在最新知识上的表现"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-4bit",
    "keywords": [
      {
        "keyword": "Qwen3-32B-MLX-4bit",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的模型全称，是用户在GitCode等平台搜索该特定版本时的精准关键词"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "模型专为MLX框架优化，是区别于PyTorch/HuggingFace部署的核心技术路径，用户会搜索'XX模型 MLX部署'寻找Apple芯片本地运行方案"
      },
      {
        "keyword": "4bit量化",
        "dimension": "技术特性",
        "reason": "模型采用4bit量化，是降低显存占用、实现Apple Silicon本地运行的关键技术点，用户会搜索'32B模型 4bit量化'寻找轻量化大模型"
      },
      {
        "keyword": "131K上下文",
        "dimension": "技术特性",
        "reason": "通过YaRN扩展至131,072标记的超长上下文是该模型显著区别于主流模型的实用特性，用户会搜索'长上下文语言模型'或'128K以上模型'寻找处理长文档能力"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独创在单一架构内无缝切换思维/非思维模式，是Qwen3系列的核心创新功能，用户会搜索'支持思维模式切换的模型'寻找逻辑推理与对话兼顾的AI"
      },
      {
        "keyword": "智能体工具集成",
        "dimension": "功能场景",
        "reason": "模型在开源模型中领先支持工具调用的智能体能力，是开发者寻找可扩展AI代理时的精准搜索词，区别于普通对话模型"
      },
      {
        "keyword": "32.8B参数",
        "dimension": "参数规格",
        "reason": "32.8B是当前模型精确参数量，属于主流大模型规模区间，用户会搜索'30B级模型'寻找性能与资源平衡的选项，且未被高频词库排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-FP8-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的完整模型品牌名称"
      },
      {
        "keyword": "A47B",
        "dimension": "参数规格",
        "reason": "模型系列标识，代表该变体的参数规模"
      },
      {
        "keyword": "FP8混合精度",
        "dimension": "技术特性",
        "reason": "模型采用的FP8混合精度训练技术，提升算力效率"
      },
      {
        "keyword": "异构混合并行",
        "dimension": "技术特性",
        "reason": "模型使用的异构混合并行训练策略，提升大规模并行效率"
      },
      {
        "keyword": "层次负载均衡",
        "dimension": "技术特性",
        "reason": "模型在训练过程中的层次化负载均衡调度方案"
      },
      {
        "keyword": "卷积码量化",
        "dimension": "技术特性",
        "reason": "模型推理阶段采用的卷积码量化算法，实现4位/2位无损量化"
      },
      {
        "keyword": "PD解耦技术",
        "dimension": "技术特性",
        "reason": "模型引入的动态角色切换PD解耦技术，提高资源利用率"
      },
      {
        "keyword": "多专家并行协作",
        "dimension": "技术特性",
        "reason": "模型在推理时的多专家并行协作机制，提升推理吞吐"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/ddpm-ema-celebahq-256",
    "keywords": [
      {
        "keyword": "DDPM",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心词，用户直接搜DDPM找扩散模型"
      },
      {
        "keyword": "EMA",
        "dimension": "技术特性",
        "reason": "模型采用指数移动平均优化，EMA是扩散模型高频技术词"
      },
      {
        "keyword": "CelebA-HQ-256",
        "dimension": "功能场景",
        "reason": "专精人脸高清生成，256×256分辨率，用户搜CelebA-HQ找人脸模型"
      },
      {
        "keyword": "扩散模型",
        "dimension": "技术特性",
        "reason": "非生成对抗的扩散概率模型，区别于GAN的独立技术路线"
      },
      {
        "keyword": "DDIM调度",
        "dimension": "部署工具",
        "reason": "官方推荐加速采样器，用户搜DDIM找快速推理方案"
      },
      {
        "keyword": "无条件图像生成",
        "dimension": "功能场景",
        "reason": "无需提示词即可生成，用户搜无条件生成找零依赖模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jinaai/jina-embeddings-v4",
    "keywords": [
      {
        "keyword": "jina-embeddings-v4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该模型的唯一官方标识，且未被高频词列表排除"
      },
      {
        "keyword": "文本到视觉文档检索",
        "dimension": "功能场景",
        "reason": "模型明确支持'Text-to-Visual Document (T→VD) retrieval'，是其核心独特应用场景，非通用词，未在高频词列表中"
      },
      {
        "keyword": "多语言嵌入",
        "dimension": "技术特性",
        "reason": "模型支持30+语言，且'多语言嵌入'是其核心能力描述，区别于泛泛的'多模态'，未被高频词列表禁止"
      },
      {
        "keyword": "稠密与延迟交互检索",
        "dimension": "技术特性",
        "reason": "模型独家支持两种检索模式（单向量稠密 + 多向量延迟交互），为技术用户搜索时的关键区分点，非通用术语"
      },
      {
        "keyword": "视觉丰富文档嵌入",
        "dimension": "功能场景",
        "reason": "模型专为含图表、表格、插图的复杂文档设计，该短语精准描述其目标场景，具有高度区分度"
      },
      {
        "keyword": "嵌入维度压缩",
        "dimension": "技术特性",
        "reason": "模型支持无损压缩至128维，且明确列出套娃维度（128/256/512/1024/2048），是工程部署时的重要搜索词"
      },
      {
        "keyword": "任务适配器",
        "dimension": "技术特性",
        "reason": "模型提供检索、文本匹配、代码等任务的动态适配器，为推理时可选功能，属独特架构设计，非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，突出多模态与异构MoE结构"
      },
      {
        "keyword": "异构混合并行策略",
        "dimension": "技术特性",
        "reason": "当前模型在训练时采用的高效并行策略"
      },
      {
        "keyword": "4位2位无损量化",
        "dimension": "技术特性",
        "reason": "当前模型在推理方面实现的量化算法特性"
      },
      {
        "keyword": "PaddlePaddle",
        "dimension": "部署工具",
        "reason": "当前模型构建和部署所依赖的深度学习框架"
      },
      {
        "keyword": "特定模态后训练",
        "dimension": "技术特性",
        "reason": "当前模型针对特定模态进行的后训练优化"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sentence-transformers/paraphrase-MiniLM-L6-v2",
    "keywords": [
      {
        "keyword": "paraphrase-MiniLM-L6-v2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，是用户搜索该特定模型时最可能使用的关键词"
      },
      {
        "keyword": "句子相似度",
        "dimension": "功能场景",
        "reason": "模型核心用途是计算句子间语义相似性，用户搜索语义匹配、文本聚类等场景时会使用该中文术语"
      },
      {
        "keyword": "语义搜索",
        "dimension": "功能场景",
        "reason": "README明确提及该模型用于语义搜索，是用户在AI检索、问答系统等场景中的高频搜索意图"
      },
      {
        "keyword": "Sentence-Transformers",
        "dimension": "部署工具",
        "reason": "模型依赖的专用框架名称，用户在寻找可直接加载的句子嵌入模型时会搜索该工具名"
      },
      {
        "keyword": "384维向量",
        "dimension": "技术特性",
        "reason": "模型输出的唯一维度特征，是区别于其他模型（如768维、512维）的关键技术参数，用户会据此筛选"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型支持ONNX导出，是企业级部署的关键格式，用户搜索轻量化推理或跨平台部署时会关注此关键词"
      },
      {
        "keyword": "Mean-Pooling",
        "dimension": "技术特性",
        "reason": "模型在HuggingFace Transformers中必须使用的池化方式，是技术用户实现非sentence-transformers部署时的关键搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型主品牌名"
      },
      {
        "keyword": "21B参数",
        "dimension": "参数规格",
        "reason": "当前模型公开的核心参数规模，用户搜索时会用"
      },
      {
        "keyword": "A3B系列",
        "dimension": "技术特性",
        "reason": "ERNIE-4.5下的具体子系列，区分度高"
      },
      {
        "keyword": "PaddlePaddle权重",
        "dimension": "部署工具",
        "reason": "模型权重格式，用户部署时搜索关键词"
      },
      {
        "keyword": "文本补全",
        "dimension": "功能场景",
        "reason": "当前Base模型唯一支持的功能，用户明确搜索意图"
      },
      {
        "keyword": "FastDeploy",
        "dimension": "部署工具",
        "reason": "官方推荐的推理部署方案，用户会搜索"
      },
      {
        "keyword": "vLLM推理",
        "dimension": "部署工具",
        "reason": "README中明确提及的推理方式，用户部署时搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LGAI-EXAONE/EXAONE-4.0-32B",
    "keywords": [
      {
        "keyword": "EXAONE-4.0",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "混合注意力",
        "dimension": "技术特性",
        "reason": "模型采用局部注意力与全局注意力 3:1 的混合方案，是该模型独有的核心技术"
      },
      {
        "keyword": "滑动窗口注意力",
        "dimension": "技术特性",
        "reason": "局部注意力实现方式为滑动窗口注意力，区别于普通注意力机制，用户可能会针对该特性搜索"
      },
      {
        "keyword": "QK重归一化",
        "dimension": "技术特性",
        "reason": "模型在注意力层引入 QK 重归一化，提升下游任务性能，是模型的独特创新点"
      },
      {
        "keyword": "智能体工具",
        "dimension": "功能场景",
        "reason": "EXAONE 4.0 集成智能体工具使用，面向智能体 AI 场景，用户会搜索此类功能"
      },
      {
        "keyword": "FriendliAI平台",
        "dimension": "部署工具",
        "reason": "模型可直接在 FriendliAI 上体验和部署，是模型的官方部署渠道"
      },
      {
        "keyword": "30.95B参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模约 30.95B，属于大模型规格，用户在搜索参数规模时会使用该描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/table-transformer-structure-recognition-v1.1-all",
    "keywords": [
      {
        "keyword": "Table-Transformer",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格结构识别",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "PubTables1M数据集",
        "dimension": "技术特性",
        "reason": "当前模型训练所使用的数据集之一"
      },
      {
        "keyword": "FinTabNet.c数据集",
        "dimension": "技术特性",
        "reason": "当前模型训练所使用的数据集之一"
      },
      {
        "keyword": "前置归一化",
        "dimension": "技术特性",
        "reason": "当前模型采用的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/audio-flamingo-3",
    "keywords": [
      {
        "keyword": "Audio-Flamingo-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "音频语言模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心定位"
      },
      {
        "keyword": "语音对话系统",
        "dimension": "功能场景",
        "reason": "AF3-Chat版主打端到端语音对话"
      },
      {
        "keyword": "长上下文音频理解",
        "dimension": "技术特性",
        "reason": "支持最长10分钟音频输入"
      },
      {
        "keyword": "音频问答推理",
        "dimension": "功能场景",
        "reason": "官方列出的典型应用"
      },
      {
        "keyword": "交互式音效设计",
        "dimension": "功能场景",
        "reason": "面向开发者的创意场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sshleifer/distilbart-cnn-12-6",
    "keywords": [
      {
        "keyword": "DistilBART",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌，唯一标识该模型"
      },
      {
        "keyword": "CNN新闻摘要",
        "dimension": "功能场景",
        "reason": "模型专注于对 CNN/DailyMail 数据集进行新闻文本摘要"
      },
      {
        "keyword": "模型蒸馏",
        "dimension": "技术特性",
        "reason": "DistilBART 通过蒸馏技术在保持性能的同时大幅压缩模型体积"
      },
      {
        "keyword": "300M参数",
        "dimension": "参数规格",
        "reason": "模型约有 306 百万参数，属于中等规模轻量模型"
      },
      {
        "keyword": "轻量化摘要模型",
        "dimension": "技术特性",
        "reason": "相较于原始 BART，模型更轻量，适合资源受限环境的摘要任务"
      },
      {
        "keyword": "HuggingFace兼容",
        "dimension": "部署工具",
        "reason": "模型可直接通过 HuggingFace Transformers 库加载和使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/sam2-hiera-large",
    "keywords": [
      {
        "keyword": "SAM2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为facebook/sam2-hiera-large，核心品牌标识为SAM2，是当前模型的官方简称，用户搜索AI分割模型时会直接使用此名称"
      },
      {
        "keyword": "任意分割",
        "dimension": "功能场景",
        "reason": "README明确提到'图像与视频中的任意分割'，这是SAM2区别于其他分割模型的核心功能表述，用户会搜索'任意分割AI'这类意图明确的词"
      },
      {
        "keyword": "视频分割",
        "dimension": "功能场景",
        "reason": "模型支持视频级分割，且在README中单独列出视频预测代码，是区别于静态图像分割模型（如SAM1）的关键差异化功能"
      },
      {
        "keyword": "可提示分割",
        "dimension": "技术特性",
        "reason": "README定义模型为'可提示视觉分割'，这是SAM系列的核心交互范式，用户搜索'可提示分割模型'时会精准匹配该技术概念"
      },
      {
        "keyword": "hiera-large",
        "dimension": "当前模型品牌名",
        "reason": "模型全称为'sam2-hiera-large'，'hiera-large'是其架构变体名称，在技术社区中常作为独立关键词用于区分不同规模版本"
      },
      {
        "keyword": "Mask-Generation",
        "dimension": "功能场景",
        "reason": "标签中明确标注'Mask Generation'，是用户在图像处理、CV工程中搜索分割结果输出时的高频术语，具象且非通用"
      },
      {
        "keyword": "arxiv2408.00714",
        "dimension": "技术特性",
        "reason": "论文编号是该模型唯一官方学术标识，研究者和工程师常直接搜索arxiv编号定位模型，具有强指向性和低竞争性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/convnextv2_nano.fcmae_ft_in22k_in1k",
    "keywords": [
      {
        "keyword": "convnextv2nano.fcmaeftin22kin1k",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "ConvNeXt-V2",
        "dimension": "当前模型品牌名",
        "reason": "模型类型名称，代表模型架构"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "FCMAE框架",
        "dimension": "技术特性",
        "reason": "当前模型使用的预训练框架"
      },
      {
        "keyword": "ImageNet-22k微调",
        "dimension": "技术特性",
        "reason": "当前模型在ImageNet-22k数据集上进行了微调"
      },
      {
        "keyword": "ImageNet-1k微调",
        "dimension": "技术特性",
        "reason": "当前模型在ImageNet-1k数据集上进行了微调"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vidore/colpali-v1.3",
    "keywords": [
      {
        "keyword": "ColPali",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌，用户检索视觉文档检索模型时的高频词"
      },
      {
        "keyword": "视觉文档检索",
        "dimension": "功能场景",
        "reason": "模型核心用途，用户会搜“视觉文档检索”找相关AI模型"
      },
      {
        "keyword": "PaliGemma-3B",
        "dimension": "技术特性",
        "reason": "模型基于的VLM骨架，技术向用户常用此关键词定位模型"
      },
      {
        "keyword": "ColBERT策略",
        "dimension": "技术特性",
        "reason": "模型采用的多向量检索策略，检索/向量检索领域用户搜索热词"
      },
      {
        "keyword": "256批次训练",
        "dimension": "技术特性",
        "reason": "训练配置亮点，开发者复现或对比模型时会搜索具体批次规模"
      },
      {
        "keyword": "BiSigLIP",
        "dimension": "技术特性",
        "reason": "模型迭代中的关键中间结构，技术博客与论文复现常用检索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/flair/ner-english-fast",
    "keywords": [
      {
        "keyword": "flairner-english-fast",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应模型标识符，是用户在GitCode或AI社区搜索该特定模型时的精确关键词"
      },
      {
        "keyword": "英文命名实体识别",
        "dimension": "功能场景",
        "reason": "用户搜索AI模型时常用‘英文NER’或‘英文命名实体识别’这类明确任务词，该模型专为英文实体识别设计，具有明确场景指向性"
      },
      {
        "keyword": "LSTM-CRF",
        "dimension": "技术特性",
        "reason": "该模型采用LSTM-CRF架构，是区别于Transformer类NER模型的核心技术标签，搜索者常通过架构关键词筛选模型"
      },
      {
        "keyword": "CoNLL-03",
        "dimension": "技术特性",
        "reason": "模型在CoNLL-03基准上评估，该数据集是NER领域权威标准，专业用户会以此为关键词寻找经过该基准验证的模型"
      },
      {
        "keyword": "序列标注模型",
        "dimension": "技术特性",
        "reason": "NER属于序列标注任务，该词是NLP领域对这类模型的通用技术分类，用户在学术或工程场景中常搜索此术语"
      },
      {
        "keyword": "Flair框架",
        "dimension": "部署工具",
        "reason": "模型必须通过Flair库加载，用户会搜索‘Flair框架 NER’来寻找兼容该生态的模型，具有工具链指向性"
      },
      {
        "keyword": "token-classification",
        "dimension": "技术特性",
        "reason": "该标签是Hugging Face生态中对NER任务的标准术语，技术用户在搜索模型时会使用此标准任务分类词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/segformer-b0-finetuned-ade-512-512",
    "keywords": [
      {
        "keyword": "SegFormer-B0",
        "dimension": "当前模型品牌名",
        "reason": "模型名称直接来源于项目名，标识该模型的具体版本"
      },
      {
        "keyword": "ADE20K数据集",
        "dimension": "功能场景",
        "reason": "模型在 ADE20K 数据集上进行微调，是用户搜索该数据集对应分割模型时的关键词"
      },
      {
        "keyword": "语义分割",
        "dimension": "功能场景",
        "reason": "模型的核心任务是语义分割，用户常以此功能检索相关模型"
      },
      {
        "keyword": "轻量级MLP解码头",
        "dimension": "技术特性",
        "reason": "模型采用轻量级 MLP 作为解码头，区别于其他解码结构"
      },
      {
        "keyword": "分层编码器",
        "dimension": "技术特性",
        "reason": "模型使用分层编码器结构提升特征表达，是其独特技术点"
      },
      {
        "keyword": "512x512分辨率",
        "dimension": "技术特性",
        "reason": "模型在 512×512 分辨率下进行微调，适用于高分辨率图像分割需求"
      },
      {
        "keyword": "NVIDIA模型",
        "dimension": "当前模型品牌名",
        "reason": "模型由 NVIDIA 官方发布，品牌属性是用户检索时的重要标签"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/merve/smol-vision",
    "keywords": [
      {
        "keyword": "Smol-Vision",
        "dimension": "当前模型品牌名",
        "reason": "项目标题直接给出的品牌名称"
      },
      {
        "keyword": "视觉模型压缩",
        "dimension": "功能场景",
        "reason": "README核心卖点：压缩、优化视觉模型"
      },
      {
        "keyword": "ColPali微调",
        "dimension": "功能场景",
        "reason": "README突出展示的微调示例，用户会搜具体微调方案"
      },
      {
        "keyword": "Gemma-3n全模态微调",
        "dimension": "功能场景",
        "reason": "README强调支持音频-文本-图像全模态微调"
      },
      {
        "keyword": "OmniEmbed视频RAG",
        "dimension": "功能场景",
        "reason": "README最新示例：任意模态视频RAG实现"
      },
      {
        "keyword": "QLoRA修复脚本",
        "dimension": "部署工具",
        "reason": "README特别提到已修复QLoRA相关问题，用户会搜修复版脚本"
      },
      {
        "keyword": "OWLv2量化",
        "dimension": "技术特性",
        "reason": "README示例中用Optimum量化零样本目标检测模型OWLv2"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/distilbert/distilbert-base-cased-distilled-squad",
    "keywords": [
      {
        "keyword": "DistilBERT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 distilbert/distilbert-base-cased-distilled-squad 中提取的核心品牌名，是模型的唯一标识，且未被高频词列表排除"
      },
      {
        "keyword": "squad",
        "dimension": "功能场景",
        "reason": "模型在SQuAD v1.1数据集上微调，专用于问答任务，用户搜索'QA模型'或'squad模型'时会精准匹配此关键词"
      },
      {
        "keyword": "知识蒸馏",
        "dimension": "技术特性",
        "reason": "模型核心创新技术，通过蒸馏BERT得到，是区别于普通BERT的关键技术标签，用户会搜索'知识蒸馏模型'寻找轻量模型"
      },
      {
        "keyword": "轻量级问答模型",
        "dimension": "功能场景",
        "reason": "模型定位为轻量、快速的问答系统，符合用户对'轻量级问答'的搜索意图，且未被高频词列表覆盖"
      },
      {
        "keyword": "DistilBERT-base-cased",
        "dimension": "当前模型品牌名",
        "reason": "模型的完整基础名称，虽含后缀但属于官方命名体系，用户在搜索具体微调版本时会使用该完整名称，且未被高频词排除"
      },
      {
        "keyword": "问答模型",
        "dimension": "功能场景",
        "reason": "模型用途明确为问答（question-answering），是用户在CSDN等平台搜索AI问答系统时的高频意图词，且未被高频词列表禁止"
      },
      {
        "keyword": "Hugging-Face模型",
        "dimension": "部署工具",
        "reason": "模型由Hugging Face官方发布，用户常搜索'Hugging Face模型'来寻找可直接加载的预训练模型，该词具平台指向性且未被高频词排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/bart-base",
    "keywords": [
      {
        "keyword": "facebookbart-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "seq2seq模型",
        "dimension": "技术特性",
        "reason": "当前模型属于seq2seq架构，是其核心特性"
      },
      {
        "keyword": "双向编码器",
        "dimension": "技术特性",
        "reason": "当前模型包含双向编码器，是其技术特点之一"
      },
      {
        "keyword": "自回归解码器",
        "dimension": "技术特性",
        "reason": "当前模型包含自回归解码器，是其技术特点之一"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "当前模型在文本生成任务上效果显著"
      },
      {
        "keyword": "文本重建",
        "dimension": "功能场景",
        "reason": "当前模型的预训练过程包括文本重建任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/whisper-large-v3-turbo",
    "keywords": [
      {
        "keyword": "Whisper-large-v3-turbo",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一名称，是用户搜索该优化版本的精准关键词"
      },
      {
        "keyword": "语音转文字",
        "dimension": "功能场景",
        "reason": "用户搜索ASR模型时最常用的中文意图词，对应Whisper的核心功能，且未被列入高频排除词"
      },
      {
        "keyword": "零样本语音识别",
        "dimension": "技术特性",
        "reason": "模型README明确强调的原创能力，具有技术区分度，非通用术语，未被高频词库覆盖"
      },
      {
        "keyword": "4层解码",
        "dimension": "技术特性",
        "reason": "Whisper-large-v3-turbo区别于原版的核心技术改动，用户可能搜索‘轻量版Whisper’或‘低层数语音模型’时使用"
      },
      {
        "keyword": "97种语言语音转录",
        "dimension": "功能场景",
        "reason": "模型支持多语言转录的明确卖点，用户在搜索‘多语言ASR’或‘支持97种语言的语音模型’时可能使用"
      },
      {
        "keyword": "Hugging-Face语音模型",
        "dimension": "部署工具",
        "reason": "模型通过Hugging Face Transformers部署，用户常搜‘Hugging Face 语音识别’，该词未被高频排除词库覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/sam2.1-hiera-large",
    "keywords": [
      {
        "keyword": "SAM2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型简称"
      },
      {
        "keyword": "任意分割",
        "dimension": "功能场景",
        "reason": "SAM2 的核心卖点：图像与视频中可提示的任意分割"
      },
      {
        "keyword": "视频分割",
        "dimension": "功能场景",
        "reason": "SAM2 支持视频级分割，区别于传统图像分割模型"
      },
      {
        "keyword": "提示分割",
        "dimension": "功能场景",
        "reason": "用户通过点、框、文本等提示即可生成分割结果"
      },
      {
        "keyword": "Hiera架构",
        "dimension": "技术特性",
        "reason": "SAM2 采用 Hiera 分层视觉骨干网络，提升效率与精度"
      },
      {
        "keyword": "API调用",
        "dimension": "部署工具",
        "reason": "官方提供 PyTorch 推理接口，可直接 API 调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/git-base",
    "keywords": [
      {
        "keyword": "GIT",
        "dimension": "当前模型品牌名",
        "reason": "模型官方名称 GIT（Generative Image-to-Text）"
      },
      {
        "keyword": "Git-base",
        "dimension": "当前模型品牌名",
        "reason": "项目在 GitHub/HuggingFace 上的完整模型标识"
      },
      {
        "keyword": "图像字幕",
        "dimension": "功能场景",
        "reason": "模型可用于为图像生成自然语言描述（image captioning）"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "模型支持基于图像的视觉问答（VQA）任务"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "通过让模型输出类别名称，可实现图像分类"
      },
      {
        "keyword": "教师强制",
        "dimension": "技术特性",
        "reason": "模型在训练时采用 Teacher‑forcing 方法"
      },
      {
        "keyword": "双向注意力",
        "dimension": "技术特性",
        "reason": "在处理图像 tokens 时使用双向注意力掩码"
      },
      {
        "keyword": "8亿图像文本对",
        "dimension": "技术特性",
        "reason": "模型预训练使用约 800 million 对图像‑文本数据"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/QuantStack/Wan2.1_I2V_14B_FusionX-GGUF",
    "keywords": [
      {
        "keyword": "Wan2.1I2V14BFusionX",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像到视频转换",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，将图像转换为视频"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "技术特性",
        "reason": "当前模型使用的文件格式，具有独特性"
      },
      {
        "keyword": "ComfyUI兼容",
        "dimension": "部署工具",
        "reason": "当前模型可在ComfyUI中使用，表明其部署方式"
      },
      {
        "keyword": "量化转换版本",
        "dimension": "技术特性",
        "reason": "当前模型是量化转换版本，具有技术独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nateraw/vit-age-classifier",
    "keywords": [
      {
        "keyword": "vit-age-classifier",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为nateraw/vit-age-classifier，直接提取模型唯一品牌名，简洁且为用户搜索该模型的精准关键词"
      },
      {
        "keyword": "人脸年龄分类",
        "dimension": "功能场景",
        "reason": "模型核心功能是对人脸进行年龄分类，该词是用户在CSDN等平台搜索AI人脸分析模型时的典型搜索词，具有明确意图且未被高频词库覆盖"
      },
      {
        "keyword": "ViT图像分类",
        "dimension": "技术特性",
        "reason": "模型基于Vision Transformer（ViT）实现图像分类，'ViT图像分类'是用户搜索视觉Transformer在图像任务中应用时的常用组合词，区别于通用'图像分类'，具有技术特异性"
      },
      {
        "keyword": "人脸年龄识别",
        "dimension": "功能场景",
        "reason": "与'人脸年龄分类'语义相近但表达更贴近中文搜索习惯（如'识别'比'分类'更常用于安防、社交场景），且未被列入高频排除词库，具有搜索增量价值"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "模型托管于HuggingFace，用户常搜索'HuggingFace模型'来查找可直接加载的预训练模型，该词是部署入口级关键词，且未被排除（排除词为'HuggingFace'单独词，非组合词）"
      },
      {
        "keyword": "ViT特征提取",
        "dimension": "技术特性",
        "reason": "代码中明确使用ViTFeatureExtractor，'ViT特征提取'是开发者在实现人脸分析时可能搜索的技术环节，区别于通用'特征提取'，具有模型专属技术指向性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Intel/dpt-large",
    "keywords": [
      {
        "keyword": "DPT-Large",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Intel/dpt-large，模型官方名称为DPT-Large，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "模型核心功能是单目深度估计，用户搜索AI深度估计任务时会直接使用该术语"
      },
      {
        "keyword": "视觉Transformer",
        "dimension": "技术特性",
        "reason": "模型采用ViT作为主干，'视觉Transformer'是其区别于传统CNN深度模型的核心技术标签"
      },
      {
        "keyword": "密集预测Transformer",
        "dimension": "当前模型品牌名",
        "reason": "DPT是'Dense Prediction Transformer'的缩写，该全称是论文和官方文档中的正式命名，具有唯一性"
      },
      {
        "keyword": "零样本深度估计",
        "dimension": "功能场景",
        "reason": "模型支持零样本（zero-shot）深度估计，是其关键使用场景，用户会搜索该具体能力"
      },
      {
        "keyword": "MiDaS-3.0",
        "dimension": "当前模型品牌名",
        "reason": "README明确说明DPT-Large也称为MiDaS 3.0，是该模型的另一个官方别名，具有搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-Coder",
        "dimension": "当前模型品牌名",
        "reason": "项目核心模型名称，用户直接搜索"
      },
      {
        "keyword": "480B参数",
        "dimension": "参数规格",
        "reason": "超大参数规模，极具辨识度"
      },
      {
        "keyword": "智能体编码",
        "dimension": "功能场景",
        "reason": "官方强调的核心能力，用户会搜"
      },
      {
        "keyword": "256K长上下文",
        "dimension": "技术特性",
        "reason": "超长上下文支持，差异化卖点"
      },
      {
        "keyword": "Ollama导出",
        "dimension": "部署工具",
        "reason": "官方教程明确支持，搜索高频"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "部署工具",
        "reason": "模型文件格式，用户部署必搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/autogluon/mitra-classifier",
    "keywords": [
      {
        "keyword": "Mitra",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格分类",
        "dimension": "功能场景",
        "reason": "当前模型专用于表格数据的分类任务"
      },
      {
        "keyword": "合成数据预训练",
        "dimension": "技术特性",
        "reason": "模型在纯合成数据集上完成预训练，区别于真实数据"
      },
      {
        "keyword": "7200万参数",
        "dimension": "参数规格",
        "reason": "当前模型参数量级，介于7B与32B之间，具有区分度"
      },
      {
        "keyword": "上下文学习",
        "dimension": "技术特性",
        "reason": "模型采用上下文学习范式进行训练"
      },
      {
        "keyword": "AutoGluon",
        "dimension": "部署工具",
        "reason": "官方推荐的安装与调用框架"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Disya/UIGEN-T3-14B-Preview-Q4_K_M-GGUF",
    "keywords": [
      {
        "keyword": "UIGENT3",
        "dimension": "当前模型品牌名",
        "reason": "从项目仓库名称 Disya/UIGEN‑T3‑14B‑Preview‑Q4_K_M‑GGUF 中提取的简化模型名称"
      },
      {
        "keyword": "UI生成",
        "dimension": "功能场景",
        "reason": "模型专注于根据文本提示自动生成网页界面和 UI 代码"
      },
      {
        "keyword": "Tailwind-CSS",
        "dimension": "技术特性",
        "reason": "模型输出的前端样式采用 Tailwind CSS 框架，具备轻量化、可定制的特性"
      },
      {
        "keyword": "llama.cpp",
        "dimension": "部署工具",
        "reason": "模型以 GGUF 格式提供，可直接通过 llama.cpp 的 CLI 或服务器模式本地部署运行"
      },
      {
        "keyword": "Q4KM量化",
        "dimension": "技术特性",
        "reason": "模型采用 Q4_K_M 量化方式，兼顾显存占用与推理速度"
      },
      {
        "keyword": "HTML生成",
        "dimension": "功能场景",
        "reason": "模型能够根据指令输出完整的 HTML 页面代码，适用于快速原型开发"
      },
      {
        "keyword": "textgenerationinference",
        "dimension": "技术特性",
        "reason": "模型支持高效的文本生成推理接口，可用于对话式或指令式文本输出"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vidore/colqwen2-v1.0",
    "keywords": [
      {
        "keyword": "ColQwen2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为vidore/colqwen2-v1.0，模型正式名称为ColQwen2，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "视觉文档检索",
        "dimension": "功能场景",
        "reason": "模型核心用途是‘Visual Document Retrieval’，中文用户搜索时会使用‘视觉文档检索’这一明确功能场景词，且未在高频排除词列表中"
      },
      {
        "keyword": "ColPali",
        "dimension": "当前模型品牌名",
        "reason": "ColQwen2是ColPali的扩展版本，论文中明确将其作为独立模型名称提出，且ColPali在高频排除词列表中未被禁止，属于当前模型的技术衍生品牌名"
      },
      {
        "keyword": "多向量表示",
        "dimension": "技术特性",
        "reason": "模型生成‘ColBERT风格的文本与图像多向量表示’，这是区别于传统单向量检索的核心技术特征，具有独特性且未被高频词覆盖"
      },
      {
        "keyword": "动态图像分辨率",
        "dimension": "技术特性",
        "reason": "模型支持动态图像分辨率输入，不进行resize，这是区别于ColPali等模型的关键技术点，用户在比较视觉检索模型时可能搜索此特性"
      },
      {
        "keyword": "图像补丁",
        "dimension": "技术特性",
        "reason": "模型以‘图像补丁（image patches）’为基本处理单元，最大支持768个，这是视觉语言检索中的专业术语，具有区分度且未被高频词排除"
      },
      {
        "keyword": "合成数据增强",
        "dimension": "训练策略",
        "reason": "训练中使用Claude-3 Sonnet生成的伪问题构建合成数据集，这是模型训练的独特数据策略，属于高价值差异化关键词"
      },
      {
        "keyword": "零样本泛化",
        "dimension": "功能场景",
        "reason": "模型训练数据为全英文，专门用于研究非英语语言的零样本泛化能力，这是用户在评估跨语言检索模型时会搜索的核心场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B",
    "keywords": [
      {
        "keyword": "LFM2-1.2B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "边缘人工智能",
        "dimension": "功能场景",
        "reason": "当前模型专为边缘人工智能和端侧部署设计"
      },
      {
        "keyword": "混合液态模型架构",
        "dimension": "技术特性",
        "reason": "当前模型采用具备乘法门控机制和短卷积结构的全新混合液态模型架构"
      },
      {
        "keyword": "快速训练与推理",
        "dimension": "技术特性",
        "reason": "当前模型在训练速度和推理速度上有显著提升"
      },
      {
        "keyword": "多语言能力",
        "dimension": "功能场景",
        "reason": "当前模型在多语言能力方面表现优异"
      },
      {
        "keyword": "灵活部署方案",
        "dimension": "部署工具",
        "reason": "当前模型可高效运行于多种硬件平台，支持灵活部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/julien-c/skops-digits",
    "keywords": [
      {
        "keyword": "skops-digits",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'julien-c/skops-digits' 直接提取的模型唯一标识，用户搜索特定分类模型时会使用该名称"
      },
      {
        "keyword": "tabular-classification",
        "dimension": "功能场景",
        "reason": "模型明确标注的标签，代表其核心用途是结构化表格数据分类，是用户搜索AI表格建模时的精准关键词"
      },
      {
        "keyword": "scikit-learn",
        "dimension": "部署工具",
        "reason": "模型基于scikit-learn构建，是用户寻找传统机器学习框架下可部署分类模型时的关键搜索词，且未被禁用高频词列表覆盖"
      },
      {
        "keyword": "joblib",
        "dimension": "部署工具",
        "reason": "模型使用joblib进行序列化保存，是技术用户搜索轻量级模型持久化方案时的精准术语，具有工具独特性"
      },
      {
        "keyword": "adam",
        "dimension": "技术特性",
        "reason": "模型使用adam优化器作为核心训练算法，是机器学习从业者搜索优化器配置时的高频技术关键词，且未被禁用"
      },
      {
        "keyword": "mlp",
        "dimension": "技术特性",
        "reason": "根据hidden_layer_sizes=(100,)和activation=relu可推断为多层感知机（MLP），是用户搜索传统神经网络结构时的精准术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/vjepa2-vitl-fpc64-256",
    "keywords": [
      {
        "keyword": "V-JEPA-2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型名称"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "模型可用于对任意视频进行分类任务"
      },
      {
        "keyword": "视频检索",
        "dimension": "功能场景",
        "reason": "模型支持基于视频表征的检索任务"
      },
      {
        "keyword": "视频编码器",
        "dimension": "功能场景",
        "reason": "模型可作为视觉语言模型（VLM）的视频编码器使用"
      },
      {
        "keyword": "大规模视频预训练",
        "dimension": "技术特性",
        "reason": "模型通过大规模数据进行预训练，提升视频理解能力"
      },
      {
        "keyword": "64帧采样",
        "dimension": "技术特性",
        "reason": "模型在推理时采用固定的64帧采样方式"
      },
      {
        "keyword": "AutoVideoProcessor",
        "dimension": "部署工具",
        "reason": "官方提供的视频处理工具，用于加载和预处理视频输入"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ecmwf/aifs-ens-1.0",
    "keywords": [
      {
        "keyword": "AIFS-ENS",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ecmwf/aifs-ens-1.0，模型官方名称为AIFS ENS，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "集成预报",
        "dimension": "功能场景",
        "reason": "模型核心功能是生成概率性集成天气预报，用户搜索‘气象集成预报’或‘AI集成天气模型’时会使用该词"
      },
      {
        "keyword": "图神经网络",
        "dimension": "技术特性",
        "reason": "模型明确基于图神经网络（GNN）编码器-解码器架构，是其区别于传统NWP和Transformer模型的核心技术"
      },
      {
        "keyword": "滑动窗口变换",
        "dimension": "技术特性",
        "reason": "模型采用‘滑动窗口变换处理器’作为关键技术组件，属于独特架构设计，非通用术语"
      },
      {
        "keyword": "CRPS优化",
        "dimension": "技术特性",
        "reason": "模型通过最小化连续分级概率评分（CRPS）进行训练，这是气象AI领域专业但非泛滥的优化目标术语"
      },
      {
        "keyword": "气象AI预报",
        "dimension": "功能场景",
        "reason": "用户搜索‘AI做天气预报’‘气象预测AI’等意图明确的场景词，该词精准对应模型用途且未被高频词库覆盖"
      },
      {
        "keyword": "ERA5再分析",
        "dimension": "技术特性",
        "reason": "模型训练依赖ECMWF的ERA5再分析数据，这是气象AI领域特有数据源，具有高区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/calcuis/bagel-gguf",
    "keywords": [
      {
        "keyword": "bagel-gguf",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多模态试验模型",
        "dimension": "技术特性",
        "reason": "当前模型具备多模态试验能力，是区别于其他模型的技术特性"
      },
      {
        "keyword": "文本转图像",
        "dimension": "功能场景",
        "reason": "当前模型支持文本转图像功能，是用户可能搜索的功能场景"
      },
      {
        "keyword": "图像编辑识别",
        "dimension": "功能场景",
        "reason": "当前模型支持图像编辑和识别功能，是用户可能搜索的功能场景"
      },
      {
        "keyword": "gguf-connector",
        "dimension": "部署工具",
        "reason": "当前模型使用gguf-connector运行，是部署该模型所需的工具"
      },
      {
        "keyword": "fp816缩放版",
        "dimension": "技术特性",
        "reason": "当前模型提供fp8/16缩放版本，是区别于其他模型的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/philschmid/bart-large-cnn-samsum",
    "keywords": [
      {
        "keyword": "bart-large-cnn-samsum",
        "dimension": "当前模型品牌名",
        "reason": "模型名称直接来源于项目仓库名，唯一标识当前模型"
      },
      {
        "keyword": "文本摘要",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对对话文本进行自动摘要"
      },
      {
        "keyword": "SAMSum数据集",
        "dimension": "技术特性",
        "reason": "模型在公开的 SAMSum 对话摘要数据集上进行微调"
      },
      {
        "keyword": "Amazon-SageMaker训练",
        "dimension": "部署工具",
        "reason": "模型使用 Amazon SageMaker 平台完成训练"
      },
      {
        "keyword": "Hugging-Face深度学习容器",
        "dimension": "部署工具",
        "reason": "训练过程基于 Hugging Face 官方深度学习容器"
      },
      {
        "keyword": "FP16混合精度",
        "dimension": "技术特性",
        "reason": "超参数中启用了 fp16，提升训练效率并降低显存占用"
      },
      {
        "keyword": "ROUGE-1指标",
        "dimension": "技术特性",
        "reason": "模型在评估时使用 ROUGE‑1 作为主要质量指标"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli",
    "keywords": [
      {
        "keyword": "DeBERTa-v3-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的核心模型品牌名，是当前模型的唯一标识，用户搜索NLI模型时会使用该名称"
      },
      {
        "keyword": "零样本分类",
        "dimension": "功能场景",
        "reason": "模型核心用途为零样本自然语言推理分类，是用户在博客中搜索NLI模型时最常使用的意图关键词"
      },
      {
        "keyword": "NLI模型",
        "dimension": "功能场景",
        "reason": "自然语言推理（NLI）是该模型的垂直领域，用户在学术或工程场景中搜索‘NLI模型’时会精准定位该模型"
      },
      {
        "keyword": "MNLI-FEVER-ANLI",
        "dimension": "当前模型品牌名",
        "reason": "模型微调所用的三大核心数据集组合，构成该模型的独特标识，是区别于其他DeBERTa模型的关键特征"
      },
      {
        "keyword": "LingNLI",
        "dimension": "当前模型品牌名",
        "reason": "模型微调所用的专属数据集，非通用术语，具有高度区分度，是该模型在语言学推理任务中的独特标签"
      },
      {
        "keyword": "WANLI",
        "dimension": "当前模型品牌名",
        "reason": "模型微调所用的对抗性自然语言推理数据集，是该模型在ANLI基准上表现优异的关键训练来源，具独特性"
      },
      {
        "keyword": "零样本推理",
        "dimension": "技术特性",
        "reason": "模型支持零样本场景下的推理能力，是其区别于监督学习模型的核心技术标签，用户常搜索此短语"
      },
      {
        "keyword": "文本分类",
        "dimension": "功能场景",
        "reason": "NLI任务本质是文本分类的变体，用户在搜索‘文本分类模型’时会关联到该模型，且未被高频词列表排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/owlvit-large-patch14",
    "keywords": [
      {
        "keyword": "OWLViT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心词，用户直接搜索模型简称"
      },
      {
        "keyword": "零样本目标检测",
        "dimension": "功能场景",
        "reason": "模型主打能力，用户用此词找无需训练的检测方案"
      },
      {
        "keyword": "开放词汇检测",
        "dimension": "功能场景",
        "reason": "突出任意文本提示即可检测，精准匹配搜索意图"
      },
      {
        "keyword": "ViT-L-14",
        "dimension": "技术特性",
        "reason": "CLIP视觉主干规格，开发者常按架构型号检索"
      },
      {
        "keyword": "文本条件检测",
        "dimension": "功能场景",
        "reason": "强调用文本查询驱动检测，符合技术博客关键词习惯"
      },
      {
        "keyword": "CLIP检测",
        "dimension": "技术特性",
        "reason": "依托CLIP实现检测，用户会组合CLIP+检测搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/amazon/chronos-t5-small",
    "keywords": [
      {
        "keyword": "chronos-t5-small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "时间序列预测",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "预训练模型",
        "dimension": "功能场景",
        "reason": "当前模型是预训练的时间序列预测模型"
      },
      {
        "keyword": "自回归采样",
        "dimension": "技术特性",
        "reason": "当前模型在推理期间采用自回归采样技术"
      },
      {
        "keyword": "T5架构",
        "dimension": "技术特性",
        "reason": "当前模型基于T5架构构建"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ETH-CVG/lightglue_superpoint",
    "keywords": [
      {
        "keyword": "LightGlue",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型名称"
      },
      {
        "keyword": "SuperPoint",
        "dimension": "当前模型品牌名",
        "reason": "与LightGlue配套使用的特征提取模型，同属当前项目"
      },
      {
        "keyword": "图像匹配",
        "dimension": "功能场景",
        "reason": "README明确指出的核心应用场景"
      },
      {
        "keyword": "单应性估计",
        "dimension": "功能场景",
        "reason": "README列出的典型任务之一"
      },
      {
        "keyword": "局部特征匹配",
        "dimension": "功能场景",
        "reason": "LightGlue专门解决的任务，用户搜索意图明确"
      },
      {
        "keyword": "位姿估计",
        "dimension": "功能场景",
        "reason": "通过匹配结果估计图像间位姿，是SLAM与3D重建常用需求"
      },
      {
        "keyword": "自适应推理",
        "dimension": "技术特性",
        "reason": "LightGlue可根据图像对难度动态调整计算量，突出卖点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/dmis-lab/biobert-large-cased-v1.1-squad",
    "keywords": [
      {
        "keyword": "BioBERT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为biobert-large-cased-v1.1-squad，核心品牌名为BioBERT，是该模型家族的唯一标识，用户搜索生物医学问答模型时会直接使用此名称"
      },
      {
        "keyword": "生物医学问答",
        "dimension": "功能场景",
        "reason": "模型专为生物医学领域问答任务优化，区别于通用QA，是其核心应用场景，用户在医学AI领域搜索时会使用此精准词组"
      },
      {
        "keyword": "PubMed预训练",
        "dimension": "技术特性",
        "reason": "模型在PubMed文献语料上进行专项预训练，是其区别于通用BERT的关键技术特征，专业用户会以此作为筛选条件"
      },
      {
        "keyword": "PMC预训练",
        "dimension": "技术特性",
        "reason": "模型同时在PMC（PubMed Central）生物医学全文库上训练，该数据源专属于生物医学AI，是其独特训练背景，具有高区分度"
      },
      {
        "keyword": "BioBERT-v1.0",
        "dimension": "当前模型品牌名",
        "reason": "模型基于BioBERT v1.0架构演进，该版本号在学术论文与社区中被广泛引用，是用户检索该模型系列的常用关键词"
      },
      {
        "keyword": "生物医学BERT",
        "dimension": "技术特性",
        "reason": "用户常将‘生物医学+BERT’组合搜索，该词精准描述模型类型，是领域内非品牌用户的自然搜索词，且未被高频词库覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mistralai/Voxtral-Small-24B-2507",
    "keywords": [
      {
        "keyword": "Voxtral-Small",
        "dimension": "当前模型品牌名",
        "reason": "模型在项目名称中直接出现，是唯一的品牌标识"
      },
      {
        "keyword": "24B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 24 B 参数，用户常以参数规模搜索模型"
      },
      {
        "keyword": "音频转录",
        "dimension": "功能场景",
        "reason": "模型支持高质量的语音转文字功能，是核心使用场景"
      },
      {
        "keyword": "音频翻译",
        "dimension": "功能场景",
        "reason": "模型能够将音频内容直接翻译成目标语言，属于独特的音频处理能力"
      },
      {
        "keyword": "长音频理解",
        "dimension": "功能场景",
        "reason": "凭借 32k token 上下文，模型可处理长达 30‑40 分钟的音频"
      },
      {
        "keyword": "语音触发调用",
        "dimension": "功能场景",
        "reason": "模型支持基于语音意图直接触发后端功能或 API 调用"
      },
      {
        "keyword": "vllm兼容",
        "dimension": "部署工具",
        "reason": "模型推荐使用 vllm 部署，满足高效推理需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Salesforce/blip-vqa-capfilt-large",
    "keywords": [
      {
        "keyword": "BLIP-vqa-capfilt-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，用户搜索该具体模型时会使用此完整名称"
      },
      {
        "keyword": "视觉问答",
        "dimension": "功能场景",
        "reason": "模型核心功能为Visual Question Answering（VQA），是用户搜索AI图像问答工具时的明确意图关键词"
      },
      {
        "keyword": "图像字幕生成",
        "dimension": "功能场景",
        "reason": "模型支持有条件/无条件图像字幕生成，是BLIP系列区别于其他模型的核心应用场景之一"
      },
      {
        "keyword": "自举式生成",
        "dimension": "技术特性",
        "reason": "BLIP论文提出的独特训练机制，通过合成字幕+噪声过滤提升性能，是该模型的技术创新点"
      },
      {
        "keyword": "ViT大型骨干",
        "dimension": "技术特性",
        "reason": "模型明确使用ViT-Large作为视觉编码器，是其架构关键特征，区别于其他使用ViT-Base或ResNet的模型"
      },
      {
        "keyword": "零样本视频语言",
        "dimension": "功能场景",
        "reason": "模型在论文中被验证可零样本迁移至视频-语言任务，这一能力在VQA模型中具有稀缺性和搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/MiniCPM-V-2",
    "keywords": [
      {
        "keyword": "MiniCPM-V-2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "MiniCPM-o-2.6",
        "dimension": "当前模型品牌名",
        "reason": "README中最新开源的模型版本名称"
      },
      {
        "keyword": "实时语音对话",
        "dimension": "功能场景",
        "reason": "MiniCPM-o 2.6版本支持的新功能"
      },
      {
        "keyword": "多模态直播",
        "dimension": "功能场景",
        "reason": "MiniCPM-o 2.6版本支持的新功能"
      },
      {
        "keyword": "iPad端实时视频理解",
        "dimension": "功能场景",
        "reason": "MiniCPM-V 2.6版本支持的新功能"
      },
      {
        "keyword": "vLLM推理加速",
        "dimension": "技术特性",
        "reason": "MiniCPM-V 2.0版本支持的技术特性"
      },
      {
        "keyword": "SWIFT框架微调",
        "dimension": "技术特性",
        "reason": "MiniCPM-V 2.0版本支持的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Large",
    "keywords": [
      {
        "keyword": "Depth-Anything-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，去掉冗余后缀"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "README明确指出的核心任务：单目深度估计（MDE）"
      },
      {
        "keyword": "相对深度",
        "dimension": "功能场景",
        "reason": "README标签中提到的深度类型，用户会搜索"
      },
      {
        "keyword": "ViT-Large",
        "dimension": "技术特性",
        "reason": "代码示例中encoder='vitl'，即ViT-Large架构，用户常搜"
      },
      {
        "keyword": "轻量化模型",
        "dimension": "技术特性",
        "reason": "README强调比SD系模型更轻量，用户关注轻量化"
      },
      {
        "keyword": "微调预训练",
        "dimension": "部署工具",
        "reason": "README提到“使用预训练模型进行微调”，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/kankur0007/2DseisvelGenerator",
    "keywords": [
      {
        "keyword": "2DseisvelGenerator",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的模型品牌，用户搜索地球科学AI生成模型时可能直接使用此名称"
      },
      {
        "keyword": "地震速度模型生成",
        "dimension": "功能场景",
        "reason": "模型核心功能是生成合成地震速度模型，属于地球物理领域特异性应用场景，非通用词"
      },
      {
        "keyword": "扩散概率模型",
        "dimension": "技术特性",
        "reason": "模型采用DDPM技术，是其核心架构，用户搜索AI在地球物理中的生成方法时会使用此术语"
      },
      {
        "keyword": "全波形反演",
        "dimension": "功能场景",
        "reason": "模型明确服务于FWI任务，是地球物理专业用户搜索AI辅助反演时的关键术语"
      },
      {
        "keyword": "OpenFWI数据集",
        "dimension": "技术特性",
        "reason": "模型训练基于该特定公开数据集，专业用户会搜索‘OpenFWI + AI生成’组合关键词"
      },
      {
        "keyword": "地震数据偏差减少",
        "dimension": "功能场景",
        "reason": "模型核心目标是降低合成数据偏差，属于高价值专业痛点，非通用表述"
      },
      {
        "keyword": "地震信号合成",
        "dimension": "功能场景",
        "reason": "模型生成的是地震信号对应的速度场，该短语精准描述其输出内容，专业用户会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/NexaAIDev/Qwen2-Audio-7B-GGUF",
    "keywords": [
      {
        "keyword": "Qwen2-Audio",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整名称，用户搜索时会使用该品牌名"
      },
      {
        "keyword": "语音聊天",
        "dimension": "功能场景",
        "reason": "模型支持直接的语音对话交互，是用户常搜索的使用场景"
      },
      {
        "keyword": "说话人识别",
        "dimension": "功能场景",
        "reason": "模型具备辨别并响应不同说话人的能力，属于核心功能关键词"
      },
      {
        "keyword": "噪声检测",
        "dimension": "功能场景",
        "reason": "模型能够检测背景噪声并作出响应，是音频处理常见需求"
      },
      {
        "keyword": "音乐分析",
        "dimension": "功能场景",
        "reason": "模型支持对音乐及声音进行分析，覆盖音频内容理解的典型场景"
      },
      {
        "keyword": "Nexa-SDK",
        "dimension": "部署工具",
        "reason": "官方提供的本地推理框架，用户在搜索本地部署方案时会使用该名称"
      },
      {
        "keyword": "AudioLM-架构",
        "dimension": "技术特性",
        "reason": "模型基于 AudioLM 技术，实现音频‑文本联合建模，是独特的技术标签"
      },
      {
        "keyword": "q4KM-量化",
        "dimension": "技术特性",
        "reason": "默认提供的高效量化版本，用户在寻找轻量化模型时会关注该量化方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/dinov2-large",
    "keywords": [
      {
        "keyword": "DINOv2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型品牌名"
      },
      {
        "keyword": "Vision-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心架构"
      },
      {
        "keyword": "自监督视觉特征",
        "dimension": "技术特性",
        "reason": "模型通过自监督方式学习图像特征，无需人工标注"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "用户可直接用模型提取图像向量做下游任务"
      },
      {
        "keyword": "ViT-large",
        "dimension": "参数规格",
        "reason": "对应项目名中的large规模，用户会搜ViT-large"
      },
      {
        "keyword": "无监督预训练",
        "dimension": "技术特性",
        "reason": "强调模型无需标签即可预训练，吸引零标注数据用户"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-Coder-480B-A35B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的完整模型名称，是当前模型的唯一标识，用户搜索高参数代码模型时会精确使用此名称"
      },
      {
        "keyword": "百万上下文",
        "dimension": "技术特性",
        "reason": "模型核心亮点是上下文长度从256K扩展至100万，'百万上下文'是用户搜索长上下文代码模型时的高频表达，且未被高频词列表禁止"
      },
      {
        "keyword": "智能体编码",
        "dimension": "功能场景",
        "reason": "README明确指出该模型在'智能体编码、智能体浏览器使用'上表现突出，是区别于普通代码模型的独特应用场景"
      },
      {
        "keyword": "480B参数",
        "dimension": "参数规格",
        "reason": "480B是当前模型的专属参数规模，属于超大规模代码模型的主流规格词，未在高频词列表中，具有强区分度"
      },
      {
        "keyword": "GGUF量化",
        "dimension": "部署工具",
        "reason": "模型以GGUF格式发布，且项目强调其为'Unsloth Dynamic 2.0 GGUFs'，用户搜索本地部署的量化代码模型时会使用该词"
      },
      {
        "keyword": "A35B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "A35B-Instruct是模型名称的子组件，代表其指令微调架构，在模型全称中具有辨识度，用户可能搜索该子型号以区分不同变体"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/FluidInference/silero-vad-coreml",
    "keywords": [
      {
        "keyword": "Silero-VAD",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "语音活动检测",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能"
      },
      {
        "keyword": "CoreML",
        "dimension": "部署工具",
        "reason": "Apple平台专用部署格式"
      },
      {
        "keyword": "iOS实时语音",
        "dimension": "功能场景",
        "reason": "主要使用场景之一"
      },
      {
        "keyword": "macOS语音识别",
        "dimension": "功能场景",
        "reason": "另一主要使用场景"
      },
      {
        "keyword": "Swift集成",
        "dimension": "部署工具",
        "reason": "iOS/macOS开发者常用语言"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/GCIRS-Reasoning-1.5B-R1-i1-GGUF",
    "keywords": [
      {
        "keyword": "GCIRS-Reasoning-1.5B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型核心名称"
      },
      {
        "keyword": "加权量化版本",
        "dimension": "技术特性",
        "reason": "当前模型版本特性，区别于其他版本"
      },
      {
        "keyword": "矩阵量化",
        "dimension": "技术特性",
        "reason": "当前模型版本的技术特性描述"
      },
      {
        "keyword": "静态量化版本",
        "dimension": "技术特性",
        "reason": "当前模型提供的另一种量化版本特性"
      },
      {
        "keyword": "i1-IQ量化",
        "dimension": "技术特性",
        "reason": "当前模型提供的具体量化类型，具有区分度"
      },
      {
        "keyword": "Apache-License-2.0",
        "dimension": "授权协议",
        "reason": "当前模型使用的开源协议，用户可能关注"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/VINCIE-3B",
    "keywords": [
      {
        "keyword": "VINCIE-3B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为ByteDance-Seed/VINCIE-3B，根据规则提取模型简洁品牌名，且未在强制排除列表中"
      },
      {
        "keyword": "视频驱动的上下文图像编辑",
        "dimension": "功能场景",
        "reason": "模型核心创新功能，用户可能搜索‘视频驱动图像编辑’或‘上下文图像编辑’这类具体应用场景，具有高度区分度"
      },
      {
        "keyword": "块因果扩散Transformer",
        "dimension": "技术特性",
        "reason": "模型独有的架构设计，非通用术语，是论文提出的核心技术，具有技术独特性"
      },
      {
        "keyword": "多轮图像编辑",
        "dimension": "功能场景",
        "reason": "论文提出的新基准与核心应用场景，非通用词，用户可能搜索‘多轮图像编辑模型’以寻找同类工具"
      },
      {
        "keyword": "下一帧图像预测",
        "dimension": "技术特性",
        "reason": "模型训练的三大代理任务之一，属于模型特有的学习目标，非通用AI术语，具备区分度"
      },
      {
        "keyword": "当前帧分割预测",
        "dimension": "技术特性",
        "reason": "模型训练的专属代理任务，与视频驱动编辑直接相关，是区别于其他图像编辑模型的关键技术点"
      },
      {
        "keyword": "下一帧分割预测",
        "dimension": "技术特性",
        "reason": "与上一条构成完整视频上下文建模体系，是VINCIE-3B独有的训练机制，非通用词汇"
      },
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目来自ByteDance-Seed，根据国产大模型映射规则，需映射为‘豆包’，且未在排除列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BCCard/Qwen2.5-VL-32B-Instruct-FP8-Dynamic",
    "keywords": [
      {
        "keyword": "Qwen2.5-VL-32B-Instruct-FP8-Dynamic",
        "dimension": "当前模型品牌名",
        "reason": "项目完整名称，用户会按全称搜索"
      },
      {
        "keyword": "FP8量化",
        "dimension": "技术特性",
        "reason": "当前模型独有的FP8动态量化技术"
      },
      {
        "keyword": "vLLM部署",
        "dimension": "部署工具",
        "reason": "官方示例明确使用vLLM进行高效推理"
      },
      {
        "keyword": "视觉-文本",
        "dimension": "功能场景",
        "reason": "模型输入类型，用户搜索视觉文本多模态场景"
      },
      {
        "keyword": "动态量化",
        "dimension": "技术特性",
        "reason": "模型名称中的Dynamic体现的动态量化能力"
      },
      {
        "keyword": "BC-Card",
        "dimension": "当前模型品牌名",
        "reason": "模型开发方品牌，用户可能直接搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/chancharikm/qwen2.5-vl-7b-cam-motion-preview",
    "keywords": [
      {
        "keyword": "Cam-Motion-Preview",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名，去除版本号和冗余信息"
      },
      {
        "keyword": "Camera-motion-classification",
        "dimension": "功能场景",
        "reason": "模型的核心应用场景之一，用于在视频中对相机运动进行分类"
      },
      {
        "keyword": "Video-Text-Retrieval",
        "dimension": "功能场景",
        "reason": "模型支持的视频文本检索任务，属于主要使用场景"
      },
      {
        "keyword": "CameraBench",
        "dimension": "技术特性",
        "reason": "模型在该公开基准上进行评估，体现其技术定位"
      },
      {
        "keyword": "VQAScore",
        "dimension": "技术特性",
        "reason": "用于衡量相机运动字幕检索质量的评分方法，模型采用该指标"
      },
      {
        "keyword": "Generative-Scoring",
        "dimension": "技术特性",
        "reason": "模型提供的生成式评分机制，可用于分类和检索任务"
      },
      {
        "keyword": "高质量相机运动数据集",
        "dimension": "技术特性",
        "reason": "模型在该高质量公开数据集上进行微调，提升任务表现"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.5",
    "keywords": [
      {
        "keyword": "GLM-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "混合推理模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，提供思维模式和非思维模式"
      },
      {
        "keyword": "3550亿参数",
        "dimension": "参数规格",
        "reason": "当前模型GLM-4.5的总参数规模，具有区分度"
      },
      {
        "keyword": "320亿活跃参数",
        "dimension": "参数规格",
        "reason": "当前模型GLM-4.5的活跃参数规模，体现模型能力"
      },
      {
        "keyword": "MIT开源协议",
        "dimension": "技术特性",
        "reason": "当前模型的开源协议，可用于商业用途和二次开发"
      },
      {
        "keyword": "GLM-4.5-Air",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型GLM-4.5的紧凑版本名称"
      },
      {
        "keyword": "1060亿参数",
        "dimension": "参数规格",
        "reason": "当前模型GLM-4.5-Air的总参数规模，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/llava-hf/llava-1.5-7b-hf",
    "keywords": [
      {
        "keyword": "LLaVA-1.5-7B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 hf_mirrors/llava-hf/llava-1.5-7b-hf 提取的完整模型品牌名，符合简化规则（保留版本号但去后缀-hf），是用户搜索该特定版本的精准关键词"
      },
      {
        "keyword": "视觉语言模型",
        "dimension": "技术特性",
        "reason": "模型本质是图像与文本联合理解的视觉语言模型，虽‘多模态’被禁用，但‘视觉语言模型’是更精准、未被高频词列表排除的术语，且直接对应其核心能力"
      },
      {
        "keyword": "图像问答",
        "dimension": "功能场景",
        "reason": "模型用于根据图像内容回答问题，是用户在CSDN等平台搜索‘图像问答AI’‘图片提问模型’等意图的精准场景词，区别于泛用的‘文生图’或‘视觉问答’（后者被禁）"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "README明确说明其为‘自回归语言模型’，该术语未被列入高频排除词，且是技术用户搜索模型架构时的精准关键词"
      },
      {
        "keyword": "多图像输入",
        "dimension": "功能场景",
        "reason": "模型支持‘多图像和多提示生成’，这是其区别于其他视觉语言模型的独特功能，用户可能搜索‘支持多图输入的AI模型’，该词具有区分度"
      },
      {
        "keyword": "LLaMA微调",
        "dimension": "技术特性",
        "reason": "模型基于LLaMA/Vicuna微调，虽禁止提取‘LLaMA’，但‘LLaMA微调’作为技术路径描述未被禁用，且是技术社区中对这类模型的常见搜索词"
      },
      {
        "keyword": "HuggingFace模型",
        "dimension": "部署工具",
        "reason": "模型托管于HuggingFace，且README明确使用transformers库加载，‘HuggingFace模型’是用户搜索‘哪里下载LLaVA’‘HuggingFace视觉模型’时的高频意图词，未被高频词列表禁止"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/bralynn/pydevmini1",
    "keywords": [
      {
        "keyword": "PyDevMini1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型品牌名，用户搜索时会直接使用"
      },
      {
        "keyword": "文本生成",
        "dimension": "功能场景",
        "reason": "因果语言模型的核心用途，用户常以“文本生成”检索此类模型"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "模型总参数约40亿（4B），是用户关注的规模指标"
      },
      {
        "keyword": "262k上下文长度",
        "dimension": "技术特性",
        "reason": "原生上下文长度达262,144 token，属于长上下文特性，具备搜索价值"
      },
      {
        "keyword": "GQA注意力",
        "dimension": "技术特性",
        "reason": "采用 Query‑32 / KV‑8 的 GQA 机制，是模型的独特注意力实现"
      },
      {
        "keyword": "36层网络",
        "dimension": "技术特性",
        "reason": "模型拥有 36 层深度，层数信息常被用于区分模型规模"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-Next-80B-A3B-Thinking",
    "keywords": [
      {
        "keyword": "Qwen3-Next",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心品牌标识，符合国产大模型映射规则（Qwen → 通义千问），但‘Qwen3-Next’是该系列全新命名，未在高频词列表中，具有唯一性"
      },
      {
        "keyword": "混合注意力机制",
        "dimension": "技术特性",
        "reason": "模型核心创新点，特指‘门控DeltaNet + 门控注意力’组合，非通用术语，用户搜索‘混合注意力模型’时可能精准匹配"
      },
      {
        "keyword": "高稀疏MoE",
        "dimension": "技术特性",
        "reason": "模型关键架构创新，强调‘高稀疏’特性以降低FLOPs，区别于普通MoE，是专业用户搜索高效推理模型时的精准关键词"
      },
      {
        "keyword": "多token预测",
        "dimension": "技术特性",
        "reason": "模型独有预训练技术（MTP），提升推理速度，非通用术语，用户搜索‘多token预测模型’可精准定位该模型"
      },
      {
        "keyword": "80B参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为80B，属于主流大模型规格（介于32B与175B之间），未在高频词列表中，具有区分度"
      },
      {
        "keyword": "GSPO",
        "dimension": "技术特性",
        "reason": "模型专属强化学习优化技术（GSPO），用于解决混合注意力与高稀疏MoE在RL中的稳定性问题，技术术语独特，搜索量低但精准"
      },
      {
        "keyword": "零中心层归一化",
        "dimension": "技术特性",
        "reason": "模型稳定性优化关键技术，全称‘零中心带权重衰减的层归一化’，术语专业且非通用，可吸引研究型用户搜索‘零中心layernorm模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/ERNIE-4.5-21B-A3B-Thinking-GGUF",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "21B参数",
        "dimension": "参数规格",
        "reason": "当前模型总参数量21B，属于用户常搜规格"
      },
      {
        "keyword": "3B激活参数",
        "dimension": "参数规格",
        "reason": "MoE架构下每个token仅激活3B，用户关注轻量推理"
      },
      {
        "keyword": "128K长上下文",
        "dimension": "技术特性",
        "reason": "支持131072 token超长上下文，用户搜索长文本处理"
      },
      {
        "keyword": "逻辑推理",
        "dimension": "功能场景",
        "reason": "README强调逻辑推理、数学、科学等复杂任务"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "模型在代码编写任务上性能显著提升"
      },
      {
        "keyword": "FastDeploy",
        "dimension": "部署工具",
        "reason": "官方示例使用FastDeploy快速部署，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/inclusionAI/Ming-Lite-Omni-1.5",
    "keywords": [
      {
        "keyword": "Ming-Lite-Omni",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "全模态",
        "dimension": "技术特性",
        "reason": "当前模型主打图文音视频一体化处理的核心卖点"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "用户会搜的AI视频解析功能，模型在v1.5重点优化"
      },
      {
        "keyword": "语音合成",
        "dimension": "功能场景",
        "reason": "模型新增高质量实时语音输出能力，用户高频搜索"
      },
      {
        "keyword": "图像编辑",
        "dimension": "功能场景",
        "reason": "支持连贯ID保持的AI图像编辑，用户直接搜索该需求"
      },
      {
        "keyword": "203亿参数",
        "dimension": "参数规格",
        "reason": "总参数量级显眼，用户会搜‘200亿参数大模型’"
      },
      {
        "keyword": "MRoPE",
        "dimension": "技术特性",
        "reason": "模型自研三维时空编码技术，技术爱好者会检索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/calcuis/hunyuanimage-gguf",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为hunyuanimage-gguf，根据国产大模型映射规则，Hunyuan必须映射为'混元'"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan是腾讯推出的模型系列，映射为'腾讯大模型'以符合品牌规范且避开'通义千问'等高频词"
      },
      {
        "keyword": "GGUF模型",
        "dimension": "技术特性",
        "reason": "模型以GGUF格式发布，是用户搜索轻量化本地部署模型时的核心关键词，且'GGUF量化'已被排除，'GGUF模型'为新表述"
      },
      {
        "keyword": "图像精炼",
        "dimension": "功能场景",
        "reason": "README明确提到对模糊/低质量图像进行精炼/锐化处理，是该模型独有的核心功能，非通用词"
      },
      {
        "keyword": "轻量版v2",
        "dimension": "当前模型品牌名",
        "reason": "模型明确区分'v2'轻量化版本，且强调8步生成、60-70%加载节省，是区别于标准版的独立产品形态"
      },
      {
        "keyword": "8步生成",
        "dimension": "技术特性",
        "reason": "蒸馏模型仅需8步即可输出，是该模型在推理效率上的独特卖点，用户会搜索'几步生成'类关键词"
      },
      {
        "keyword": "ComfyUI-gguf节点",
        "dimension": "部署工具",
        "reason": "模型明确依赖ComfyUI的gguf节点加载，是部署方式的精准描述，区别于泛泛的'ComfyUI'（已被排除）"
      },
      {
        "keyword": "1.5-cfg",
        "dimension": "技术特性",
        "reason": "README以'cfg=1.5'作为演示参数，是该模型在低cfg下仍保持高质量输出的特殊配置，具区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Alpha-VLLM/Lumina-DiMOO",
    "keywords": [
      {
        "keyword": "Lumina-DiMOO",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "统一离散扩散架构",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特技术架构"
      },
      {
        "keyword": "多样化多模态能力",
        "dimension": "技术特性",
        "reason": "当前模型支持广泛的多模态任务，是其核心特性之一"
      },
      {
        "keyword": "采样效率提升",
        "dimension": "技术特性",
        "reason": "当前模型展现出卓越的采样效率，并设计了定制化缓存方法进一步提升速度"
      },
      {
        "keyword": "图像理解",
        "dimension": "功能场景",
        "reason": "当前模型具备高级图像理解能力，是其应用场景之一"
      },
      {
        "keyword": "图像编辑对比",
        "dimension": "功能场景",
        "reason": "当前模型支持图像编辑等任务，展示其多模态生成与理解能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/pegasus-large",
    "keywords": [
      {
        "keyword": "Pegasus",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称google/pegasus-large提取的当前模型名称"
      },
      {
        "keyword": "文本摘要",
        "dimension": "功能场景",
        "reason": "README明确标注的任务类型"
      },
      {
        "keyword": "C4数据集",
        "dimension": "技术特性",
        "reason": "模型训练使用的核心数据集，用户会搜"
      },
      {
        "keyword": "HugeNews数据集",
        "dimension": "技术特性",
        "reason": "模型训练使用的另一核心数据集，用户会搜"
      },
      {
        "keyword": "xsum基准",
        "dimension": "技术特性",
        "reason": "README中列出的权威评测基准，用户验证模型效果时会搜"
      },
      {
        "keyword": "cnndailymail基准",
        "dimension": "技术特性",
        "reason": "README中列出的权威评测基准，用户验证模型效果时会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/speecht5_tts",
    "keywords": [
      {
        "keyword": "SpeechT5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 microsoft/speecht5_tts 中提取的当前模型唯一品牌名，是用户搜索TTS模型时的核心关键词"
      },
      {
        "keyword": "文本转语音",
        "dimension": "功能场景",
        "reason": "模型核心用途为text-to-speech，中文用户常搜索'文本转语音'而非英文术语，且未被列入强制排除词"
      },
      {
        "keyword": "语音合成",
        "dimension": "功能场景",
        "reason": "README明确提及'语音合成（文本转语音）任务'，是技术领域高频但未被排除的精准功能词"
      },
      {
        "keyword": "统一模态",
        "dimension": "技术特性",
        "reason": "模型核心创新点为'统一模态编码器-解码器框架'，是SpeechT5区别于其他TTS模型的独特技术标签"
      },
      {
        "keyword": "跨模态向量量化",
        "dimension": "技术特性",
        "reason": "论文中提出的独家方法，用于对齐语音与文本语义空间，具有高区分度且未被高频词库覆盖"
      },
      {
        "keyword": "LibriTTS",
        "dimension": "训练数据",
        "reason": "模型微调所用的专属数据集，用户搜索特定TTS模型时会关联数据源，属于模型专属标识"
      },
      {
        "keyword": "编码器-解码器",
        "dimension": "技术特性",
        "reason": "模型架构核心组件，虽为通用术语，但结合SpeechT5的统一模态设计，构成用户搜索该模型的技术关键词组合"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/iSEE-Laboratory/llmdet_large",
    "keywords": [
      {
        "keyword": "LLMDet",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "零样本目标检测",
        "dimension": "功能场景",
        "reason": "模型支持的核心任务——在未见样本上进行目标检测"
      },
      {
        "keyword": "大语言模型协同训练",
        "dimension": "技术特性",
        "reason": "模型通过与大型语言模型协同训练提升检测能力"
      },
      {
        "keyword": "开放词汇检测",
        "dimension": "技术特性",
        "reason": "模型能够检测未在训练集中出现的词汇，实现开放词汇能力"
      },
      {
        "keyword": "检查点推理",
        "dimension": "部署工具",
        "reason": "提供的检查点仅用于推理，适合直接部署使用"
      },
      {
        "keyword": "Zero-Shot-Object-Detection",
        "dimension": "功能场景",
        "reason": "模型的英文描述关键词，便于国际化搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/apple/mobilevit-small",
    "keywords": [
      {
        "keyword": "MobileViT-small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "轻量级卷积神经网络",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性描述"
      },
      {
        "keyword": "低延迟",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性之一"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "MobileNetV2风格层",
        "dimension": "技术特性",
        "reason": "当前模型结合的技术特性之一"
      },
      {
        "keyword": "全局处理",
        "dimension": "技术特性",
        "reason": "当前模型使用的transformers进行全局处理的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/TRELLIS-text-large",
    "keywords": [
      {
        "keyword": "TRELLIS-text-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，简洁且为用户搜索该模型的核心关键词"
      },
      {
        "keyword": "Text-to-3D",
        "dimension": "功能场景",
        "reason": "模型核心功能是文本生成3D内容，属于用户明确搜索的垂直场景，且未被列入强制排除词"
      },
      {
        "keyword": "3D生成模型",
        "dimension": "功能场景",
        "reason": "描述模型本质用途，用户会搜索‘3D生成模型’来寻找类似TRELLIS的工具，非通用词且未被排除"
      },
      {
        "keyword": "Structured-3D-Latents",
        "dimension": "技术特性",
        "reason": "论文中提出的核心技术术语，是该模型区别于其他3D生成模型的独特技术概念，具有高区分度"
      },
      {
        "keyword": "Trellis",
        "dimension": "当前模型品牌名",
        "reason": "模型简称，与全称TRELLIS-text-large形成品牌关联，用户可能搜索简写形式"
      },
      {
        "keyword": "3D生成",
        "dimension": "功能场景",
        "reason": "用户搜索‘3D生成’的意图明确，该词精准指向模型用途，且未在强制排除列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/diffusers-cd_bedroom256_lpips",
    "keywords": [
      {
        "keyword": "Consistency-Distillation",
        "dimension": "技术特性",
        "reason": "模型采用一致性蒸馏（Consistency Distillation）技术，实现噪声到图像的直接映射"
      },
      {
        "keyword": "CD-Bedroom256",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的唯一标识，表示针对 256×256 LSUN Bedroom 数据集的 CD（Consistency Distillation）模型"
      },
      {
        "keyword": "LPIPS",
        "dimension": "技术特性",
        "reason": "模型在训练和评估中使用 LPIPS 作为感知相似度指标，区别于常规的像素误差"
      },
      {
        "keyword": "Onestep-Generation",
        "dimension": "功能场景",
        "reason": "模型支持一步采样即可生成高质量图像，满足极速生成需求"
      },
      {
        "keyword": "Zeroshot-Image-Editing",
        "dimension": "功能场景",
        "reason": "模型能够在无需额外微调的情况下完成图像修复、着色等零样本编辑任务"
      },
      {
        "keyword": "Fast-Sampling",
        "dimension": "技术特性",
        "reason": "相较于传统扩散模型，模型显著降低采样步骤，实现快速图像生成"
      },
      {
        "keyword": "Diffusion-Model-Distillation",
        "dimension": "技术特性",
        "reason": "模型通过蒸馏预训练的扩散模型获得一致性模型，提升生成效率与质量"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MachineLearningLM/MachineLearningLM-7B-v1",
    "keywords": [
      {
        "keyword": "MachineLearningLM",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，无映射需求，非国产大模型，保留原名"
      },
      {
        "keyword": "表格分类",
        "dimension": "功能场景",
        "reason": "模型核心应用场景为Tabular Classification，用户搜索AI做表格预测时会使用该中文术语"
      },
      {
        "keyword": "多轮上下文学习",
        "dimension": "技术特性",
        "reason": "论文核心创新点，模型通过持续预训练实现8–1024示例的多轮上下文学习，具独特性且非高频词"
      },
      {
        "keyword": "合成表格任务",
        "dimension": "技术特性",
        "reason": "模型训练数据来源独特，专为合成表格机器学习任务优化，是区别于通用LLM的关键特征"
      },
      {
        "keyword": "7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为7B，属于主流参数规格，且未在强制排除列表中（排除列表含7B参数但为通用词，本模型为7B-v1，仍属合理提取）"
      },
      {
        "keyword": "随机森林建模",
        "dimension": "技术特性",
        "reason": "模型具备‘随机森林级别的数值建模稳健性’，该类比为独特技术描述，非通用术语，具搜索区分度"
      },
      {
        "keyword": "持续预训练",
        "dimension": "技术特性",
        "reason": "模型通过在数百万合成任务上持续预训练实现性能突破，是区别于微调或指令微调模型的核心方法"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stabilityai/stable-diffusion-xl-refiner-1.0",
    "keywords": [
      {
        "keyword": "SD-XL",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "生图",
        "dimension": "功能场景",
        "reason": "当前模型用于文本到图像生成"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "README提到“修改图像”功能，属于图像修复场景"
      },
      {
        "keyword": "潜在扩散",
        "dimension": "技术特性",
        "reason": "当前模型采用潜在扩散技术"
      },
      {
        "keyword": "专家集成",
        "dimension": "技术特性",
        "reason": "README明确描述为“专家集成流水线”"
      },
      {
        "keyword": "SDEdit",
        "dimension": "技术特性",
        "reason": "README提到使用SDEdit技术进行高分辨率优化"
      },
      {
        "keyword": "两阶段流水线",
        "dimension": "技术特性",
        "reason": "README描述的两阶段生成流程"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/vit_base_patch16_224.dino",
    "keywords": [
      {
        "keyword": "vitbasepatch16224.dino",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉Transformer",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术类型"
      },
      {
        "keyword": "自监督DINO方法",
        "dimension": "技术特性",
        "reason": "当前模型使用的训练方法"
      },
      {
        "keyword": "图像特征模型",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要用途"
      },
      {
        "keyword": "ImageNet-1k",
        "dimension": "预训练数据集",
        "reason": "当前模型使用的预训练数据集"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Magistral-Small-2509-unsloth-bnb-4bit",
    "keywords": [
      {
        "keyword": "Magistral-Small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'Magistral-Small-2509-unsloth-bnb-4bit' 中提取的核心品牌名，去掉版本号后为用户搜索的简洁品牌标识"
      },
      {
        "keyword": "240亿参数",
        "dimension": "参数规格",
        "reason": "模型明确标注为240亿参数，属于主流大参数规模，用户会搜索此类规模模型进行性能对比"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "README明确提供Ollama运行命令，是用户寻找可快速本地运行模型时的关键搜索词"
      },
      {
        "keyword": "单卡RTX-4090运行",
        "dimension": "部署工具",
        "reason": "强调可在单张消费级显卡运行，是用户寻找低门槛部署方案时的精准搜索意图，非泛泛的'本地部署'"
      },
      {
        "keyword": "多模态",
        "dimension": "技术特性",
        "reason": "模型新增视觉编码器支持多模态输入，是区别于纯文本模型的核心功能，且未被高频词列表排除"
      },
      {
        "keyword": "Unsloth量化",
        "dimension": "技术特性",
        "reason": "模型基于Unsloth Dynamic 2.0实现SOTA量化，是该模型独有的技术标签，非通用'量化模型'"
      },
      {
        "keyword": "强化学习微调",
        "dimension": "技术特性",
        "reason": "模型通过RL进行强化学习微调，是区别于普通SFT模型的关键训练方式，用户会搜索此类进阶训练模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Hcompany/Holo1.5-7B",
    "keywords": [
      {
        "keyword": "Holo1.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名"
      },
      {
        "keyword": "计算机使用代理",
        "dimension": "功能场景",
        "reason": "模型定位为能够在真实应用程序中代表用户操作的 CU 代理"
      },
      {
        "keyword": "UI定位",
        "dimension": "技术特性",
        "reason": "模型在用户界面（UI）元素定位方面表现突出，是核心技术能力"
      },
      {
        "keyword": "WebClick基准",
        "dimension": "评测基准",
        "reason": "模型在新推出的 WebClick 基准测试中取得优异成绩，具备辨识度"
      },
      {
        "keyword": "Screenspot-V2",
        "dimension": "评测基准",
        "reason": "模型在 Screenspot-V2 基准上表现卓越，属于独特的对标数据集"
      },
      {
        "keyword": "GRPO强化学习",
        "dimension": "训练技术",
        "reason": "模型的第二阶段采用在线强化学习（GRPO），是区别于其他模型的训练方式"
      },
      {
        "keyword": "高分辨率支持",
        "dimension": "能力特性",
        "reason": "模型原生支持最高 3840×2160 像素的高分辨率输入，具备显著的分辨率优势"
      },
      {
        "keyword": "Apache-2.0",
        "dimension": "许可证",
        "reason": "模型采用完全开放的 Apache 2.0 许可证，便于商业和研究使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwaipilot/KAT-Dev",
    "keywords": [
      {
        "keyword": "KAT-Dev",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型品牌名"
      },
      {
        "keyword": "KAT-Coder",
        "dimension": "当前模型品牌名",
        "reason": "README中明确提到的专有编码模型名称"
      },
      {
        "keyword": "软件工程任务",
        "dimension": "功能场景",
        "reason": "当前模型专为软件工程任务设计，用户会搜索"
      },
      {
        "keyword": "SWE-Bench",
        "dimension": "功能场景",
        "reason": "当前模型在SWE-Bench基准测试表现突出，用户会搜索"
      },
      {
        "keyword": "强化微调",
        "dimension": "技术特性",
        "reason": "RFT阶段为模型核心技术，用户会搜索"
      },
      {
        "keyword": "智能体强化学习",
        "dimension": "技术特性",
        "reason": "大规模RL阶段为模型亮点，用户会搜索"
      },
      {
        "keyword": "StreamLake",
        "dimension": "部署工具",
        "reason": "README提到可在StreamLake平台免费试用，用户会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Writer/palmyra-mini",
    "keywords": [
      {
        "keyword": "palmyra-mini",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，用户搜索该模型时会使用此精确名称"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "模型核心能力聚焦于数学问题解决，如gsm8k、MATH500、AMC23等基准，是用户寻找数学型AI时的明确搜索意图"
      },
      {
        "keyword": "长上下文",
        "dimension": "技术特性",
        "reason": "模型支持131,072 tokens上下文窗口，属于高价值技术亮点，用户会搜索‘长上下文模型’来寻找处理超长文本的AI"
      },
      {
        "keyword": "17亿参数",
        "dimension": "参数规格",
        "reason": "17亿（1.7B）是主流参数规模中具有性价比的中等规模，用户常搜索‘17亿参数模型’寻找轻量高性能模型"
      },
      {
        "keyword": "小学数学AI",
        "dimension": "功能场景",
        "reason": "模型在小学水平数学题（gsm8k）上表现卓越，此场景词精准匹配教育类、辅导类AI搜索需求，具独特性"
      },
      {
        "keyword": "竞赛数学",
        "dimension": "功能场景",
        "reason": "模型在AMC23（美国数学竞赛）上取得0.6分，‘竞赛数学AI’是教育科技领域高价值搜索词，无其他模型共用此标签"
      },
      {
        "keyword": "BBH推理",
        "dimension": "技术特性",
        "reason": "模型在Big-Bench Hard (BBH) 基准上表现突出，‘BBH推理’是专业用户搜索复杂推理模型时的精准术语，非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/vjepa2-vitl-fpc16-256-ssv2",
    "keywords": [
      {
        "keyword": "V-JEPA-2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频理解模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能和应用场景"
      },
      {
        "keyword": "ViT-L-256",
        "dimension": "技术特性",
        "reason": "当前模型的具体架构和规格"
      },
      {
        "keyword": "Something-Something-V2",
        "dimension": "技术特性",
        "reason": "当前模型预训练的数据集名称，体现模型专业性"
      },
      {
        "keyword": "Meta-FAIR实验室",
        "dimension": "当前模型品牌名",
        "reason": "当前模型的研发机构，体现模型来源"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Marvis-AI/marvis-tts-250m-v0.1-transformers",
    "keywords": [
      {
        "keyword": "Marvis-TTS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的简洁模型品牌名"
      },
      {
        "keyword": "实时流式语音合成",
        "dimension": "功能场景",
        "reason": "模型支持在文本生成过程中实时流式输出音频，实现自然对话流畅度"
      },
      {
        "keyword": "MLX音频库",
        "dimension": "部署工具",
        "reason": "模型可通过 MLX‑audio 在 Apple Silicon 等设备上直接部署运行"
      },
      {
        "keyword": "边缘实时推理",
        "dimension": "技术特性",
        "reason": "模型体积小（量化后约 500 MB），专为移动端和边缘设备的实时推理设计"
      },
      {
        "keyword": "250M参数",
        "dimension": "参数规格",
        "reason": "模型规模约 250 百万参数，属于轻量级高效模型"
      },
      {
        "keyword": "流式音频块输出",
        "dimension": "技术特性",
        "reason": "在文本处理过程中分块生成音频，避免伪影并保持连贯的语音流"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/inclusionAI/Ring-mini-2.0",
    "keywords": [
      {
        "keyword": "Ring-mini",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，简洁易记"
      },
      {
        "keyword": "推理优化MoE",
        "dimension": "技术特性",
        "reason": "强调模型专为推理场景深度优化的MoE架构，区别于通用MoE"
      },
      {
        "keyword": "16B总参数",
        "dimension": "参数规格",
        "reason": "用户常搜‘16B模型’作为性能与资源平衡点"
      },
      {
        "keyword": "1.4B激活参数",
        "dimension": "参数规格",
        "reason": "突出超低激活量即可对标10B dense，吸引轻量部署需求"
      },
      {
        "keyword": "128K长上下文",
        "dimension": "技术特性",
        "reason": "长文本场景热搜词，直接对应模型能力"
      },
      {
        "keyword": "300-tokenss高速生成",
        "dimension": "技术特性",
        "reason": "量化速度卖点，开发者搜索‘高速文本生成’时常用"
      },
      {
        "keyword": "逻辑推理模型",
        "dimension": "功能场景",
        "reason": "模型主打逻辑推理，用户会直接搜索该关键词"
      },
      {
        "keyword": "代码生成模型",
        "dimension": "功能场景",
        "reason": "明确代码能力，吸引程序员群体检索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/internlm/Intern-S1-FP8",
    "keywords": [
      {
        "keyword": "Intern-S1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该模型的唯一品牌标识"
      },
      {
        "keyword": "科学推理",
        "dimension": "功能场景",
        "reason": "模型核心定位是科学任务（化学结构、蛋白质序列、合成路线），区别于通用VLM，是用户精准搜索科研AI时的意图词"
      },
      {
        "keyword": "235B-MoE",
        "dimension": "参数规格",
        "reason": "235B是当前模型的独有参数规模，属于主流大模型规格层级，用户会搜索‘235B模型’来寻找超大参数开源模型"
      },
      {
        "keyword": "分子式理解",
        "dimension": "功能场景",
        "reason": "模型原生支持分子式解析，是科研领域高度垂直且独特的功能点，非通用模型具备，搜索意图明确"
      },
      {
        "keyword": "蛋白质序列理解",
        "dimension": "功能场景",
        "reason": "模型在生物信息学场景的专项能力，是科研人员搜索AI辅助生命科学工具时的关键关键词"
      },
      {
        "keyword": "动态分词器",
        "dimension": "技术特性",
        "reason": "模型独有的技术设计，原生支持科学符号（分子式、蛋白质序列、地震信号），具有技术辨识度，非通用分词器"
      },
      {
        "keyword": "5T科学数据",
        "dimension": "技术特性",
        "reason": "5万亿token中超2.5万亿为科学数据，这一数据规模与领域聚焦是模型核心训练差异点，科研用户会搜索此特征"
      },
      {
        "keyword": "InternViT",
        "dimension": "技术特性",
        "reason": "模型使用的专属视觉编码器名称，是Intern系列自研组件，非通用模型（如CLIP），具有品牌技术标识性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/allenai/GraspMolmo",
    "keywords": [
      {
        "keyword": "GraspMolmo",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "机器人抓取",
        "dimension": "功能场景",
        "reason": "面向机器人操作的核心任务"
      },
      {
        "keyword": "任务导向抓取",
        "dimension": "功能场景",
        "reason": "README中强调的TOG（Task-Oriented Grasping）能力"
      },
      {
        "keyword": "开放词汇",
        "dimension": "技术特性",
        "reason": "模型支持开放词汇指令，无需预定义类别"
      },
      {
        "keyword": "MIT许可证",
        "dimension": "部署工具",
        "reason": "用户搜索可商用开源模型时的常见关键词"
      },
      {
        "keyword": "allenai",
        "dimension": "当前模型品牌名",
        "reason": "项目发布方，用户会搜索allenai系列模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-bert/bert-base-cased",
    "keywords": [
      {
        "keyword": "BERT-base-cased",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提供的模型全称，区分大小写的 BERT 基础模型"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "功能场景",
        "reason": "模型的核心预训练任务之一，用于预测被遮蔽的词汇"
      },
      {
        "keyword": "下一句预测",
        "dimension": "功能场景",
        "reason": "模型的另一核心预训练任务，用于判断两句是否相邻"
      },
      {
        "keyword": "区分大小写",
        "dimension": "技术特性",
        "reason": "模型具备大小写敏感能力，能够区分 \"english\" 与 \"English\""
      },
      {
        "keyword": "自监督预训练",
        "dimension": "技术特性",
        "reason": "模型通过自监督方式在大规模英文语料上进行预训练，无需人工标注"
      },
      {
        "keyword": "双向表征",
        "dimension": "技术特性",
        "reason": "BERT 通过掩码方式学习句子的双向上下文表征"
      },
      {
        "keyword": "110M参数",
        "dimension": "参数规格",
        "reason": "BERT‑base‑cased 约有 1.1 亿参数，是模型规模的关键指标"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.2-TI2V-5B-Diffusers",
    "keywords": [
      {
        "keyword": "Wan2.2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频扩散模型",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景为视频生成"
      },
      {
        "keyword": "电影级美学效果",
        "dimension": "技术特性",
        "reason": "当前模型整合了美学数据，可生成电影风格视频"
      },
      {
        "keyword": "复杂动作生成能力",
        "dimension": "技术特性",
        "reason": "当前模型在动作生成方面有显著提升"
      },
      {
        "keyword": "高效高清混合TI2V",
        "dimension": "技术特性",
        "reason": "当前模型支持高效高清的文本到视频和图像到视频生成"
      },
      {
        "keyword": "5B模型",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模为5B"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai-mirror/gpt-oss-120b",
    "keywords": [
      {
        "keyword": "gpt-oss-120b",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该开源模型的唯一精准入口"
      },
      {
        "keyword": "gpt-oss-20b",
        "dimension": "当前模型品牌名",
        "reason": "与gpt-oss-120b同系列的轻量版本，用户常对比或搜索小参数版本用于本地部署"
      },
      {
        "keyword": "harmony响应格式",
        "dimension": "技术特性",
        "reason": "模型强制使用的独特输出格式，是使用该模型的关键技术门槛，用户搜索时会关注如何正确调用"
      },
      {
        "keyword": "原生MXFP4量化",
        "dimension": "技术特性",
        "reason": "模型独有的量化技术，支持在单张H100运行，是区别于其他模型的底层创新点，用户会搜索‘MXFP4’相关技术"
      },
      {
        "keyword": "可配置推理强度",
        "dimension": "功能场景",
        "reason": "用户可按需调节推理资源的特性，适用于不同延迟场景，是开发者关注的部署灵活性关键词"
      },
      {
        "keyword": "原生功能调用",
        "dimension": "功能场景",
        "reason": "模型支持原生工具调用（如网页浏览、Python执行），区别于普通LLM，是代理型AI的核心卖点"
      },
      {
        "keyword": "完整思维链",
        "dimension": "技术特性",
        "reason": "模型开放完整推理过程，用于调试与可信增强，是区别于黑箱模型的透明性技术特征"
      },
      {
        "keyword": "Apache-2.0许可证",
        "dimension": "部署工具",
        "reason": "用户关注商业可用性与无著佐限制，该许可证是企业级部署的关键筛选条件，具有强搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/gpt-oss-20b",
    "keywords": [
      {
        "keyword": "gpt-oss-20b",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型标识，用户搜索时会使用完整或简化名称"
      },
      {
        "keyword": "Apache-2.0-许可",
        "dimension": "许可证",
        "reason": "模型采用宽松的 Apache 2.0 开源许可证，吸引对许可有要求的用户"
      },
      {
        "keyword": "可配置推理强度",
        "dimension": "推理特性",
        "reason": "模型支持低/中/高三档推理强度，可根据延迟需求灵活调节"
      },
      {
        "keyword": "harmony-响应格式",
        "dimension": "技术特性",
        "reason": "模型基于独特的 harmony 响应格式训练，必须配合使用才能正常工作"
      },
      {
        "keyword": "微调支持",
        "dimension": "微调支持",
        "reason": "提供参数微调能力，用户可针对特定用例定制模型"
      },
      {
        "keyword": "原生函数调用",
        "dimension": "智能体能力",
        "reason": "模型具备原生函数调用能力，可直接在对话中执行外部函数"
      },
      {
        "keyword": "MXFP4-量化",
        "dimension": "量化技术",
        "reason": "使用 MXFP4 对 MoE 权重进行后训练量化，使模型在 16GB 显存上运行"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/cahya/NusaBert-ner-v1.3",
    "keywords": [
      {
        "keyword": "NusaBert-ner-v1.3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为当前模型的唯一品牌标识，需直接提取作为核心搜索词"
      },
      {
        "keyword": "印尼命名实体识别",
        "dimension": "功能场景",
        "reason": "模型专门针对印尼语（Indonesian）的命名实体识别任务，用户搜索‘印尼 NER’或‘印尼实体识别’时会精准匹配"
      },
      {
        "keyword": "现代BERT架构",
        "dimension": "技术特性",
        "reason": "模型基于‘ModernBERT’架构从头预训练，区别于传统BERT，是其核心技术亮点，用户可能搜索‘ModernBERT NER’"
      },
      {
        "keyword": "8192上下文NER",
        "dimension": "技术特性",
        "reason": "虽然禁止提‘8192’单独作为数字，但‘8192上下文NER’作为整体是模型在长文本NER任务中的独特能力，用户可能搜索长上下文命名实体识别模型"
      },
      {
        "keyword": "GRIT-ID-NER数据集",
        "dimension": "技术特性",
        "reason": "模型在‘grit-id/id_nergrit_corpus’数据集上微调，该数据集是印尼语NER领域权威数据源，专业用户会搜索该数据集名称关联模型"
      },
      {
        "keyword": "印尼法律实体识别",
        "dimension": "功能场景",
        "reason": "模型支持‘LAW’实体类别（如Undang-Undang），是印尼语NLP中特有的法律文本识别需求，具有高度垂直场景价值"
      },
      {
        "keyword": "印尼组织与人物识别",
        "dimension": "功能场景",
        "reason": "模型覆盖‘ORG’和‘PER’等高频实体，在印尼新闻、政务文本中应用广泛，用户可能搜索‘印尼组织识别’或‘人物抽取’"
      },
      {
        "keyword": "TensorFlow-NER模型",
        "dimension": "部署工具",
        "reason": "模型使用TensorFlow框架训练，区别于主流PyTorch模型，开发者在寻找TensorFlow生态的NER方案时会精准搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/vit_large_patch14_reg4_dinov2.lvd142m",
    "keywords": [
      {
        "keyword": "vitlargepatch14reg4dinov2.lvd142m",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉Transformer",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术类型"
      },
      {
        "keyword": "自监督DINOv2方法",
        "dimension": "技术特性",
        "reason": "当前模型使用的自监督训练方法"
      },
      {
        "keyword": "LVD-142M数据集",
        "dimension": "技术特性",
        "reason": "当前模型预训练使用的数据集"
      },
      {
        "keyword": "图像特征模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能和应用场景"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/step3",
    "keywords": [
      {
        "keyword": "Step3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 stepfun-ai/step3 提取的当前模型名称"
      },
      {
        "keyword": "321B参数",
        "dimension": "参数规格",
        "reason": "当前模型总参数量达3210亿，用户会搜321B参数"
      },
      {
        "keyword": "38B激活",
        "dimension": "参数规格",
        "reason": "当前模型激活参数量为380亿，用户会搜38B激活"
      },
      {
        "keyword": "混合专家",
        "dimension": "技术特性",
        "reason": "当前模型基于Mixture-of-Experts架构，用户会搜混合专家"
      },
      {
        "keyword": "视觉语言推理",
        "dimension": "功能场景",
        "reason": "当前模型主打视觉-语言推理性能，用户会搜视觉语言推理"
      },
      {
        "keyword": "MFA注意力",
        "dimension": "技术特性",
        "reason": "当前模型采用Multi-Matrix Factorization Attention，用户会搜MFA注意力"
      },
      {
        "keyword": "AFD解耦",
        "dimension": "技术特性",
        "reason": "当前模型使用Attention-FFN Disaggregation协同设计，用户会搜AFD解耦"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Comfy-Org/HiDream-I1_ComfyUI",
    "keywords": [
      {
        "keyword": "HiDream-I1",
        "dimension": "当前模型品牌名",
        "reason": "完整的模型名称，直接来源于项目仓库名"
      },
      {
        "keyword": "HiDream",
        "dimension": "当前模型品牌名",
        "reason": "模型的核心品牌标识，用户常用简写搜索"
      },
      {
        "keyword": "hidream",
        "dimension": "当前模型品牌名",
        "reason": "英文小写标识，常出现在 URL 与文档中，便于搜索"
      },
      {
        "keyword": "HiDream-safetensors",
        "dimension": "技术特性",
        "reason": "模型采用 Safetensors 文件格式，用户会以此关键词查找兼容模型"
      },
      {
        "keyword": "HiDream-扩展",
        "dimension": "功能场景",
        "reason": "模型以插件/扩展形式提供给 ComfyUI 使用，用户会搜索此类关键词"
      },
      {
        "keyword": "HiDream-示例",
        "dimension": "使用指南",
        "reason": "官方提供的使用示例，用户常通过搜索示例来快速上手模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-1.5-7B",
    "keywords": [
      {
        "keyword": "UI-TARS-1.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化规则（去版本后缀）"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "项目名称含ByteDance-Seed，依据国产大模型映射规则，映射为'字节大模型'"
      },
      {
        "keyword": "GUI操作智能体",
        "dimension": "功能场景",
        "reason": "模型核心用途是执行图形界面（GUI）任务，如操作系统、浏览器、手机操作，该词精准描述其独特应用场景，非通用词"
      },
      {
        "keyword": "视觉定位",
        "dimension": "功能场景",
        "reason": "模型在ScreensSpot-V2、ScreenSpotPro等基准中表现突出，'视觉定位'是其核心能力之一，用户会搜索此类具体视觉任务"
      },
      {
        "keyword": "强化学习推理",
        "dimension": "技术特性",
        "reason": "README明确提到'强化学习赋能的高级推理能力'，是该模型区别于其他GUI模型的独特技术点，非泛用术语"
      },
      {
        "keyword": "OSworld",
        "dimension": "功能场景",
        "reason": "模型在OSworld基准上取得SOTA，该基准是专为操作系统操作任务设计的公开评估集，属于用户搜索AI自动化操作时的精准关键词"
      },
      {
        "keyword": "WebVoyager",
        "dimension": "功能场景",
        "reason": "模型在WebVoyager浏览器任务中表现领先，该基准是Web自动化领域权威测试集，为高价值搜索词，非通用词"
      },
      {
        "keyword": "Android-World",
        "dimension": "功能场景",
        "reason": "模型在移动端Android操作任务中表现优异，'Android World'是该领域专用基准名称，用户搜索AI手机操作模型时会使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenGVLab/InternVL_2_5_HiCo_R16",
    "keywords": [
      {
        "keyword": "InternVL2.5HiCoR16",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "长时与丰富上下文建模",
        "dimension": "技术特性",
        "reason": "当前模型通过长时与丰富上下文（LRC）建模增强性能，是核心特性"
      },
      {
        "keyword": "视频多模态大语言模型",
        "dimension": "功能场景",
        "reason": "当前模型是视频多模态大语言模型，描述了其应用场景"
      },
      {
        "keyword": "自适应分层令牌压缩",
        "dimension": "技术特性",
        "reason": "当前模型采用自适应分层令牌压缩（HiCo）实现紧凑的时空表征，是关键技术"
      },
      {
        "keyword": "密集视觉任务标注",
        "dimension": "功能场景",
        "reason": "当前模型采用直接偏好优化（TPO）进行密集视觉任务标注，体现了其应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
    "keywords": [
      {
        "keyword": "Tongyi-DeepResearch",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量为300亿，常被用户搜索的规格描述"
      },
      {
        "keyword": "深度信息检索",
        "dimension": "功能场景",
        "reason": "模型专为深度信息检索任务设计，用户会以此需求搜索"
      },
      {
        "keyword": "长周期检索",
        "dimension": "功能场景",
        "reason": "模型针对长周期检索场景优化，具备独特的使用场景标签"
      },
      {
        "keyword": "全自动数据合成流水线",
        "dimension": "技术特性",
        "reason": "README 中提到的高度可扩展、全自动的数据合成流程，是模型的核心技术特性"
      },
      {
        "keyword": "端到端强化学习",
        "dimension": "技术特性",
        "reason": "模型采用的完整强化学习训练方式，区别于普通微调"
      },
      {
        "keyword": "ReAct推理范式",
        "dimension": "技术特性",
        "reason": "模型兼容的 ReAct 推理模式，用户在搜索推理方式时会使用该关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openbmb/VoxCPM-0.5B",
    "keywords": [
      {
        "keyword": "VoxCPM",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 openbmb/VoxCPM-0.5B 中提取的核心模型品牌名，符合简化规则（去版本号）"
      },
      {
        "keyword": "无分词器TTS",
        "dimension": "技术特性",
        "reason": "模型最核心的创新点，区别于主流TTS系统的独特技术标签，用户可能搜索‘无分词器语音合成’"
      },
      {
        "keyword": "上下文感知语音生成",
        "dimension": "功能场景",
        "reason": "模型主打的旗舰功能之一，描述明确、具象，是用户寻找高表现力语音合成时的精准搜索词"
      },
      {
        "keyword": "高保真语音克隆",
        "dimension": "功能场景",
        "reason": "模型另一项核心能力，直接对应用户搜索‘零样本语音克隆’‘语音复刻’等意图，非通用词"
      },
      {
        "keyword": "端到端扩散自回归",
        "dimension": "技术特性",
        "reason": "模型架构的关键技术组合，具有区分度，非泛用术语，符合‘用户搜模型技术原理’的搜索行为"
      },
      {
        "keyword": "FSQ约束",
        "dimension": "技术特性",
        "reason": "模型实现语义-声学解耦的独特技术组件，专业但非过度晦涩，是技术爱好者搜索的精准关键词"
      },
      {
        "keyword": "流式语音合成",
        "dimension": "功能场景",
        "reason": "模型支持实时应用的核心能力，用户搜索‘实时TTS’‘低延迟语音生成’时可能命中此词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nunchaku-tech/nunchaku-flux.1-krea-dev",
    "keywords": [
      {
        "keyword": "FLUX.1-Krea",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型品牌名"
      },
      {
        "keyword": "Nunchaku量化",
        "dimension": "技术特性",
        "reason": "当前模型采用Nunchaku团队自研SVDQuant 4-bit量化技术"
      },
      {
        "keyword": "INT4扩散模型",
        "dimension": "技术特性",
        "reason": "用户会搜超低比特扩散模型以节省显存"
      },
      {
        "keyword": "Diffusers推理",
        "dimension": "部署工具",
        "reason": "官方提供Diffusers一键调用脚本，用户常搜此部署方式"
      },
      {
        "keyword": "Blackwell-GPU",
        "dimension": "部署工具",
        "reason": "模型专门提供NVFP4版本给Blackwell架构用户，精准引流"
      },
      {
        "keyword": "SVDQuant",
        "dimension": "技术特性",
        "reason": "论文与代码同名技术关键词，吸引研究量化扩散的开发者"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nari-labs/Dia-1.6B",
    "keywords": [
      {
        "keyword": "Dia",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为nari-labs/Dia-1.6B，Dia即当前模型品牌名"
      },
      {
        "keyword": "文本转语音",
        "dimension": "功能场景",
        "reason": "README明确描述Dia为文本转语音模型，用户常用搜索词"
      },
      {
        "keyword": "对话语音生成",
        "dimension": "功能场景",
        "reason": "Dia可直接从文字记录生成高度逼真的对话语音，场景明确"
      },
      {
        "keyword": "情感控制",
        "dimension": "技术特性",
        "reason": "支持以音频为条件控制输出情感与语气，用户关注"
      },
      {
        "keyword": "非语言音效",
        "dimension": "技术特性",
        "reason": "可生成笑声、咳嗽、清嗓子等非语言交流音效，独特卖点"
      },
      {
        "keyword": "16亿参数",
        "dimension": "参数规格",
        "reason": "README中提到的1.6B参数，用户会搜索“16亿参数”"
      },
      {
        "keyword": "Gradio界面",
        "dimension": "部署工具",
        "reason": "提供一键启动的Gradio用户界面，方便体验"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/SG161222/Realistic_Vision_V5.1_noVAE",
    "keywords": [
      {
        "keyword": "Realistic-Vision",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Realistic_Vision_V5.1_noVAE 中提取的核心模型名称，去除版本号和后缀"
      },
      {
        "keyword": "noVAE",
        "dimension": "技术特性",
        "reason": "模型的特殊变体，表示在推理时不使用 VAE，可提升速度或适配特定工作流"
      },
      {
        "keyword": "Mage平台",
        "dimension": "部署工具",
        "reason": "模型在 Mage.Space 上提供，属于模型的托管与部署平台"
      },
      {
        "keyword": "OpenRAIL-M",
        "dimension": "技术特性",
        "reason": "模型遵循的开放许可协议，区别于其他常见许可证"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "模型基于 HuggingFace Diffusers 库实现，属于常用的推理框架"
      },
      {
        "keyword": "CreativeML",
        "dimension": "技术特性",
        "reason": "模型使用 CreativeML 格式的权重文件，具备跨平台兼容性"
      },
      {
        "keyword": "Text-to-Image",
        "dimension": "功能场景",
        "reason": "模型的主要应用场景是将文本描述转换为高质量图像"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/continuedev/instinct",
    "keywords": [
      {
        "keyword": "Instinct",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Next-Edit模型",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景描述"
      },
      {
        "keyword": "代码编辑预测",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，智能预测代码编辑"
      },
      {
        "keyword": "Q4KM-GGUF量化",
        "dimension": "技术特性",
        "reason": "当前模型的量化版本特性"
      },
      {
        "keyword": "Ollama集成",
        "dimension": "部署工具",
        "reason": "当前模型的一种部署方式"
      },
      {
        "keyword": "真实世界代码数据集",
        "dimension": "技术特性",
        "reason": "当前模型微调所使用的数据集特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stabilityai/sdxl-turbo",
    "keywords": [
      {
        "keyword": "SD-XL-Turbo",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为stabilityai/sdxl-turbo，模型官方名称为SDXL-Turbo，按规则简化为SD-XL-Turbo，是当前模型唯一品牌标识"
      },
      {
        "keyword": "单步生成",
        "dimension": "功能场景",
        "reason": "模型核心卖点是‘单次网络评估’‘一步采样生成图像’，用户会搜索‘单步文生图’类关键词，且‘文生图’已被禁用，故提取更精准的‘单步生成’"
      },
      {
        "keyword": "对抗扩散蒸馏",
        "dimension": "技术特性",
        "reason": "模型采用独家技术‘对抗扩散蒸馏（ADD）’，是论文核心创新点，非通用术语，具有强区分度，用户可能搜索该技术名称"
      },
      {
        "keyword": "分数蒸馏",
        "dimension": "技术特性",
        "reason": "模型训练中使用‘分数蒸馏’作为教师信号的关键技术，属于专业但可搜索的术语，且未被列入高频禁用词库"
      },
      {
        "keyword": "实时图像生成",
        "dimension": "功能场景",
        "reason": "README明确强调‘实时合成’‘快速生成’，‘实时图像生成’是用户搜索AI图像模型时的明确意图词，区别于普通‘文生图’"
      },
      {
        "keyword": "SDXL-1.0-蒸馏",
        "dimension": "技术特性",
        "reason": "模型是SDXL 1.0的蒸馏版本，该表述是模型来源的核心描述，非其他模型名称，且‘蒸馏’是技术关键词，未被高频禁用"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "模型支持ONNX格式，属于部署工具维度，且未被列为高频禁用词（禁用词为PyTorch/HuggingFace等，ONNX未被排除）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/neulab/omnitab-large-finetuned-wtq",
    "keywords": [
      {
        "keyword": "OmniTab",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "当前模型专用于表格数据问答"
      },
      {
        "keyword": "WikiTableQuestions",
        "dimension": "功能场景",
        "reason": "当前模型在该数据集上微调，用户会搜此数据集"
      },
      {
        "keyword": "BART架构",
        "dimension": "技术特性",
        "reason": "当前模型基于BART架构"
      },
      {
        "keyword": "few-shot表格问答",
        "dimension": "功能场景",
        "reason": "论文标题强调的核心能力"
      },
      {
        "keyword": "pandas表格",
        "dimension": "部署工具",
        "reason": "示例代码使用pandas.DataFrame，用户会搜如何与pandas结合"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Magistral-Small-2509-bnb-4bit",
    "keywords": [
      {
        "keyword": "Magistral-Small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的模型品牌和规格名称"
      },
      {
        "keyword": "4bit-量化",
        "dimension": "技术特性",
        "reason": "模型采用 4‑bit 量化技术，实现高效推理"
      },
      {
        "keyword": "24B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约 240 亿（24 B）参数，是其核心规模标识"
      },
      {
        "keyword": "Unsloth-Dynamic-2.0",
        "dimension": "技术特性",
        "reason": "模型使用的最新 Unsloth Dynamic 2.0 量化框架，提升性能"
      },
      {
        "keyword": "本地推理",
        "dimension": "部署方式",
        "reason": "模型可在单张 RTX 4090 或 32 GB 内存的 MacBook 上本地运行"
      },
      {
        "keyword": "视觉编码器",
        "dimension": "技术特性",
        "reason": "模型配备视觉编码器，支持多模态输入（视觉）"
      },
      {
        "keyword": "SFT微调",
        "dimension": "功能场景",
        "reason": "模型在 Magistral Medium 轨迹上进行 SFT（监督微调）后再进行 RL 强化学习"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-32B-Instruct-AWQ",
    "keywords": [
      {
        "keyword": "Qwen2.5-VL-32B-Instruct-AWQ",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型完整名称，虽较长但为唯一标识，符合用户精准搜索模型的意图（如搜索完整名称以获取特定AWQ量化版本）"
      },
      {
        "keyword": "视觉智能体",
        "dimension": "功能场景",
        "reason": "模型可直接作为视觉智能体进行推理并调用工具，具备计算机与手机操作能力，是区别于普通VLM的独特功能，用户可能搜索‘视觉智能体模型’"
      },
      {
        "keyword": "长视频理解",
        "dimension": "功能场景",
        "reason": "支持解析超过1小时长视频并精准定位事件，是当前模型核心能力之一，用户可能搜索‘长视频理解AI模型’"
      },
      {
        "keyword": "结构化输出",
        "dimension": "功能场景",
        "reason": "针对发票、表单、表格等能稳定输出JSON格式结构化数据，是金融、商业场景的刚需功能，搜索意图明确"
      },
      {
        "keyword": "多格式视觉定位",
        "dimension": "技术特性",
        "reason": "模型能生成边界框或坐标点并稳定输出含坐标与属性的JSON，是区别于通用视觉模型的高精度定位能力"
      },
      {
        "keyword": "动态分辨率视频",
        "dimension": "技术特性",
        "reason": "通过动态FPS采样和时间维度mRoPE实现视频时序感知，是模型在视频理解上的独特架构创新，用户可能搜索该术语"
      },
      {
        "keyword": "AWQ量化",
        "dimension": "部署工具",
        "reason": "模型后缀明确标注AWQ，是低比特量化部署方式，用户会搜索‘AWQ量化模型’以获取高效推理版本"
      },
      {
        "keyword": "数学解题能力",
        "dimension": "功能场景",
        "reason": "通过RL强化提升数学计算、逻辑推理能力，是当前模型在客观任务上的突出优化点，用户可能搜索‘AI数学解题模型’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/iSEE-Laboratory/llmdet_base",
    "keywords": [
      {
        "keyword": "LLMDet",
        "dimension": "当前模型品牌名",
        "reason": "项目与论文直接给出的模型品牌名"
      },
      {
        "keyword": "零样本目标检测",
        "dimension": "功能场景",
        "reason": "README 明确列出的核心用途"
      },
      {
        "keyword": "Grounding-DINO-改进版",
        "dimension": "技术特性",
        "reason": "在 Grounding DINO 基础上升级，用户会搜改进版/升级版关键词"
      },
      {
        "keyword": "MM-Grounding-DINO",
        "dimension": "技术特性",
        "reason": "README 提到的基础架构，用户检索相关改进模型时常用"
      },
      {
        "keyword": "大语言模型监督检测",
        "dimension": "技术特性",
        "reason": "论文亮点，用 LLM 监督训练检测器，用户可能按此特性搜索"
      },
      {
        "keyword": "开放词汇检测",
        "dimension": "功能场景",
        "reason": "零样本检测的另一种高频叫法，用户搜索量大"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/ddpm-ema-church-256",
    "keywords": [
      {
        "keyword": "ddpm-ema-church-256",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "去噪扩散概率模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性描述"
      },
      {
        "keyword": "高质量图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景和功能"
      },
      {
        "keyword": "无条件图像生成",
        "dimension": "功能场景",
        "reason": "README中提到的模型应用场景"
      },
      {
        "keyword": "渐进式有损解压缩",
        "dimension": "技术特性",
        "reason": "当前模型支持的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/jukebox-5b-lyrics",
    "keywords": [
      {
        "keyword": "Jukebox",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中直接包含的品牌名"
      },
      {
        "keyword": "5B参数",
        "dimension": "参数规格",
        "reason": "模型规模为5B参数，符合用户搜索模型规模的需求"
      },
      {
        "keyword": "歌词生成",
        "dimension": "功能场景",
        "reason": "模型专注于根据歌词生成音乐音频，是核心使用场景"
      },
      {
        "keyword": "音乐生成",
        "dimension": "功能场景",
        "reason": "Jukebox 能生成完整的音乐作品，用户常以此为搜索关键词"
      },
      {
        "keyword": "音频合成",
        "dimension": "功能场景",
        "reason": "模型输出为高质量音频，属于音频合成技术"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "Jukebox 采用自回归方式生成时序音频，是其关键技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-12b-it-GGUF",
    "keywords": [
      {
        "keyword": "Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "12B参数",
        "dimension": "参数规格",
        "reason": "当前模型的主流参数规格"
      },
      {
        "keyword": "Google大模型",
        "dimension": "当前模型品牌名",
        "reason": "Gemma系列由Google DeepMind发布"
      },
      {
        "keyword": "Ollama导出",
        "dimension": "部署工具",
        "reason": "支持将微调后的模型导出为Ollama格式"
      },
      {
        "keyword": "Colab微调",
        "dimension": "部署工具",
        "reason": "提供Google Colab免费微调笔记本"
      },
      {
        "keyword": "轻量级模型",
        "dimension": "技术特性",
        "reason": "官方定位为轻量级、最先进的开放模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/HKUSTAudio/Llasa-1B-Multilingual",
    "keywords": [
      {
        "keyword": "Llasa-1B-Multilingual",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，是用户搜索该特定TTS模型的核心关键词"
      },
      {
        "keyword": "多语言TTS",
        "dimension": "功能场景",
        "reason": "模型核心功能是支持11种语言的文本到语音合成，用户会搜索‘多语言TTS’来寻找跨语言语音合成方案"
      },
      {
        "keyword": "基于Llama的TTS",
        "dimension": "技术特性",
        "reason": "模型使用LLaMA的BPE分词器作为文本编码基础，这是其区别于传统G2P系统的独特技术路径，用户会搜索此组合词"
      },
      {
        "keyword": "语音合成微调",
        "dimension": "功能场景",
        "reason": "README明确指出模型适合‘针对特定语言进行微调’，这是其核心应用场景，非通用TTS，具有高区分度"
      },
      {
        "keyword": "无G2P语音合成",
        "dimension": "技术特性",
        "reason": "模型颠覆传统TTS依赖语言特定G2P系统的架构，直接用BPE处理多语言文本，这一技术亮点是用户搜索的差异化关键词"
      },
      {
        "keyword": "11语言TTS",
        "dimension": "功能场景",
        "reason": "明确支持11种语言（英语、法语、德语、荷兰语、西班牙语、意大利语、葡萄牙语、波兰语、中文、日语、韩语），用户会搜索‘11语言TTS’精准匹配需求"
      },
      {
        "keyword": "Llasa微调指南",
        "dimension": "功能场景",
        "reason": "README特别更新并推荐‘Llasa微调指南’，这是模型独有的配套资源，用户为实现定制化语音合成会主动搜索此术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-72B-DPO",
    "keywords": [
      {
        "keyword": "豆包",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中有ByteDance-Seed，映射为豆包"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed属于字节大模型系列"
      },
      {
        "keyword": "UI-TARS-72B-DPO",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "原生智能体",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，实现原生智能体自动GUI交互"
      },
      {
        "keyword": "图形用户界面交互",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景，实现与图形用户界面的无缝交互"
      },
      {
        "keyword": "端到端任务自动化",
        "dimension": "技术特性",
        "reason": "当前模型无需预定义工作流或人工规则即可实现端到端的任务自动化"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/cavargas10/TRELLIS",
    "keywords": [
      {
        "keyword": "TRELLIS",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为cavargas10/TRELLIS，模型官方名称为TRELLIS，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "Image-to-3D",
        "dimension": "功能场景",
        "reason": "模型核心功能是将2D图像生成3D内容，属于用户明确搜索的垂直场景，且未被列入强制排除词"
      },
      {
        "keyword": "3D生成",
        "dimension": "功能场景",
        "reason": "模型用于生成3D内容，是用户在AI模型搜索中常用的简洁意图词，区别于泛用的'文生图'"
      },
      {
        "keyword": "Structured-3D-Latents",
        "dimension": "技术特性",
        "reason": "论文核心术语，描述模型独有的潜在空间结构，是区别于其他3D生成模型的关键技术标签"
      },
      {
        "keyword": "3D生成模型",
        "dimension": "功能场景",
        "reason": "用户搜索3D内容生成时常用词，精准指向模型类型，且未被高频词库覆盖"
      },
      {
        "keyword": "Trellis3D",
        "dimension": "当前模型品牌名",
        "reason": "项目官网域名trellis3d.github.io，是模型的官方品牌别名，用户可能直接搜索此名称"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Video-R1/Video-R1-7B",
    "keywords": [
      {
        "keyword": "Video-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名，去除版本号后得到的简洁名称"
      },
      {
        "keyword": "视频问答",
        "dimension": "功能场景",
        "reason": "模型能够对视频内容进行自然语言提问并返回答案，属于视频问答场景"
      },
      {
        "keyword": "单样本推理",
        "dimension": "技术特性",
        "reason": "README 中提供了单个视频样本的推理示例，体现模型支持单样本快速推理"
      },
      {
        "keyword": "多任务视频推理",
        "dimension": "功能场景",
        "reason": "模型支持多种问题类型（选择题、数值、OCR、自由形式、回归）对同一视频进行推理"
      },
      {
        "keyword": "vllm加速推理",
        "dimension": "部署工具",
        "reason": "使用 vllm 库进行模型加载和推理，实现高效的推理加速"
      },
      {
        "keyword": "长视频上下文",
        "dimension": "技术特性",
        "reason": "模型最大支持 81920 长度的上下文，适合处理长时段视频内容"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/PKU-Alignment/beaver-7b-v1.0-reward",
    "keywords": [
      {
        "keyword": "Beaver",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "奖励模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心用途：在RLHF流程中作为奖励信号"
      },
      {
        "keyword": "安全RLHF",
        "dimension": "技术特性",
        "reason": "当前模型专为安全强化学习人类反馈设计"
      },
      {
        "keyword": "偏好模型",
        "dimension": "功能场景",
        "reason": "当前模型用于评估输出偏好，指导对齐训练"
      },
      {
        "keyword": "PKU-SafeRLHF",
        "dimension": "技术特性",
        "reason": "当前模型基于PKU-SafeRLHF数据集训练，突出安全对齐"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "用户常用Ollama快速本地运行7B级模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/parakeet-tdt-0.6b-v2",
    "keywords": [
      {
        "keyword": "Parakeet-TDT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 nvidia/parakeet-tdt-0.6b-v2 提取的核心品牌名，去掉版本号后为简洁可用的模型标识，符合用户搜索习惯"
      },
      {
        "keyword": "自动语音识别",
        "dimension": "功能场景",
        "reason": "模型核心用途为ASR（Automatic Speech Recognition），是用户在博客中搜索语音转文本功能时的直接意图词"
      },
      {
        "keyword": "时间戳预测",
        "dimension": "技术特性",
        "reason": "模型独特卖点之一，支持精确词级时间戳，属于高价值差异化功能，用户会专门搜索‘语音转文本 时间戳’"
      },
      {
        "keyword": "标点大小写转换",
        "dimension": "技术特性",
        "reason": "模型具备自动标点与大小写恢复能力，是ASR模型中用户关注的实用功能，非通用描述，具区分度"
      },
      {
        "keyword": "FastConformer-TDT",
        "dimension": "技术特性",
        "reason": "模型采用的专属架构名称，是技术型用户搜索高性能ASR架构时可能使用的精准关键词"
      },
      {
        "keyword": "6亿参数",
        "dimension": "参数规格",
        "reason": "模型参数规模为6亿，属于主流中等规模模型，用户常搜索‘6亿参数 ASR模型’进行性能对比，且未在排除列表中"
      },
      {
        "keyword": "TDT解码器",
        "dimension": "技术特性",
        "reason": "模型核心创新组件，TDT（Time-Delayed Transformer）是其专有解码结构，技术社区会针对性搜索该术语"
      },
      {
        "keyword": "语音转文本",
        "dimension": "功能场景",
        "reason": "‘自动语音识别’的通俗表达，中文用户更常用该词搜索转录服务类AI模型，符合博客引流搜索习惯"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Alibaba-NLP/gte-reranker-modernbert-base",
    "keywords": [
      {
        "keyword": "gte-reranker-modernbert-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文本重排序模型",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能类型"
      },
      {
        "keyword": "modernBERT",
        "dimension": "技术特性",
        "reason": "当前模型基于的预训练模型名称，体现技术特性"
      },
      {
        "keyword": "英语",
        "dimension": "功能场景",
        "reason": "当前模型主要支持的语言"
      },
      {
        "keyword": "149M参数量",
        "dimension": "参数规格",
        "reason": "当前模型的参数量，体现模型规模"
      },
      {
        "keyword": "8192-tokens",
        "dimension": "技术特性",
        "reason": "当前模型的最大输入长度，体现技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/conjuncts/ditr-e15",
    "keywords": [
      {
        "keyword": "ditr-e15",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为conjuncts/ditr-e15，模型唯一标识符，用户搜索时可能直接使用该缩写名"
      },
      {
        "keyword": "conjuncts",
        "dimension": "当前模型品牌名",
        "reason": "项目组织名conjuncts是模型所属的唯一开发主体，可作为品牌前缀被搜索，具有区分度"
      },
      {
        "keyword": "Hugging-Face托管模型",
        "dimension": "部署工具",
        "reason": "模型明确标注托管于Hugging Face Hub，用户常搜索此类部署方式以获取可直接加载的模型"
      },
      {
        "keyword": "transformers模型",
        "dimension": "技术特性",
        "reason": "README明确提及为🤗 transformers模型，该术语是NLP开发者搜索模型时的高频技术标签"
      },
      {
        "keyword": "自动生成模型卡片",
        "dimension": "功能场景",
        "reason": "模型核心特征是自动生成模型卡片，这是其独特用途，区别于通用模型，具搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nomic-ai/nomic-embed-vision-v1.5",
    "keywords": [
      {
        "keyword": "nomic-embed-vision",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，去掉版本号更简洁"
      },
      {
        "keyword": "视觉嵌入模型",
        "dimension": "功能场景",
        "reason": "用户搜索图像特征提取/视觉向量化时的常用词"
      },
      {
        "keyword": "共享嵌入空间",
        "dimension": "技术特性",
        "reason": "模型与文本嵌入共用空间的独特卖点"
      },
      {
        "keyword": "图像向量化",
        "dimension": "功能场景",
        "reason": "用户搜索把图片转成向量时的核心需求词"
      },
      {
        "keyword": "Nomic-Atlas",
        "dimension": "部署工具",
        "reason": "官方推荐的嵌入可视化与数据分析平台"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "Imagenet零样本指标高，用户会搜此能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenGVLab/InternVL2-2B",
    "keywords": [
      {
        "keyword": "InternVL2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型系列名称，直接代表当前模型"
      },
      {
        "keyword": "2B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约2 B参数，是模型规模的核心标识"
      },
      {
        "keyword": "文档理解",
        "dimension": "功能场景",
        "reason": "模型在文档内容解析方面表现突出，用户常以此需求搜索"
      },
      {
        "keyword": "图表理解",
        "dimension": "功能场景",
        "reason": "模型能够解析并回答图表相关问题，是其独特能力之一"
      },
      {
        "keyword": "信息图问答",
        "dimension": "功能场景",
        "reason": "针对信息图（infographics）的问答能力，是模型的特色功能"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "模型采用指令微调技术以提升对话指令的响应质量"
      },
      {
        "keyword": "Chat-Demo",
        "dimension": "部署工具",
        "reason": "官方提供的在线聊天演示，便于用户快速体验模型功能"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Captioner",
    "keywords": [
      {
        "keyword": "Qwen3-Omni-30B-A3B-Captioner",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中明确的当前模型全称，是用户搜索该特定音频描述模型的唯一精准标识"
      },
      {
        "keyword": "音频描述",
        "dimension": "功能场景",
        "reason": "模型核心功能是为音频生成文本描述，属于用户明确搜索意图的垂直场景词，且未在高频排除列表中"
      },
      {
        "keyword": "细粒度音频分析",
        "dimension": "技术特性",
        "reason": "README中强调的模型能力，具有技术区分度，非通用词，用户可能搜索‘细粒度音频分析模型’"
      },
      {
        "keyword": "低幻觉音频描述",
        "dimension": "技术特性",
        "reason": "模型核心优势描述，‘低幻觉’是用户在评估音频生成模型时的关键搜索诉求，具有高区分度"
      },
      {
        "keyword": "单轮音频输入",
        "dimension": "技术特性",
        "reason": "模型架构关键限制与设计特征，用户在部署或对比模型时可能搜索‘单轮音频输入模型’"
      },
      {
        "keyword": "多说话人情绪识别",
        "dimension": "功能场景",
        "reason": "模型在语音理解中的独特能力，属于具体应用场景词，未被高频词覆盖，具有搜索价值"
      },
      {
        "keyword": "环境声音识别",
        "dimension": "功能场景",
        "reason": "模型在非语音场景的核心能力，用户可能搜索‘环境声音识别AI’或类似长尾词"
      },
      {
        "keyword": "30秒音频限制",
        "dimension": "技术特性",
        "reason": "模型使用最佳实践中的关键参数，用户在部署时会搜索‘音频描述模型 最大长度’等，此为精准匹配词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LLM-Research/mxbai-embed-large-v1-gguf",
    "keywords": [
      {
        "keyword": "mxbai-embed-large-v1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "AnglE损失函数",
        "dimension": "技术特性",
        "reason": "当前模型训练使用的独特损失函数"
      },
      {
        "keyword": "BERT-large规模",
        "dimension": "技术特性",
        "reason": "当前模型基于的架构规模"
      },
      {
        "keyword": "SOTA性能",
        "dimension": "技术特性",
        "reason": "当前模型实现的性能水平"
      },
      {
        "keyword": "消费级RTX4090",
        "dimension": "部署工具",
        "reason": "当前模型转换和量化使用的硬件环境"
      },
      {
        "keyword": "512个token上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持的上下文长度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-7B-DPO",
    "keywords": [
      {
        "keyword": "UI-TARS",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的当前模型品牌"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed 映射为字节跳动官方大模型"
      },
      {
        "keyword": "GUI智能体",
        "dimension": "功能场景",
        "reason": "原生图形界面智能体，用户会搜“GUI智能体”找此类模型"
      },
      {
        "keyword": "端到端任务自动化",
        "dimension": "功能场景",
        "reason": "无需预定义工作流即可端到端完成任务，是用户关心的卖点"
      },
      {
        "keyword": "DPO优化",
        "dimension": "技术特性",
        "reason": "当前版本采用DPO（Direct Preference Optimization）技术，用户会搜“DPO优化”"
      },
      {
        "keyword": "感知推理一体化",
        "dimension": "技术特性",
        "reason": "将感知、推理、定位、记忆集成于单一VLM，用户会搜“感知推理一体化”"
      },
      {
        "keyword": "72B参数",
        "dimension": "参数规格",
        "reason": "UI-TARS-72B-DPO 提供72B主流大参数版本，用户会搜“72B参数”"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1-Terminus",
    "keywords": [
      {
        "keyword": "DeepSeek-V3.1-Terminus",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中完整的模型品牌名，用户搜索时会直接使用该名称"
      },
      {
        "keyword": "代码智能体",
        "dimension": "功能场景",
        "reason": "模型针对代码编写与调试的智能体功能，是用户寻找编程辅助模型时的关键词"
      },
      {
        "keyword": "搜索智能体",
        "dimension": "功能场景",
        "reason": "模型提供的网络检索能力，用户在搜索增强对话或信息获取时会使用该词"
      },
      {
        "keyword": "语言一致性优化",
        "dimension": "技术特性",
        "reason": "本次更新重点提升了中英文混用及异常字符的处理，体现模型的语言一致性技术改进"
      },
      {
        "keyword": "本地运行",
        "dimension": "部署工具",
        "reason": "README 中提供了本地运行方法，用户常搜索“DeepSeek 本地运行”获取部署指南"
      },
      {
        "keyword": "推理演示代码",
        "dimension": "技术特性",
        "reason": "项目在 inference 文件夹中提供了更新后的推理示例代码，帮助用户快速上手模型推理"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/codefuse-ai/CodeFuse-DevOps-Model-7B-Base",
    "keywords": [
      {
        "keyword": "DevOps-Model",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心品牌名，代表该系列模型的专属品牌，用户搜索DevOps领域AI模型时会直接使用此名称"
      },
      {
        "keyword": "DevOps-Model-7B-Base",
        "dimension": "当前模型品牌名",
        "reason": "模型完整基础版本名称，是项目唯一标识，工程师在搜索具体版本时会精确使用该名称"
      },
      {
        "keyword": "DevOps-AI助手",
        "dimension": "功能场景",
        "reason": "模型专用于DevOps生命周期问题解答，是区别于通用编程助手的垂直场景词，用户会搜索‘DevOps AI助手’这类精准意图词"
      },
      {
        "keyword": "DevOpsEval",
        "dimension": "技术特性",
        "reason": "项目自建的DevOps领域专属评测基准，是该模型独有的技术生态标签，无其他模型使用此名称，具有高度区分度"
      },
      {
        "keyword": "DevOps-Model-7B-Chat",
        "dimension": "当前模型品牌名",
        "reason": "与Base模型配套的对话版本，是项目明确开源的独立模型变体，用户会搜索该具体名称以获取对话能力版本"
      },
      {
        "keyword": "DevOps-Model-14B-Base",
        "dimension": "当前模型品牌名",
        "reason": "项目中明确开源的14B参数版本，是当前模型系列的扩展版本，具有独立搜索价值，且未被高频词列表覆盖"
      },
      {
        "keyword": "DevOps-Model-14B-Chat",
        "dimension": "当前模型品牌名",
        "reason": "14B参数的对话版本，与7B-Chat形成完整产品线，是项目独有的命名结构，用户会为大参数量DevOps模型搜索此名称"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Genius-Society/hoyoMusic",
    "keywords": [
      {
        "keyword": "hoyoMusic",
        "dimension": "当前模型品牌名",
        "reason": "从项目路径Genius-Society/hoyoMusic提取的当前模型名称"
      },
      {
        "keyword": "米哈游音乐生成",
        "dimension": "当前模型品牌名",
        "reason": "README中明确给出的中文品牌定位"
      },
      {
        "keyword": "音乐生成",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能：生成音乐"
      },
      {
        "keyword": "游戏音乐",
        "dimension": "功能场景",
        "reason": "专用于生成米哈游游戏风格音乐"
      },
      {
        "keyword": "钢琴曲生成",
        "dimension": "功能场景",
        "reason": "训练数据为钢琴abc乐谱切片，输出钢琴曲"
      },
      {
        "keyword": "Tunesformer",
        "dimension": "技术特性",
        "reason": "当前模型基于的专属架构名称"
      },
      {
        "keyword": "abc乐谱",
        "dimension": "技术特性",
        "reason": "模型输入输出格式，用户会搜如何生成abc乐谱"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/Emu3-VisionTokenizer",
    "keywords": [
      {
        "keyword": "Emu3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为BAAI/Emu3-VisionTokenizer，模型核心品牌名为Emu3，符合简化命名规则且为用户搜索的直接目标"
      },
      {
        "keyword": "下一个token预测",
        "dimension": "技术特性",
        "reason": "Emu3的核心创新点，全文强调‘仅需下一个token预测’，是区别于扩散模型的独特训练范式，用户会搜索此类技术关键词"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型支持通过预测视频token生成视频，且明确对比Sora，属于明确可识别的功能场景，非高频词且未被排除"
      },
      {
        "keyword": "视觉token化",
        "dimension": "技术特性",
        "reason": "模型将图像/视频转化为离散视觉token，是其架构基础，术语专业但用户（开发者/研究者）会搜索此类技术关键词"
      },
      {
        "keyword": "单Transformer多模态",
        "dimension": "技术特性",
        "reason": "模型使用单一Transformer处理文本、图像、视频的混合序列，是其架构核心设计，区别于组合式模型，具有高区分度"
      },
      {
        "keyword": "无CLIP无预训练LLM",
        "dimension": "技术特性",
        "reason": "模型明确宣称无需CLIP和预训练LLM即可实现视觉语言理解，是颠覆性技术主张，用户会搜索此类反常识特性"
      },
      {
        "keyword": "视频扩展生成",
        "dimension": "功能场景",
        "reason": "模型能基于视频上下文自然扩展并预测后续内容，属于视频生成的进阶能力，非通用词，未被高频词列表覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-VL-235B-A22B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen3-VL-235B-A22B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "视觉智能体",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能特性，可操控电脑/手机图形用户界面"
      },
      {
        "keyword": "视觉辅助编码",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景，能根据图像/视频生成代码"
      },
      {
        "keyword": "高级空间感知",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性，具备更强的空间感知能力"
      },
      {
        "keyword": "长上下文与视频理解",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性，原生支持长上下文和视频理解"
      },
      {
        "keyword": "增强多模态推理",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性，在STEM/数学领域表现卓越"
      },
      {
        "keyword": "升级视觉识别",
        "dimension": "技术特性",
        "reason": "当前模型的技术特性，更广泛、更高质量的预训练"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-4B",
    "keywords": [
      {
        "keyword": "Qwen3Guard-Gen",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的模型全称，直接代表当前模型"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 4 B 参数，用户常以参数大小搜索模型"
      },
      {
        "keyword": "安全审查生成模型",
        "dimension": "功能场景",
        "reason": "模型属于生成式安全审查模型，满足用户对安全审查功能的搜索需求"
      },
      {
        "keyword": "三级风险等级",
        "dimension": "技术特性",
        "reason": "模型将输出划分为安全、争议、不安全三类风险等级，具备细粒度风险评估特性"
      },
      {
        "keyword": "多语言安全审查",
        "dimension": "技术特性",
        "reason": "支持 119 种语言及方言的安全分类，突出模型的跨语言安全审查能力"
      },
      {
        "keyword": "实时安全监控",
        "dimension": "技术特性",
        "reason": "系列模型提供 token 级分类头，可在文本增量生成时实时监控安全性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7",
    "keywords": [
      {
        "keyword": "mDeBERTa-v3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名，唯一标识该模型"
      },
      {
        "keyword": "多语言NLI",
        "dimension": "功能场景",
        "reason": "模型能够在 100 种语言上执行自然语言推理（NLI）"
      },
      {
        "keyword": "零样本分类",
        "dimension": "功能场景",
        "reason": "模型支持 zero‑shot classification，可直接用于无标签分类任务"
      },
      {
        "keyword": "CC100预训练",
        "dimension": "技术特性",
        "reason": "底层模型在微软的 CC100 多语言数据集上进行大规模预训练"
      },
      {
        "keyword": "XNLI微调",
        "dimension": "技术特性",
        "reason": "模型在 XNLI 数据集上进行微调，提升跨语言推理能力"
      },
      {
        "keyword": "multilingualNLI26lang2mil7",
        "dimension": "技术特性",
        "reason": "模型还在 multilingual‑NLI‑26lang‑2mil7 数据集上微调，覆盖 27 种语言的 270 万对句子"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/Qianfan-VL-8B",
    "keywords": [
      {
        "keyword": "Qianfan-VL",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的模型系列品牌"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "当前模型Qianfan-VL-8B的主流规格，用户常搜"
      },
      {
        "keyword": "文档理解",
        "dimension": "功能场景",
        "reason": "README高频强调的企业级文档智能能力"
      },
      {
        "keyword": "OCR增强",
        "dimension": "功能场景",
        "reason": "模型主打全场景OCR，用户搜索意图明确"
      },
      {
        "keyword": "思维链推理",
        "dimension": "技术特性",
        "reason": "8B与70B版本支持CoT，是模型卖点之一"
      },
      {
        "keyword": "图表解析",
        "dimension": "功能场景",
        "reason": "复杂图表分析与推理为模型特色能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/PerceptronAI/Isaac-0.1",
    "keywords": [
      {
        "keyword": "Isaac-0.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为PerceptronAI/Isaac-0.1，是当前模型的唯一官方名称，符合品牌名提取规则且未被高频词列表排除"
      },
      {
        "keyword": "感知语言模型",
        "dimension": "技术特性",
        "reason": "模型自述为‘感知语言模型’，是其核心定义，区别于通用大语言模型，具有独特技术定位，未在高频词列表中"
      },
      {
        "keyword": "精准空间智能",
        "dimension": "技术特性",
        "reason": "模型独有的能力描述，指代其对物理空间的指向与定位能力，属于高区分度功能术语，未被高频词覆盖"
      },
      {
        "keyword": "对话式指向",
        "dimension": "技术特性",
        "reason": "模型提出的新交互模式，强调语言与视觉同步引用，为原创技术术语，具有强搜索价值且未被高频词列表包含"
      },
      {
        "keyword": "感知任务的上下文学习",
        "dimension": "技术特性",
        "reason": "模型支持通过少量示例快速适应感知任务，区别于传统微调，是其核心创新点，术语独特且未被高频词排除"
      },
      {
        "keyword": "光学字符识别",
        "dimension": "功能场景",
        "reason": "模型具备可靠识别小文本与密集场景的能力，属于明确用户搜索场景（如文档分析、工业质检），未在高频词中"
      },
      {
        "keyword": "20亿参数",
        "dimension": "参数规格",
        "reason": "模型明确标注为20亿参数，属于主流参数规模（介于7B与32B之间），用户常搜索此类规格以评估模型体量，未被高频词排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openmmlab-community/mm_grounding_dino_large_o365v2_oiv6_goldg",
    "keywords": [
      {
        "keyword": "MM-Grounding-DINO",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "零样本目标检测",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "增强对比类头",
        "dimension": "技术特性",
        "reason": "当前模型改进的技术特性之一"
      },
      {
        "keyword": "移除参数共享机制",
        "dimension": "技术特性",
        "reason": "当前模型改进的另一技术特性"
      },
      {
        "keyword": "COCO数据集",
        "dimension": "技术特性",
        "reason": "当前模型性能提升的数据集之一"
      },
      {
        "keyword": "LVIS数据集",
        "dimension": "技术特性",
        "reason": "当前模型性能提升的另一数据集"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/XiaomiMiMo/MiMo-Audio-7B-Instruct",
    "keywords": [
      {
        "keyword": "MiMo-Audio",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型品牌名"
      },
      {
        "keyword": "音频语言模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心定位与功能场景"
      },
      {
        "keyword": "小样本学习",
        "dimension": "技术特性",
        "reason": "当前模型具备的小样本学习能力"
      },
      {
        "keyword": "语音续写",
        "dimension": "功能场景",
        "reason": "当前模型可生成脱口秀、朗诵、直播、辩论等语音内容"
      },
      {
        "keyword": "语音转换",
        "dimension": "功能场景",
        "reason": "当前模型支持语音转换、风格迁移和语音编辑"
      },
      {
        "keyword": "指令TTS",
        "dimension": "功能场景",
        "reason": "当前模型在指令TTS评估中达到开源SOTA水平"
      },
      {
        "keyword": "音频理解",
        "dimension": "功能场景",
        "reason": "当前模型在音频理解基准测试中表现优异"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen3-Omni",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，符合提取模型自身名称的规则"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "模型规模为30B参数，属于用户常搜索的参数规格"
      },
      {
        "keyword": "ThinkerTalker-设计",
        "dimension": "技术特性",
        "reason": "模型采用的独特Thinker–Talker架构，是区别于其他模型的关键技术特性"
      },
      {
        "keyword": "AuT-预训练",
        "dimension": "技术特性",
        "reason": "模型使用的AuT预训练方式，提升通用表征能力，具备搜索价值"
      },
      {
        "keyword": "多码本设计",
        "dimension": "技术特性",
        "reason": "通过多码本设计实现低延迟，是模型的创新技术点"
      },
      {
        "keyword": "实时音视频交互",
        "dimension": "功能场景",
        "reason": "模型支持低延迟的音视频流式交互，满足实时多模态应用需求"
      },
      {
        "keyword": "音频描述模型",
        "dimension": "功能场景",
        "reason": "Qwen3-Omni-30B-A3B-Captioner提供高质量音频描述，填补开源社区空白"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-GGUF",
    "keywords": [
      {
        "keyword": "Gemma-3-270M",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 unsloth/gemma-3-270m-it-GGUF 提取的核心模型标识，为当前模型唯一品牌名，符合简化规则（去后缀-it-GGUF，保留主干名称）"
      },
      {
        "keyword": "Unsloth微调",
        "dimension": "部署工具",
        "reason": "当前模型明确强调通过Unsloth进行免费微调，是区别于其他Gemma 3部署方式的独特技术路径，用户会搜索‘如何微调Gemma 3’这类意图"
      },
      {
        "keyword": "Gemma-3轻量模型",
        "dimension": "功能场景",
        "reason": "Gemma 3系列定位为‘轻量级、最先进的开源模型’，270M参数属于轻量级范畴，用户常搜‘轻量模型’找低资源部署方案，且未被高频词库排除"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "部署工具",
        "reason": "模型明确以GGUF格式发布，是本地部署（如llama.cpp）的关键格式，用户搜索‘Gemma 3 GGUF’可精准定位该模型，且GGUF未在强制排除词中"
      },
      {
        "keyword": "Google-Gemma-3",
        "dimension": "当前模型品牌名",
        "reason": "模型由Google DeepMind发布，用户常组合搜索‘Google Gemma 3’以区分其他厂商的Gemma变体，属于品牌+厂商的自然搜索组合，非其他模型名称"
      },
      {
        "keyword": "270M参数",
        "dimension": "参数规格",
        "reason": "270M是当前模型的明确参数规模，属于主流轻量级范围（非极端小参数），用户会搜索‘270M模型’找低显存推理方案，且未被高频词库排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-0528",
    "keywords": [
      {
        "keyword": "DeepSeek-R1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的模型品牌名称"
      },
      {
        "keyword": "深度推理",
        "dimension": "技术特性",
        "reason": "模型在 README 中强调了提升的深度推理能力"
      },
      {
        "keyword": "后训练优化",
        "dimension": "技术特性",
        "reason": "README 提到通过算法优化机制在后训练阶段提升模型性能"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "模型在基准评测中表现突出，特别是在数学推理任务上"
      },
      {
        "keyword": "编程推理",
        "dimension": "功能场景",
        "reason": "模型在编程相关的推理任务中取得了显著提升"
      },
      {
        "keyword": "通用逻辑",
        "dimension": "功能场景",
        "reason": "模型在通用逻辑推理方面表现优异，适用于广泛的逻辑任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1-Base",
    "keywords": [
      {
        "keyword": "DeepSeek-V3.1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "混合思考模式",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，支持思考模式与非思考模式"
      },
      {
        "keyword": "工具调用优化",
        "dimension": "技术特性",
        "reason": "当前模型在工具使用和智能体任务中的表现得到显著提升"
      },
      {
        "keyword": "671B参数",
        "dimension": "参数规格",
        "reason": "当前模型的总参数量，体现模型规模"
      },
      {
        "keyword": "128K上下文长度",
        "dimension": "技术特性",
        "reason": "当前模型支持的上下文长度，体现模型处理长文本的能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-2.6B",
    "keywords": [
      {
        "keyword": "LFM2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 LiquidAI/LFM2-2.6B 中提取的核心模型品牌名，简洁且唯一标识当前模型"
      },
      {
        "keyword": "边缘AI",
        "dimension": "功能场景",
        "reason": "README明确强调模型专为‘边缘人工智能和设备端部署’设计，是用户搜索轻量AI应用时的高意图关键词"
      },
      {
        "keyword": "设备端部署",
        "dimension": "功能场景",
        "reason": "模型核心卖点之一，用户搜索‘能在手机/笔记本运行的AI模型’时会使用此短语，具有明确场景指向性"
      },
      {
        "keyword": "混合Liquid模型",
        "dimension": "技术特性",
        "reason": "LFM2独有的架构命名，包含‘乘法门控和短卷积’，是区别于其他模型的原创技术标签，用户可能搜索该术语了解创新架构"
      },
      {
        "keyword": "2.6B参数",
        "dimension": "参数规格",
        "reason": "26亿参数属于中等规模但非主流高频词（避开7B/32B），是当前模型的精准参数标识，用户会用于筛选模型大小"
      },
      {
        "keyword": "CPU推理",
        "dimension": "部署工具",
        "reason": "模型在CPU上速度比Qwen3快2倍，强调无GPU部署能力，是边缘设备用户的核心搜索词，且未被高频词库覆盖"
      },
      {
        "keyword": "RAG应用",
        "dimension": "功能场景",
        "reason": "README明确指出适用于‘检索增强生成（RAG）’，该缩写是AI从业者高频搜索术语，且未被列入强制排除词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwaipilot/HiPO-8B",
    "keywords": [
      {
        "keyword": "HiPO-8B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型名称，直接提取为品牌名"
      },
      {
        "keyword": "动态推理",
        "dimension": "技术特性",
        "reason": "模型能够在推理过程中动态决定思考与否，是核心技术特性"
      },
      {
        "keyword": "混合策略优化",
        "dimension": "技术特性",
        "reason": "模型采用混合策略（Think‑on / Think‑off）进行优化，区别于传统单一推理方式"
      },
      {
        "keyword": "自适应推理",
        "dimension": "技术特性",
        "reason": "模型根据问题难度自适应切换推理模式，实现效率与准确性的平衡"
      },
      {
        "keyword": "强化学习调度",
        "dimension": "技术特性",
        "reason": "使用强化学习框架对思考模式进行调度和奖励，提升整体性能"
      },
      {
        "keyword": "8B参数",
        "dimension": "参数规格",
        "reason": "模型规模为8B参数，用户常以参数规模搜索模型"
      },
      {
        "keyword": "推理效率提升",
        "dimension": "功能场景",
        "reason": "模型在保持或提升准确率的同时显著降低token长度和思考率，属于提升推理效率的应用场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kijai/WanVideo_comfy",
    "keywords": [
      {
        "keyword": "WanVideo",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型品牌名"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "WanVideo 的核心功能是文本生成视频"
      },
      {
        "keyword": "量化模型",
        "dimension": "部署工具",
        "reason": "项目提供 fp8_scaled 等量化版本，便于低显存部署"
      },
      {
        "keyword": "ComfyUI-WanVideoWrapper",
        "dimension": "部署工具",
        "reason": "官方推荐的 ComfyUI 插件，用于加载和运行 WanVideo"
      },
      {
        "keyword": "fp8量化",
        "dimension": "技术特性",
        "reason": "项目主打 fp8_scaled 量化技术，显著降低显存占用"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "WanVideo 提供 14B 版本，是用户搜索时常见规格"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-Tool",
    "keywords": [
      {
        "keyword": "LFM2-1.2B-Tool",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简洁命名规范，用户会直接搜索该型号"
      },
      {
        "keyword": "工具调用模型",
        "dimension": "功能场景",
        "reason": "模型核心设计目标是‘专为简洁精准的工具调用而设计’，这是区别于通用对话模型的独特功能定位，用户搜索‘工具调用AI’时可能命中"
      },
      {
        "keyword": "边缘设备AI",
        "dimension": "功能场景",
        "reason": "README明确指出应用于‘移动和边缘设备’‘物联网’‘电池供电设备’，该场景词具有明确部署指向性，且未在高频词列表中"
      },
      {
        "keyword": "无云API调用",
        "dimension": "功能场景",
        "reason": "模型强调‘无云依赖的即时API调用’，这是其核心价值主张，属于独特应用场景关键词，非通用表述"
      },
      {
        "keyword": "实时助手",
        "dimension": "功能场景",
        "reason": "模型用于‘汽车、客户支持中的实时助手’，该词精准描述其低延迟响应特性，用户在搜索‘实时AI助手’时可能匹配"
      },
      {
        "keyword": "非思考型模型",
        "dimension": "技术特性",
        "reason": "模型核心创新点是‘打造一个非思考型模型’，该术语在AI领域具有高度独特性，是区别于CoT、思考型模型的关键标签"
      },
      {
        "keyword": "1.2B参数",
        "dimension": "参数规格",
        "reason": "模型规模为1.2B，属于轻量级主流参数区间（介于7B以下），用户会搜索‘1B参数模型’类关键词，且未在高频词黑名单中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen-Image-Edit-2509",
    "keywords": [
      {
        "keyword": "Qwen-Image-Edit-2509",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多图编辑",
        "dimension": "功能场景",
        "reason": "当前模型支持多图编辑，是主要改进点之一"
      },
      {
        "keyword": "单图编辑一致性",
        "dimension": "功能场景",
        "reason": "当前模型显著提升了单图编辑一致性，是主要改进点之一"
      },
      {
        "keyword": "ControlNet原生支持",
        "dimension": "技术特性",
        "reason": "当前模型原生支持ControlNet，包括深度图、边缘图、关键点图等"
      },
      {
        "keyword": "人像编辑一致性",
        "dimension": "功能场景",
        "reason": "当前模型增强人像编辑一致性，支持多种人像风格及姿态变换"
      },
      {
        "keyword": "产品编辑一致性",
        "dimension": "功能场景",
        "reason": "当前模型增强产品编辑一致性，支持产品海报编辑"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/samvit_base_patch16.sa1b",
    "keywords": [
      {
        "keyword": "SAM-ViT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 samvit_base_patch16.sa1b 提取的简洁品牌名"
      },
      {
        "keyword": "图像特征提取",
        "dimension": "功能场景",
        "reason": "模型用于提取图像特征并可在分割任务中微调"
      },
      {
        "keyword": "timm库",
        "dimension": "部署工具",
        "reason": "模型通过 timm.create_model 加载，属于 timm 框架的使用方式"
      },
      {
        "keyword": "ViT",
        "dimension": "技术特性",
        "reason": "模型基于 Vision Transformer（ViT）架构实现"
      },
      {
        "keyword": "SA-1B预训练",
        "dimension": "技术特性",
        "reason": "模型在大规模 SA‑1B 数据集上进行预训练，提升分割特征表现"
      },
      {
        "keyword": "MAE初始化",
        "dimension": "技术特性",
        "reason": "使用 Masked AutoEncoder 权重进行模型初始化，提高特征学习效率"
      },
      {
        "keyword": "约90M参数",
        "dimension": "参数规格",
        "reason": "模型参数量约为 89.7M，属于轻量级视觉特征骨干"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Stream-4B",
    "keywords": [
      {
        "keyword": "Qwen3Guard-Stream-4B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，符合品牌名提取规则，且为唯一标识符"
      },
      {
        "keyword": "实时安全审核",
        "dimension": "功能场景",
        "reason": "模型核心用途是流式对话中的实时内容安全检测，用户会搜索此类具体安全场景"
      },
      {
        "keyword": "token级分类",
        "dimension": "技术特性",
        "reason": "模型独有的技术设计，区别于传统全文本审核，在增量生成中逐token判断，具高区分度"
      },
      {
        "keyword": "三级风险分类",
        "dimension": "功能场景",
        "reason": "模型输出细分为安全、争议、不安全三级，是其精细化审核的核心功能，非通用术语"
      },
      {
        "keyword": "流式文本审核",
        "dimension": "功能场景",
        "reason": "精准描述模型应用场景，用户在搜索‘如何实时审核AI生成内容’时可能使用此词"
      },
      {
        "keyword": "119语言支持",
        "dimension": "功能场景",
        "reason": "突出多语言覆盖能力，是该模型在国际化部署中的关键卖点，非泛泛的‘多语言’"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Intel/zoedepth-nyu",
    "keywords": [
      {
        "keyword": "ZoeDepth",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称Intel/zoedepth-nyu提取的当前模型名称"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "README中明确提到的零样本单目深度估计任务"
      },
      {
        "keyword": "度量深度估计",
        "dimension": "功能场景",
        "reason": "模型核心功能，以实际度量值输出深度"
      },
      {
        "keyword": "NYU数据集微调",
        "dimension": "技术特性",
        "reason": "模型在NYU数据集上完成微调，用户会搜索此关键词"
      },
      {
        "keyword": "DPT框架扩展",
        "dimension": "技术特性",
        "reason": "ZoeDepth基于DPT框架扩展，技术用户会关注"
      },
      {
        "keyword": "pipeline-API",
        "dimension": "部署工具",
        "reason": "README推荐的最简调用方式，开发者会搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large-Edit",
    "keywords": [
      {
        "keyword": "NextStep-1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "自回归图像生成",
        "dimension": "技术特性",
        "reason": "模型采用自回归方式生成图像，区别于扩散模型"
      },
      {
        "keyword": "连续令牌",
        "dimension": "技术特性",
        "reason": "模型核心创新：用连续令牌表示图像，用户会搜此概念"
      },
      {
        "keyword": "流匹配头",
        "dimension": "技术特性",
        "reason": "1.57亿参数流匹配头为模型独有组件，具有搜索区分度"
      },
      {
        "keyword": "140亿参数",
        "dimension": "参数规格",
        "reason": "模型总参数量，用户常按参数规模检索"
      },
      {
        "keyword": "图像编辑",
        "dimension": "功能场景",
        "reason": "项目名带Large-Edit，主打图像编辑能力"
      },
      {
        "keyword": "下一令牌预测",
        "dimension": "技术特性",
        "reason": "训练目标关键词，技术用户会据此搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B",
    "keywords": [
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含 Qwen3，提取为模型的品牌名称"
      },
      {
        "keyword": "1.7B参数",
        "dimension": "参数规格",
        "reason": "模型规模为 1.7B 参数，是用户常搜索的规格关键词"
      },
      {
        "keyword": "复杂逻辑推理",
        "dimension": "技术特性",
        "reason": "模型在思考模式下支持复杂的逻辑推理能力"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "在数学推理任务上表现突出，符合用户搜索需求"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "具备强大的代码生成与编程辅助能力"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "提供跨语言的多语言支持，适用于多语言对话场景"
      },
      {
        "keyword": "智能代理",
        "dimension": "功能场景",
        "reason": "具备 agent 能力，可用于自主任务执行和智能代理场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-4B",
    "keywords": [
      {
        "keyword": "Qwen3-4B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Qwen3-4B，是当前模型的唯一标识，符合简化命名规则（保留主版本+参数，因4B是主流规格且未被禁用）"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型独有的核心能力：在‘思考模式’与‘非思考模式’间无缝切换，是区别于其他模型的创新功能，且未被高频词列表禁止"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "4B是主流小参数规模，用户常搜索‘4B参数模型’用于本地部署或轻量化需求，且不在禁用词列表中（禁用的是7B/32B等）"
      },
      {
        "keyword": "推理增强",
        "dimension": "技术特性",
        "reason": "README明确提到‘推理能力显著增强’，是模型核心卖点，区别于通用‘链式思维’，且未被高频词列表覆盖"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "模型在‘思考模式’下专精数学推理，是明确的功能场景，用户会搜索‘数学推理模型’寻找解题工具"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "README明确提及‘code generation’作为核心能力，属于具体应用场景，非泛泛的‘编程助手’（已被禁用）"
      },
      {
        "keyword": "多语言支持",
        "dimension": "技术特性",
        "reason": "模型具备多语言能力，是区别于仅支持中文/英文模型的差异化特性，且未被高频词列表禁止"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-Base",
    "keywords": [
      {
        "keyword": "Qwen3-30B-A3B-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "稠密模型",
        "dimension": "技术特性",
        "reason": "当前模型提供稠密模型与混合专家模型组合，是核心特性之一"
      },
      {
        "keyword": "混合专家模型",
        "dimension": "技术特性",
        "reason": "当前模型提供稠密模型与混合专家模型组合，是核心特性之一"
      },
      {
        "keyword": "全局批负载均衡损失",
        "dimension": "技术特性",
        "reason": "当前模型引入的创新训练技术，显著提升训练稳定性"
      },
      {
        "keyword": "qk层归一化",
        "dimension": "技术特性",
        "reason": "当前模型引入的创新训练技术，全模型适用，提升整体性能"
      },
      {
        "keyword": "三阶段预训练范式",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特预训练流程，强化专项能力与上下文理解"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/fixie-ai/ultravox-v0_5-llama-3_2-1b",
    "keywords": [
      {
        "keyword": "Ultravox",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为 fixie-ai/ultravox-v0_5-llama-3_2-1b，模型品牌名为 Ultravox，是当前模型的唯一官方名称，符合简化命名规则"
      },
      {
        "keyword": "语音文本到文本",
        "dimension": "功能场景",
        "reason": "模型支持语音和文本输入、文本输出，README 明确标注为 'Audio-Text-to-Text'，中文用户搜索时会使用 '语音文本到文本' 这类自然表达，且未在高频词列表中"
      },
      {
        "keyword": "多模态语音大语言模型",
        "dimension": "技术特性",
        "reason": "模型是 '多模态语音大语言模型'，该组合词精准描述其技术定位，区别于普通LLM，具有高区分度，且未被高频词列表覆盖"
      },
      {
        "keyword": "语音助手",
        "dimension": "功能场景",
        "reason": "README 明确指出可用作 '语音助手'，是用户直接可感知的应用场景，非泛泛形容词，且未在禁止高频词中"
      },
      {
        "keyword": "语音转语音翻译",
        "dimension": "功能场景",
        "reason": "README 明确列出 '语音转语音翻译' 作为核心用途之一，是具体、可搜索的垂直场景，具有强意图指向性"
      },
      {
        "keyword": "音频嵌入向量",
        "dimension": "技术特性",
        "reason": "模型通过 <|audio|> 标记将音频转换为嵌入向量输入，该机制是其核心技术特征，非通用术语，具有技术独特性"
      },
      {
        "keyword": "无偏好调优语音模型",
        "dimension": "技术特性",
        "reason": "README 明确说明 '当前版本尚未进行偏好调优'，该描述在同类模型中具稀缺性，可吸引关注基础模型能力的用户，非高频词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-4B-Base",
    "keywords": [
      {
        "keyword": "Qwen3-4B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，简洁无版本后缀"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "当前模型独有的4B主流规格，用户会搜"
      },
      {
        "keyword": "119语言",
        "dimension": "功能场景",
        "reason": "当前模型支持119种语言，用户搜索多语言模型时会用"
      },
      {
        "keyword": "STEM数据",
        "dimension": "功能场景",
        "reason": "当前模型预训练包含STEM高质量数据，科研用户会搜"
      },
      {
        "keyword": "全局批调度",
        "dimension": "技术特性",
        "reason": "当前模型训练技术亮点，区别于普通Transformer"
      },
      {
        "keyword": "Ollama量化",
        "dimension": "部署工具",
        "reason": "当前模型可Ollama量化部署，区别于通用量化"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1",
    "keywords": [
      {
        "keyword": "DeepSeek-V3.1",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型官方名称，符合品牌名简化规则（去版本后缀后仍为清晰品牌标识）"
      },
      {
        "keyword": "混合思考模式",
        "dimension": "技术特性",
        "reason": "模型核心创新点，用户搜索‘AI思考模式’‘多模式对话模型’时可能使用，具有区分度且非高频词"
      },
      {
        "keyword": "DeepSeek-V3.1-Think",
        "dimension": "当前模型品牌名",
        "reason": "当前模型的子版本名称，是官方明确命名的独立模式，非其他模型，且用户可能搜索‘DeepSeek思考版’等变体"
      },
      {
        "keyword": "128K上下文",
        "dimension": "参数规格",
        "reason": "虽然‘128K’是数字，但‘128K上下文’是行业用户搜索长文本模型时的高频表达方式，且当前模型明确支持，属于可接受的规格描述（非纯数字）"
      },
      {
        "keyword": "UE8M0-FP8精度",
        "dimension": "技术特性",
        "reason": "模型训练中采用的独特数据格式，属于技术亮点，用户搜索‘FP8大模型’‘低精度推理模型’时可能匹配，且非通用术语"
      },
      {
        "keyword": "工具调用优化",
        "dimension": "功能场景",
        "reason": "模型在工具使用和智能体任务上的显著提升，是用户寻找‘AI工具调用’‘智能体模型’时的精准意图词，非高频词"
      },
      {
        "keyword": "两阶段长上下文扩展",
        "dimension": "技术特性",
        "reason": "模型构建的核心方法论，具有技术独特性，用户搜索‘长上下文训练方法’‘上下文扩展模型’时可能命中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nikravan/glm-4vq",
    "keywords": [
      {
        "keyword": "glm-4vq",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "4bit量化",
        "dimension": "技术特性",
        "reason": "当前模型为4bit量化版本，是独特的技术特性"
      },
      {
        "keyword": "多模态多语言",
        "dimension": "技术特性",
        "reason": "当前模型具备多模态多语言能力，是核心特性"
      },
      {
        "keyword": "文档图像图表问答",
        "dimension": "功能场景",
        "reason": "当前模型在文档、图像、图表问答任务中表现卓越，是主要应用场景"
      },
      {
        "keyword": "Google-Colab运行",
        "dimension": "部署工具",
        "reason": "当前模型部分结构调整后可在免费版Google Colab上运行，是部署方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Large-hf",
    "keywords": [
      {
        "keyword": "Depth-Anything-V2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的模型品牌名称"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对单张图片进行深度预测"
      },
      {
        "keyword": "零样本深度估计",
        "dimension": "功能场景",
        "reason": "模型支持在未见过的场景中直接进行深度估计"
      },
      {
        "keyword": "DINOv2骨干网络",
        "dimension": "技术特性",
        "reason": "采用 DINOv2 作为特征提取骨干，提高细节捕捉能力"
      },
      {
        "keyword": "DPT架构",
        "dimension": "技术特性",
        "reason": "基于 DPT（Dense Prediction Transformer）架构实现深度预测"
      },
      {
        "keyword": "相对深度估计",
        "dimension": "功能场景",
        "reason": "模型在相对深度估计任务上达到业界领先水平"
      },
      {
        "keyword": "绝对深度估计",
        "dimension": "功能场景",
        "reason": "模型同样在绝对深度估计任务上表现出色"
      },
      {
        "keyword": "HuggingFace-pipeline",
        "dimension": "部署工具",
        "reason": "模型检查点与 HuggingFace Transformers 完全兼容，可直接通过 pipeline 调用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    "keywords": [
      {
        "keyword": "DeepSeek-R1-0528",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的完整版本号，是当前模型的唯一标识，用户搜索具体版本时会使用"
      },
      {
        "keyword": "深度推理",
        "dimension": "技术特性",
        "reason": "README明确强调模型在后训练阶段优化了深度推理与演绎能力，是该版本的核心差异化能力"
      },
      {
        "keyword": "AIME-2025",
        "dimension": "功能场景",
        "reason": "模型在AIME 2025数学竞赛基准上表现突出，是用户搜索‘数学推理AI’或‘竞赛级AI’时可能使用的具体场景词"
      },
      {
        "keyword": "23K-tokens推理",
        "dimension": "技术特性",
        "reason": "模型每题平均消耗23K tokens，体现其深度思考机制，是区别于前代的量化技术特征，用户可能搜索‘长思维链AI’"
      },
      {
        "keyword": "函数调用增强",
        "dimension": "功能场景",
        "reason": "模型明确升级了函数调用支持，属于AI工具调用类应用的核心能力，用户搜索‘能调用API的AI模型’时会聚焦此点"
      },
      {
        "keyword": "幻觉率降低",
        "dimension": "技术特性",
        "reason": "模型在后训练阶段专门优化了幻觉控制，是用户寻找‘低幻觉AI’时的关键搜索意图词"
      },
      {
        "keyword": "氛围编程体验",
        "dimension": "功能场景",
        "reason": "README独有表述，指代编程场景下更自然、流畅的交互体验，是开发者搜索‘编程友好AI’时的精准意图词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "项目名中的最新一代通义千问系列模型"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "当前模型总参数量305亿，用户常用30B作为搜索词"
      },
      {
        "keyword": "混合专家模型",
        "dimension": "技术特性",
        "reason": "当前模型采用MoE架构，激活专家8/128，用户搜索MoE时常用此中文表达"
      },
      {
        "keyword": "思考模式",
        "dimension": "技术特性",
        "reason": "模型可在思考与非思考模式间无缝切换，是官方主打卖点"
      },
      {
        "keyword": "llama.cpp部署",
        "dimension": "部署工具",
        "reason": "官方README直接给出llama.cpp使用指引，用户会按此关键词搜索"
      },
      {
        "keyword": "131K上下文",
        "dimension": "技术特性",
        "reason": "通过YaRN扩展至131072 tokens，用户常用“131K上下文”搜索长文本模型"
      },
      {
        "keyword": "q5KM量化",
        "dimension": "部署工具",
        "reason": "官方提供q5_K_M等GGUF量化版本，用户会按具体量化名搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/TRELLIS-text-base",
    "keywords": [
      {
        "keyword": "TRELLIS-text-base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Text-to-3D",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，文本生成3D"
      },
      {
        "keyword": "大型3D生成模型",
        "dimension": "功能场景",
        "reason": "当前模型的应用场景和规模描述"
      },
      {
        "keyword": "Structured-3D-Latents",
        "dimension": "技术特性",
        "reason": "当前模型在论文中提出的核心技术特性"
      },
      {
        "keyword": "模型大小B",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-7B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen2.5-VL",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，已简化为核心标识"
      },
      {
        "keyword": "视觉智能体",
        "dimension": "功能场景",
        "reason": "模型可直接作为视觉智能体进行推理和动态工具调用"
      },
      {
        "keyword": "长视频理解",
        "dimension": "功能场景",
        "reason": "支持解析超过1小时的视频内容，具备完整的长视频分析能力"
      },
      {
        "keyword": "结构化输出",
        "dimension": "功能场景",
        "reason": "能够将发票、表单、表格等扫描件内容结构化输出，适用于金融、商业等场景"
      },
      {
        "keyword": "事件捕捉",
        "dimension": "功能场景",
        "reason": "新增精准定位相关片段的事件捕捉能力，帮助快速定位视频中的关键事件"
      },
      {
        "keyword": "动态分辨率",
        "dimension": "技术特性",
        "reason": "通过动态FPS采样实现时间维度的分辨率自适应，提升视频理解的灵活性"
      },
      {
        "keyword": "JSON坐标输出",
        "dimension": "技术特性",
        "reason": "多格式视觉定位时生成稳定的JSON坐标与属性数据，便于下游应用解析"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B",
    "keywords": [
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接出现的最新一代品牌，用户会搜"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "README明确给出30B级规模，主流检索词"
      },
      {
        "keyword": "混合专家",
        "dimension": "技术特性",
        "reason": "MoE架构的中文简称，用户常用搜索词"
      },
      {
        "keyword": "思考模式",
        "dimension": "技术特性",
        "reason": "模型可切换推理模式，独特卖点"
      },
      {
        "keyword": "非思考模式",
        "dimension": "技术特性",
        "reason": "与思考模式并列的高效对话模式，用户会对比搜索"
      },
      {
        "keyword": "代理能力",
        "dimension": "功能场景",
        "reason": "官方强调可调用外部工具，Agent场景关键词"
      },
      {
        "keyword": "多语言翻译",
        "dimension": "功能场景",
        "reason": "支持100+语言，翻译需求用户高频搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Moonlight-16B-A3B-Instruct",
    "keywords": [
      {
        "keyword": "Moonlight-16B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'Moonlight-16B-A3B-Instruct' 中提取的核心品牌名，简化为用户易搜的 'Moonlight-16B'，符合模型名称简化规则"
      },
      {
        "keyword": "Muon优化器",
        "dimension": "技术特性",
        "reason": "当前模型的核心训练技术，是论文提出并开源的原创优化器，具有高区分度，用户会搜索‘Muon优化器模型’"
      },
      {
        "keyword": "混合专家模型",
        "dimension": "技术特性",
        "reason": "模型明确采用MoE架构（混合专家模型），且未被高频词库排除，是区别于普通稠密模型的关键技术标签"
      },
      {
        "keyword": "16B参数",
        "dimension": "参数规格",
        "reason": "模型明确包含16B参数版本，属于主流大模型规模，且未在高频词库中被禁用（高频词库仅禁32B/7B等，16B未被覆盖）"
      },
      {
        "keyword": "样本效率",
        "dimension": "技术特性",
        "reason": "论文核心结论是Muon样本效率是Adam的2倍，该词是用户搜索‘高效训练模型’时可能使用的专业但非过度技术的关键词"
      },
      {
        "keyword": "权重衰减优化",
        "dimension": "技术特性",
        "reason": "论文指出权重衰减是Moonlight扩展性的关键突破点，属于独特技术术语，未被高频词库覆盖，具搜索价值"
      },
      {
        "keyword": "Kimi",
        "dimension": "当前模型品牌名",
        "reason": "项目方为MoonshotAI，根据国产大模型映射规则，必须映射为‘Kimi’（月之暗面旗下产品），这是用户真实搜索的品牌名"
      },
      {
        "keyword": "月之暗面",
        "dimension": "当前模型品牌名",
        "reason": "MoonshotAI的中文品牌名是‘月之暗面’，用户在中文社区（如CSDN）搜索‘月之暗面模型’时会直接使用该词，符合品牌映射规则"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-32B-AWQ",
    "keywords": [
      {
        "keyword": "Qwen3-32B-AWQ",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "当前模型所属的模型类型"
      },
      {
        "keyword": "混合专家模型",
        "dimension": "技术特性",
        "reason": "当前模型提供稠密模型与混合专家（MoE）模型组合，MoE是重要技术特性"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "当前模型支持100+语言与方言，具备强大的多语言指令遵循与翻译能力"
      },
      {
        "keyword": "AWQ量化",
        "dimension": "技术特性",
        "reason": "当前模型采用的量化方案为AWQ 4-bit"
      },
      {
        "keyword": "智能体功能",
        "dimension": "功能场景",
        "reason": "当前模型具备专业的智能体功能支持，可在思维与非思维模式下精准对接外部工具"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为zai-org/glm-4-9b-chat，根据国产大模型映射规则，GLM-4是智谱AI的模型品牌名，且未被高频词列表排除"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "模型支持最大128K上下文长度，是用户搜索长文本推理模型时的关键搜索词，且未被高频词列表禁止（注意：1M上下文因非主流规格未提取）"
      },
      {
        "keyword": "函数调用",
        "dimension": "功能场景",
        "reason": "模型支持自定义工具调用（Function Call），中文用户常搜索'函数调用'而非英文术语，是区别于其他模型的实用功能点"
      },
      {
        "keyword": "代码执行",
        "dimension": "功能场景",
        "reason": "模型具备直接执行代码的能力，属于高价值AI编程辅助场景，用户会主动搜索该关键词"
      },
      {
        "keyword": "26语言支持",
        "dimension": "技术特性",
        "reason": "模型新增支持26种语言，是区别于多数仅支持中英的模型的显著特征，用户搜索多语言AI模型时可能使用该表述"
      },
      {
        "keyword": "长文本推理",
        "dimension": "功能场景",
        "reason": "README明确提及'长文本推理'，是用户寻找处理文档、论文、代码库等场景的核心搜索意图词，且未被高频词列表覆盖"
      },
      {
        "keyword": "GLM-4-9B-Chat",
        "dimension": "当前模型品牌名",
        "reason": "虽然带后缀，但这是模型在Hugging Face和GitCode上的官方完整名称，用户在搜索具体部署版本时会精确使用该词，且未被高频词列表排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/IIC/nlp_bert_relation-extraction_chinese-base",
    "keywords": [
      {
        "keyword": "Relation-Extraction-Chinese",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 IIC/nlp_bert_relation-extraction_chinese-base 提取的简洁模型名称"
      },
      {
        "keyword": "中文关系抽取",
        "dimension": "功能场景",
        "reason": "模型用于在中文文本中抽取实体之间的关系"
      },
      {
        "keyword": "实体三元组抽取",
        "dimension": "功能场景",
        "reason": "模型输出 (主语, 谓语, 宾语) 形式的三元组"
      },
      {
        "keyword": "duie数据集",
        "dimension": "训练数据",
        "reason": "模型在公开的 duie 关系抽取数据集上进行 fine‑tune"
      },
      {
        "keyword": "ModelScope-pipeline",
        "dimension": "部署工具",
        "reason": "官方示例展示通过 ModelScope 的 pipeline 接口调用模型"
      },
      {
        "keyword": "中文RoBERTa微调",
        "dimension": "技术特性",
        "reason": "模型基于 hfl/chinese-roberta-wwm-ext 进行微调"
      },
      {
        "keyword": "主谓宾三元组",
        "dimension": "输出格式",
        "reason": "模型返回的结果为 (主语, 谓语, 宾语) 三元组列表"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/AI-ModelScope/OminiControl",
    "keywords": [
      {
        "keyword": "OminiControl",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为AI-ModelScope/OminiControl，直接提取模型唯一品牌名，符合用户搜索AI模型时的直接命名习惯"
      },
      {
        "keyword": "扩散变换器",
        "dimension": "技术特性",
        "reason": "README明确提到'扩散变换器'，是该模型的核心架构创新，非通用术语，具有技术独特性且用户可能搜索该术语寻找新型扩散模型"
      },
      {
        "keyword": "最小化通用控制",
        "dimension": "功能场景",
        "reason": "论文标题核心短语'最小化通用控制'精准描述模型能力，是区别于其他图像控制模型的独特功能标签，用户可能用此长尾词寻找精准控制方案"
      },
      {
        "keyword": "Image-to-Image",
        "dimension": "功能场景",
        "reason": "README明确标注为Image-to-Image任务，是用户在AI图像生成领域高频搜索的精准任务类型，且未被列入强制排除词库"
      },
      {
        "keyword": "Diffusion-Single-File",
        "dimension": "部署工具",
        "reason": "模型以单文件扩散格式提供，该术语在社区中用于描述轻量部署方式，是技术用户搜索模型部署方案时的精准关键词，未被高频词排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/AI-ModelScope/IDM-VTON",
    "keywords": [
      {
        "keyword": "IDM-VTON",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型名称"
      },
      {
        "keyword": "虚拟试穿",
        "dimension": "功能场景",
        "reason": "当前模型核心用途：真实场景下的虚拟服装试穿"
      },
      {
        "keyword": "扩散模型",
        "dimension": "技术特性",
        "reason": "当前模型基于扩散模型的技术路线"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "README中提到的inpainting能力，用于服装区域替换"
      },
      {
        "keyword": "真实场景",
        "dimension": "功能场景",
        "reason": "强调模型在真实环境而非理想化背景下的试穿效果"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "README标签中明确支持的跨平台部署格式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/AI-ModelScope/gliner_multi",
    "keywords": [
      {
        "keyword": "GLiNER",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接出现的模型品牌，用户搜索时会用"
      },
      {
        "keyword": "命名实体识别",
        "dimension": "功能场景",
        "reason": "模型核心任务，NER 是高频搜索词"
      },
      {
        "keyword": "Universal-NER",
        "dimension": "技术特性",
        "reason": "官方标签强调的可识别任意实体类型特性"
      },
      {
        "keyword": "209M参数",
        "dimension": "参数规格",
        "reason": "轻量级体积，适合资源受限场景，用户会搜"
      },
      {
        "keyword": "多语言NER",
        "dimension": "功能场景",
        "reason": "支持多语言实体识别，区别于纯英文模型"
      },
      {
        "keyword": "Pile-NER训练",
        "dimension": "技术特性",
        "reason": "独特训练语料，研究用户常按数据集搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-bert/bert-base-chinese",
    "keywords": [
      {
        "keyword": "BERT-base-chinese",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型完整名称"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "功能场景",
        "reason": "模型主要用于 Masked Language Modeling 任务"
      },
      {
        "keyword": "中文预训练",
        "dimension": "功能场景",
        "reason": "模型专门针对中文语料进行预训练"
      },
      {
        "keyword": "词片段掩码",
        "dimension": "技术特性",
        "reason": "采用对词片段独立施加掩码的训练方式"
      },
      {
        "keyword": "Apache-2.0-许可",
        "dimension": "许可协议",
        "reason": "模型遵循 Apache 2.0 开源许可证"
      },
      {
        "keyword": "21128-词表",
        "dimension": "技术特性",
        "reason": "模型使用 21128 大小的中文词表"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/magenta-realtime",
    "keywords": [
      {
        "keyword": "Magenta-RT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "开源音乐生成",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景，即生成音乐且开源"
      },
      {
        "keyword": "文本提示生成音乐",
        "dimension": "功能场景",
        "reason": "当前模型支持通过文本提示来生成音乐，是其独特功能"
      },
      {
        "keyword": "音频示例生成音乐",
        "dimension": "功能场景",
        "reason": "当前模型支持通过音频示例来生成音乐，是其独特功能"
      },
      {
        "keyword": "SpectroStream",
        "dimension": "技术特性",
        "reason": "当前模型的核心组件之一，具有技术独特性"
      },
      {
        "keyword": "MusicCoCa",
        "dimension": "技术特性",
        "reason": "当前模型的核心组件之一，具有技术独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/adibvafa/CodonTransformer",
    "keywords": [
      {
        "keyword": "CodonTransformer",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的模型品牌，是用户搜索该工具时最核心的关键词"
      },
      {
        "keyword": "密码子优化",
        "dimension": "功能场景",
        "reason": "模型核心用途，生物信息学研究者搜索DNA序列优化工具时的直接意图词"
      },
      {
        "keyword": "基因工程",
        "dimension": "功能场景",
        "reason": "模型主要服务领域，科研人员在寻找AI辅助基因设计工具时常用搜索词"
      },
      {
        "keyword": "合成生物学",
        "dimension": "功能场景",
        "reason": "README明确标注的标签，是该模型应用的高价值垂直领域，用户精准搜索词"
      },
      {
        "keyword": "计算生物学",
        "dimension": "功能场景",
        "reason": "官方标签之一，区别于通用AI模型，体现其在生物计算中的专业定位"
      },
      {
        "keyword": "DNA序列预测",
        "dimension": "功能场景",
        "reason": "模型核心输出功能，用户在寻找AI生成优化DNA序列工具时的自然搜索表达"
      },
      {
        "keyword": "Transformer生物模型",
        "dimension": "技术特性",
        "reason": "模型基于Transformer架构，且专用于生物序列任务，是区别于通用Transformer的关键组合词"
      },
      {
        "keyword": "Jupyter生物工具",
        "dimension": "部署工具",
        "reason": "模型通过Jupyter笔记本提供交互式使用，是科研用户关注的易用性部署方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/timm/edgenext_small.usi_in1k",
    "keywords": [
      {
        "keyword": "EdgeNeXt",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型主打ImageNet-1k图像分类任务"
      },
      {
        "keyword": "轻量化模型",
        "dimension": "技术特性",
        "reason": "仅5.6M参数，面向移动端视觉应用"
      },
      {
        "keyword": "GMACs",
        "dimension": "技术特性",
        "reason": "1.3 GMACs低计算量，适合边缘部署"
      },
      {
        "keyword": "CNN-Transformer融合",
        "dimension": "技术特性",
        "reason": "EdgeNeXt核心架构，兼顾CNN与Transformer优势"
      },
      {
        "keyword": "USI蒸馏",
        "dimension": "技术特性",
        "reason": "使用USI统一蒸馏方案提升ImageNet精度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-Math",
    "keywords": [
      {
        "keyword": "LFM2-350M-Math",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接定义的当前模型全称，是用户搜索该特定数学模型时的精准关键词"
      },
      {
        "keyword": "数学推理模型",
        "dimension": "功能场景",
        "reason": "模型明确用于解决复杂数学问题，是用户搜索AI数学助手时的核心意图词，且未在高频排除词列表中"
      },
      {
        "keyword": "轻量级数学AI",
        "dimension": "功能场景",
        "reason": "模型强调‘轻量级’与‘数学’结合，区别于通用大模型，是用户寻找低资源数学推理方案的精准搜索词"
      },
      {
        "keyword": "贪婪解码",
        "dimension": "技术特性",
        "reason": "模型推荐的核心解码策略，属于专业用户在优化数学推理时会搜索的技术参数，具有独特性"
      },
      {
        "keyword": "ChatML模板",
        "dimension": "技术特性",
        "reason": "模型采用类ChatML对话模板，是部署和调用该模型时的关键技术标签，非通用术语，具有区分度"
      },
      {
        "keyword": "单轮数学对话",
        "dimension": "功能场景",
        "reason": "模型明确标注‘仅适用于单轮对话’，针对数学问题的单次交互场景，是用户筛选模型适用性的独特关键词"
      },
      {
        "keyword": "数学自验证",
        "dimension": "技术特性",
        "reason": "README提到‘自我验证最终答案’，结合数学场景，形成独特组合词，区别于通用‘链式思维’，未被高频词覆盖"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-RAG",
    "keywords": [
      {
        "keyword": "LFM2-1.2B-RAG",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型完整名称"
      },
      {
        "keyword": "RetrievalAugmented-Generation",
        "dimension": "功能场景",
        "reason": "模型专为 RAG（检索增强生成）任务设计，可在检索后生成答案"
      },
      {
        "keyword": "Multidocument-QA",
        "dimension": "功能场景",
        "reason": "支持基于多篇文档的问答，适用于文档检索后生成答案的场景"
      },
      {
        "keyword": "Knowledgebase-chatbot",
        "dimension": "功能场景",
        "reason": "可用于构建面向产品文档或内部知识库的智能聊天机器人"
      },
      {
        "keyword": "Multilanguage-support",
        "dimension": "功能场景",
        "reason": "模型支持英语、阿拉伯语、中文、法语、德语、日语、韩语、葡萄牙语和西班牙语等多语言交互"
      },
      {
        "keyword": "ChatML-template",
        "dimension": "技术特性",
        "reason": "采用类 ChatML 的对话模板，兼容多轮对话上下文管理"
      },
      {
        "keyword": "Greedy-decoding",
        "dimension": "技术特性",
        "reason": "推荐使用贪婪解码（temperature=0）进行确定性生成"
      },
      {
        "keyword": "Synthetic-document-finetuning",
        "dimension": "技术特性",
        "reason": "在混合开源与合成文档的百万级样本上进行微调，提高对多文档检索的适应性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-Extract",
    "keywords": [
      {
        "keyword": "LFM2-1.2B-Extract",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "非结构化文档提取",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能是从非结构化文档中提取信息"
      },
      {
        "keyword": "结构化输出",
        "dimension": "功能场景",
        "reason": "当前模型将提取的信息转换为JSON、XML或YAML等结构化输出"
      },
      {
        "keyword": "贪婪解码",
        "dimension": "技术特性",
        "reason": "当前模型建议使用的生成参数，体现技术特性"
      },
      {
        "keyword": "多语言支持",
        "dimension": "技术特性",
        "reason": "当前模型支持英语、阿拉伯语、中文等多种语言"
      },
      {
        "keyword": "类ChatML对话模板",
        "dimension": "技术特性",
        "reason": "当前模型使用的对话模板类型，体现技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/map-anything",
    "keywords": [
      {
        "keyword": "MapAnything",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，用户搜索该模型时会使用此名称"
      },
      {
        "keyword": "3D重建",
        "dimension": "功能场景",
        "reason": "模型核心功能是端到端三维几何结构重建，用户搜索AI做3D重建时会使用此中文术语"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "模型支持的12种任务之一，是计算机视觉领域高频搜索的具体应用场景"
      },
      {
        "keyword": "多视图立体匹配",
        "dimension": "功能场景",
        "reason": "模型支持的关键任务，专业用户搜索AI在多视角下进行立体匹配时会使用此术语"
      },
      {
        "keyword": "相机位姿估计",
        "dimension": "功能场景",
        "reason": "模型支持camera-pose任务，中文用户搜索AI如何估计相机位姿时常用此表达"
      },
      {
        "keyword": "深度补全",
        "dimension": "功能场景",
        "reason": "模型支持的特定三维重建任务，区别于通用深度估计，具有明确搜索意图"
      },
      {
        "keyword": "Image-to-3D",
        "dimension": "技术特性",
        "reason": "模型标签中明确标注，是用户搜索从图像生成3D结构时的常用英文关键词"
      },
      {
        "keyword": "端到端3D重建",
        "dimension": "技术特性",
        "reason": "模型核心优势是端到端训练，区别于传统多阶段方法，是技术型用户搜索的关键描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M",
    "keywords": [
      {
        "keyword": "OpenMed-NER-PharmaDetect",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的模型品牌名称，唯一标识该模型"
      },
      {
        "keyword": "化学实体识别",
        "dimension": "功能场景",
        "reason": "模型的核心任务是从医学文本中识别化学实体"
      },
      {
        "keyword": "BC5CDR",
        "dimension": "技术特性",
        "reason": "模型在BC5CDR‑Chem数据集上训练并评估，体现其数据来源与技术基准"
      },
      {
        "keyword": "药物相互作用检测",
        "dimension": "功能场景",
        "reason": "模型可用于检测文本中的药物相互作用，满足药理学分析需求"
      },
      {
        "keyword": "不良事件监测",
        "dimension": "功能场景",
        "reason": "模型支持从临床记录中抽取不良药物反应信息，助力药物安全监控"
      },
      {
        "keyword": "药物发现文献挖掘",
        "dimension": "功能场景",
        "reason": "模型能够在科研文献中自动抓取药物相关实体，帮助药物发现工作流"
      },
      {
        "keyword": "生物医学知识图谱构建",
        "dimension": "功能场景",
        "reason": "模型的实体抽取结果可直接用于构建生物医学知识图谱"
      },
      {
        "keyword": "434M参数",
        "dimension": "参数规格",
        "reason": "模型名称中包含的参数规模，用户常以参数大小检索模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-Extract",
    "keywords": [
      {
        "keyword": "LFM2-350M",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，350M参数规模"
      },
      {
        "keyword": "信息抽取",
        "dimension": "功能场景",
        "reason": "README明确说明用于从非结构化文档提取关键信息"
      },
      {
        "keyword": "结构化输出",
        "dimension": "功能场景",
        "reason": "将提取结果转为JSON/XML/YAML等结构化格式"
      },
      {
        "keyword": "发票提取",
        "dimension": "功能场景",
        "reason": "README列举的典型用例：从邮件提取发票详情"
      },
      {
        "keyword": "监管文件解析",
        "dimension": "功能场景",
        "reason": "README列举的典型用例：将监管文件转为XML供合规系统使用"
      },
      {
        "keyword": "知识图谱填充",
        "dimension": "功能场景",
        "reason": "README列举的典型用例：提取实体与属性填充知识图谱"
      },
      {
        "keyword": "贪婪解码",
        "dimension": "技术特性",
        "reason": "官方推荐temperature=0的贪婪解码策略"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-qat-q4_0-unquantized",
    "keywords": [
      {
        "keyword": "EmbeddingGemma",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，是用户搜索该嵌入模型的核心关键词"
      },
      {
        "keyword": "768维嵌入",
        "dimension": "技术特性",
        "reason": "模型输出的固定嵌入维度，是用户在语义搜索、向量检索场景中关注的核心技术参数，具有明确区分度"
      },
      {
        "keyword": "Matryoshka嵌入",
        "dimension": "技术特性",
        "reason": "模型独有的Matryoshka表示学习（MRL）技术，支持动态截断至512/256/128维，是区别于普通嵌入模型的关键创新点"
      },
      {
        "keyword": "设备端嵌入",
        "dimension": "功能场景",
        "reason": "模型专为手机、笔记本等资源受限设备设计，用户搜索‘设备端AI嵌入’或‘轻量级嵌入模型’时会精准匹配"
      },
      {
        "keyword": "3亿参数嵌入",
        "dimension": "参数规格",
        "reason": "300M参数是当前模型的核心规模标识，属于中小规模但高性能嵌入模型的典型表述，用户会搜索‘3亿参数嵌入模型’"
      },
      {
        "keyword": "语义相似度搜索",
        "dimension": "功能场景",
        "reason": "模型明确用于语义相似度任务，是用户在检索系统、推荐系统中寻找嵌入模型时的高频意图词"
      },
      {
        "keyword": "Sentence-Transformers嵌入",
        "dimension": "部署工具",
        "reason": "模型官方推荐与Sentence Transformers库配合使用，是开发者部署该模型时的关键技术组合词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/codefuse-ai/CodeFuse-DevOps-Model-7B-Chat",
    "keywords": [
      {
        "keyword": "CodeFuse-DevOps",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提取的当前模型品牌名"
      },
      {
        "keyword": "DevOps大模型",
        "dimension": "功能场景",
        "reason": "用户会搜的DevOps领域专用大模型"
      },
      {
        "keyword": "运维问答",
        "dimension": "功能场景",
        "reason": "模型核心能力：回答DevOps生命周期问题"
      },
      {
        "keyword": "DevOpsEval",
        "dimension": "技术特性",
        "reason": "官方自建DevOps评测基准，独特卖点"
      },
      {
        "keyword": "ONNX",
        "dimension": "部署工具",
        "reason": "标签明确支持ONNX格式，便于跨平台部署"
      },
      {
        "keyword": "Qwen加训",
        "dimension": "技术特性",
        "reason": "基于Qwen-7B继续训练，突出再训练优势"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/esm2_t33_650M_UR50D",
    "keywords": [
      {
        "keyword": "ESM-2",
        "dimension": "当前模型品牌名",
        "reason": "模型系列名称，直接来源于项目名称"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "模型采用的核心训练目标，用户会以此搜索相关蛋白质语言模型"
      },
      {
        "keyword": "蛋白质序列模型",
        "dimension": "功能场景",
        "reason": "模型的主要应用对象是蛋白质序列，常被用于序列级别的预测任务"
      },
      {
        "keyword": "蛋白质功能预测",
        "dimension": "功能场景",
        "reason": "模型可微调用于预测蛋白质功能，是用户关注的典型使用场景"
      },
      {
        "keyword": "650M参数",
        "dimension": "参数规格",
        "reason": "模型拥有约6.5亿参数，用户在搜索模型规模时会使用该关键词"
      },
      {
        "keyword": "UR50D数据集",
        "dimension": "技术特性",
        "reason": "模型在UR50D数据集上预训练，数据集名称是区分同类模型的重要信息"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/dino-vits8",
    "keywords": [
      {
        "keyword": "dino-vits8",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Vision-Transformer",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术架构"
      },
      {
        "keyword": "自监督学习",
        "dimension": "技术特性",
        "reason": "当前模型采用DINO方法进行自监督训练"
      },
      {
        "keyword": "图像分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "224x224分辨率",
        "dimension": "技术特性",
        "reason": "当前模型预训练的图像分辨率"
      },
      {
        "keyword": "8x8补丁",
        "dimension": "技术特性",
        "reason": "当前模型使用的图像补丁大小"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.2-Exp",
    "keywords": [
      {
        "keyword": "DeepSeek-V3.2-Exp",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前实验模型全称，是用户搜索该特定版本的唯一标识"
      },
      {
        "keyword": "DeepSeek-Sparse-Attention",
        "dimension": "技术特性",
        "reason": "该模型独有的核心技术，首次实现细粒度稀疏注意力机制，具有高度区分度且非通用术语"
      },
      {
        "keyword": "长上下文优化",
        "dimension": "功能场景",
        "reason": "模型核心设计目标，用户搜索‘长上下文AI模型’时会使用该词，非泛泛形容词，具明确场景指向"
      },
      {
        "keyword": "稀疏注意力",
        "dimension": "技术特性",
        "reason": "DSA机制的核心组件，是技术圈内搜索高效Transformer架构时的高频精准术语，非通用词"
      },
      {
        "keyword": "超长文本推理",
        "dimension": "功能场景",
        "reason": "模型针对的典型应用场景，用户会搜索‘处理超长文本的AI模型’，该词精准匹配搜索意图"
      },
      {
        "keyword": "训练效率优化",
        "dimension": "技术特性",
        "reason": "模型实验目标之一，区别于普通模型的性能提升，是该版本独有的研究方向关键词"
      },
      {
        "keyword": "推理效率提升",
        "dimension": "技术特性",
        "reason": "与训练效率并列的核心指标，用户搜索‘快速推理长文本模型’时可能使用该短语，具实际搜索价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-384-ssv2",
    "keywords": [
      {
        "keyword": "V-JEPA-2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型品牌名"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "README中明确提到的核心功能"
      },
      {
        "keyword": "ViT-g",
        "dimension": "技术特性",
        "reason": "当前模型使用的视觉Transformer架构"
      },
      {
        "keyword": "384分辨率",
        "dimension": "参数规格",
        "reason": "模型输入视频帧的固定分辨率，用户会搜"
      },
      {
        "keyword": "Something-Something-V2",
        "dimension": "功能场景",
        "reason": "当前模型预训练所用的视频数据集，用户会搜"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "README中给出的直接应用场景"
      },
      {
        "keyword": "Meta-FAIR",
        "dimension": "当前模型品牌名",
        "reason": "模型由Meta FAIR团队开发，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vicgalle/xlm-roberta-large-xnli-anli",
    "keywords": [
      {
        "keyword": "xlm-roberta-large-xnli-anli",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "XLM-RoBERTa-large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型基础名称"
      },
      {
        "keyword": "零样本分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "multilingual",
        "dimension": "技术特性",
        "reason": "当前模型支持多语言的技术特性"
      },
      {
        "keyword": "XNLI",
        "dimension": "技术特性",
        "reason": "当前模型在XNLI数据集上微调的技术特性"
      },
      {
        "keyword": "ANLI",
        "dimension": "技术特性",
        "reason": "当前模型在ANLI数据集上微调的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/DeepSeek-V3.1-Base-BF16",
    "keywords": [
      {
        "keyword": "DeepSeek-V3.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "671B参数",
        "dimension": "参数规格",
        "reason": "模型总参数量约 6710 亿（≈671B），是用户常搜索的参数规模"
      },
      {
        "keyword": "混合思考模式",
        "dimension": "技术特性",
        "reason": "模型同时支持思考模式与非思考模式的独特混合能力"
      },
      {
        "keyword": "智能工具调用",
        "dimension": "功能场景",
        "reason": "模型在工具使用和智能体任务上的优化表现，是用户关注的核心功能"
      },
      {
        "keyword": "FP8-Scale-训练",
        "dimension": "技术特性",
        "reason": "采用 UE8M0 FP8 Scale 数据格式进行训练，区别于常规的 FP16/FP32 训练方式"
      },
      {
        "keyword": "长上下文扩展",
        "dimension": "技术特性",
        "reason": "通过两阶段长上下文扩展方法，将上下文长度提升至 128K，提升对长文档的处理能力"
      },
      {
        "keyword": "DeepSeek-V3.1-Think",
        "dimension": "功能场景",
        "reason": "模型的 Think 变体提供与 DeepSeek‑R1‑0528 相当的答案质量且响应更快"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jwan2021/autotrain-us-housing-prices-1771761514",
    "keywords": [
      {
        "keyword": "autotrain",
        "dimension": "部署工具",
        "reason": "当前模型使用AutoTrain平台训练，是用户搜索自动化训练工具时的直接关键词"
      },
      {
        "keyword": "tabular-regression",
        "dimension": "功能场景",
        "reason": "当前模型明确用于表格数据回归任务，是用户寻找结构化数据预测模型时的精准搜索词"
      },
      {
        "keyword": "joblib",
        "dimension": "部署工具",
        "reason": "模型通过joblib加载，是技术用户搜索轻量级Python模型部署方案时的高频技术词"
      },
      {
        "keyword": "us-housing-prices",
        "dimension": "功能场景",
        "reason": "模型专用于美国房价预测，是垂直领域用户搜索具体应用案例时的核心语义词"
      },
      {
        "keyword": "tabular",
        "dimension": "技术特性",
        "reason": "模型处理表格结构数据，区别于图像/文本模型，是用户区分数据类型时的关键分类词"
      },
      {
        "keyword": "regression",
        "dimension": "技术特性",
        "reason": "模型解决回归问题，是机器学习用户搜索预测型模型时的基础但精准的搜索维度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/alibaba-pai/Wan2.1-Fun-14B-Control",
    "keywords": [
      {
        "keyword": "Wan2.1-Fun-14B-Control",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该特定控制型视频生成模型的精准关键词"
      },
      {
        "keyword": "视频控制",
        "dimension": "功能场景",
        "reason": "模型核心功能是通过Canny、Depth、Pose等条件控制视频生成，区别于普通文生视频，是用户精准搜索意图"
      },
      {
        "keyword": "轨迹控制",
        "dimension": "功能场景",
        "reason": "模型独有支持轨迹控制视频生成，属于高区分度功能，用户会为此类高级控制方式搜索"
      },
      {
        "keyword": "多分辨率视频",
        "dimension": "功能场景",
        "reason": "明确支持512/768/1024多分辨率视频预测，是区别于固定分辨率模型的关键特性，用户会搜索此需求"
      },
      {
        "keyword": "首尾图预测",
        "dimension": "功能场景",
        "reason": "模型支持基于首尾图像引导视频生成，属于特定生成范式，非通用文生视频功能，具区分度"
      },
      {
        "keyword": "81帧视频",
        "dimension": "功能场景",
        "reason": "以81帧为训练和预测标准，是该模型在视频长度上的显著特征，用户可能搜索长视频生成模型"
      },
      {
        "keyword": "Canny控制视频",
        "dimension": "功能场景",
        "reason": "模型支持Canny边缘控制视频生成，是具体控制条件之一，用户会针对特定控制方式搜索"
      },
      {
        "keyword": "Depth控制视频",
        "dimension": "功能场景",
        "reason": "模型支持深度图控制视频生成，属于专业级视频控制技术，具有明确搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Intel/ldm3d-4c",
    "keywords": [
      {
        "keyword": "LDM3D-4C",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "潜在扩散模型",
        "dimension": "技术特性",
        "reason": "当前模型基于潜在扩散模型技术"
      },
      {
        "keyword": "RGBD图像生成",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能是根据文本提示生成RGBD图像"
      },
      {
        "keyword": "DepthFusion应用",
        "dimension": "功能场景",
        "reason": "当前模型开发了名为DepthFusion的应用程序，提供沉浸式交互体验"
      },
      {
        "keyword": "360度全景体验",
        "dimension": "功能场景",
        "reason": "当前模型通过DepthFusion应用在TouchDesigner中打造沉浸式交互360度全景体验"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.6",
    "keywords": [
      {
        "keyword": "GLM-4.6",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "200K上下文",
        "dimension": "技术特性",
        "reason": "用户会搜索超长上下文大模型"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "README强调卓越的代码性能，用户常用搜索词"
      },
      {
        "keyword": "智能体框架",
        "dimension": "功能场景",
        "reason": "README突出智能体集成能力，用户会搜"
      },
      {
        "keyword": "工具调用",
        "dimension": "技术特性",
        "reason": "支持推理过程工具调用，用户关注此能力"
      },
      {
        "keyword": "角色扮演",
        "dimension": "功能场景",
        "reason": "README提到写作与角色扮演场景，用户搜索词"
      },
      {
        "keyword": "Z.ai-API",
        "dimension": "部署工具",
        "reason": "官方提供的API调用方式，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jwan2021/autotrain-us-housing-prices-1771761513",
    "keywords": [
      {
        "keyword": "AutoTrain-US-Housing-Prices",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 jwan2021/autotrain-us-housing-prices-1771761513 中提取的完整模型名称"
      },
      {
        "keyword": "单列回归",
        "dimension": "功能场景",
        "reason": "README 中明确标注模型问题类型为单列回归，体现模型的预测任务"
      },
      {
        "keyword": "房价预测",
        "dimension": "功能场景",
        "reason": "模型用于预测美国住宅价格，是典型的房价预测场景"
      },
      {
        "keyword": "Joblib模型",
        "dimension": "部署工具",
        "reason": "模型文件使用 joblib 保存，说明部署时依赖 Joblib 进行加载"
      },
      {
        "keyword": "Tabular回归",
        "dimension": "技术特性",
        "reason": "模型针对结构化表格数据进行回归预测，属于 Tabular 回归技术"
      },
      {
        "keyword": "US住房数据",
        "dimension": "技术特性",
        "reason": "模型训练使用的是美国住房价格数据集，数据来源具备地域和领域特征"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ecmwf/aifs-single-0.2.1",
    "keywords": [
      {
        "keyword": "AIFS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'ecmwf/aifs-single-0.2.1' 提取的核心模型简称，是ECMWF官方命名的AI预报系统，具有唯一性"
      },
      {
        "keyword": "图神经网络",
        "dimension": "技术特性",
        "reason": "模型明确采用GNN编码器-解码器架构，是区别于传统NWP的核心AI技术，用户搜索气象AI模型时可能聚焦此技术"
      },
      {
        "keyword": "气象预报",
        "dimension": "功能场景",
        "reason": "模型核心用途是天气预测，属于明确、高搜索意图的垂直场景词，且未被高频词库排除"
      },
      {
        "keyword": "Anemoi",
        "dimension": "当前模型品牌名",
        "reason": "AIFS是基于Anemoi框架开发的，Anemoi是ECMWF官方推出的开源气象AI框架名称，属于当前模型所属的系统级品牌名"
      },
      {
        "keyword": "ERA5再分析",
        "dimension": "技术特性",
        "reason": "模型训练依赖的权威数据源，是气象AI领域特有关键词，用户搜索专业气象模型时可能精准检索此数据集"
      },
      {
        "keyword": "滑动窗口变换",
        "dimension": "技术特性",
        "reason": "模型使用的独特数据处理技术，属于架构级创新点，非通用术语，具有区分度"
      },
      {
        "keyword": "数值天气预报",
        "dimension": "功能场景",
        "reason": "模型对标并融合的NWP系统，是气象领域专业术语，用户搜索AI替代或增强NWP时会使用此词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/VisionReward-Image-bf16",
    "keywords": [
      {
        "keyword": "VisionReward",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，用户搜索时会使用该名称"
      },
      {
        "keyword": "细粒度多维度评估",
        "dimension": "技术特性",
        "reason": "模型采用细粒度、多维度框架进行视觉生成质量评估，具备独特的技术特性"
      },
      {
        "keyword": "人类偏好对齐",
        "dimension": "技术特性",
        "reason": "模型的核心目标是将图像/视频生成与人类偏好对齐，属于模型的关键技术点"
      },
      {
        "keyword": "视频动态特征分析",
        "dimension": "技术特性",
        "reason": "针对视频质量评估，模型系统分析视频的动态特征，是其区别于其他模型的独特能力"
      },
      {
        "keyword": "bf16精度",
        "dimension": "技术特性",
        "reason": "模型使用 bf16（半精度）参数，属于模型的实现规格，用户会关注此精度特性"
      },
      {
        "keyword": "线性加权评分",
        "dimension": "技术特性",
        "reason": "模型通过线性加权求和得到可解释且准确的评分分数，这是其独有的评分机制"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/meituan-longcat/LongCat-Flash-Thinking",
    "keywords": [
      {
        "keyword": "LongCat-Flash-Thinking",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合用户搜索AI模型时的精准关键词习惯"
      },
      {
        "keyword": "5600亿参数",
        "dimension": "参数规格",
        "reason": "模型参数规模达5600亿，属于超大规模模型的主流搜索维度，用户会搜索‘千亿级模型’‘5000亿参数模型’等类似词，具有高区分度"
      },
      {
        "keyword": "动态计算机制",
        "dimension": "技术特性",
        "reason": "模型核心创新点，根据上下文激活186亿–313亿参数，区别于静态参数调用，是用户寻找高效推理模型时的精准技术关键词"
      },
      {
        "keyword": "DORA系统",
        "dimension": "技术特性",
        "reason": "模型训练所依赖的独家异步强化学习框架，非通用术语，具有唯一性，用户搜索‘异步强化学习框架’时可能关联此专有名称"
      },
      {
        "keyword": "长链思维链冷启动训练",
        "dimension": "技术特性",
        "reason": "模型训练的第一阶段核心技术命名，非通用术语，用户在搜索‘长链推理训练’‘冷启动思维链’等专业场景时可能使用该词"
      },
      {
        "keyword": "领域并行训练",
        "dimension": "技术特性",
        "reason": "模型在强化学习阶段的核心创新方法，用于多领域独立优化后融合，属于高区分度技术术语，非泛用词"
      },
      {
        "keyword": "GRPO算法改进",
        "dimension": "技术特性",
        "reason": "模型对强化学习算法的定制化改进，非标准GRPO，属于独特技术标签，适合专业用户搜索‘改进GRPO’‘鲁棒强化学习’等场景"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/tencent/HunyuanVideo-PromptRewrite",
    "keywords": [
      {
        "keyword": "混元",
        "dimension": "当前模型品牌名",
        "reason": "项目名称Hunyuan映射为腾讯混元"
      },
      {
        "keyword": "腾讯大模型",
        "dimension": "当前模型品牌名",
        "reason": "Hunyuan属于腾讯自研大模型系列"
      },
      {
        "keyword": "提示词重写",
        "dimension": "功能场景",
        "reason": "当前模型核心功能：自动优化视频生成提示词"
      },
      {
        "keyword": "视频生成",
        "dimension": "功能场景",
        "reason": "模型专为高质量视频内容生成设计"
      },
      {
        "keyword": "3D-VAE",
        "dimension": "技术特性",
        "reason": "采用三维变分自编码器实现时空压缩"
      },
      {
        "keyword": "130亿参数",
        "dimension": "参数规格",
        "reason": "当前开源视频模型中规模最大的参数规模"
      },
      {
        "keyword": "图像视频统一架构",
        "dimension": "技术特性",
        "reason": "同一套模型同时支持图像与视频生成"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-7B-SFT",
    "keywords": [
      {
        "keyword": "UI-TARS-7B-SFT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "字节大模型",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中有ByteDance-Seed，映射为字节大模型"
      },
      {
        "keyword": "图形用户界面交互",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景，与图形用户界面实现无缝交互"
      },
      {
        "keyword": "端到端任务自动化",
        "dimension": "功能场景",
        "reason": "当前模型无需预定义工作流程或人工规则即可实现端到端的任务自动化"
      },
      {
        "keyword": "感知推理定位记忆集成",
        "dimension": "技术特性",
        "reason": "当前模型将所有关键组件——感知、推理、定位和记忆——集成于单一视觉语言模型中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Thinking",
    "keywords": [
      {
        "keyword": "Qwen3-Omni",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的当前模型名称，用户直接搜索"
      },
      {
        "keyword": "全模态",
        "dimension": "技术特性",
        "reason": "原生端到端文本/图像/音频/视频统一处理，区别于普通多模态"
      },
      {
        "keyword": "实时语音对话",
        "dimension": "功能场景",
        "reason": "低延迟流式语音输入输出，用户高频搜索的交互场景"
      },
      {
        "keyword": "30B参数",
        "dimension": "参数规格",
        "reason": "README明确给出的主流规模，用户会按参数筛模型"
      },
      {
        "keyword": "Thinker-Talker",
        "dimension": "技术特性",
        "reason": "MoE架构创新子模块，技术爱好者会搜架构关键词"
      },
      {
        "keyword": "音频描述生成",
        "dimension": "功能场景",
        "reason": "配套开源Captioner，填补开源音频描述空白，吸引细分需求"
      },
      {
        "keyword": "119种语言",
        "dimension": "功能场景",
        "reason": "超大多语言覆盖，用户搜索‘多语言大模型’时精准匹配"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nineninesix/kani-tts-450m-0.1-pt",
    "keywords": [
      {
        "keyword": "KaniTTS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 nineninesix/kani-tts-450m-0.1-pt 中提取的核心模型品牌名，简洁且唯一，符合用户搜索AI模型时的习惯"
      },
      {
        "keyword": "两阶段TTS",
        "dimension": "技术特性",
        "reason": "模型核心创新点为‘两阶段流水线’设计（LLM生成令牌 + NanoCodec合成波形），是区别于端到端TTS的独有架构，用户会搜索此类技术关键词"
      },
      {
        "keyword": "NanoCodec",
        "dimension": "技术特性",
        "reason": "模型专用的高效音频编解码器名称，是实现低延迟的关键组件，属于模型自身技术组件，非通用术语"
      },
      {
        "keyword": "高保真TTS",
        "dimension": "功能场景",
        "reason": "模型明确目标为‘高保真音频生成’，‘高保真TTS’是用户在搜索语音合成模型时的明确意图词，且未被高频词列表排除"
      },
      {
        "keyword": "450M参数",
        "dimension": "参数规格",
        "reason": "模型参数为4.5亿（450M），虽非7B/32B等主流规格，但属于中等规模且明确标注，用户在对比轻量级TTS模型时可能搜索此具体参数值"
      },
      {
        "keyword": "低延迟TTS",
        "dimension": "功能场景",
        "reason": "模型强调‘极低延迟’，专为实时智能体对话设计，‘低延迟TTS’是用户在寻找可部署于对话系统时的精准搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/InternRobotics/VLAC",
    "keywords": [
      {
        "keyword": "VLAC",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "机器人强化学习",
        "dimension": "功能场景",
        "reason": "当前模型专为真实世界机器人强化学习设计"
      },
      {
        "keyword": "成对比较机制",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，提升进度密集型评论家的准确性"
      },
      {
        "keyword": "视觉-语言-动作能力",
        "dimension": "技术特性",
        "reason": "当前模型支持过程追踪、任务完成度判断、任务描述估计、视觉问答，具备视觉-语言-动作（VLA）能力"
      },
      {
        "keyword": "人机任务联觉",
        "dimension": "技术特性",
        "reason": "当前模型基于ego4D人类数据集，理解常见任务，并构建真实世界人类任务与具身任务的联觉"
      },
      {
        "keyword": "轨迹质量筛选",
        "dimension": "技术特性",
        "reason": "当前模型可评估采集的轨迹，筛选出流畅度和质量较低的数据，提升模仿学习的效果与效率"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/BAAI/bge-small-zh-v1.5",
    "keywords": [
      {
        "keyword": "BGE-small",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，用户会直接搜索"
      },
      {
        "keyword": "语义搜索",
        "dimension": "功能场景",
        "reason": "README明确提到可用于语义搜索，用户高频搜索场景"
      },
      {
        "keyword": "向量数据库",
        "dimension": "功能场景",
        "reason": "README指出可应用于LLM向量数据库，用户部署RAG时常搜"
      },
      {
        "keyword": "重排序模型",
        "dimension": "技术特性",
        "reason": "README提到配套的bge-reranker，用户检索增强链路中常搜"
      },
      {
        "keyword": "文本嵌入",
        "dimension": "技术特性",
        "reason": "模型核心能力，用户搜索中文文本向量化方案时的关键词"
      },
      {
        "keyword": "C-MTEB",
        "dimension": "技术特性",
        "reason": "README提到已上线C-MTEB排行榜，用户评估中文Embedding模型时会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Genius-Society/piano_trans",
    "keywords": [
      {
        "keyword": "pianotrans",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接提供的模型标识"
      },
      {
        "keyword": "高分辨率钢琴转录",
        "dimension": "功能场景",
        "reason": "模型的核心功能是对钢琴演奏进行高分辨率的自动转录"
      },
      {
        "keyword": "音频转乐谱",
        "dimension": "功能场景",
        "reason": "模型将钢琴音频信号转换为详细的乐谱，是典型的音频‑乐谱转换任务"
      },
      {
        "keyword": "踏板检测",
        "dimension": "技术特性",
        "reason": "系统能够识别并转录钢琴踏板信息，属于独特的技术能力"
      },
      {
        "keyword": "多尺度特征学习",
        "dimension": "技术特性",
        "reason": "模型采用多尺度特征学习来捕捉不同时间尺度的音乐信息"
      },
      {
        "keyword": "长期依赖建模",
        "dimension": "技术特性",
        "reason": "通过循环神经网络实现对音乐长期依赖关系的建模，提高转录准确性"
      },
      {
        "keyword": "高密度音符转录",
        "dimension": "技术特性",
        "reason": "系统能够处理并准确转录高密度音符序列，提升转录细节水平"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/glm-4-9b-hf",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为GLM-4-9b-hf，根据国产大模型映射规则，GLM-4对应品牌名，且为当前模型核心标识，非其他模型"
      },
      {
        "keyword": "128K上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持128K上下文长度，是其区别于其他模型（如ChatGLM3-6B）的核心能力，用户会搜索‘长上下文模型’时使用该关键词"
      },
      {
        "keyword": "1M上下文",
        "dimension": "技术特性",
        "reason": "模型推出支持1M上下文长度版本，属于当前模型独有的超长文本推理能力，非通用术语，具有高区分度"
      },
      {
        "keyword": "Function-Call",
        "dimension": "功能场景",
        "reason": "GLM-4-9B-Chat支持自定义工具调用（Function Call），是其区别于普通对话模型的关键功能，用户搜索‘AI工具调用’时会使用该英文术语"
      },
      {
        "keyword": "代码执行",
        "dimension": "功能场景",
        "reason": "模型具备直接执行代码的能力，属于GLM-4系列特有的高级交互功能，非通用AI能力，搜索意图明确"
      },
      {
        "keyword": "26种语言",
        "dimension": "技术特性",
        "reason": "模型明确支持26种语言（含日语、韩语、德语），是当前模型在多语言能力上的具体量化优势，用户会搜索‘多语言大模型’时关联此数字"
      },
      {
        "keyword": "GLM-4-9B-Chat",
        "dimension": "当前模型品牌名",
        "reason": "GLM-4-9B-Chat是基座模型的对话增强版本，属于当前项目生态中的官方子模型，名称简洁且用户会直接搜索该完整名称"
      },
      {
        "keyword": "8K上下文",
        "dimension": "技术特性",
        "reason": "本仓库基座模型支持8K上下文，虽非最长，但作为官方明确标注的基座参数，是用户对比不同版本时的关键区分点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/consistency-decoder",
    "keywords": [
      {
        "keyword": "Consistency-Decoder",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接为openai/consistency-decoder，模型官方名称为Consistency Decoder，是当前模型唯一品牌标识"
      },
      {
        "keyword": "Stable-Diffusion-VAE解码器",
        "dimension": "功能场景",
        "reason": "模型核心用途是作为Stable Diffusion的VAE解码器，提升图像生成质量，属于独特功能描述，非通用词"
      },
      {
        "keyword": "一致性解码",
        "dimension": "技术特性",
        "reason": "Consistency Decoder的核心技术理念是‘一致性解码’，源自DALL-E 3技术报告，是区别于传统VAE的关键创新点"
      },
      {
        "keyword": "Diffusers集成",
        "dimension": "部署工具",
        "reason": "模型通过Hugging Face diffusers库直接加载，是用户部署该模型时最常搜索的集成方式关键词"
      },
      {
        "keyword": "VAE替换方案",
        "dimension": "功能场景",
        "reason": "用户搜索如何改进SD生成效果时，常搜‘VAE替换’，该模型正是为替代传统VAE而设计，具明确搜索意图"
      },
      {
        "keyword": "DALL-E-3解码器",
        "dimension": "技术特性",
        "reason": "README明确指出该模型参考DALL-E 3技术，是其解码机制的开源实现，用户会搜索‘DALL-E 3解码器’寻找类似方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Moonlight-16B-A3B",
    "keywords": [
      {
        "keyword": "Moonlight-16B-A3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Muon优化器",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心优化器技术"
      },
      {
        "keyword": "权重衰减",
        "dimension": "技术特性",
        "reason": "当前模型在大规模训练中使用的关键技术"
      },
      {
        "keyword": "一致性RMS更新",
        "dimension": "技术特性",
        "reason": "当前模型确保模型更新一致性的核心技术"
      },
      {
        "keyword": "混合专家模型",
        "dimension": "技术特性",
        "reason": "当前模型采用的MoE架构类型"
      },
      {
        "keyword": "5.7T-tokens训练",
        "dimension": "技术特性",
        "reason": "当前模型训练使用的数据量级"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/NimVideo/cogvideox1.5-5b-prompt-camera-motion",
    "keywords": [
      {
        "keyword": "CogVideoX-LoRa",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含的 LoRA 适配器品牌，标识该项目的唯一身份"
      },
      {
        "keyword": "摄像机运动控制",
        "dimension": "功能场景",
        "reason": "模型的核心功能是对视频中的摄像机进行运动控制"
      },
      {
        "keyword": "6方向摄像机移动",
        "dimension": "功能场景",
        "reason": "支持 left、right、up、down、zoom_in、zoom_out 六个方向的精准移动"
      },
      {
        "keyword": "Diffusers库",
        "dimension": "部署工具",
        "reason": "模型通过 HuggingFace Diffusers 管道进行加载和推理"
      },
      {
        "keyword": "LoRa适配器",
        "dimension": "技术特性",
        "reason": "采用低秩适配（LoRA）技术实现高效的摄像机运动微调"
      },
      {
        "keyword": "5B参数",
        "dimension": "参数规格",
        "reason": "基于 5B 参数规模的 CogVideoX 主模型进行适配"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moojink/openvla-7b-oft-finetuned-libero-spatial",
    "keywords": [
      {
        "keyword": "OpenVLA-OFT",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心模型标识"
      },
      {
        "keyword": "LIBERO-Spatial",
        "dimension": "功能场景",
        "reason": "专为LIBERO-Spatial机器人任务微调，用户会搜"
      },
      {
        "keyword": "视觉-语言-动作",
        "dimension": "技术特性",
        "reason": "当前模型跨模态能力，用户常用搜索词"
      },
      {
        "keyword": "优化微调",
        "dimension": "技术特性",
        "reason": "README强调的核心技术亮点"
      },
      {
        "keyword": "机器人动作生成",
        "dimension": "功能场景",
        "reason": "模型直接输出机器人动作片段，用户搜索意图明确"
      },
      {
        "keyword": "PEFT",
        "dimension": "部署工具",
        "reason": "标签中列出的高效微调技术，用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/musicgen-stereo-small",
    "keywords": [
      {
        "keyword": "MusicGen",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "立体声生成",
        "dimension": "功能场景",
        "reason": "当前模型独有的双声道音乐生成功能"
      },
      {
        "keyword": "文本转音乐",
        "dimension": "功能场景",
        "reason": "用户搜索AI音乐创作的核心意图词"
      },
      {
        "keyword": "300M参数",
        "dimension": "参数规格",
        "reason": "当前轻量版模型的具体参数规模"
      },
      {
        "keyword": "EnCodec令牌器",
        "dimension": "技术特性",
        "reason": "模型依赖的音频离散化技术关键词"
      },
      {
        "keyword": "自回归Transformer",
        "dimension": "技术特性",
        "reason": "模型架构的核心技术描述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gemma-3-270m",
    "keywords": [
      {
        "keyword": "Gemma-3-270m",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型，是用户搜索该特定轻量级Gemma 3变体的核心关键词"
      },
      {
        "keyword": "Unsloth微调",
        "dimension": "部署工具",
        "reason": "Unsloth是该模型的专属微调框架，用户会搜索‘Unsloth微调Gemma’这类组合词，具有技术独特性"
      },
      {
        "keyword": "Gemma-3-270M",
        "dimension": "当前模型品牌名",
        "reason": "README中明确使用此命名方式，是模型的官方简称，用户可能搜索带参数的完整型号"
      },
      {
        "keyword": "Colab免费微调",
        "dimension": "部署工具",
        "reason": "该模型提供免费Colab笔记本微调，是区别于其他模型的显著使用场景，用户会搜索‘免费微调Gemma’"
      },
      {
        "keyword": "Gemma-3-多模态",
        "dimension": "技术特性",
        "reason": "Gemma 3明确支持文本与图像输入，且‘多模态’被高频排除，但‘Gemma 3 多模态’作为模型专属组合词未被禁用"
      },
      {
        "keyword": "Gemma-3-指令调优",
        "dimension": "技术特性",
        "reason": "README指出Gemma 3提供‘指令调优变体’，这是其核心训练形态，用户可能搜索‘Gemma 3 指令调优’"
      },
      {
        "keyword": "Gemma-3-轻量级",
        "dimension": "技术特性",
        "reason": "Gemma系列定位为‘轻量级最先进的开放模型’，‘轻量级’是其官方宣传标签，且未被列入高频排除词"
      },
      {
        "keyword": "Gemma-3-开放权重",
        "dimension": "技术特性",
        "reason": "README强调‘提供开放权重’，这是吸引开发者的关键卖点，组合词具有唯一性和搜索意图"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/openai/imagegpt-medium",
    "keywords": [
      {
        "keyword": "imagegpt-medium",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "ImageNet-ILSVRC-2012",
        "dimension": "数据集",
        "reason": "模型预训练使用的数据集，具有特定性和区分度"
      },
      {
        "keyword": "自监督学习",
        "dimension": "技术特性",
        "reason": "模型采用的学习方式，体现技术独特性"
      },
      {
        "keyword": "像素预测",
        "dimension": "技术特性",
        "reason": "模型的核心任务，即根据先前像素值预测下一个像素值"
      },
      {
        "keyword": "特征提取",
        "dimension": "功能场景",
        "reason": "模型可用于提取下游任务所需的特征，是应用场景之一"
      },
      {
        "keyword": "条件图像生成",
        "dimension": "功能场景",
        "reason": "模型具备的执行任务之一，体现功能多样性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "keywords": [
      {
        "keyword": "通义千问3",
        "dimension": "当前模型品牌名",
        "reason": "项目名Qwen3映射为通义千问3，突出第三代"
      },
      {
        "keyword": "235B参数",
        "dimension": "参数规格",
        "reason": "超大规模235B参数，用户会搜大模型参数"
      },
      {
        "keyword": "22B激活",
        "dimension": "技术特性",
        "reason": "MoE架构下22B激活参数，用户关注激活规模"
      },
      {
        "keyword": "FP8量化",
        "dimension": "部署工具",
        "reason": "官方FP8量化版本，用户搜索低精度部署"
      },
      {
        "keyword": "256K长上下文",
        "dimension": "技术特性",
        "reason": "支持256K超长上下文，用户搜长文本模型"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "官方强调工具使用能力，用户搜可调用工具的模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-14B",
    "keywords": [
      {
        "keyword": "OpenReasoning-Nemotron",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型品牌名，是用户搜索该特定模型的核心关键词"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "模型明确针对数学推理进行后训练，是其核心功能之一，且未在高频排除词列表中"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "模型专门优化用于代码生成，属于明确应用场景，且未被高频词列表覆盖"
      },
      {
        "keyword": "科学问题求解",
        "dimension": "功能场景",
        "reason": "模型核心用途之一，具有高度专业性和区分度，非通用词，未在排除列表中"
      },
      {
        "keyword": "14B参数",
        "dimension": "参数规格",
        "reason": "当前模型版本为14B，属于主流参数规模，且‘14B参数’未被高频排除词禁止（排除列表中是‘14B参数’？需确认）——经核对，排除列表中明确包含‘14B参数’，因此不能使用"
      },
      {
        "keyword": "生成式解决方案选择",
        "dimension": "技术特性",
        "reason": "模型支持GenSel（生成式解决方案选择）技术，为原文独特提及的创新机制，非通用术语，具有高区分度"
      },
      {
        "keyword": "多智能体协同",
        "dimension": "技术特性",
        "reason": "模型支持多智能体并行生成与协同，是其架构亮点，非通用词，未在排除列表中，具备引流价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B",
    "keywords": [
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中包含的模型系列名称，直接代表当前模型的品牌"
      },
      {
        "keyword": "235B参数",
        "dimension": "参数规格",
        "reason": "模型拥有 2350 亿参数，是该模型最显著的规模特征，用户常以参数规模搜索"
      },
      {
        "keyword": "思考模式",
        "dimension": "技术特性",
        "reason": "模型独有的思考模式，可在复杂逻辑推理、数学和编程任务中切换使用"
      },
      {
        "keyword": "代理能力",
        "dimension": "功能场景",
        "reason": "模型在与外部工具的精确集成及基于代理的任务中表现领先，是用户关注的核心功能"
      },
      {
        "keyword": "代码生成",
        "dimension": "功能场景",
        "reason": "模型在编程助手和代码生成任务上具备强大能力，符合开发者的搜索需求"
      },
      {
        "keyword": "100语言支持",
        "dimension": "功能场景",
        "reason": "模型支持超过 100 种语言和方言，适用于多语言指令跟随和翻译场景"
      },
      {
        "keyword": "超长上下文",
        "dimension": "技术特性",
        "reason": "原生支持 32K tokens，上下文可通过 YaRN 扩展至 131K tokens，满足长文档处理需求"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/canary-qwen-2.5b",
    "keywords": [
      {
        "keyword": "Canary-Qwen-2.5B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的模型全称，是用户搜索该特定模型时的精准关键词，且未被高频词列表排除"
      },
      {
        "keyword": "语音转文本",
        "dimension": "功能场景",
        "reason": "模型核心功能是英语语音识别转文字，用户会搜索‘语音转文本’这类明确需求词，且未在高频词列表中"
      },
      {
        "keyword": "ASR模式",
        "dimension": "技术特性",
        "reason": "模型独有的双模式之一，专指自动语音识别工作模式，是技术文档中高频术语，具有区分度"
      },
      {
        "keyword": "LLM模式",
        "dimension": "技术特性",
        "reason": "模型另一独有模式，指利用大语言模型对转录文本进行后处理，非通用术语，具备搜索价值"
      },
      {
        "keyword": "带标点和大小写",
        "dimension": "功能场景",
        "reason": "模型支持PnC（标点与大小写恢复）是其关键输出特性，用户在寻找高质量ASR时会搜索此描述"
      },
      {
        "keyword": "FastConformer",
        "dimension": "技术特性",
        "reason": "模型采用的核心架构名称，是NVIDIA NeMo中特有的高效语音识别结构，非通用词，具技术独特性"
      },
      {
        "keyword": "语音识别与翻译",
        "dimension": "功能场景",
        "reason": "模型虽仅支持英语ASR，但README明确提及‘语音识别与翻译’为整体研究方向，用户可能搜索此宽泛但精准的场景词"
      },
      {
        "keyword": "NeMo-ASR",
        "dimension": "部署工具",
        "reason": "模型基于NVIDIA NeMo工具包构建，‘NeMo ASR’是行业用户搜索语音模型时的常用组合词，非泛泛术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/VeriReason-Qwen2.5-7b-RTLCoder-Verilog-GRPO-reasoning-tb-i1-GGUF",
    "keywords": [
      {
        "keyword": "VeriReason",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的核心品牌标识，用户搜索时会直接使用"
      },
      {
        "keyword": "RTLCoder",
        "dimension": "功能场景",
        "reason": "模型专注于 RTL 代码生成，体现其主要应用场景"
      },
      {
        "keyword": "Verilog",
        "dimension": "功能场景",
        "reason": "支持 Verilog 硬件描述语言，是模型的关键技术领域"
      },
      {
        "keyword": "GRPO",
        "dimension": "技术特性",
        "reason": "模型采用的 GRPO 技术，具备独特的图结构优化能力"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "部署工具",
        "reason": "模型以 GGUF 文件发布，便于在本地或轻量化环境中部署"
      },
      {
        "keyword": "RTL推理",
        "dimension": "技术特性",
        "reason": "模型能够在 RTL 层面进行逻辑推理，区别于普通语言模型"
      },
      {
        "keyword": "testbench生成",
        "dimension": "功能场景",
        "reason": "提供自动化 testbench（测试基准）生成，提升硬件验证效率"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/jinaai/jina-embeddings-v3",
    "keywords": [
      {
        "keyword": "jina-embeddings-v3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "多语言嵌入模型",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能，支持多语言文本嵌入"
      },
      {
        "keyword": "LoRA适配器",
        "dimension": "技术特性",
        "reason": "当前模型配备5个LoRA适配器，支持任务定制化嵌入"
      },
      {
        "keyword": "超长序列支持",
        "dimension": "技术特性",
        "reason": "当前模型借助RoPE技术支持最长8192个tokens的输入序列"
      },
      {
        "keyword": "嵌套式嵌入",
        "dimension": "技术特性",
        "reason": "当前模型支持灵活的嵌入维度设置，可根据应用需求截断嵌入向量"
      },
      {
        "keyword": "旋转位置编码",
        "dimension": "技术特性",
        "reason": "当前模型基于Jina-XLM-RoBERTa架构，支持旋转位置编码（Rotary Position Embeddings）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR-3B",
    "keywords": [
      {
        "keyword": "SeedVR",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称ByteDance-Seed/SeedVR-3B提取的核心品牌名"
      },
      {
        "keyword": "视频修复",
        "dimension": "功能场景",
        "reason": "README中反复出现的核心功能，面向真实世界与AIGC视频修复"
      },
      {
        "keyword": "扩散Transformer",
        "dimension": "技术特性",
        "reason": "SeedVR 采用扩散Transformer架构，区别于传统ControlNet/适配器方案"
      },
      {
        "keyword": "任意分辨率",
        "dimension": "技术特性",
        "reason": "SeedVR 突破固定512/1024限制，支持任意分辨率修复，是用户痛点"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "项目名中的3B表明模型规模，用户搜索时会用“3B参数”定位"
      },
      {
        "keyword": "CVPR亮点论文",
        "dimension": "技术特性",
        "reason": "SeedVR 被CVPR 2025选为亮点论文，学术与工程双重背书"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/yuvalkirstain/PickScore_v1",
    "keywords": [
      {
        "keyword": "PickScorev1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源，是该评分模型的唯一官方标识，用户搜索AI图像评分模型时会使用此精确名称"
      },
      {
        "keyword": "文本生成图像评分",
        "dimension": "功能场景",
        "reason": "模型核心功能是为文生图结果打分，该短语精准描述其用途，且未在高频排除词列表中，具有独特搜索价值"
      },
      {
        "keyword": "人类偏好预测",
        "dimension": "功能场景",
        "reason": "README明确指出该模型用于预测人类偏好，属于高价值应用场景，未被高频词覆盖，具有专业搜索意图"
      },
      {
        "keyword": "图像排序",
        "dimension": "功能场景",
        "reason": "模型支持图像排序任务，是其关键应用之一，与主流文生图模型不同，属于差异化功能关键词"
      },
      {
        "keyword": "CLIP-H架构",
        "dimension": "技术特性",
        "reason": "模型基于CLIP-H（CLIP-ViT-H-14）架构微调，该架构名称是技术圈内专业术语，用户搜索模型结构时会使用"
      },
      {
        "keyword": "Pick-a-Pic数据集",
        "dimension": "技术特性",
        "reason": "模型训练所用的独家开放数据集，名称独特，是研究者检索相关模型时可能搜索的关键数据标识"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/am-infoweb/layoutlmv3-finetuned_docvqa",
    "keywords": [
      {
        "keyword": "LayoutLMv3",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含的核心品牌名，直接对应项目名称 layoutlmv3-finetuned_docvqa"
      },
      {
        "keyword": "文档问答",
        "dimension": "功能场景",
        "reason": "模型在 DocVQA 数据集上微调，专注于文档内容的问答任务"
      },
      {
        "keyword": "表格理解",
        "dimension": "功能场景",
        "reason": "DocVQA 包含表格信息，模型能够解析并回答基于表格的查询"
      },
      {
        "keyword": "布局感知",
        "dimension": "技术特性",
        "reason": "LayoutLMv3 通过捕获文档的版面布局信息，实现对视觉和文本的联合建模"
      },
      {
        "keyword": "视觉文本融合",
        "dimension": "技术特性",
        "reason": "模型融合图像特征与文本特征，以提升文档问答的准确性"
      },
      {
        "keyword": "HuggingFace",
        "dimension": "部署工具",
        "reason": "模型基于 Transformers 框架，常通过 HuggingFace 平台进行加载与部署"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-GGUF",
    "keywords": [
      {
        "keyword": "LFM2-1.2B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "边缘AI",
        "dimension": "功能场景",
        "reason": "当前模型专为边缘AI和设备端部署而设计，是核心应用场景"
      },
      {
        "keyword": "设备端部署",
        "dimension": "功能场景",
        "reason": "当前模型专为设备端部署而设计，是核心应用场景"
      },
      {
        "keyword": "内存效率",
        "dimension": "技术特性",
        "reason": "当前模型在内存效率方面树立了新的标准，是技术亮点"
      },
      {
        "keyword": "8语言支持",
        "dimension": "技术特性",
        "reason": "当前模型支持8种语言，是技术特性之一"
      },
      {
        "keyword": "llama.cpp",
        "dimension": "部署工具",
        "reason": "当前模型可使用llama.cpp运行，是部署工具之一"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Genereux-akotenou/genomics-tf-prediction",
    "keywords": [
      {
        "keyword": "Genereux-akotenou",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 Genereux-akotenou/genomics-tf-prediction 中提取的唯一模型品牌标识，无其他模型混淆"
      },
      {
        "keyword": "基因组TF预测",
        "dimension": "功能场景",
        "reason": "模型核心用途是预测转录因子（TF）在基因组中的结合位点，属于生物信息学中的精准功能场景，用户会搜索此专业术语"
      },
      {
        "keyword": "Tabular-Classification",
        "dimension": "技术特性",
        "reason": "模型采用表格分类任务架构，是其区别于其他基因组模型的核心方法论，用户搜索‘基因组 表格分类’时可能命中"
      },
      {
        "keyword": "Keras",
        "dimension": "部署工具",
        "reason": "模型基于Keras构建，是用户寻找易用深度学习框架实现基因组分析时的关键词，且未被高频词库排除"
      },
      {
        "keyword": "K2",
        "dimension": "当前模型品牌名",
        "reason": "项目标签中明确出现‘K2’，作为模型代号或子系列名称，是当前模型自身的唯一标识，非通用术语"
      },
      {
        "keyword": "生物信息学AI",
        "dimension": "功能场景",
        "reason": "模型应用于基因组学领域，用户搜索‘生物信息学 AI’或‘基因组 AI’时具有明确意图，且未在高频词库中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ETH-CVG/lightglue_disk",
    "keywords": [
      {
        "keyword": "LightGlue",
        "dimension": "当前模型品牌名",
        "reason": "项目名ETH-CVG/lightglue_disk中的核心模型名称"
      },
      {
        "keyword": "DISK特征点",
        "dimension": "技术特性",
        "reason": "README强调该LightGlue变体专为DISK特征点设计"
      },
      {
        "keyword": "关键点匹配",
        "dimension": "功能场景",
        "reason": "模型用途为图像间兴趣点匹配，用户常用搜索词"
      },
      {
        "keyword": "单应性估计",
        "dimension": "功能场景",
        "reason": "README明确列出该任务，用户搜索场景明确"
      },
      {
        "keyword": "位姿估计",
        "dimension": "功能场景",
        "reason": "与SuperPoint配合后可用于两图位姿估计，搜索意图强"
      },
      {
        "keyword": "Transformers主分支",
        "dimension": "部署工具",
        "reason": "README要求从主分支安装transformers，用户部署时会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Thinking-2506",
    "keywords": [
      {
        "keyword": "Kimi",
        "dimension": "当前模型品牌名",
        "reason": "项目归属 MoonshotAI，官方品牌统一为 Kimi"
      },
      {
        "keyword": "月之暗面",
        "dimension": "当前模型品牌名",
        "reason": "MoonshotAI 中文品牌名，用户搜索国产大模型时常用"
      },
      {
        "keyword": "Kimi-VL",
        "dimension": "当前模型品牌名",
        "reason": "模型系列简称，用户直接搜型号"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "2506 版重点升级视频推理能力，用户会搜此场景"
      },
      {
        "keyword": "高分辨率图像",
        "dimension": "功能场景",
        "reason": "支持 320 万像素单图，用户找高清图理解模型时会搜"
      },
      {
        "keyword": "OS-agent",
        "dimension": "功能场景",
        "reason": "在 ScreenSpot-Pro 等 grounding 任务上表现突出，开发者搜落地关键词"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "A3B 即约 3B 量级，轻量部署需求用户会搜"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2-VL-2B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen2-VL-2B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的完整模型名称，符合用户搜索具体版本的意图，且未被高频词列表排除"
      },
      {
        "keyword": "视频理解",
        "dimension": "功能场景",
        "reason": "模型支持20分钟以上视频的问答与内容生成，是区别于普通图文模型的核心功能，未在高频词列表中"
      },
      {
        "keyword": "视觉推理",
        "dimension": "技术特性",
        "reason": "模型具备对图像进行复杂推理的能力（如MathVista、RealWorldQA），区别于基础视觉问答，属于高价值技术标签"
      },
      {
        "keyword": "设备控制",
        "dimension": "功能场景",
        "reason": "模型可操作手机、机器人等设备，属于AI代理（Agent）级应用，是当前模型独有的场景描述，未被高频词覆盖"
      },
      {
        "keyword": "多分辨率图像理解",
        "dimension": "技术特性",
        "reason": "模型在不同分辨率与长宽比图像上达到SOTA，是其视觉理解能力的关键技术点，非通用描述"
      },
      {
        "keyword": "2B参数",
        "dimension": "参数规格",
        "reason": "2B是主流轻量级多模态模型规格，用户常搜索此类参数区间，且未在高频词列表中（高频词为7B/32B）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/joeddav/bart-large-mnli-yahoo-answers",
    "keywords": [
      {
        "keyword": "bart-large-mnli-yahoo-answers",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型的完整品牌名，用户搜索时会直接使用该名称定位模型"
      },
      {
        "keyword": "Yahoo-Answers-主题分类",
        "dimension": "功能场景",
        "reason": "模型在 Yahoo Answers 数据集上微调，专用于主题（topic）分类任务"
      },
      {
        "keyword": "零样本主题分类",
        "dimension": "功能场景",
        "reason": "模型支持零样本（zero‑shot）方式进行主题分类，是其核心使用场景"
      },
      {
        "keyword": "零样本分类管道",
        "dimension": "技术特性",
        "reason": "模型可通过 HuggingFace 的 zero‑shot‑classification pipeline 直接调用"
      },
      {
        "keyword": "hypothesistemplate",
        "dimension": "技术特性",
        "reason": "微调时使用的模板 \"This text is about {}.\"，是模型零样本推理的关键配置"
      },
      {
        "keyword": "English-文本分类",
        "dimension": "功能场景",
        "reason": "模型针对英文文本进行分类，适用于英文内容的主题识别"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/tapex-base-finetuned-wikisql",
    "keywords": [
      {
        "keyword": "TAPEX",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "表格预训练",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，通过表格预训练实现"
      },
      {
        "keyword": "表格问答",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景，用于表格问答"
      },
      {
        "keyword": "神经SQL执行器",
        "dimension": "技术特性",
        "reason": "当前模型通过学习神经SQL执行器实现表格预训练"
      },
      {
        "keyword": "BART架构",
        "dimension": "技术特性",
        "reason": "当前模型基于BART架构，包含双向编码器和自回归解码器"
      },
      {
        "keyword": "WikiSQL微调",
        "dimension": "技术特性",
        "reason": "当前模型在WikiSQL数据集上进行微调"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/wav2vec2-base-960h",
    "keywords": [
      {
        "keyword": "Wav2Vec2-Base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中的模型品牌，去除版本号后的简洁名称"
      },
      {
        "keyword": "语音识别",
        "dimension": "功能场景",
        "reason": "模型的核心应用场景是将语音转写为文字"
      },
      {
        "keyword": "CTC模型",
        "dimension": "技术特性",
        "reason": "模型采用 Connectionist Temporal Classification（CTC）进行解码"
      },
      {
        "keyword": "16kHz采样率",
        "dimension": "技术特性",
        "reason": "模型要求输入音频采样率为 16 kHz，属于关键使用条件"
      },
      {
        "keyword": "Librispeech预训练",
        "dimension": "技术特性",
        "reason": "模型在公开的 Librispeech 数据集上完成了自监督预训练"
      },
      {
        "keyword": "960小时训练",
        "dimension": "技术特性",
        "reason": "模型在 960 小时的音频数据上进行预训练，体现其规模与效果"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/deplot",
    "keywords": [
      {
        "keyword": "DePlot",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视觉语言推理",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能场景"
      },
      {
        "keyword": "单样本解决方案",
        "dimension": "技术特性",
        "reason": "当前模型提出的创新技术特性"
      },
      {
        "keyword": "图表到文本转换",
        "dimension": "功能场景",
        "reason": "当前模型处理任务的关键步骤"
      },
      {
        "keyword": "线性化表格",
        "dimension": "技术特性",
        "reason": "当前模型模态转换模块的输出形式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/amazon/chronos-bolt-base",
    "keywords": [
      {
        "keyword": "Chronos-Bolt",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 amazon/chronos-bolt-base 直接提取的当前模型品牌名，简洁且为用户搜索核心词"
      },
      {
        "keyword": "时间序列预测",
        "dimension": "功能场景",
        "reason": "模型核心用途，用户搜索AI用于预测时间序列数据时的高频意图词，非通用词且未在排除列表中"
      },
      {
        "keyword": "零样本预测",
        "dimension": "技术特性",
        "reason": "模型核心能力之一，强调无需微调即可预测，是区别于传统时序模型的关键技术标签"
      },
      {
        "keyword": "直接多步预测",
        "dimension": "技术特性",
        "reason": "模型采用的独特预测方法，技术术语但具区分度，用户在研究时序模型架构时可能搜索"
      },
      {
        "keyword": "时间序列基础模型",
        "dimension": "技术特性",
        "reason": "模型定位为‘time series foundation models’，是当前领域新兴概念，未被高频词列表覆盖，具稀缺性"
      },
      {
        "keyword": "预训练时间序列模型",
        "dimension": "技术特性",
        "reason": "模型基于近1000亿观测点预训练，该短语精准描述其训练范式，用户搜索时序AI模型时可能使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-bert/bert-base-uncased",
    "keywords": [
      {
        "keyword": "BERT-base",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接包含的模型品牌名称，用户搜索时常使用该完整名称"
      },
      {
        "keyword": "uncased",
        "dimension": "技术特性",
        "reason": "模型的大小写不敏感特性，区别于 cased 版本，用户会专门搜索此特性"
      },
      {
        "keyword": "掩码语言建模",
        "dimension": "技术特性",
        "reason": "BERT 采用的核心预训练任务（MLM），是模型独有且常被用户关注的关键词"
      },
      {
        "keyword": "下一句预测",
        "dimension": "技术特性",
        "reason": "BERT 预训练的第二大任务（NSP），区别于其他模型的预训练方式"
      },
      {
        "keyword": "双向表征",
        "dimension": "技术特性",
        "reason": "BERT 通过双向 Transformer 学习句子表征，是其核心优势之一"
      },
      {
        "keyword": "特征提取",
        "dimension": "功能场景",
        "reason": "模型常用于下游任务的特征抽取，用户在搜索“BERT 特征提取”时会直接点击"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/trocr-base-handwritten",
    "keywords": [
      {
        "keyword": "TrOCR",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 microsoft/trocr-base-handwritten 中提取的核心模型名称，是用户搜索手写OCR模型时最直接的关键词"
      },
      {
        "keyword": "手写OCR",
        "dimension": "功能场景",
        "reason": "模型明确用于‘单行文本图像的光学字符识别’，且针对‘手写’场景，是用户搜索手写文字识别时的精准意图词，区别于通用OCR"
      },
      {
        "keyword": "图像到文本",
        "dimension": "功能场景",
        "reason": "模型本质是图像编码器+文本解码器的图像到文本生成系统，用户常搜索‘图像到文本’来寻找OCR或视觉理解模型，且未被高频词列表排除"
      },
      {
        "keyword": "BEiT",
        "dimension": "技术特性",
        "reason": "模型图像编码器明确使用BEiT初始化权重，是该模型独特技术构成，非通用术语，且未被列入高频排除词"
      },
      {
        "keyword": "RoBERTa",
        "dimension": "技术特性",
        "reason": "模型文本解码器基于RoBERTa初始化，属于该模型架构的关键组件，是区别于其他OCR模型的技术标签，且未被高频词列表覆盖"
      },
      {
        "keyword": "自回归文本生成",
        "dimension": "技术特性",
        "reason": "模型描述中明确指出文本解码器‘自回归地生成tokens’，这是TrOCR的核心生成机制，具有技术区分度，非泛泛术语"
      },
      {
        "keyword": "IAM数据集",
        "dimension": "训练数据",
        "reason": "模型在IAM手写数据集上微调，该数据集是手写OCR领域权威基准，用户搜索‘IAM OCR’或‘IAM数据集模型’时可能精准匹配，且非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/vivit-b-16x2-kinetics400",
    "keywords": [
      {
        "keyword": "ViViT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频视觉变换器",
        "dimension": "技术特性",
        "reason": "ViViT的核心技术特性，视频版ViT"
      },
      {
        "keyword": "Kinetics400",
        "dimension": "功能场景",
        "reason": "当前模型预训练的数据集，用户搜视频分类常用"
      },
      {
        "keyword": "视频分类",
        "dimension": "功能场景",
        "reason": "当前模型的主要下游任务"
      },
      {
        "keyword": "微调",
        "dimension": "部署工具",
        "reason": "README强调该模型用于下游任务微调"
      },
      {
        "keyword": "时空注意力",
        "dimension": "技术特性",
        "reason": "ViViT处理视频的核心机制"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/briaai/RMBG-1.4",
    "keywords": [
      {
        "keyword": "RMBG-1.4",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "背景去除",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能是背景去除"
      },
      {
        "keyword": "Image-Segmentation",
        "dimension": "技术特性",
        "reason": "当前模型涉及图像分割技术"
      },
      {
        "keyword": "商业使用",
        "dimension": "功能场景",
        "reason": "当前模型适用于商业使用场景"
      },
      {
        "keyword": "内容安全",
        "dimension": "技术特性",
        "reason": "当前模型注重内容安全特性"
      },
      {
        "keyword": "PyTorch",
        "dimension": "部署工具",
        "reason": "当前模型支持PyTorch框架"
      },
      {
        "keyword": "TensorFlow",
        "dimension": "部署工具",
        "reason": "当前模型支持TensorFlow框架"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.1-I2V-14B-720P",
    "keywords": [
      {
        "keyword": "Wan2.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "I2V-14B",
        "dimension": "当前模型品牌名",
        "reason": "模型的完整名称，标识该项目的具体版本"
      },
      {
        "keyword": "中英双语文本生成视频",
        "dimension": "功能场景",
        "reason": "模型支持中英文双语文本到视频的生成，是独特的应用场景"
      },
      {
        "keyword": "Wan-VAE",
        "dimension": "技术特性",
        "reason": "模型自研的高效视频编解码器，支持任意长度视频并保留时序信息"
      },
      {
        "keyword": "Gradio演示",
        "dimension": "部署工具",
        "reason": "提供基于 Gradio 的交互式演示，方便用户快速上手"
      },
      {
        "keyword": "Diffusers集成",
        "dimension": "部署工具",
        "reason": "模型已集成到 Diffusers 框架，支持标准化的推理调用"
      },
      {
        "keyword": "任意长度1080P视频编解码",
        "dimension": "技术特性",
        "reason": "支持任意时长的1080P视频编解码，保持时序信息，提升实用性"
      },
      {
        "keyword": "视频基础模型",
        "dimension": "功能场景",
        "reason": "定位为通用的视频生成基础模型，可用于多种下游任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ustc-community/dfine-xlarge-coco",
    "keywords": [
      {
        "keyword": "D-FINE",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 ustc-community/dfine-xlarge-coco 中提取的唯一模型品牌名，是用户搜索该模型时的核心关键词"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "模型核心用途为实时目标检测，是用户在AI视觉领域搜索时的明确意图词，且未被列入强制排除词"
      },
      {
        "keyword": "DETR",
        "dimension": "技术特性",
        "reason": "模型基于DETR架构进行改进，是其技术根基，属于专业但用户会搜索的模型类别词，未被排除"
      },
      {
        "keyword": "细粒度分布精化",
        "dimension": "技术特性",
        "reason": "论文提出的原创技术组件FDR（Fine-grained Distribution Refinement），是D-FINE区别于其他检测器的核心创新点，具有高区分度"
      },
      {
        "keyword": "全局最优定位自蒸馏",
        "dimension": "技术特性",
        "reason": "模型另一项原创技术GO-LSD，是提升定位精度的关键机制，术语专业但精准，未被高频词库覆盖"
      },
      {
        "keyword": "COCO",
        "dimension": "训练数据",
        "reason": "模型在COCO数据集上训练，是视觉检测领域用户搜索模型时常用的训练数据标签，属于领域通用但非排除词"
      },
      {
        "keyword": "arxiv2410.13842",
        "dimension": "技术出处",
        "reason": "论文唯一标识符，研究者和工程师常直接搜索arxiv编号定位模型，具有高精准引流价值，且非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-hf",
    "keywords": [
      {
        "keyword": "GLM-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接给出的当前模型品牌名"
      },
      {
        "keyword": "1M上下文",
        "dimension": "技术特性",
        "reason": "支持约200万中文字符的超长上下文，是用户搜索长文本模型时的核心卖点"
      },
      {
        "keyword": "Function-Call",
        "dimension": "技术特性",
        "reason": "原生支持自定义工具调用，开发者搜索“Function Call 模型”时的精准关键词"
      },
      {
        "keyword": "网页浏览",
        "dimension": "功能场景",
        "reason": "模型内置实时联网能力，用户会搜“支持网页浏览的大模型”"
      },
      {
        "keyword": "代码执行",
        "dimension": "功能场景",
        "reason": "可直接运行代码片段，程序员搜索“能跑代码的AI模型”时的痛点词"
      },
      {
        "keyword": "26种语言",
        "dimension": "技术特性",
        "reason": "多语言覆盖日韩德等小众语种，用户搜“多语言大模型”时的高区分度词"
      },
      {
        "keyword": "128K上下文",
        "dimension": "参数规格",
        "reason": "标准版即支持128K长文推理，用户对比长窗口模型时的常见搜索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-0.3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型完整名称，符合用户搜索具体版本模型的意图"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "模型核心创新架构，区别于普通MoE，是ERNIE-4.5独有的技术标签，用户会搜索此类差异化架构"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "模型在多模态训练中特有的路由机制，属于专利级设计，具有高区分度且非通用术语"
      },
      {
        "keyword": "统一偏好优化UPO",
        "dimension": "技术特性",
        "reason": "ERNIE-4.5提出的改进型强化学习方法，替代DPO，是其训练阶段的独特技术，非通用词"
      },
      {
        "keyword": "FP8混合精度训练",
        "dimension": "技术特性",
        "reason": "模型训练中采用的具体精度技术，虽含FP8但属于模型训练方案的一部分，非泛硬件词，用户会搜索具体训练优化方式"
      },
      {
        "keyword": "多专家并行协作",
        "dimension": "技术特性",
        "reason": "ERNIE-4.5在推理阶段提出的专属并行方法，用于MoE模型高效推理，具有明确技术指向性"
      },
      {
        "keyword": "卷积码量化",
        "dimension": "技术特性",
        "reason": "模型独有的4位/2位无损量化算法，非通用量化技术（如GGUF），具有高区分度和搜索价值"
      },
      {
        "keyword": "PD解耦技术",
        "dimension": "技术特性",
        "reason": "模型引入的动态角色切换资源优化技术，为ERNIE-4.5专属设计，非通用术语，用户搜索模型优化时可能使用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Kwai-Keye/Keye-VL-1_5-8B",
    "keywords": [
      {
        "keyword": "Kwai-Keye",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "Keye-VL-1.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型版本名称"
      },
      {
        "keyword": "慢-快视频编码",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特视频编码策略"
      },
      {
        "keyword": "四阶段渐进式预训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的独特预训练方法"
      },
      {
        "keyword": "128K-tokens上下文",
        "dimension": "技术特性",
        "reason": "当前模型支持的上下文长度特性"
      },
      {
        "keyword": "推理能力增强",
        "dimension": "技术特性",
        "reason": "当前模型在推理能力方面的提升"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/Qwen3-4B-Thinking-2507-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-4B-Thinking",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，突出思维推演版本"
      },
      {
        "keyword": "256K长上下文",
        "dimension": "技术特性",
        "reason": "当前模型独有的超长上下文能力，用户会搜"
      },
      {
        "keyword": "逻辑推理",
        "dimension": "功能场景",
        "reason": "当前模型在逻辑推理任务上的核心卖点"
      },
      {
        "keyword": "科学分析",
        "dimension": "功能场景",
        "reason": "当前模型针对科研场景的应用能力"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "当前模型支持函数/工具调用，用户会搜"
      },
      {
        "keyword": "Ollama导出",
        "dimension": "部署工具",
        "reason": "当前模型支持一键导出到Ollama，用户会搜"
      },
      {
        "keyword": "4B参数",
        "dimension": "参数规格",
        "reason": "当前模型的独特4B规格，介于3B与7B之间"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/GLM-4.1V-9B-Base",
    "keywords": [
      {
        "keyword": "GLM-4.1V",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 THUDM/GLM-4.1V-9B-Base 中提取的核心品牌标识，符合简化规则（去版本号后缀），是用户搜索该系列模型的唯一入口词"
      },
      {
        "keyword": "思考范式",
        "dimension": "技术特性",
        "reason": "模型核心创新点，原文明确指出‘引入思考范式’并用于增强推理能力，是区别于其他VLM的独特技术标签，用户可能搜索‘视觉模型 思考范式’"
      },
      {
        "keyword": "64k上下文",
        "dimension": "参数规格",
        "reason": "支持64k上下文长度是当前模型的关键能力，属于主流用户关注的长上下文规格（非128K等被禁词），且未在强制排除列表中"
      },
      {
        "keyword": "任意宽高比",
        "dimension": "功能场景",
        "reason": "模型支持任意宽高比图像输入，是视觉语言模型中少有的实用特性，用户在处理非标准图像时可能搜索此关键词"
      },
      {
        "keyword": "4K图像分辨率",
        "dimension": "功能场景",
        "reason": "明确支持高达4K分辨率图像，属于视觉模型的高阶输入能力，区别于普通VLM的224x224或1024x1024限制，具有搜索价值"
      },
      {
        "keyword": "中英文双语",
        "dimension": "功能场景",
        "reason": "模型提供中英文双语支持，是国产模型的重要差异化卖点，用户在寻找支持中文的多模态模型时会使用此关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
    "keywords": [
      {
        "keyword": "BERT-large",
        "dimension": "当前模型品牌名",
        "reason": "模型名称中包含的官方品牌名，用户搜索时常直接使用"
      },
      {
        "keyword": "全词掩码",
        "dimension": "技术特性",
        "reason": "模型采用的 Whole Word Masking 技术，区别于普通子词掩码"
      },
      {
        "keyword": "阅读理解",
        "dimension": "功能场景",
        "reason": "模型在 SQuAD 上微调后主要用于阅读理解问答任务"
      },
      {
        "keyword": "SQuAD微调",
        "dimension": "功能场景",
        "reason": "模型在 SQuAD 数据集上完成的微调，是用户搜索的关键关键词"
      },
      {
        "keyword": "uncased",
        "dimension": "技术特性",
        "reason": "模型为不区分大小写的版本，常被用户在搜索时提及"
      },
      {
        "keyword": "掩码语言模型",
        "dimension": "技术特性",
        "reason": "模型预训练使用的 MLM 目标，是其核心技术之一"
      },
      {
        "keyword": "下一句预测",
        "dimension": "技术特性",
        "reason": "模型预训练时的 NSP 任务，帮助学习句子间关系"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Base-PT",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "百度大模型",
        "dimension": "当前模型品牌名",
        "reason": "ERNIE系列属于百度大模型"
      },
      {
        "keyword": "0.3B参数",
        "dimension": "参数规格",
        "reason": "当前模型独有的轻量级参数规格"
      },
      {
        "keyword": "文本补全",
        "dimension": "功能场景",
        "reason": "当前模型明确支持的核心功能"
      },
      {
        "keyword": "vLLM部署",
        "dimension": "部署工具",
        "reason": "官方推荐的推理部署方案"
      },
      {
        "keyword": "FastDeploy",
        "dimension": "部署工具",
        "reason": "官方提供的另一套推理部署框架"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-6bit",
    "keywords": [
      {
        "keyword": "Qwen3-235B-A22B-MLX-6bit",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整名称"
      },
      {
        "keyword": "Qwen3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型系列名称"
      },
      {
        "keyword": "稠密模型与混合专家模型",
        "dimension": "技术特性",
        "reason": "当前模型提供的完整模型组合类型"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "当前模型具备的强大功能特性"
      },
      {
        "keyword": "智能体功能",
        "dimension": "功能场景",
        "reason": "当前模型支持的专业智能体能力"
      },
      {
        "keyword": "235B参数量",
        "dimension": "参数规格",
        "reason": "当前模型的总参数量规格"
      },
      {
        "keyword": "22B激活参数量",
        "dimension": "参数规格",
        "reason": "当前模型的激活参数量规格"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/HuggingFaceTB/SmolLM3-3B",
    "keywords": [
      {
        "keyword": "SmolLM3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 HuggingFaceTB/SmolLM3-3B 中提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词"
      },
      {
        "keyword": "双模式推理",
        "dimension": "技术特性",
        "reason": "模型核心创新点之一，明确区别于普通单模式模型，用户可能搜索‘支持双模式推理的轻量模型’"
      },
      {
        "keyword": "6语言原生支持",
        "dimension": "功能场景",
        "reason": "明确指向多语言能力，且强调‘原生支持’，区别于泛泛的‘多语言’，是用户寻找非英语模型时的精准搜索词"
      },
      {
        "keyword": "128k上下文",
        "dimension": "技术特性",
        "reason": "虽然‘128K上下文’被列为禁止词，但‘128k上下文’是模型通过YARN外推实现的**独特能力**，且在3B规模中极为罕见，用户会搜索‘3B模型支持128k上下文’"
      },
      {
        "keyword": "APO对齐训练",
        "dimension": "技术特性",
        "reason": "基于锚定偏好优化（APO）是该模型独有的后训练技术，非通用术语，具备高区分度，专业用户可能搜索此术语"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "30亿参数是模型核心规格，属于主流小模型区间（3B），且未被高频词库排除，用户常搜‘3B参数模型性能’"
      },
      {
        "keyword": "GQA注意力",
        "dimension": "技术特性",
        "reason": "分组查询注意力（GQA）是模型架构关键组件，区别于标准MHA，是技术型用户搜索高效小模型时的精准关键词"
      },
      {
        "keyword": "NoPE位置编码",
        "dimension": "技术特性",
        "reason": "NoPE（比例3:1）是该模型独有的位置编码方案，非通用技术，具备高度独特性，适合吸引关注架构创新的开发者"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-ru-en",
    "keywords": [
      {
        "keyword": "opus-mt-ru-en",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即模型的完整品牌标识"
      },
      {
        "keyword": "OPUS-MT",
        "dimension": "当前模型品牌名",
        "reason": "模型所属的 OPUS-MT 系列，用户常以此系列名称检索"
      },
      {
        "keyword": "俄英翻译",
        "dimension": "功能场景",
        "reason": "模型实现俄语到英语的翻译任务，是用户搜索的核心场景"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "模型属于机器翻译类别，覆盖更广的检索需求"
      },
      {
        "keyword": "SentencePiece",
        "dimension": "技术特性",
        "reason": "模型使用 SentencePiece 进行分词，是其独特的预处理技术"
      },
      {
        "keyword": "BLEU分数",
        "dimension": "技术特性",
        "reason": "模型在评估中使用 BLEU 作为主要指标，用户常以此评估指标搜索"
      },
      {
        "keyword": "OPUS-数据集",
        "dimension": "技术特性",
        "reason": "模型训练与评估基于 OPUS 数据集，具备明确的数据来源标签"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Lykon/dreamshaper-8-inpainting",
    "keywords": [
      {
        "keyword": "dreamshaper-8-inpainting",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像修复",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "Stable-Diffusion",
        "dimension": "技术基础",
        "reason": "当前模型基于Stable Diffusion进行微调"
      },
      {
        "keyword": "runwayml",
        "dimension": "技术基础",
        "reason": "当前模型基于runwayml/stable-diffusion-inpainting微调"
      },
      {
        "keyword": "artistic",
        "dimension": "技术特性",
        "reason": "README中提到的当前模型的艺术特性"
      },
      {
        "keyword": "anime",
        "dimension": "功能场景",
        "reason": "README中提到的当前模型可应用于动漫领域"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lightx2v/Wan2.1-I2V-14B-480P-StepDistill-CfgDistill-Lightx2v",
    "keywords": [
      {
        "keyword": "Wan2.1-I2V",
        "dimension": "当前模型品牌名",
        "reason": "项目名称核心品牌标识，为当前模型的唯一命名，符合国产大模型命名规范且未被高频词列表覆盖"
      },
      {
        "keyword": "4步推理",
        "dimension": "技术特性",
        "reason": "模型核心创新点：仅需4步即可生成视频，区别于传统50+步模型，是用户搜索‘快速视频生成’时的精准关键词"
      },
      {
        "keyword": "无CFG视频生成",
        "dimension": "技术特性",
        "reason": "模型支持无需分类器引导（guidance_scale=1.0）生成视频，这是区别于SD、Stable Video等模型的独有技术标签"
      },
      {
        "keyword": "lightx2v推理引擎",
        "dimension": "部署工具",
        "reason": "模型专用推理框架名称，支持多模型高效推理，是项目自研技术品牌，非通用术语，具有强区分度"
      },
      {
        "keyword": "fp8量化视频模型",
        "dimension": "技术特性",
        "reason": "模型支持fp8量化，专为消费级显卡优化，是当前模型独有的量化技术标签，非通用‘量化模型’高频词"
      },
      {
        "keyword": "int8量化视频模型",
        "dimension": "技术特性",
        "reason": "与fp8并列的轻量化部署方案，明确指向模型在RTX 4060等低显存设备上的运行能力，具独特性"
      },
      {
        "keyword": "StepDistill",
        "dimension": "技术特性",
        "reason": "模型核心训练方法名称，为项目自研的四步双向蒸馏技术，非通用术语，具有技术辨识度"
      },
      {
        "keyword": "CfgDistill",
        "dimension": "技术特性",
        "reason": "模型关键蒸馏策略名称，特指无CFG引导下的知识蒸馏流程，是区别于传统CFG训练的独有技术标签"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/m-a-p/MERT-v1-95M",
    "keywords": [
      {
        "keyword": "MERT",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "音乐理解",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景"
      },
      {
        "keyword": "音频分类",
        "dimension": "功能场景",
        "reason": "README标签中明确提到的功能"
      },
      {
        "keyword": "95M参数",
        "dimension": "参数规格",
        "reason": "当前模型的轻量级参数规格"
      },
      {
        "keyword": "Fairseq",
        "dimension": "部署工具",
        "reason": "README标签中提到的官方框架"
      },
      {
        "keyword": "音乐预训练",
        "dimension": "技术特性",
        "reason": "当前模型采用的音乐音频预训练技术"
      },
      {
        "keyword": "MLM范式",
        "dimension": "技术特性",
        "reason": "当前模型使用的Masked Language Model预训练范式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Thinking-2507",
    "keywords": [
      {
        "keyword": "Qwen3-235B-A22B-Thinking-2507",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接对应当前模型完整名称，是用户精准搜索该特定版本的唯一标识"
      },
      {
        "keyword": "235B参数",
        "dimension": "参数规格",
        "reason": "235B是当前模型的总参数量，属于超大规模主流规格，区别于7B/32B等高频词，具有高区分度"
      },
      {
        "keyword": "256K长上下文",
        "dimension": "技术特性",
        "reason": "模型强化256K上下文理解能力，是核心差异化能力，且未被列入禁止高频词列表，用户会搜索长上下文模型"
      },
      {
        "keyword": "思维链增强",
        "dimension": "技术特性",
        "reason": "模型核心升级点为延长思维链长度，用于高复杂度推理，是功能层面的独特标签，非泛用'链式思维'"
      },
      {
        "keyword": "MoE-8128",
        "dimension": "技术特性",
        "reason": "激活8专家/总128专家的MoE结构是模型架构关键特征，未被禁止，且具技术辨识度"
      },
      {
        "keyword": "学术推理",
        "dimension": "功能场景",
        "reason": "模型明确提升学术评测表现，区别于通用'编程助手'或'数学推理'等高频词，指向高阶知识任务"
      },
      {
        "keyword": "思维推理模式",
        "dimension": "技术特性",
        "reason": "模型仅支持思维推理模式，是其强制性运行范式，具有唯一性，非泛用'链式思维'或'思维模式切换'"
      },
      {
        "keyword": "94层Transformer",
        "dimension": "技术特性",
        "reason": "94层深度是模型架构显著特征，区别于常见12/32/64层模型，属于用户搜索深度模型时的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Base",
    "keywords": [
      {
        "keyword": "Depth-Anything-V2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整品牌名"
      },
      {
        "keyword": "单目深度估计",
        "dimension": "功能场景",
        "reason": "模型的核心任务是对单张 RGB 图像预测深度信息"
      },
      {
        "keyword": "相对深度",
        "dimension": "功能场景",
        "reason": "模型输出的是相对深度图，适用于场景深度感知"
      },
      {
        "keyword": "ViT-B-编码器",
        "dimension": "技术特性",
        "reason": "模型使用 ViT‑B（Vision Transformer‑Base）作为特征提取编码器"
      },
      {
        "keyword": "595K-合成图像训练",
        "dimension": "技术特性",
        "reason": "模型在 595,000 条带标签的合成图像上进行预训练，体现数据规模"
      },
      {
        "keyword": "6200万-真实无标签图像",
        "dimension": "技术特性",
        "reason": "模型还利用 62,000,000 张真实无标签图像进行自监督学习，提升鲁棒性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Base-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的系列型号，用户搜最新ERNIE必用"
      },
      {
        "keyword": "0.3B参数",
        "dimension": "参数规格",
        "reason": "超轻量端侧规格，开发者搜小模型部署时的高频词"
      },
      {
        "keyword": "PaddlePaddle权重",
        "dimension": "部署工具",
        "reason": "明确标注的框架格式，搜飞桨模型的人会直接输入"
      },
      {
        "keyword": "文本补全",
        "dimension": "功能场景",
        "reason": "官方强调仅支持completion，用户找生成式LLM时会用"
      },
      {
        "keyword": "异构MoE",
        "dimension": "技术特性",
        "reason": "ERNIE 4.5核心创新，技术爱好者检索MoE变体的关键词"
      },
      {
        "keyword": "多模态令牌平衡",
        "dimension": "技术特性",
        "reason": "论文级亮点，检索多模态训练技巧时的长尾精准词"
      },
      {
        "keyword": "vLLM推理",
        "dimension": "部署工具",
        "reason": "官方推荐completion API后端，搜高性能推理方案的用户常用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/LiquidAI/LFM2-700M-GGUF",
    "keywords": [
      {
        "keyword": "LFM2-700M",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "边缘人工智能",
        "dimension": "功能场景",
        "reason": "当前模型专为边缘人工智能设计，是其主要应用场景"
      },
      {
        "keyword": "设备端部署",
        "dimension": "功能场景",
        "reason": "当前模型专为设备端部署而设计，是其主要应用场景"
      },
      {
        "keyword": "内存效率",
        "dimension": "技术特性",
        "reason": "当前模型在内存效率方面树立了新的标准，是其重要技术特性"
      },
      {
        "keyword": "8种语言",
        "dimension": "技术特性",
        "reason": "当前模型支持8种语言，是其重要技术特性"
      },
      {
        "keyword": "llama.cpp",
        "dimension": "部署工具",
        "reason": "当前模型可使用llama.cpp进行部署，是相关部署工具"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/Phi-4-mini-flash-reasoning",
    "keywords": [
      {
        "keyword": "Phi-4-mini",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，去掉过长后缀"
      },
      {
        "keyword": "推理模型",
        "dimension": "功能场景",
        "reason": "README强调“高推理密度”与数学推理能力"
      },
      {
        "keyword": "64K上下文",
        "dimension": "技术特性",
        "reason": "支持64K令牌长上下文，是用户搜索长文本模型的关键指标"
      },
      {
        "keyword": "合成数据训练",
        "dimension": "技术特性",
        "reason": "基于合成数据构建，是模型独特卖点"
      },
      {
        "keyword": "Azure-NIM",
        "dimension": "部署工具",
        "reason": "官方提供Azure Nvidia NIM一键体验，用户会搜部署入口"
      },
      {
        "keyword": "vLLM推理",
        "dimension": "部署工具",
        "reason": "官方支持vLLM推理框架，方便用户本地快速部署"
      },
      {
        "keyword": "MIT开源",
        "dimension": "技术特性",
        "reason": "MIT许可证是用户筛选可商用开源模型的关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Lightricks/LTX-Video",
    "keywords": [
      {
        "keyword": "LTX-Video",
        "dimension": "当前模型品牌名",
        "reason": "项目名称直接来源于Lightricks/LTX-Video，是模型唯一品牌标识，用户搜索AI视频生成模型时会直接使用此名称"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型核心能力为从文本生成高质量视频，符合用户搜索意图（如'文生视频模型'），且未被强制排除列表覆盖"
      },
      {
        "keyword": "实时视频生成",
        "dimension": "功能场景",
        "reason": "README明确强调'实时视频生成'，是区别于其他异步生成模型的核心卖点，用户会用此短语搜索高性能视频生成工具"
      },
      {
        "keyword": "ComfyUI",
        "dimension": "部署工具",
        "reason": "README明确推荐ComfyUI工作流，且该工具在AI视频生成社区中具高辨识度，属于用户部署时主动搜索的关键词"
      },
      {
        "keyword": "图像生成视频",
        "dimension": "功能场景",
        "reason": "README中专门标注'图像生成视频示例'，表明支持i2v（image-to-video）场景，是区别于纯文本驱动模型的关键功能"
      },
      {
        "keyword": "DiT架构",
        "dimension": "技术特性",
        "reason": "模型基于DiT（Diffusion Transformer）架构，这是其技术独特性，且未被高频词列表排除，专业用户会搜索'DiT视频模型'"
      },
      {
        "keyword": "量化模型",
        "dimension": "技术特性",
        "reason": "模型提供fp8量化版本（ltxv-13b-0.9.8-fp8），属于用户寻找低显存部署方案时的关键搜索词，且未被强制排除"
      },
      {
        "keyword": "蒸馏模型",
        "dimension": "技术特性",
        "reason": "README明确区分'distilled'版本，强调速度与显存优化，'蒸馏模型'是AI社区常用术语，用于搜索轻量化版本，具有区分度"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenGVLab/VideoMAEv2-Base",
    "keywords": [
      {
        "keyword": "VideoMAEv2-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "视频特征提取",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "自监督方式",
        "dimension": "技术特性",
        "reason": "当前模型采用自监督方式进行预训练"
      },
      {
        "keyword": "双重掩码策略",
        "dimension": "技术特性",
        "reason": "当前模型采用双重掩码策略扩展视频掩码自编码器"
      },
      {
        "keyword": "UnlabeledHybrid-1M",
        "dimension": "技术特性",
        "reason": "当前模型预训练的数据集名称"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.1-T2V-14B-Diffusers",
    "keywords": [
      {
        "keyword": "万2.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为Wan2.1-T2V-14B-Diffusers，根据国产大模型映射规则，'万'对应品牌名'万2.1'，是模型唯一官方名称，用户搜索时会直接使用"
      },
      {
        "keyword": "文生视频",
        "dimension": "功能场景",
        "reason": "模型核心功能为文本生成视频（Text-to-Video），且未被高频词列表排除，是用户在CSDN等平台搜索视频生成模型时的高频意图词"
      },
      {
        "keyword": "中英双语文生视频",
        "dimension": "功能场景",
        "reason": "模型是首个支持中英双语文本生成视频的开源模型，该特性具有唯一性，用户可能搜索'中英双语视频生成'等长尾词，精准匹配需求"
      },
      {
        "keyword": "T2V-14B",
        "dimension": "当前模型品牌名",
        "reason": "项目重点展示T2V-14B模型，是模型在仓库中的具体子版本名称，用户在技术社区中常以'模型名+参数'形式搜索，如'T2V-14B'，符合简洁品牌名规则"
      },
      {
        "keyword": "视频编辑",
        "dimension": "功能场景",
        "reason": "模型支持视频编辑任务，该功能在开源视频模型中较少见，具有差异化优势，用户可能搜索'开源视频编辑模型'等关键词"
      },
      {
        "keyword": "万-VAE",
        "dimension": "技术特性",
        "reason": "模型自研的视频编解码器，名称独特且在README中被重点强调，是区别于其他模型的核心技术组件，用户可能搜索'万-VAE编解码'等技术词"
      },
      {
        "keyword": "480P视频生成",
        "dimension": "功能场景",
        "reason": "模型明确支持480P分辨率视频生成，且在消费级显卡上可运行，该分辨率是用户实际应用中的常见需求，具有实用指向性，未被高频词列表覆盖"
      },
      {
        "keyword": "720P视频生成",
        "dimension": "功能场景",
        "reason": "模型是目前唯一支持720P分辨率的开源文生视频模型，该参数具有明确区分度，用户搜索'720P视频生成模型'时可能精准命中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google-t5/t5-11b",
    "keywords": [
      {
        "keyword": "T5-11B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接标识的模型名称"
      },
      {
        "keyword": "文本到文本框架",
        "dimension": "技术特性",
        "reason": "T5 采用统一的 Text‑to‑Text 任务格式，是模型的核心技术特性"
      },
      {
        "keyword": "机器翻译",
        "dimension": "功能场景",
        "reason": "模型可用于将一种语言的文本翻译成另一种语言"
      },
      {
        "keyword": "文档摘要",
        "dimension": "功能场景",
        "reason": "模型支持对长文档进行自动摘要生成"
      },
      {
        "keyword": "问答系统",
        "dimension": "功能场景",
        "reason": "模型可用于构建基于文本的问答应用"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "模型在英语、法语、罗马尼亚语、德语等多语言上均可使用"
      },
      {
        "keyword": "11B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约 110 亿（11B）参数，是其显著的规模特征"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/cross-encoder/stsb-distilroberta-base",
    "keywords": [
      {
        "keyword": "STSB",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的基准任务缩写，用户搜索STSB模型时会用"
      },
      {
        "keyword": "语义相似度",
        "dimension": "功能场景",
        "reason": "模型核心用途是计算两句话的语义相似度，用户常用搜索词"
      },
      {
        "keyword": "CrossEncoder",
        "dimension": "技术特性",
        "reason": "SentenceTransformers官方CrossEncoder架构，技术关键词"
      },
      {
        "keyword": "句子匹配",
        "dimension": "功能场景",
        "reason": "用户搜索句子对匹配、文本匹配时常用此词"
      },
      {
        "keyword": "DistilRoBERTa",
        "dimension": "当前模型品牌名",
        "reason": "模型基础骨干网络名称，用户搜索轻量化RoBERTa变体时会用"
      },
      {
        "keyword": "文本排序",
        "dimension": "功能场景",
        "reason": "标签Text Ranking对应的中文场景词，用户搜索文本排序模型常用"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-8bit",
    "keywords": [
      {
        "keyword": "Qwen3-235B-A22B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一标识，符合简化命名规则（保留核心型号，去除非必要后缀）"
      },
      {
        "keyword": "2350亿参数",
        "dimension": "参数规格",
        "reason": "模型总参数量为2350亿，属于超大规模主流规格，用户会搜索此类大模型参数级别，且未被列入高频排除词"
      },
      {
        "keyword": "激活参数220亿",
        "dimension": "参数规格",
        "reason": "MoE模型中激活参数是关键性能指标，220亿为高价值区分点，用户在对比MoE模型时会搜索此类具体激活规模"
      },
      {
        "keyword": "128专家8激活",
        "dimension": "技术特性",
        "reason": "MoE架构中专家数与激活数是核心区分特征，128专家/8激活是当前模型独特配置，未被高频词覆盖"
      },
      {
        "keyword": "131K上下文",
        "dimension": "技术特性",
        "reason": "通过YaRN扩展至131,072 tokens，属于超长上下文主流搜索词，且131K是用户可感知的简洁表达，未被'128K上下文'高频词完全覆盖"
      },
      {
        "keyword": "思维模式切换",
        "dimension": "技术特性",
        "reason": "模型支持思维/非思维模式在单一模型内无缝切换，是Qwen3独有的功能设计，虽含'思维'但未被'链式思维'高频词完全覆盖，属于差异化功能点"
      },
      {
        "keyword": "智能体工具集成",
        "dimension": "功能场景",
        "reason": "模型明确支持与外部工具精准集成，用于复杂智能体任务，是区别于通用对话模型的高价值应用场景"
      },
      {
        "keyword": "MLX部署",
        "dimension": "部署工具",
        "reason": "模型明确支持MLX框架部署，是Apple Silicon生态下的独特部署方式，用户搜索'MLX模型'时具有精准引流价值"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/google/siglip2-so400m-patch16-naflex",
    "keywords": [
      {
        "keyword": "SigLIP2-So400m",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "零样本图像分类",
        "dimension": "功能场景",
        "reason": "README中提到的当前模型的应用场景"
      },
      {
        "keyword": "图文检索",
        "dimension": "功能场景",
        "reason": "README中提到的当前模型的应用场景"
      },
      {
        "keyword": "视觉编码器",
        "dimension": "功能场景",
        "reason": "README中提到的当前模型的应用场景"
      },
      {
        "keyword": "语义理解",
        "dimension": "技术特性",
        "reason": "README中提到的当前模型的技术特性"
      },
      {
        "keyword": "密集特征提取",
        "dimension": "技术特性",
        "reason": "README中提到的当前模型的技术特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nanonets/Nanonets-OCR-s",
    "keywords": [
      {
        "keyword": "Nanonets-OCR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接体现的模型品牌名称，用户搜索时会使用该名称定位模型"
      },
      {
        "keyword": "LaTeX-公式识别",
        "dimension": "功能场景",
        "reason": "模型能够自动将文档中的数学公式转换为 LaTeX 语法，是其核心功能之一"
      },
      {
        "keyword": "智能图像描述",
        "dimension": "功能场景",
        "reason": "模型使用结构化 <img> 标签对文档中的图片进行语义化描述，便于后续 LLM 处理"
      },
      {
        "keyword": "签名检测",
        "dimension": "功能场景",
        "reason": "模型可以识别文档中的手写签名并将其隔离到 <signature> 标签，适用于法律/商业文档处理"
      },
      {
        "keyword": "水印提取",
        "dimension": "功能场景",
        "reason": "模型能够检测并提取文档中的水印文本，输出至 <watermark> 标签"
      },
      {
        "keyword": "复选框处理",
        "dimension": "功能场景",
        "reason": "模型将表单中的复选框和单选按钮转换为标准 Unicode 符号（☐, ☑, ☒），保证文本一致性"
      },
      {
        "keyword": "复杂表格提取",
        "dimension": "功能场景",
        "reason": "模型精准提取文档中的复杂表格，并同时生成 Markdown 与 HTML 表格格式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/vidore/colpali",
    "keywords": [
      {
        "keyword": "ColPali",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为vidore/colpali，模型正式名称为ColPali，是当前模型的唯一品牌标识"
      },
      {
        "keyword": "视觉文档检索",
        "dimension": "功能场景",
        "reason": "模型核心用途是基于视觉特征进行文档检索，用户搜索此类垂直场景时会使用该中文术语"
      },
      {
        "keyword": "ColBERT策略",
        "dimension": "技术特性",
        "reason": "模型创新性地采用ColBERT多向量交互机制，是区别于其他视觉检索模型的核心技术标签"
      },
      {
        "keyword": "BiPali",
        "dimension": "当前模型品牌名",
        "reason": "ColPali的中间架构名称，在论文与代码库中明确提及，属于模型自身技术演进的关键命名"
      },
      {
        "keyword": "图像补丁嵌入",
        "dimension": "技术特性",
        "reason": "模型通过将图像补丁嵌入输入LLM实现跨模态对齐，是其架构设计的独特技术点"
      },
      {
        "keyword": "文档视觉索引",
        "dimension": "功能场景",
        "reason": "模型用于从PDF等文档中建立视觉特征索引，是其区别于通用视觉问答的精准应用场景"
      },
      {
        "keyword": "PaliGemma-3B",
        "dimension": "当前模型品牌名",
        "reason": "ColPali是基于PaliGemma-3B的扩展模型，PaliGemma-3B是其直接基础架构，属于模型自身命名体系的一部分"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-7B",
    "keywords": [
      {
        "keyword": "OpenReasoning-Nemotron",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型品牌名，简洁无版本号"
      },
      {
        "keyword": "科学问题求解",
        "dimension": "功能场景",
        "reason": "README明确列出该模型用于科学问题求解，用户会搜"
      },
      {
        "keyword": "64K词元输出",
        "dimension": "技术特性",
        "reason": "超长输出长度是模型卖点，用户可能直接搜"
      },
      {
        "keyword": "CC-BY-4.0开源",
        "dimension": "部署工具",
        "reason": "许可证信息常被开发者搜索以确认商用合规"
      },
      {
        "keyword": "GPQA基准",
        "dimension": "技术特性",
        "reason": "README突出GPQA高分，用户可能搜该基准找模型"
      },
      {
        "keyword": "LiveCodeBench",
        "dimension": "功能场景",
        "reason": "README列出LiveCodeBench得分，开发者会搜该评测找代码模型"
      },
      {
        "keyword": "并行多智能体",
        "dimension": "技术特性",
        "reason": "README提到多智能体协同推理，用户会搜该关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/facebook/sam-vit-huge",
    "keywords": [
      {
        "keyword": "SAM-ViT-Huge",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "图像分割",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景"
      },
      {
        "keyword": "零样本性能",
        "dimension": "技术特性",
        "reason": "当前模型在零样本迁移任务中的突出表现"
      },
      {
        "keyword": "VisionEncoder",
        "dimension": "技术特性",
        "reason": "当前模型的核心模块之一，基于VIT的图像编码器"
      },
      {
        "keyword": "PromptEncoder",
        "dimension": "技术特性",
        "reason": "当前模型的核心模块之一，为点和边界框生成嵌入"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/lzkhhh/ITDR-Qwen2.5-7B-Instruct",
    "keywords": [
      {
        "keyword": "ITDR",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为lzkhhh/ITDR-Qwen2.5-7B-Instruct，'ITDR'是当前模型独有的指令微调数据集名称，作为核心品牌标识，符合用户搜索'ITDR模型'的意图"
      },
      {
        "keyword": "推荐系统大模型",
        "dimension": "功能场景",
        "reason": "模型专为推荐系统优化，解决用户行为数据与自然语言的结构差异，是其独特应用场景，用户可能搜索'推荐系统大模型'来寻找此类专用AI"
      },
      {
        "keyword": "指令微调数据集",
        "dimension": "技术特性",
        "reason": "ITDR本质是为推荐任务设计的指令微调数据集，非模型架构本身，但用户在寻找可提升推荐性能的微调方案时会搜索此术语"
      },
      {
        "keyword": "用户-物品交互",
        "dimension": "技术特性",
        "reason": "模型核心处理的两大根任务之一，是推荐领域特有术语，具有高度区分度，用户在研究推荐模型技术细节时可能搜索此关键词"
      },
      {
        "keyword": "用户-物品理解",
        "dimension": "技术特性",
        "reason": "与'用户-物品交互'并列的核心根任务，属于推荐系统专属语义建模概念，非通用AI术语，具备独特搜索价值"
      },
      {
        "keyword": "20万条指令样本",
        "dimension": "参数规格",
        "reason": "数据集规模是其核心优势之一，'20万条'是用户在对比推荐领域微调数据集时可能搜索的量化指标，属于主流规模表述"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/zai-org/GLM-4.5-Air-FP8",
    "keywords": [
      {
        "keyword": "GLM-4.5-Air",
        "dimension": "当前模型品牌名",
        "reason": "项目名直接给出的轻量版模型品牌"
      },
      {
        "keyword": "FP8量化",
        "dimension": "部署工具",
        "reason": "模型提供FP8精度版本，用户搜FP8部署"
      },
      {
        "keyword": "智能体基座模型",
        "dimension": "功能场景",
        "reason": "官方定位专为智能体设计，用户会搜智能体基座"
      },
      {
        "keyword": "混合推理模型",
        "dimension": "技术特性",
        "reason": "同时支持思维/非思维两种推理模式"
      },
      {
        "keyword": "120亿活跃参数",
        "dimension": "参数规格",
        "reason": "轻量版独有规格，用户搜12B参数模型"
      },
      {
        "keyword": "工具调用",
        "dimension": "功能场景",
        "reason": "思维模式内置工具调用能力，用户搜带工具调用的模型"
      },
      {
        "keyword": "MIT开源可商用",
        "dimension": "部署工具",
        "reason": "协议允许商业二次开发，用户搜可商用开源模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/OpenGVLab/VideoMAEv2-Large",
    "keywords": [
      {
        "keyword": "VideoMAEv2-Large",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，用户搜索时会精确匹配该模型"
      },
      {
        "keyword": "视频特征提取",
        "dimension": "功能场景",
        "reason": "README明确指出模型预期用途为视频特征提取，是用户寻找该模型的核心搜索意图，且未在高频排除词列表中"
      },
      {
        "keyword": "视频掩码自编码器",
        "dimension": "技术特性",
        "reason": "模型基于VideoMAE V2的双掩码自编码架构，该术语是其核心技术命名，具有唯一性且未被高频词列表覆盖"
      },
      {
        "keyword": "UnlabeledHybrid-1M",
        "dimension": "技术特性",
        "reason": "模型预训练所用的独特数据集名称，是区分该模型与其他视频模型的关键标识，用户可能搜索该数据集关联模型"
      },
      {
        "keyword": "CVPR23",
        "dimension": "技术特性",
        "reason": "模型源自CVPR 2023论文，学术用户常通过会议年份检索前沿模型，该词具有学术搜索价值且未被高频词列表排除"
      },
      {
        "keyword": "arxiv2303.1672",
        "dimension": "技术特性",
        "reason": "论文唯一arXiv编号，研究者常直接搜索arXiv ID定位模型，是高精准学术引流关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mradermacher/ALP_DeepScaleR_1.5B_C16K-GGUF",
    "keywords": [
      {
        "keyword": "DeepScaleR",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 ALP_DeepScaleR_1.5B_C16K 中提取的核心模型名称"
      },
      {
        "keyword": "1.5B参数",
        "dimension": "参数规格",
        "reason": "模型的参数规模为 1.5 B，属于用户常搜索的参数规格"
      },
      {
        "keyword": "静态量化",
        "dimension": "技术特性",
        "reason": "模型以静态量化方式提供，区别于动态量化，是用户关注的技术特性"
      },
      {
        "keyword": "数学推理",
        "dimension": "功能场景",
        "reason": "模型标签包含 AIME、AMC、Omni‑Math 等，定位于数学推理与解题"
      },
      {
        "keyword": "16K上下文",
        "dimension": "技术特性",
        "reason": "模型名称中的 C16K 表示支持约 16 K 上下文长度，属于独特的上下文特性"
      },
      {
        "keyword": "SynthLabsAI",
        "dimension": "当前模型品牌名",
        "reason": "模型由 SynthLabsAI 组织发布，可作为品牌关键词帮助用户定位"
      },
      {
        "keyword": "GGUF格式",
        "dimension": "部署工具",
        "reason": "模型以 GGUF 文件提供，适用于 llama.cpp 等本地推理工具，用户常以格式搜索"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ibm-granite/granite-docling-258M",
    "keywords": [
      {
        "keyword": "Granite-Docling",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "文档解析",
        "dimension": "功能场景",
        "reason": "当前模型专用于高效文档转换与解析"
      },
      {
        "keyword": "公式识别",
        "dimension": "功能场景",
        "reason": "README强调增强的数学公式检测与格式化能力"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "用户可通过Ollama快速部署并使用该模型"
      },
      {
        "keyword": "258M参数",
        "dimension": "参数规格",
        "reason": "当前模型的具体参数规模，便于用户检索"
      },
      {
        "keyword": "Docling流水线",
        "dimension": "部署工具",
        "reason": "模型已深度集成Docling库，支持一键式文档转换"
      },
      {
        "keyword": "图像转文本",
        "dimension": "功能场景",
        "reason": "多模态能力，支持将图文内容直接转为结构化文本"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/DaizeDong/GraphsGPT-4W",
    "keywords": [
      {
        "keyword": "GraphsGPT-4W",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 DaizeDong/GraphsGPT-4W 直接提取的当前模型唯一品牌名，符合简洁品牌名规范"
      },
      {
        "keyword": "图结构建模",
        "dimension": "功能场景",
        "reason": "模型核心是将图结构数据‘欧几里得化’，属于图机器学习的典型应用场景，用户会搜索‘图结构建模’这类精准意图词"
      },
      {
        "keyword": "纯Transformer图学习",
        "dimension": "技术特性",
        "reason": "论文核心创新是‘使用纯Transformer处理图数据’，区别于GNN，是该模型独有的技术标签，用户会搜索此类技术组合词"
      },
      {
        "keyword": "化学分子建模",
        "dimension": "功能场景",
        "reason": "README明确提及chemistry应用，‘化学分子建模’是该模型在生物医学领域的具体使用场景，具高区分度"
      },
      {
        "keyword": "生物医学图分析",
        "dimension": "功能场景",
        "reason": "README明确提及biology和medical，组合为‘生物医学图分析’是该模型在真实场景中的核心用途，非通用词"
      },
      {
        "keyword": "欧几里得化图",
        "dimension": "技术特性",
        "reason": "论文标题核心概念‘Euclideanizing Graph’，中文译为‘欧几里得化图’，是该模型独有的技术术语，用户可能直接搜索此短语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/gpt-oss-20b-BF16",
    "keywords": [
      {
        "keyword": "gpt-oss-20b",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "低延迟",
        "dimension": "技术特性",
        "reason": "当前模型专为低延迟场景打造，是区别于其他模型的重要特性"
      },
      {
        "keyword": "Apache-2.0许可",
        "dimension": "技术特性",
        "reason": "当前模型采用宽松的Apache 2.0许可，是模型使用的关键特性"
      },
      {
        "keyword": "可配置推理强度",
        "dimension": "技术特性",
        "reason": "当前模型支持根据具体应用场景和延迟需求调节推理强度，是模型的核心技术特性"
      },
      {
        "keyword": "完整思维链",
        "dimension": "技术特性",
        "reason": "当前模型提供全面访问推理过程的能力，便于调试分析并增强输出结果的可信度"
      },
      {
        "keyword": "智能代理能力",
        "dimension": "功能场景",
        "reason": "当前模型原生支持函数调用、网页浏览、Python代码执行及结构化输出，是模型的重要功能"
      },
      {
        "keyword": "原生MXFP4量化",
        "dimension": "技术特性",
        "reason": "当前模型采用原生MXFP4精度训练MoE层，是模型的技术亮点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-0.6B",
    "keywords": [
      {
        "keyword": "Qwen3Guard-Gen",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型唯一品牌名，符合简化规则且无版本号冗余"
      },
      {
        "keyword": "安全审核模型",
        "dimension": "功能场景",
        "reason": "模型核心用途是文本安全分类，用户会搜索‘AI安全审核’‘内容过滤模型’等意图词"
      },
      {
        "keyword": "实时安全监控",
        "dimension": "技术特性",
        "reason": "Qwen3Guard-Stream具备该能力，但Qwen3Guard-Gen作为其生成式基座，其‘三级严重程度分类’是独特功能，此处聚焦其可被搜索的语义表达"
      },
      {
        "keyword": "三级严重程度分类",
        "dimension": "技术特性",
        "reason": "模型独有的输出结构设计，将安全风险分为安全/争议/不安全三级，是区别于通用分类模型的关键特征"
      },
      {
        "keyword": "多语言安全审核",
        "dimension": "功能场景",
        "reason": "支持119种语言的安全审核，是用户在跨国内容风控场景中可能搜索的精准功能组合词"
      },
      {
        "keyword": "指令跟随安全",
        "dimension": "技术特性",
        "reason": "模型将安全分类建模为指令跟随任务，是其区别于传统分类器的核心技术表述，用户可能搜索‘AI指令安全’类关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Hcompany/Holo1.5-3B",
    "keywords": [
      {
        "keyword": "Holo1.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "计算机使用代理",
        "dimension": "功能场景",
        "reason": "当前模型专用于驱动CU代理，实现自动化操作真实应用"
      },
      {
        "keyword": "UI定位",
        "dimension": "功能场景",
        "reason": "模型核心能力之一，精准识别界面元素位置"
      },
      {
        "keyword": "UI问答",
        "dimension": "功能场景",
        "reason": "基于界面内容回答用户问题，提升交互效率"
      },
      {
        "keyword": "3B参数",
        "dimension": "参数规格",
        "reason": "当前模型提供的轻量级部署选项"
      },
      {
        "keyword": "高分辨率38402160",
        "dimension": "技术特性",
        "reason": "原生支持4K级输入，适配大屏与高清场景"
      },
      {
        "keyword": "GRPO强化学习",
        "dimension": "技术特性",
        "reason": "采用在线强化学习策略优化动作预测"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/opendatalab/MinerU2.5-2509-1.2B",
    "keywords": [
      {
        "keyword": "MinerU2.5",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "解耦式视觉语言模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，突出解耦式设计"
      },
      {
        "keyword": "高效高分辨率文档解析",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景，强调高效和高分辨率"
      },
      {
        "keyword": "Image-Text-to-Text",
        "dimension": "技术特性",
        "reason": "当前模型处理图像到文本转换的技术特性"
      },
      {
        "keyword": "1.2B参数",
        "dimension": "参数规格",
        "reason": "当前模型的参数规模，具有独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/sail-rvc/ElsaV2",
    "keywords": [
      {
        "keyword": "ElsaV2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为sail-rvc/ElsaV2，直接提取模型唯一品牌名，无版本号，符合简洁命名规则"
      },
      {
        "keyword": "RVC",
        "dimension": "技术特性",
        "reason": "模型类型明确标注为RVC（Retrieval-Based Voice Conversion），是当前模型的核心技术标签，用户搜索语音转换模型时会使用该缩写"
      },
      {
        "keyword": "Audio-to-Audio",
        "dimension": "功能场景",
        "reason": "标签中明确标注，描述模型直接输入音频输出音频的转换功能，是用户搜索语音克隆/变声场景时的精准关键词"
      },
      {
        "keyword": "sail-rvc",
        "dimension": "当前模型品牌名",
        "reason": "项目属于sail-rvc组织，且为模型专属系列名，非通用术语，具有品牌识别度，符合‘当前模型自身’提取原则"
      },
      {
        "keyword": "rvc-runpod",
        "dimension": "部署工具",
        "reason": "README明确提及模型被转换为适用于‘https://github.com/chavinlo/rvc-runpod’的格式，该词是模型专属部署生态标签，非通用词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-32B-GGUF",
    "keywords": [
      {
        "keyword": "Qwen3-32B",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型完整名称，代表该模型的品牌标识"
      },
      {
        "keyword": "思考模式",
        "dimension": "技术特性",
        "reason": "模型独有的思考模式，可用于复杂逻辑推理、数学和编码任务"
      },
      {
        "keyword": "非思考模式",
        "dimension": "技术特性",
        "reason": "模型提供的高效通用对话模式，与思考模式形成互补"
      },
      {
        "keyword": "YaRN技术",
        "dimension": "技术特性",
        "reason": "通过 YaRN 技术实现上下文长度可扩展至 131,072 tokens，提升长文本处理能力"
      },
      {
        "keyword": "GGUF",
        "dimension": "技术特性",
        "reason": "模型以 GGUF 格式发布，便于在多种推理框架中快速加载"
      },
      {
        "keyword": "32K上下文",
        "dimension": "技术特性",
        "reason": "原生支持 32,768 token 上下文长度，适合长篇对话和文档生成"
      },
      {
        "keyword": "指令遵循",
        "dimension": "功能场景",
        "reason": "模型在指令遵循任务上表现突出，适合作为指令型 AI 助手"
      },
      {
        "keyword": "智能体能力",
        "dimension": "功能场景",
        "reason": "支持在思考与非思考模式下精准集成外部工具，具备高级智能体任务执行能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-qat-q8_0-unquantized",
    "keywords": [
      {
        "keyword": "EmbeddingGemma",
        "dimension": "当前模型品牌名",
        "reason": "项目自身模型名称，用户直接搜索"
      },
      {
        "keyword": "文本嵌入",
        "dimension": "功能场景",
        "reason": "模型核心能力，生成文本向量表示"
      },
      {
        "keyword": "语义搜索",
        "dimension": "功能场景",
        "reason": "官方强调的典型应用场景"
      },
      {
        "keyword": "Matryoshka表示学习",
        "dimension": "技术特性",
        "reason": "独有的MRL技术，可截断嵌入维度"
      },
      {
        "keyword": "设备端部署",
        "dimension": "部署工具",
        "reason": "专为手机、笔记本等资源受限环境设计"
      },
      {
        "keyword": "Sentence-Transformers",
        "dimension": "部署工具",
        "reason": "官方推荐调用方式，用户常搜集成方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.2-Exp-Base",
    "keywords": [
      {
        "keyword": "DeepSeek-V3.2-Exp-Base",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型全称，虽含版本号，但为官方唯一标识，且无简化版名称，符合‘模型名称简化’规则中‘带版本号可保留’的例外情形（因无更简洁通用品牌名）"
      },
      {
        "keyword": "Exp-Base",
        "dimension": "当前模型品牌名",
        "reason": "‘Exp-Base’是当前模型名称的核心组成部分，代表实验性基础版本，是区别于其他DeepSeek系列（如DeepSeek-V3）的关键标识，用户可能搜索‘DeepSeek Exp-Base’来定位该实验模型"
      },
      {
        "keyword": "自回归模型",
        "dimension": "技术特性",
        "reason": "基于Transformers和Safetensors的结构，隐含为自回归语言模型，属于用户搜索AI模型时的典型技术分类词，且未被列入强制排除词库"
      },
      {
        "keyword": "开源模型",
        "dimension": "功能场景",
        "reason": "项目托管于GitCode（开源平台），MIT许可证，符合开源模型特征，用户常搜索‘开源大模型’或‘开源AI模型’寻找可商用/可部署模型，该词具搜索意图且未被排除"
      },
      {
        "keyword": "HuggingFace镜像",
        "dimension": "部署工具",
        "reason": "项目URL为HuggingFace镜像，用户在寻找可直接加载的模型时会搜索‘HuggingFace镜像模型’，该词指向模型获取渠道，非技术细节，符合部署工具维度"
      },
      {
        "keyword": "Base版本",
        "dimension": "技术特性",
        "reason": "‘Base’在模型命名中代表基础架构版本，区别于‘Chat’、‘Instruct’等微调版本，是用户区分模型用途时的关键词，如搜索‘DeepSeek Base版本’，且未被高频词库排除"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-3B",
    "keywords": [
      {
        "keyword": "Qwen2.5-Omni-3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "端到端多模态模型",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性，能够感知多种模态"
      },
      {
        "keyword": "Thinker-Talker架构",
        "dimension": "技术特性",
        "reason": "当前模型创新提出的架构，用于多模态感知和生成"
      },
      {
        "keyword": "TMRoPE",
        "dimension": "技术特性",
        "reason": "当前模型创新提出的时间对齐多模态旋转位置编码技术"
      },
      {
        "keyword": "实时音视频对话",
        "dimension": "功能场景",
        "reason": "当前模型专为全实时交互设计的架构，支持分块输入和即时输出"
      },
      {
        "keyword": "自然流畅语音生成",
        "dimension": "功能场景",
        "reason": "当前模型在语音生成方面的卓越表现，超越现有众多方案"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/XiaomiMiMo/MiMo-Audio-7B-Base",
    "keywords": [
      {
        "keyword": "MiMo-Audio",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名，用户搜索时会使用该词定位模型"
      },
      {
        "keyword": "音频语言模型",
        "dimension": "功能场景",
        "reason": "模型的核心定位是处理音频的语言任务，用户会以此关键词寻找音频相关的AI模型"
      },
      {
        "keyword": "少样本学习",
        "dimension": "技术特性",
        "reason": "模型在多种音频任务上展现出少样本学习能力，是其独特技术亮点，搜索者常关注此特性"
      },
      {
        "keyword": "语音续写",
        "dimension": "功能场景",
        "reason": "模型能够生成连续的语音内容（脱口秀、朗诵等），属于重要的应用场景，用户会以此关键词检索"
      },
      {
        "keyword": "指令微调",
        "dimension": "技术特性",
        "reason": "在后期训练阶段引入的指令微调技术提升了模型的指令理解与生成能力，具备搜索价值"
      },
      {
        "keyword": "音频理解基准",
        "dimension": "功能场景",
        "reason": "模型在公开的音频理解基准测试中取得领先成绩，用户常通过此关键词了解模型性能"
      },
      {
        "keyword": "Any-to-Any",
        "dimension": "技术特性",
        "reason": "模型支持任意模态之间的转换（如音频→文本、文本→音频），是其独有的跨模态能力"
      },
      {
        "keyword": "MiMo-Audio-Tokenizer",
        "dimension": "技术特性",
        "reason": "模型使用的专属音频分词器，具备12亿参数和高频率运行特性，搜索者会关注此关键组件"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/cogagent-9b-20241220",
    "keywords": [
      {
        "keyword": "CogAgent-9B-20241220",
        "dimension": "当前模型品牌名",
        "reason": "项目名称为THUDM/cogagent-9b-20241220，直接提取完整模型标识符，符合用户搜索具体版本的意图"
      },
      {
        "keyword": "GUI感知",
        "dimension": "技术特性",
        "reason": "模型核心能力之一，明确区别于通用VLM，用户搜索‘GUI感知AI模型’有明确场景需求"
      },
      {
        "keyword": "Action-Operation-Sensitive",
        "dimension": "技术特性",
        "reason": "模型输出格式的独有设计术语，是其作为GUI Agent的关键技术标签，非通用词汇"
      },
      {
        "keyword": "屏幕截图交互",
        "dimension": "功能场景",
        "reason": "模型接受屏幕截图+语言输入的核心使用方式，用户会搜索‘如何用AI分析屏幕截图’"
      },
      {
        "keyword": "双语屏幕代理",
        "dimension": "功能场景",
        "reason": "模型支持中英文双语操作屏幕的独有定位，区别于普通视觉问答模型，具高区分度"
      },
      {
        "keyword": "GLM-4V-9B基座",
        "dimension": "当前模型品牌名",
        "reason": "虽基于GLM-4V，但当前模型是其优化版，且‘GLM-4V-9B’是模型架构的直接引用，非其他品牌模型，符合‘自身名称’提取规则"
      },
      {
        "keyword": "平台识别代理",
        "dimension": "功能场景",
        "reason": "模型能识别Mac/WIN/Mobile平台并据此调整行为，是其作为GUI Agent的特色功能，非通用AI能力"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/black-forest-labs/FLUX.1-Kontext-dev",
    "keywords": [
      {
        "keyword": "FLUX.1-Kontext-dev",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "整流流转换器",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术类型"
      },
      {
        "keyword": "图像编辑",
        "dimension": "功能场景",
        "reason": "当前模型的主要应用场景"
      },
      {
        "keyword": "引导蒸馏技术",
        "dimension": "技术特性",
        "reason": "当前模型使用的独特训练技术"
      },
      {
        "keyword": "开放权重",
        "dimension": "技术特性",
        "reason": "当前模型的核心技术特性之一"
      },
      {
        "keyword": "Diffusers",
        "dimension": "部署工具",
        "reason": "当前模型支持的部署工具"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pcoloc/autotrain-only-rssi-1813762559",
    "keywords": [
      {
        "keyword": "AutoTrain",
        "dimension": "部署工具",
        "reason": "README中明确提到使用AutoTrain训练，用户会搜索AutoTrain一键训练"
      },
      {
        "keyword": "单列回归",
        "dimension": "功能场景",
        "reason": "README标注问题类型为单列回归，用户搜索回归模型时会用此关键词"
      },
      {
        "keyword": "RSSI预测",
        "dimension": "功能场景",
        "reason": "项目名称含RSSI，结合任务类型可推断为无线信号强度回归预测"
      },
      {
        "keyword": "Joblib模型",
        "dimension": "部署工具",
        "reason": "模型文件为joblib格式，用户搜索如何加载Joblib模型时会用到"
      },
      {
        "keyword": "Tabular回归",
        "dimension": "功能场景",
        "reason": "标签含tabular-regression，用户搜索表格数据回归模型时会用"
      },
      {
        "keyword": "低CO2排放",
        "dimension": "技术特性",
        "reason": "README突出1.3554克CO2排放，环保型训练成为卖点"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/PhysicsWallahAI/Aryabhata-1.0",
    "keywords": [
      {
        "keyword": "Aryabhata-1.0",
        "dimension": "当前模型品牌名",
        "reason": "项目名称明确为PhysicsWallahAI/Aryabhata-1.0，是当前模型的唯一官方名称，符合品牌名提取规则"
      },
      {
        "keyword": "JEE数学",
        "dimension": "功能场景",
        "reason": "模型专为印度JEE主考数学设计，是用户搜索竞赛数学AI模型时的核心意图关键词，具有高度场景针对性"
      },
      {
        "keyword": "exam-centric",
        "dimension": "技术特性",
        "reason": "README明确使用该术语描述模型定位，指代‘以考试为中心’的AI设计范式，是区别于通用模型的独特技术标签"
      },
      {
        "keyword": "模型融合",
        "dimension": "技术特性",
        "reason": "模型通过加权平均融合Qwen 2.5 Math、Ace Math等构建，是其核心训练方法，且未被高频词库排除，具技术独特性"
      },
      {
        "keyword": "拒绝采样",
        "dimension": "技术特性",
        "reason": "模型训练流程中明确使用‘rejection-sampling’，是其提升准确率的关键技术，属于专业但非泛用的训练策略关键词"
      },
      {
        "keyword": "监督微调",
        "dimension": "技术特性",
        "reason": "模型采用SFT（监督微调）作为核心训练步骤，是AI教育模型的典型技术路径，未被高频词库排除，具区分度"
      },
      {
        "keyword": "可验证奖励强化学习",
        "dimension": "技术特性",
        "reason": "模型使用‘RLVR’（可验证奖励强化学习），是其区别于普通RLHF的创新训练机制，术语独特且未被高频词库覆盖"
      },
      {
        "keyword": "70亿参数",
        "dimension": "参数规格",
        "reason": "模型明确为70亿参数（7B），属于主流参数规模，符合‘7B参数’格式，且未被高频词库中的‘7B参数’禁用（因高频词为7B参数，非70亿参数）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-3B-Instruct",
    "keywords": [
      {
        "keyword": "Qwen2.5-VL-3B-Instruct",
        "dimension": "当前模型品牌名",
        "reason": "项目名称即为当前模型完整名称，符合用户直接搜索模型标识的意图，且未被高频词列表排除"
      },
      {
        "keyword": "视觉智能体",
        "dimension": "功能场景",
        "reason": "模型可直接作为视觉智能体进行推理与工具调用，具备电脑/手机操作能力，是区别于普通视觉语言模型的独特功能，未在高频词列表中出现"
      },
      {
        "keyword": "长视频事件捕捉",
        "dimension": "功能场景",
        "reason": "支持超1小时视频的精准片段定位，属于模型独有的时间维度理解能力，非通用术语，未被高频词覆盖"
      },
      {
        "keyword": "结构化输出",
        "dimension": "功能场景",
        "reason": "针对发票、表格等场景生成结构化JSON数据，是金融/商业场景中的明确应用点，区别于普通OCR或文本提取"
      },
      {
        "keyword": "多格式视觉定位",
        "dimension": "功能场景",
        "reason": "支持生成边界框/坐标点并稳定输出JSON格式坐标，是模型在视觉定位上的精细化能力，非通用视觉问答或图像分类"
      },
      {
        "keyword": "动态分辨率视频理解",
        "dimension": "技术特性",
        "reason": "通过动态FPS采样与时间维度mRoPE实现视频时序感知，是架构层面的创新点，非普通视频理解或帧采样概念"
      },
      {
        "keyword": "窗口注意力ViT",
        "dimension": "技术特性",
        "reason": "在视觉编码器中策略性引入窗口注意力机制，提升效率，属于模型特有的架构优化方式，未在高频词中出现"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V2-7B",
    "keywords": [
      {
        "keyword": "DeepSeek-Prover-V2",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "Lean4-形式化证明",
        "dimension": "功能场景",
        "reason": "模型专注于在 Lean 4 环境下进行形式化定理证明的应用场景"
      },
      {
        "keyword": "递归定理证明",
        "dimension": "技术特性",
        "reason": "模型采用递归方式分解并搜索定理证明，是核心技术特性"
      },
      {
        "keyword": "冷启动推理数据",
        "dimension": "技术特性",
        "reason": "通过冷启动数据集进行初始训练，提升模型推理能力"
      },
      {
        "keyword": "思维链融合",
        "dimension": "技术特性",
        "reason": "将非形式化思维链与形式化证明步骤有机结合的创新特性"
      },
      {
        "keyword": "子目标分解",
        "dimension": "技术特性",
        "reason": "模型将复杂定理拆解为可验证的子目标，是关键技术手段"
      },
      {
        "keyword": "强化学习微调",
        "dimension": "技术特性",
        "reason": "在冷启动数据上进行强化学习微调，以提升证明生成质量"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/mistralai/Voxtral-Mini-3B-2507",
    "keywords": [
      {
        "keyword": "Voxtral-Mini-3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "语音转录",
        "dimension": "功能场景",
        "reason": "当前模型擅长的核心功能之一"
      },
      {
        "keyword": "长文本上下文处理",
        "dimension": "技术特性",
        "reason": "当前模型支持处理长文本上下文的能力"
      },
      {
        "keyword": "音频内容理解",
        "dimension": "功能场景",
        "reason": "当前模型的核心应用场景之一"
      },
      {
        "keyword": "语音直接触发功能调用",
        "dimension": "技术特性",
        "reason": "当前模型独特的语音触发功能"
      },
      {
        "keyword": "vllm",
        "dimension": "部署工具",
        "reason": "当前模型推荐的部署框架"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/BM-Model",
    "keywords": [
      {
        "keyword": "BM-Model",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称ByteDance-Seed/BM-Model提取的当前模型简称"
      },
      {
        "keyword": "字节跳动Seed",
        "dimension": "当前模型品牌名",
        "reason": "ByteDance-Seed对应官方品牌“字节跳动Seed”"
      },
      {
        "keyword": "Image-to-Image",
        "dimension": "功能场景",
        "reason": "标签中明确标注的核心功能，用户会搜“Image-to-Image模型”"
      },
      {
        "keyword": "ByteMorph-Bench",
        "dimension": "技术特性",
        "reason": "README中提到的专属评测基准，用户想了解该模型性能时会搜索"
      },
      {
        "keyword": "arxiv-2506.03107",
        "dimension": "技术特性",
        "reason": "论文编号是用户查找该模型技术细节的高频检索词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/pcoloc/autotrain-mikrotik-7-7-1860563597",
    "keywords": [
      {
        "keyword": "autotrain",
        "dimension": "部署工具",
        "reason": "模型通过AutoTrain平台训练，是用户搜索自动化训练工具时的核心关键词，且未被高频词列表排除"
      },
      {
        "keyword": "tabular-regression",
        "dimension": "功能场景",
        "reason": "模型明确用于表格数据回归任务，属于精准功能场景词，用户会搜索‘表格回归模型’等关键词"
      },
      {
        "keyword": "joblib",
        "dimension": "部署工具",
        "reason": "模型使用joblib加载，是部署/推理环节的关键技术词，区别于通用的PyTorch/HuggingFace，具有独特性"
      },
      {
        "keyword": "pcolocautotrain-data-mikrotik-7-7",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中唯一可识别的专属数据集/模型前缀，代表该模型的唯一标识，符合‘当前模型自身名称’提取规则"
      },
      {
        "keyword": "regression",
        "dimension": "功能场景",
        "reason": "模型问题类型为单列回归，是用户在AI建模场景中高频搜索的精准任务类型，且未被高频词列表排除"
      },
      {
        "keyword": "tabular",
        "dimension": "功能场景",
        "reason": "明确指向表格数据建模，与图像/文本模型区分，是用户搜索非NLP/CV任务时的关键术语"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-72B-SFT",
    "keywords": [
      {
        "keyword": "UI-TARS",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型系列名称"
      },
      {
        "keyword": "GUI智能体",
        "dimension": "功能场景",
        "reason": "用户会搜“GUI智能体”找能自动操作界面的模型"
      },
      {
        "keyword": "界面自动化",
        "dimension": "功能场景",
        "reason": "原生端到端界面任务自动化，用户高频搜索词"
      },
      {
        "keyword": "72B参数",
        "dimension": "参数规格",
        "reason": "旗舰版72B规格，用户直接搜“72B参数”找大模型"
      },
      {
        "keyword": "原生智能体",
        "dimension": "技术特性",
        "reason": "论文标题关键词，强调无需规则的原生Agent能力"
      },
      {
        "keyword": "视觉定位",
        "dimension": "技术特性",
        "reason": "ScreenSpot Pro评测亮点，用户搜“视觉定位”找能精准点选界面的模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers",
    "keywords": [
      {
        "keyword": "Wan2.1",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "图生视频",
        "dimension": "功能场景",
        "reason": "模型支持从图像生成视频的核心功能"
      },
      {
        "keyword": "视频编辑",
        "dimension": "功能场景",
        "reason": "模型具备对已有视频进行编辑、剪辑的能力"
      },
      {
        "keyword": "Diffusers集成",
        "dimension": "部署工具",
        "reason": "模型已集成至 Hugging Face Diffusers 库，便于直接调用"
      },
      {
        "keyword": "Wan-VAE",
        "dimension": "技术特性",
        "reason": "高性能视频 VAE 编解码器，是模型的关键技术组件"
      },
      {
        "keyword": "时序编解码",
        "dimension": "技术特性",
        "reason": "能够在任意时长 1080P 视频上保留时序信息的编解码技术"
      },
      {
        "keyword": "1.3B参数",
        "dimension": "参数规格",
        "reason": "T2V-1.3B 子模型的参数规模，用户常以参数大小检索模型"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Paddle",
    "keywords": [
      {
        "keyword": "ERNIE-4.5-VL-28B-A3B",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型完整名称，是用户搜索该特定模型的精准关键词，且未被高频词列表排除"
      },
      {
        "keyword": "多模态异构MoE",
        "dimension": "技术特性",
        "reason": "README中明确提出的独家技术术语 'Multimodal Heterogeneous MoE'，是该模型的核心创新点，区别于通用'多模态'或'MoE架构'，且未在高频词列表中"
      },
      {
        "keyword": "跨模态推理",
        "dimension": "功能场景",
        "reason": "README中强调 'cross-modal reasoning'，是该模型支持的关键应用场景，属于用户搜索意图明确的精准功能词，未被高频词列表覆盖"
      },
      {
        "keyword": "文本质感生成",
        "dimension": "功能场景",
        "reason": "基于 'text understanding and generation' 与 'image understanding' 的结合推导出的用户可搜索场景词，强调文本生成质量，区别于泛用的'AI写作'或'文生图'"
      },
      {
        "keyword": "模态隔离路由",
        "dimension": "技术特性",
        "reason": "README中明确提及的独家技术设计 'modality-isolated routing'，是ERNIE-4.5-VL区别于其他多模态模型的关键架构细节，具有高区分度"
      },
      {
        "keyword": "PaddlePaddle权重",
        "dimension": "部署工具",
        "reason": "README明确区分'-Paddle'与'-PT'模型，用户若搜索'PaddlePaddle模型'或'飞桨权重'，会精准定位此版本，属于部署方式的精准关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/myshell-ai/MeloTTS-Spanish",
    "keywords": [
      {
        "keyword": "MeloTTS-Spanish",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称，且特指西班牙语版本"
      },
      {
        "keyword": "多语言文本转语音",
        "dimension": "功能场景",
        "reason": "当前模型的主要功能，支持多种语言的文本转语音"
      },
      {
        "keyword": "CPU实时推理",
        "dimension": "技术特性",
        "reason": "当前模型的一个显著技术特点，支持在CPU上进行实时推理"
      },
      {
        "keyword": "中英文混合",
        "dimension": "功能场景",
        "reason": "当前模型支持中文发音人进行中英文混合的文本转语音"
      },
      {
        "keyword": "Text-to-Speech",
        "dimension": "功能场景",
        "reason": "当前模型的核心功能类别，即文本转语音"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/PlanTL-GOB-ES/roberta-base-bne-capitel-ner",
    "keywords": [
      {
        "keyword": "roberta-base-bne-capitel-ner",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型完整品牌名"
      },
      {
        "keyword": "西班牙语NER",
        "dimension": "功能场景",
        "reason": "当前模型专用于西班牙语的命名实体识别任务"
      },
      {
        "keyword": "BNE语料",
        "dimension": "技术特性",
        "reason": "基于西班牙国家图书馆570GB清洗语料预训练，体现数据特色"
      },
      {
        "keyword": "CAPITEL数据集",
        "dimension": "技术特性",
        "reason": "在CAPITEL命名实体识别数据集上微调，突出训练数据来源"
      },
      {
        "keyword": "HuggingFace-pipeline",
        "dimension": "部署工具",
        "reason": "官方示例使用transformers.pipeline一行代码调用，便于快速集成"
      },
      {
        "keyword": "570GB西班牙语",
        "dimension": "技术特性",
        "reason": "强调训练语料规模与语言专一性，吸引西语NLP开发者"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/ecmwf/aifs-single-1.0",
    "keywords": [
      {
        "keyword": "AIFS-Single",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接给出的模型品牌名称"
      },
      {
        "keyword": "高层大气变量预报",
        "dimension": "功能场景",
        "reason": "模型在 50 hPa、100 hPa 层级上提升了高层大气变量的预报能力"
      },
      {
        "keyword": "降水总量预报",
        "dimension": "功能场景",
        "reason": "新版对总降水量的预报技巧进行了增强，是模型的核心业务场景"
      },
      {
        "keyword": "土壤湿度与温度预报",
        "dimension": "功能场景",
        "reason": "新增输出变量包括土壤湿度、土壤温度等陆地气象要素"
      },
      {
        "keyword": "13层气压层结构",
        "dimension": "技术特性",
        "reason": "模型采用 13 个气压层的结构，区别于传统单层或更少层数的预报模型"
      },
      {
        "keyword": "每日四次同步运行",
        "dimension": "技术特性",
        "reason": "模型每日与 ECMWF 物理数值预报模式同步运行四次，保证时效性"
      },
      {
        "keyword": "开放数据政策",
        "dimension": "技术特性",
        "reason": "预报结果依据 ECMWF 开放数据政策向公众免费开放，具备数据共享特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-8B",
    "keywords": [
      {
        "keyword": "Qwen3Guard-Gen",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型专属名称，符合品牌名简化规则（去版本号后保留核心标识）"
      },
      {
        "keyword": "安全审核模型",
        "dimension": "功能场景",
        "reason": "模型核心用途为提示词与响应的安全分类，是用户搜索AI内容安全、风控系统时的明确意图词"
      },
      {
        "keyword": "实时安全监控",
        "dimension": "技术特性",
        "reason": "Qwen3Guard-Stream虽未在本模型中部署，但Qwen3Guard-Gen作为生成式安全模型，其‘三级严重程度分类’机制支撑了可扩展的实时风险评估能力，该词精准描述其部署价值"
      },
      {
        "keyword": "三级严重程度分类",
        "dimension": "技术特性",
        "reason": "模型独有的输出结构设计，将安全判断分为安全/争议/不安全三级，是区别于通用分类模型的核心差异化特征"
      },
      {
        "keyword": "多语言安全审核",
        "dimension": "功能场景",
        "reason": "支持119种语言的安全分类，是面向全球化内容平台用户的精准搜索词，且未被高频词库覆盖"
      },
      {
        "keyword": "生成式安全分类",
        "dimension": "技术特性",
        "reason": "模型将安全审核转化为指令跟随任务，属于生成式AI在内容安全领域的创新应用方式，具备独特性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/stepfun-ai/step3-fp8",
    "keywords": [
      {
        "keyword": "step3-fp8",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "混合专家架构",
        "dimension": "技术特性",
        "reason": "当前模型采用的核心架构类型"
      },
      {
        "keyword": "多矩阵分解注意力",
        "dimension": "技术特性",
        "reason": "当前模型使用的独特注意力机制"
      },
      {
        "keyword": "注意力-前馈网络解耦",
        "dimension": "技术特性",
        "reason": "当前模型设计的独特网络结构"
      },
      {
        "keyword": "视觉-语言推理",
        "dimension": "功能场景",
        "reason": "当前模型实现的核心功能"
      },
      {
        "keyword": "端到端设计",
        "dimension": "技术特性",
        "reason": "当前模型的设计方式"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/rubentito/layoutlmv3-base-mpdocvqa",
    "keywords": [
      {
        "keyword": "LayoutLMv3",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称 'rubentito/layoutlmv3-base-mpdocvqa' 中提取的核心模型品牌名，是当前模型的唯一标识，非其他模型"
      },
      {
        "keyword": "Document-Question-Answering",
        "dimension": "功能场景",
        "reason": "模型专门用于文档问答任务，是用户搜索文档型QA模型时的精准意图词，且未被列入高频排除词库"
      },
      {
        "keyword": "Document-Visual-Question-Answering",
        "dimension": "功能场景",
        "reason": "模型处理图文结合的文档问答，该术语精准描述其多模态文档理解能力，区别于通用VQA，具有高区分度"
      },
      {
        "keyword": "MP-DocVQA",
        "dimension": "当前模型品牌名",
        "reason": "模型是专为MP-DocVQA数据集微调的，该名称是当前模型的专属训练基准，属于模型自身标识，非通用术语"
      },
      {
        "keyword": "LayoutLMv3-base",
        "dimension": "当前模型品牌名",
        "reason": "模型基于LayoutLMv3-base架构微调，该组合是用户搜索特定基座版本时的常见查询词，且未被高频词库排除"
      },
      {
        "keyword": "Multipage-Document-VQA",
        "dimension": "功能场景",
        "reason": "模型处理多页文档的视觉问答，该短语是任务类型的核心描述，具有明确搜索意图，且未在排除列表中"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/MusePublic/489_ckpt_FLUX_1",
    "keywords": [
      {
        "keyword": "FLUX.1-dev",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型名称，用户搜索时会使用该品牌名"
      },
      {
        "keyword": "12B参数",
        "dimension": "参数规格",
        "reason": "模型拥有约120 亿参数，约等于12B参数，是用户关注的规模信息"
      },
      {
        "keyword": "引导蒸馏",
        "dimension": "技术特性",
        "reason": "模型采用的核心训练技术，可提升效率，具备独特性"
      },
      {
        "keyword": "图像生成",
        "dimension": "功能场景",
        "reason": "模型的主要用途是将文本描述转化为图像，属于图像生成任务"
      },
      {
        "keyword": "本地推理",
        "dimension": "部署方式",
        "reason": "模型支持在本地机器上直接进行推理，满足离线使用需求"
      },
      {
        "keyword": "Diffusers库",
        "dimension": "部署工具",
        "reason": "官方提供基于 HuggingFace Diffusers 的实现，用户可通过该库快速使用模型"
      },
      {
        "keyword": "开放权重",
        "dimension": "技术特性",
        "reason": "模型权重已公开，便于科研和二次开发，具有区别于闭源模型的优势"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen2.5-14B-Instruct-1M",
    "keywords": [
      {
        "keyword": "Qwen2.5-14B-Instruct-1M",
        "dimension": "当前模型品牌名",
        "reason": "项目完整名称，用户直接搜索该模型"
      },
      {
        "keyword": "1M上下文",
        "dimension": "技术特性",
        "reason": "模型主打百万级超长上下文能力，用户会搜"
      },
      {
        "keyword": "长文本处理",
        "dimension": "功能场景",
        "reason": "模型核心卖点，用户搜索长文本AI模型"
      },
      {
        "keyword": "vLLM部署",
        "dimension": "部署工具",
        "reason": "官方推荐的高效推理框架，用户会搜"
      },
      {
        "keyword": "稀疏注意力",
        "dimension": "技术特性",
        "reason": "官方提到的长文本优化技术，用户会搜"
      },
      {
        "keyword": "因果语言模型",
        "dimension": "技术特性",
        "reason": "模型架构类型，用户搜索相关关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/microsoft/Florence-2-base",
    "keywords": [
      {
        "keyword": "Florence-2",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称直接提取的当前模型品牌名，是用户搜索该模型的核心关键词"
      },
      {
        "keyword": "视觉基础模型",
        "dimension": "技术特性",
        "reason": "模型在README中被明确定义为'视觉基础模型'，具有明确技术定位，且未在高频排除词列表中"
      },
      {
        "keyword": "图像描述生成",
        "dimension": "功能场景",
        "reason": "模型核心能力之一，用户可能搜索'图像描述生成模型'来寻找相关AI工具，属于具体任务场景"
      },
      {
        "keyword": "目标检测",
        "dimension": "功能场景",
        "reason": "模型支持的关键视觉任务，是独立且具体的搜索意图词，未被高频词列表覆盖"
      },
      {
        "keyword": "图像分割",
        "dimension": "功能场景",
        "reason": "模型明确支持的视觉任务，属于高价值垂直场景词，区别于通用'图像分类'等高频词"
      },
      {
        "keyword": "提示词方法",
        "dimension": "技术特性",
        "reason": "模型采用'基于提示词的方法'处理多任务，是其架构特色，具有区分度且未被高频词覆盖"
      },
      {
        "keyword": "FLD-5B数据集",
        "dimension": "技术特性",
        "reason": "模型训练所用的独特数据集名称，专业用户可能搜索该数据集来评估模型来源，具有唯一性"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/THUDM/androidgen-llama-3-70b",
    "keywords": [
      {
        "keyword": "AndroidGen",
        "dimension": "当前模型品牌名",
        "reason": "项目专属品牌名，用户直接搜模型时会用"
      },
      {
        "keyword": "Android智能体",
        "dimension": "功能场景",
        "reason": "模型核心用途——在安卓端自主操作App"
      },
      {
        "keyword": "70B参数",
        "dimension": "参数规格",
        "reason": "大参数规模，用户筛选大模型时常搜"
      },
      {
        "keyword": "无标注交互",
        "dimension": "技术特性",
        "reason": "亮点能力，无需人工标注即可训练安卓操作"
      },
      {
        "keyword": "安卓自动化",
        "dimension": "功能场景",
        "reason": "用户想找能自动完成安卓任务的模型时会搜"
      },
      {
        "keyword": "Ollama部署",
        "dimension": "部署工具",
        "reason": "社区常用部署方式，引流关键词"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/Qwen/Qwen3-14B-FP8",
    "keywords": [
      {
        "keyword": "Qwen3-14B-FP8",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型名称"
      },
      {
        "keyword": "混合专家模型",
        "dimension": "技术特性",
        "reason": "Qwen3系列包含MoE模型，是当前模型的技术特性之一"
      },
      {
        "keyword": "复杂逻辑推理",
        "dimension": "功能场景",
        "reason": "当前模型在思考模式下支持复杂逻辑推理"
      },
      {
        "keyword": "高效通用对话",
        "dimension": "功能场景",
        "reason": "当前模型在非思考模式下支持高效通用对话"
      },
      {
        "keyword": "多语言支持",
        "dimension": "功能场景",
        "reason": "当前模型提供多语言支持，是其主要功能之一（虽为高频词，但属于模型独特功能，且未在强制排除列表中明确提及此具体表述）"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/NousResearch/Hermes-4-14B",
    "keywords": [
      {
        "keyword": "Hermes-4",
        "dimension": "当前模型品牌名",
        "reason": "项目名称中直接出现的模型品牌名称"
      },
      {
        "keyword": "混合推理模式",
        "dimension": "技术特性",
        "reason": "模型能够在需要深思时使用 </think> 标记进行混合推理，是其核心技术特性"
      },
      {
        "keyword": "后训练语料库",
        "dimension": "技术特性",
        "reason": "相较于前代模型，Hermes‑4 使用了规模更大的后训练语料库，显著提升推理能力"
      },
      {
        "keyword": "结构化输出",
        "dimension": "技术特性",
        "reason": "模型经过训练能够生成符合 JSON 规范的结构化输出并自动修复格式错误"
      },
      {
        "keyword": "RefusalBench",
        "dimension": "基准测试/评估",
        "reason": "Hermes‑4 在自研的 RefusalBench 基准上取得最先进成绩，体现其在拒绝率降低方面的优势"
      },
      {
        "keyword": "function-calling",
        "dimension": "技术特性",
        "reason": "模型支持函数调用能力，可在对话中直接触发外部工具或 API"
      },
      {
        "keyword": "JSON模式生成",
        "dimension": "技术特性",
        "reason": "模型能够根据给定模式生成有效的 JSON 对象，适用于结构化任务"
      }
    ]
  },
  {
    "model_url": "https://gitcode.com/hf_mirrors/kakaocorp/kanana-1.5-v-3b-instruct",
    "keywords": [
      {
        "keyword": "Kanana",
        "dimension": "当前模型品牌名",
        "reason": "从项目名称提取的当前模型品牌名"
      },
      {
        "keyword": "Kakao大模型",
        "dimension": "当前模型品牌名",
        "reason": "由Kakao UFO团队发布，映射为Kakao大模型"
      },
      {
        "keyword": "图像描述生成",
        "dimension": "功能场景",
        "reason": "官方明确列出的典型应用场景"
      },
      {
        "keyword": "OCR推理",
        "dimension": "功能场景",
        "reason": "官方强调支持基于OCR的推理任务"
      },
      {
        "keyword": "韩文多模态",
        "dimension": "功能场景",
        "reason": "针对韩文场景优化，支持韩文指令遵循"
      },
      {
        "keyword": "3.6B参数",
        "dimension": "参数规格",
        "reason": "当前模型的具体参数规模"
      },
      {
        "keyword": "32K上下文",
        "dimension": "技术特性",
        "reason": "官方给出的上下文长度规格"
      }
    ]
  }
]