# 模型关键词提取分析报告

## 概览统计

- 📊 **CSV读取模型数**: 702
- ✅ **成功提取模型数**: 701
- ❌ **失败模型数**: 1
- 📈 **成功率**: 99.9%
- 🔍 **原始关键词总数**: 4622
- ✂️ **去重后关键词总数**: 3096
- 📉 **去重率**: 33.0%
- 📊 **平均每模型关键词数**: 4.4
- 🕐 **生成时间**: 2025-10-22 17:33:56

## 维度分布

| 维度 | 关键词数量 | 占比 |
|------|------------|------|
| 技术特性 | 1160 | 37.5% |
| 功能场景 | 901 | 29.1% |
| 当前模型品牌名 | 652 | 21.1% |
| 部署工具 | 191 | 6.2% |
| 参数规格 | 152 | 4.9% |
| 训练数据 | 8 | 0.3% |
| 数据来源 | 3 | 0.1% |
| 数据集 | 2 | 0.1% |
| 评估指标 | 2 | 0.1% |
| 评测基准 | 2 | 0.1% |
| 输入规格 | 1 | 0.0% |
| 数据集来源 | 1 | 0.0% |
| 技术文献 | 1 | 0.0% |
| 部署方式 | 1 | 0.0% |
| 使用方式 | 1 | 0.0% |
| 下游用途 | 1 | 0.0% |
| 语言类型 | 1 | 0.0% |
| 数据规模 | 1 | 0.0% |
| 任务细分 | 1 | 0.0% |
| 训练数据集 | 1 | 0.0% |
| 评估基准 | 1 | 0.0% |
| 训练策略 | 1 | 0.0% |
| 训练技术 | 1 | 0.0% |
| 能力特性 | 1 | 0.0% |
| 许可证 | 1 | 0.0% |
| 微调支持 | 1 | 0.0% |
| 智能体能力 | 1 | 0.0% |
| 量化技术 | 1 | 0.0% |
| 使用指南 | 1 | 0.0% |
| 输出格式 | 1 | 0.0% |
| 技术出处 | 1 | 0.0% |
| 技术基础 | 1 | 0.0% |
| 基准测试/评估 | 1 | 0.0% |

## 原始数据高频关键词分析

> 基于去重前的原始提取数据，展示整个数据集中最常见的关键词

| 排名 | 关键词 | 原始出现次数 | 最终保留次数 |
|------|--------|-------------|-------------|
| 1 | 思维模式切换 | 14 | 1 |
| 2 | 7B参数 | 13 | 1 |
| 3 | 文生视频 | 12 | 1 |
| 4 | Safetensors | 12 | 1 |
| 5 | MoE架构 | 12 | 1 |
| 6 | 视觉语言模型 | 12 | 1 |
| 7 | 阿里大模型 | 12 | 1 |
| 8 | 14B参数 | 12 | 1 |
| 9 | 百度大模型 | 12 | 1 |
| 10 | 多模态 | 11 | 1 |
| 11 | 文生图 | 11 | 1 |
| 12 | AI写作 | 11 | 1 |
| 13 | 本地部署 | 11 | 1 |
| 14 | Transformer | 11 | 1 |
| 15 | ComfyUI | 11 | 1 |
| 16 | PyTorch | 11 | 1 |
| 17 | HuggingFace | 11 | 1 |
| 18 | 智谱AI | 11 | 1 |
| 19 | 视频理解 | 11 | 1 |
| 20 | GGUF量化 | 11 | 1 |

## 所有关键词列表


### 下游用途 (2个)

- **图像生成引导** • **线性探针图像分类**

### 任务细分 (1个)

- **7子任务**

### 使用指南 (1个)

- **HiDream-示例**

### 使用方式 (1个)

- **token-classification-pipeline**

### 功能场景 (930个)

- **100万字上下文** • **100语言** • **100语言支持** • **10秒出3D** • **10秒视频生成**
- **119种语言** • **119语言** • **119语言支持** • **11语言TTS** • **1360768视频**
- **15语言支持** • **1M上下文** • **200种语言** • **256x256图像生成** • **256语言**
- **26种语言** • **338种编程语言** • **360度全景体验** • **3D建模AI** • **3D点轨迹**
- **3D生成** • **3D生成框架** • **3D生成模型** • **3D视觉感知** • **3D重建**
- **480P视频生成** • **4K图像分辨率** • **4K图像支持** • **4音色TTS** • **50语言支持**
- **52个标记点预测** • **5秒视频生成** • **6方向摄像机移动** • **6语言原生支持** • **6语言支持**
- **720P24fps** • **720P视频生成** • **81帧视频** • **97种语言语音转录** • **ADE20K数据集**
- **AIME-2025** • **AI写作** • **AI安全** • **AI手机助手** • **AI推理**
- **AI数学助手** • **AI文档解析** • **AI智能体** • **AI机器人** • **AI编程助手**
- **ASR** • **Android-World** • **Android智能体** • **Any-to-Any** • **Any2Any检索**
- **Audio-to-Audio** • **BGE重排序** • **Blender-bpy** • **CAD助手** • **CIFAR10生成**
- **CNN新闻摘要** • **COCO目标检测** • **CPU推理模型** • **Camera-motion-classification** • **Canny控制视频**
- **CelebA-HQ-256** • **CityScapes微调** • **Cityscapes语义分割** • **CoNLL-03** • **ColPali微调**
- **Crazy版本** • **DNA序列预测** • **DNS挑战** • **DeepSeek-V3.1-Think** • **DeepSex**
- **DepthFusion应用** • **Depth控制视频** • **DevOps-AI助手** • **DevOps大模型** • **DocVQA**
- **Document-Question-Answering** • **Document-Visual-Question-Answering** • **English-文本分类** • **Function-Call** • **GUI操作智能体**
- **GUI智能体** • **Gemma-3n全模态微调** • **Gemma-3轻量模型** • **Gym-Hopper** • **HTML生成**
- **HiDream-扩展** • **Image-Text-to-Text** • **Image-to-3D** • **Image-to-Image** • **JEE数学**
- **Japanese-NER** • **KC-MMBench** • **Kaggle-Age-Classification-Notebook** • **Kinetics-400** • **Kinetics400**
- **Knowledgebase-chatbot** • **KorQuAD** • **LIBERO-Spatial** • **LIBERO任务套件** • **LSUN猫数据集**
- **LaTeX-公式识别** • **Lean-4** • **Lean4-形式化证明** • **LiveCodeBench** • **LiveCodeBench-Pro**
- **Llasa微调指南** • **MNLI零样本分类** • **MS-MARCO段落排序** • **Mask-Generation** • **Multidocument-QA**
- **Multilanguage-support** • **Multipage-Document-VQA** • **NLI俄语** • **NLI模型** • **Natural-Language-Inference**
- **Next-Edit模型** • **OCR** • **OCR增强** • **OCR布局** • **OCR推理**
- **OCR理解** • **OCR问答** • **OPUS翻译模型** • **OS-agent** • **OSworld**
- **OmniEmbed视频RAG** • **Onestep-Generation** • **Open-World-Localization** • **PDF转Markdown** • **Push-in-camera**
- **PushT** • **PushT环境** • **RAG应用** • **RGBD图像生成** • **RSSI预测**
- **RTLCoder** • **RTL推理** • **Real-time-object-detection** • **RetrievalAugmented-Generation** • **SEO写作**
- **SFT微调** • **SQA任务** • **SQuAD微调** • **STEM推理** • **STEM数据**
- **STEM辅助** • **SWE-Bench** • **SWE-bench** • **Sentence-Similarity** • **Something-Something-V2**
- **Stable-Diffusion-VAE解码器** • **TTS** • **Tabular-Classification** • **Tabular-Regression** • **Tabular回归**
- **Text-to-3D** • **Text-to-Image** • **Text-to-Speech** • **Text-to-Video** • **UI定位**
- **UI生成** • **UI问答** • **US-Census-Income-Dataset** • **VAE替换方案** • **VQA-提升**
- **VQA模型** • **Verilog** • **ViT特征提取** • **Video-Text-Retrieval** • **Video-Text-to-Text**
- **Video-to-Video** • **VoiceBank** • **WebVoyager** • **WikiTable-Questions** • **WikiTableQuestions**
- **Yahoo-Answers-主题分类** • **Zero-Shot-Classification** • **Zero-Shot-Object-Detection** • **ZeroShot-Classification** • **Zeroshot-Image-Editing**
- **anime** • **artistic** • **audio-text-to-text** • **cnndailymail** • **coco**
- **feature-extraction** • **few-shot表格问答** • **iOS实时语音** • **iPad端实时视频理解** • **image-to-image**
- **in-the-wild-法线估计** • **macOS语音识别** • **mesh-generation** • **object-detection** • **regression**
- **robotic-manipulation** • **sentence-similarity** • **sim2real** • **squad** • **table-question-answering**
- **tabular** • **tabular-classification** • **tabular-regression** • **testbench生成** • **text-generation-inference**
- **text-to-image** • **unconditional-image-generation** • **us-housing-prices** • **wikisql** • **zero-shot-object-detection**
- **三级风险分类** • **上下文感知语音生成** • **下一句预测** • **下游任务微调** • **不良事件监测**
- **中文关系抽取** • **中文写作优化** • **中文语音预训练** • **中文预训练** • **中英双语**
- **中英双语对话** • **中英双语文本生成视频** • **中英双语文生视频** • **中英文双语** • **中英文混合**
- **中英文混合发音** • **中英翻译** • **事件捕捉** • **二氧化碳排放量预测** • **二氧化碳排放预测**
- **交互式音效设计** • **产品编辑一致性** • **人体姿态估计** • **人像编辑一致性** • **人物真实化**
- **人类偏好预测** • **人脸年龄分类** • **人脸年龄识别** • **人脸解析** • **代理智能**
- **代理能力** • **代码嵌入模型** • **代码执行** • **代码搜索效率** • **代码智能体**
- **代码检索** • **代码生成** • **代码生成模型** • **代码编写** • **代码编辑预测**
- **代码语言模型** • **任务导向抓取** • **任意分割** • **任意分辨率修复** • **任意宽高比**
- **位姿估计** • **低延迟TTS** • **低资源语言** • **俄英翻译** • **俄语STT**
- **俄语自然语言推理** • **俄语语音识别** • **俄语零样本分类** • **信息图问答** • **信息抽取**
- **信息检索** • **偏好模型** • **光学字符识别** • **免OCR文档理解** • **全景分割**
- **全波形反演** • **公式识别** • **关键点匹配** • **具身智能** • **几何三维视觉**
- **函数调用** • **函数调用增强** • **分子建模** • **分子式理解** • **分钟级到小时级分辨率**
- **分钟级点预测** • **前沿知识** • **前端网页开发** • **动态调整推理深度** • **化学分子建模**
- **化学实体识别** • **单列回归** • **单列回归预测** • **单图生成3D网格** • **单图编辑一致性**
- **单应性估计** • **单样本图像分割** • **单步生成** • **单步视频修复** • **单目法向量估计**
- **单目深度估计** • **单轮数学对话** • **印地语TTS** • **印地语语音识别** • **印尼命名实体识别**
- **印尼法律实体识别** • **印尼组织与人物识别** • **印尼语NLP** • **原生功能调用** • **双语交互**
- **双语屏幕代理** • **发票提取** • **句子匹配** • **句子嵌入** • **句子文本相似度**
- **句子映射** • **句子相似度** • **可配置推理强度** • **合成生物学** • **向量数据库**
- **向量检索** • **命名实体识别** • **哼唱感知VAD** • **商业使用** • **噪声抑制**
- **噪声检测** • **图像-文本对话** • **图像修复** • **图像分割** • **图像分析**
- **图像分类** • **图像到3D** • **图像到3D匹配** • **图像到图像** • **图像到文本**
- **图像到视频** • **图像到视频转换** • **图像匹配** • **图像去噪** • **图像合成**
- **图像向量化** • **图像字幕** • **图像字幕生成** • **图像排序** • **图像接地**
- **图像推理** • **图像描述** • **图像描述生成** • **图像插入** • **图像特征提取**
- **图像特征模型** • **图像理解** • **图像生成** • **图像生成引导** • **图像生成视频**
- **图像精炼** • **图像编辑** • **图像编辑对比** • **图像编辑识别** • **图像超分辨率**
- **图像转3D** • **图像转文本** • **图像转视频** • **图像问答** • **图分类**
- **图分类模型** • **图形用户界面交互** • **图文匹配** • **图文对话** • **图文检索**
- **图文理解** • **图文组合** • **图生3D** • **图生视频** • **图结构建模**
- **图表到文本转换** • **图表理解** • **图表解析** • **土壤湿度与温度预报** • **地震信号合成**
- **地震数据偏差减少** • **地震速度模型生成** • **基因工程** • **基因组TF预测** • **声音事件分类**
- **复杂任务处理** • **复杂检索任务** • **复杂表格提取** • **复杂逻辑推理** • **复选框处理**
- **多任务视频推理** • **多元时间序列预测** • **多分辨率视频** • **多图像理解** • **多图像输入**
- **多图编辑** • **多图输入** • **多格式视觉定位** • **多模态检索增强生成** • **多模态理解**
- **多模态直播** • **多模态视频评估** • **多视图立体匹配** • **多语言AI助手** • **多语言NER**
- **多语言NLI** • **多语言TTS** • **多语言VAD** • **多语言与方言支持** • **多语言安全审核**
- **多语言嵌入** • **多语言嵌入模型** • **多语言指令** • **多语言指令理解** • **多语言指令遵循**
- **多语言支持** • **多语言文本嵌入** • **多语言文本转语音** • **多语言机器翻译** • **多语言标点**
- **多语言检索** • **多语言翻译** • **多语言能力** • **多语言自然语言推理** • **多语言语音**
- **多语言语音合成** • **多语言语音重建** • **多语言重排序** • **多语言长尾覆盖** • **多语言问答**
- **多说话人情绪识别** • **多轮交互改写** • **多轮图像编辑** • **多轮对话** • **多页文档分析**
- **大型3D生成模型** • **奖励模型** • **姿态估计** • **学术推理** • **安全审查生成模型**
- **安全审核模型** • **安卓自动化** • **定理证明** • **实体三元组抽取** • **实例分割**
- **实时VAD** • **实时助手** • **实时图像生成** • **实时安全审核** • **实时流式语音合成**
- **实时翻译** • **实时视频理解** • **实时视频生成** • **实时语音对话** • **实时语音活动检测**
- **实时音视频交互** • **实时音视频对话** • **密码子优化** • **密集视觉任务标注** • **对话语音生成**
- **对象擦除** • **小学数学AI** • **小数据预测** • **小样本表格学习** • **小说文本生成**
- **少样本微调** • **少样本预测** • **局部特征匹配** • **居家预训练模型** • **屏幕截图交互**
- **嵌入式推理** • **工业图像分析** • **工具调用** • **工具调用优化** • **工具调用模型**
- **工程代码** • **工程代码编写** • **巴西葡萄牙语NLP** • **带标点和大小写** • **平台识别代理**
- **年龄段图像分类** • **序列视频数据洞察** • **序列问答微调** • **度估计** • **度量深度估计**
- **开发者友好** • **开放词汇检测** • **开放词汇目标检测** • **开源模型** • **开源音乐生成**
- **形式化数学语言** • **思维推理模型** • **思维模式** • **情感分析** • **情感识别**
- **房价预测** • **手写OCR** • **手机端GPT-4o级别** • **报告生成** • **抽取式问答**
- **指令TTS** • **指令微调数据集** • **指令调优** • **指令跟随** • **指令遵循**
- **推理加速** • **推理效率提升** • **推理模型** • **推理能力** • **推荐指令微调**
- **推荐系统增强** • **推荐系统大模型** • **推荐系统微调** • **掩码生成** • **掩码语言建模**
- **提示分割** • **提示词重写** • **搜索智能体** • **摄像机运动控制** • **摘要生成**
- **数值天气预报** • **数学推理** • **数学推理模型** • **数学自动形式化** • **数学解题能力**
- **文字识别** • **文本分类** • **文本到图像生成** • **文本到文本生成** • **文本到视觉文档检索**
- **文本到音乐** • **文本到音频检索** • **文本图像生成** • **文本嵌入** • **文本引导编辑**
- **文本排序** • **文本推理** • **文本提示生成音乐** • **文本摘要** • **文本条件检测**
- **文本条件目标检测** • **文本标点修复** • **文本生成** • **文本生成图像评分** • **文本生成视频**
- **文本蕴含识别** • **文本补全** • **文本质感生成** • **文本转图像** • **文本转语音**
- **文本转音乐** • **文本重建** • **文本重排序模型** • **文档OCR** • **文档图像图表问答**
- **文档布局模型** • **文档摘要** • **文档检索** • **文档理解** • **文档结构分析**
- **文档表格图表理解** • **文档表格检测** • **文档视觉索引** • **文档解析** • **文档问答**
- **文生3D** • **文生图** • **文生视频** • **文生视频评估** • **文生语音**
- **文生音乐** • **无云API调用** • **无条件图像生成** • **无边框表格识别** • **日本語固有表現抽出**
- **日英翻译** • **日语语音识别** • **时间序列预测** • **智能交互式图像编辑** • **智能代理**
- **智能代理功能** • **智能代理能力** • **智能体** • **智能体交互** • **智能体任务**
- **智能体功能** • **智能体基座模型** • **智能体工具** • **智能体工具对接** • **智能体工具集成**
- **智能体控制** • **智能体智能** • **智能体框架** • **智能体模型** • **智能体编码**
- **智能体能力** • **智能体设计** • **智能体集成** • **智能图像描述** • **智能对话**
- **智能工具调用** • **最小化通用控制** • **机器人动作生成** • **机器人强化学习** • **机器人抓取**
- **机器人控制** • **机器人规划模型** • **机器人视觉** • **机器翻译** • **条件图像生成**
- **查询重排序** • **检索任务** • **检索增强** • **概率预测** • **歌词生成**
- **段落排序** • **气象AI预报** • **气象预报** • **氛围编程体验** • **水印提取**
- **法律自然语言处理** • **法线图生成** • **法英翻译** • **法语词性标注** • **流式文本审核**
- **流式语音合成** • **流式语音生成** • **深度信息检索** • **深度图** • **深度补全**
- **混合检索** • **游戏音乐** • **点云图** • **物理常识推理** • **特征提取**
- **特征骨干网络** • **环境声音识别** • **生图** • **生物信息学AI** • **生物力学分析**
- **生物医学图分析** • **生物医学知识图谱构建** • **生物医学视觉语言** • **生物医学问答** • **用户-物品交互**
- **用户-物品理解** • **用户物品交互** • **电话语音识别** • **界面自动化** • **百万字上下文**
- **百语言支持** • **监管文件解析** • **目标检测** • **相关性打分** • **相对深度**
- **相对深度估计** • **相机位姿估计** • **相机内参** • **相机外参** • **真实场景**
- **知识图谱SEO** • **知识图谱填充** • **知识图谱补全** • **短视频理解** • **研究型写作**
- **神经声码器** • **科学分析** • **科学推理** • **科学问题求解** • **立体声生成**
- **竞赛数学** • **端到端任务自动化** • **端到端目标检测** • **端到端语音对话** • **签名检测**
- **结构化数据分类** • **结构化输出** • **结构化输出生成** • **绝对深度估计** • **维度情感分析**
- **编程助手** • **编程推理** • **网络导航代理** • **网页浏览** • **网页端音频模型**
- **翻译质量提升** • **聊天模型** • **聚类任务** • **背景去除** • **自动标点**
- **自动生成模型卡片** • **自动语音识别** • **自动语音转文字** • **自回归图像生成** • **自然流畅语音生成**
- **英德翻译** • **英文命名实体识别** • **英文实体识别** • **英文问答** • **英文预训练**
- **英法机器翻译** • **英语** • **英语嵌入模型** • **英语语言模型** • **英语语音识别**
- **英语问答模型** • **药物发现文献挖掘** • **药物相互作用检测** • **荷兰语翻译** • **葡萄牙语语音识别**
- **虚拟试穿** • **蛋白质功能预测** • **蛋白质序列模型** • **蛋白质序列理解** • **表格事实验证**
- **表格分类** • **表格回归** • **表格基础模型** • **表格推理能力** • **表格理解**
- **表格目标检测** • **表格结构识别** • **表格问答** • **表格预训练** • **西班牙语-英语翻译**
- **西班牙语NER** • **西班牙语情感分析** • **视觉-文本** • **视觉-语言推理** • **视觉-语言模型**
- **视觉丰富文档嵌入** • **视觉定位** • **视觉嵌入模型** • **视觉文档检索** • **视觉智能体**
- **视觉检索** • **视觉检索模型** • **视觉模型** • **视觉模型压缩** • **视觉理解**
- **视觉理解生成统一** • **视觉生成** • **视觉空间智能** • **视觉编码器** • **视觉美学感知**
- **视觉语言动作模型** • **视觉语言推理** • **视觉语言模型** • **视觉语言理解** • **视觉语言理解与生成**
- **视觉辅助编码** • **视觉问答** • **视频-文本检索** • **视频修复** • **视频分割**
- **视频分类** • **视频基础模型** • **视频多模态大语言模型** • **视频对话** • **视频扩展生成**
- **视频扩散模型** • **视频指令跟随** • **视频控制** • **视频检索** • **视频特征提取**
- **视频理解** • **视频理解模型** • **视频生成** • **视频生成模型** • **视频编码器**
- **视频编辑** • **视频质量评估** • **视频超分** • **视频重光照** • **视频问答**
- **视频驱动的上下文图像编辑** • **角色扮演** • **角色扮演体验** • **计算机使用代理** • **计算生物学**
- **设备控制** • **设备端AI** • **设备端嵌入** • **设备端部署** • **词性标注**
- **语义分割** • **语义搜索** • **语义相似度** • **语义相似度搜索** • **语码混合TTS**
- **语言识别** • **语音令牌化器** • **语音克隆** • **语音到文本** • **语音助手**
- **语音合成** • **语音合成微调** • **语音增强** • **语音对话** • **语音对话系统**
- **语音情感识别** • **语音摘要** • **语音文本到文本** • **语音活动检测** • **语音特征提取**
- **语音续写** • **语音翻译** • **语音聊天** • **语音触发调用** • **语音识别**
- **语音识别与翻译** • **语音调用API** • **语音转录** • **语音转换** • **语音转文字**
- **语音转文本** • **语音转语音翻译** • **语音问答** • **语音降噪** • **说话人分割**
- **说话人识别** • **超分辨率** • **超长文本推理** • **跨模态推理** • **跨模态检索**
- **跨语言文本推理** • **跨语言翻译** • **轨迹控制** • **软件工程任务** • **软件工程智能体**
- **轻量化OCR** • **轻量级大模型** • **轻量级数学AI** • **轻量级问答模型** • **边缘AI**
- **边缘AI模型** • **边缘人工智能** • **边缘翻译** • **边缘设备AI** • **运动捕捉**
- **运维问答** • **连续控制** • **通用逻辑** • **逻辑推理** • **逻辑推理模型**
- **重叠语音检测** • **重排序器** • **重排模型** • **钢琴曲生成** • **长上下文**
- **长上下文优化** • **长上下文检索** • **长周期检索** • **长文本处理** • **长文本推理**
- **长文本生成** • **长文档嵌入** • **长文档解析** • **长视频事件捕捉** • **长视频处理**
- **长视频理解** • **长音频理解** • **问答任务** • **问答模型** • **问答系统**
- **阅读理解** • **降水总量预报** • **集成预报** • **零样本主题分类** • **零样本分类**
- **零样本图像分割** • **零样本图像分类** • **零样本数据编辑** • **零样本文本条件目标检测** • **零样本文本目标检测**
- **零样本泛化** • **零样本深度估计** • **零样本目标检测** • **零样本视频语言** • **零样本音频分类**
- **零样本预测** • **非思维模式** • **非结构化文档提取** • **非语言音效生成** • **韩国语AI模型**
- **韩文多模态** • **韩语大模型** • **韩语支持** • **韩语问答** • **音乐元数据识别**
- **音乐分析** • **音乐理解** • **音乐理解模型** • **音乐生成** • **音频-文本转文本**
- **音频内容理解** • **音频分类** • **音频去噪** • **音频合成** • **音频对话模型**
- **音频描述** • **音频描述模型** • **音频描述生成** • **音频提示生成** • **音频摘要**
- **音频理解** • **音频理解基准** • **音频生成** • **音频示例生成音乐** • **音频翻译**
- **音频语言模型** • **音频转乐谱** • **音频转录** • **音频问答** • **音频问答推理**
- **预训练模型** • **额外upscale模型** • **首尾图预测** • **高保真TTS** • **高保真图像合成**
- **高保真语音克隆** • **高分辨率图像** • **高分辨率视觉** • **高分辨率钢琴转录** • **高层大气变量预报**
- **高帧率视频理解** • **高效通用对话** • **高效高分辨率文档解析** • **高级推理** • **高质量图像生成**

### 参数规格 (157个)

- **0.3B参数** • **1.24亿参数** • **1.2B参数** • **1.3B参数** • **1.4B激活参数**
- **1.5B参数** • **1.6B参数** • **1.7B参数** • **1060B参数** • **1060亿参数**
- **10亿激活参数** • **110M参数** • **11B参数** • **120B参数** • **120亿活跃参数**
- **120亿激活参数** • **128K上下文** • **12B参数** • **12层模型** • **12层蒸馏**
- **1300亿参数** • **130亿参数** • **131K上下文** • **140亿参数** • **149M参数量**
- **14B参数** • **14帧视频** • **150亿参数** • **16.9万参数** • **16B参数**
- **16B总参数** • **16亿参数** • **175k步检查点** • **17亿参数** • **18B参数**
- **1B参数** • **1万亿参数** • **1层Transformer** • **2.21B参数** • **2.2亿参数**
- **2.5M-参数** • **2.6B参数** • **203亿参数** • **209M参数** • **20万条指令样本**
- **20亿参数** • **210亿参数** • **21B参数** • **220亿参数** • **224分辨率**
- **22B激活参数量** • **22kHz采样率** • **230百万参数** • **2350B参数** • **2350亿参数**
- **235B-MoE** • **235B参数** • **235B参数量** • **236B参数** • **240亿参数**
- **24B参数** • **250M参数** • **256M参数** • **256分辨率** • **258M参数**
- **270M参数** • **27B参数** • **28B参数** • **2B参数** • **3.6B参数**
- **30.95B参数** • **300B参数** • **300M参数** • **306M参数** • **30B参数**
- **30亿参数** • **32.8B参数** • **320亿活跃参数** • **320亿激活参数** • **321B参数**
- **32B参数** • **32B激活参数** • **32K上下文** • **32k上下文** • **330M参数**
- **340M参数** • **34B参数** • **350M参数** • **3550B参数** • **3550亿参数**
- **36B参数** • **3700万参数** • **384分辨率** • **38B激活** • **39M参数**
- **3B参数** • **3B激活** • **3B激活参数** • **3亿参数嵌入** • **3亿参数嵌入模型**
- **40B参数** • **424B参数** • **434M参数** • **44-kHz音频** • **44kHz采样率**
- **450M参数** • **47B激活参数** • **480B参数** • **4B参数** • **5.5M参数**
- **512倍上采样** • **512分辨率** • **512维嵌入** • **5600亿参数** • **576x1024分辨率**
- **5B参数** • **5B模型** • **600M参数** • **64k上下文** • **650M参数**
- **66M参数** • **671B参数** • **6亿参数** • **7.7亿参数** • **700M参数模型**
- **70B参数** • **70亿参数** • **7200万参数** • **72B参数** • **74M参数**
- **769M参数** • **78B参数** • **7B参数** • **800万参数** • **80B参数**
- **80亿参数量** • **82亿参数** • **86.6M参数** • **8B参数** • **95M参数**
- **9B参数** • **A47B** • **IQ1S** • **MoE-300B** • **OPT-2.7b**
- **Q4KM** • **Q5KL** • **Q6KL** • **Q80** • **Tiny模型**
- **ViT-large** • **万亿参数** • **小尺寸模型** • **模型大小B** • **激活参数220亿**
- **激活参数3.3B** • **约90M参数**

### 基准测试/评估 (1个)

- **RefusalBench**

### 当前模型品牌名 (658个)

- **2DseisvelGenerator** • **A.X-3.1** • **A35B-Instruct** • **A47B** • **AIFS**
- **AIFS-ENS** • **AIFS-Single** • **AndroidGen** • **Anemoi** • **AnimateDiff-Lightning**
- **Apriel-1.5-15b-Thinker** • **Aryabhata-1.0** • **Audio-Flamingo-3** • **AutoTrain-US-Housing-Prices** • **AutoTrain回归模型**
- **BC-Card** • **BERT-base** • **BERT-base-cased** • **BERT-base-chinese** • **BERT-large**
- **BERT-large-SQuAD2** • **BERTimbau-Base** • **BGE** • **BGE-Embedding** • **BGE-M3**
- **BGE-base** • **BGE-small** • **BGE-small-en-v1.5** • **BLIP** • **BLIP-2**
- **BLIP-image-captioning-large** • **BLIP-vqa-capfilt-large** • **BM-Model** • **Beaver** • **Beaver-7B**
- **BetaCeti-Beta-4B** • **BiPali** • **BigVGAN** • **BigVGAN-v2** • **BioBERT**
- **BioBERT-v1.0** • **BiomedCLIP** • **BlenderLLM** • **Bllossom-AICA-5B** • **CD-Bedroom256**
- **CIDASclipseg-rd64-refined** • **CLAP-HTSAT-FUSED** • **CLIP** • **CLIP-ViT-B-32** • **CLIP-ViT-H-14**
- **CLIP-ViT-L-14** • **CLIPSeg** • **Cam-Motion-Preview** • **Canary-Qwen-2.5B** • **CelebAMask-HQ**
- **Chronos-Bolt** • **Chronos-T5** • **CodeFuse-DevOps** • **CodonTransformer** • **CogAgent**
- **CogAgent-9B** • **CogAgent-9B-20241220** • **CogVideoX** • **CogVideoX-LoRa** • **CogVideoX1.5-5B-I2V**
- **Cogito-v2** • **ColPali** • **ColQwen2** • **ColSmol** • **Consistency-Decoder**
- **ControlNet-v1-1** • **ConvNeXt-V2** • **Cosmos-Reason1** • **D-FINE** • **DDPM**
- **DETR** • **DETR-resnet-101** • **DETR模型** • **DETR表格检测** • **DINOv2**
- **DINOv2-giant** • **DINOv2-small** • **DPT-Hybrid** • **DPT-Large** • **DUSt3R**
- **DataComp.XL** • **DeBERTa** • **DeBERTa-v3-large** • **DePlot** • **Decision-Transformer**
- **DeepScaleR** • **DeepSeek-Coder-V2** • **DeepSeek-Prover** • **DeepSeek-Prover-V2** • **DeepSeek-R1**
- **DeepSeek-R1-0528** • **DeepSeek-R1-Distill-Qwen-1.5B** • **DeepSeek-R1-Distill-Qwen-7B** • **DeepSeek-R1-Zero** • **DeepSeek-V2**
- **DeepSeek-V2-Lite** • **DeepSeek-V2.5** • **DeepSeek-V3** • **DeepSeek-V3.1** • **DeepSeek-V3.1-Terminus**
- **DeepSeek-V3.1-Think** • **DeepSeek-V3.2-Exp** • **DeepSeek-V3.2-Exp-Base** • **DeepSeek-VL2** • **DeepSeek-VL2-Tiny**
- **Depth-Anything-V2** • **DevOps-Model** • **DevOps-Model-14B-Base** • **DevOps-Model-14B-Chat** • **DevOps-Model-7B-Base**
- **DevOps-Model-7B-Chat** • **Dia** • **Diffusion-Policy** • **DistilBART** • **DistilBERT**
- **DistilBERT-base-cased** • **DistilBart** • **DistilRoBERTa** • **DobbE** • **DocOwl2**
- **Dolphin-Mistral-24B** • **DreamShaper-7** • **E2-TTS** • **E5-large** • **ERNIE-4.5**
- **ERNIE-4.5-0.3B** • **ERNIE-4.5-300B-A47B-Base** • **ERNIE-4.5-Base** • **ERNIE-4.5-VL** • **ERNIE-4.5-VL-28B-A3B**
- **ERNIE-VL** • **ERNIE4.5** • **ESM-2** • **EXAONE-4.0** • **EdgeNeXt**
- **ElsaV2** • **EmbeddingGemma** • **Emu3** • **Exp-Base** • **F5-TTS**
- **F5TTSv1Base** • **FLUX-Kontext** • **FLUX.1-Kontext-dev** • **FLUX.1-Krea** • **FLUX.1-dev**
- **FairFace-Age-Detection** • **FairFace-数据集** • **Falconsai** • **Florence-2** • **Frame-VAD**
- **GCIRS-Reasoning** • **GCIRS-Reasoning-1.5B** • **GIT** • **GLM-4** • **GLM-4-9B-Chat**
- **GLM-4.1V** • **GLM-4.5** • **GLM-4.5-Air** • **GLM-4.6** • **GLM-4V-9B**
- **GLM-4V-9B基座** • **GLM-Edge-4B-Chat** • **GLM-Edge-V-2B** • **GLM-Edge-V-5B** • **GLM-Z1**
- **GLM-Z1-Rumination** • **GLiNER** • **GPT-2** • **Gemma-3** • **Gemma-3-270M**
- **Gemma-3-270m** • **Genereux-akotenou** • **Git-base** • **Google-Gemma-3** • **Google大模型**
- **Granite-Docling** • **Granite-TimeSeries-TTM-R2** • **Graphormer** • **Graphormer-base-pcqm4mv2** • **GraphsGPT-4W**
- **GraspMolmo** • **Grok-2** • **HMAET回归** • **Helsinki-NLP** • **Hermes-4**
- **HiDream** • **HiDream-E1** • **HiDream-E1.1** • **HiDream-I1** • **HiDream.ai**
- **HiPO-8B** • **Holo1.5** • **HumAware-VAD** • **I2V-14B** • **I2V-A14B**
- **IDM-VTON** • **ITDR** • **ITDR-GLM-4-9B** • **ITDR-LLaMA3.2-3B** • **ImageGPT**
- **InstantMesh** • **Instinct** • **Intern-S1** • **InternLM-XComposer2.5** • **InternVL2**
- **InternVL2.5HiCoR16** • **InternVL3** • **InternVideo2.5** • **Isaac-0.1** • **Janus-Pro**
- **JanusFlow** • **Jukebox** • **K2** • **KAT** • **KAT-Coder**
- **KAT-Dev** • **KDD-CUP-2021** • **Kakao大模型** • **Kanana** • **KaniTTS**
- **Keye-VL** • **Keye-VL-1.5** • **Kimi** • **Kimi-Audio** • **Kimi-K2**
- **Kimi-K2-Instruct** • **Kimi-VL** • **Kimi-VL-A3B-Thinking** • **KoELECTRA** • **Kontext**
- **Kosmos-2** • **Kwai-Keye** • **KwaiCoder-AutoThink-preview** • **Kwaipilot-AutoThink** • **LAION-Audio-630K**
- **LDM3D-4C** • **LEGAL-BERT** • **LFM2** • **LFM2-1.2B** • **LFM2-1.2B-Extract**
- **LFM2-1.2B-RAG** • **LFM2-1.2B-Tool** • **LFM2-350M** • **LFM2-350M-Math** • **LFM2-700M**
- **LLMDet** • **LLaMA-Mesh** • **LLaVA-1.5-7B** • **LLaVA-NeXT-Video** • **LLaVA-Video-7B-Qwen2**
- **LTX-Video** • **LayoutLM** • **LayoutLMv2** • **LayoutLMv3** • **LayoutLMv3-base**
- **LeRobot** • **LightGlue** • **Ling-1T** • **LingNLI** • **Liquid**
- **Llasa-1B-Multilingual** • **LongCat-Flash-Thinking** • **Lumina-DiMOO** • **M3-Agent** • **M3-Agent-Memorization**
- **MAR** • **MASt3R** • **MERT** • **MERT-v1** • **MM-Grounding-DINO**
- **MMS-LID-256** • **MMaDA-8B** • **MMaDA-8B-MixCoT** • **MNLI-FEVER-ANLI** • **MP-DocVQA**
- **MP-SENet** • **MachineLearningLM** • **Magenta-RT** • **MagicQuill** • **Magistral-Small**
- **Magistral-Small-2507** • **MapAnything** • **MarbleNet** • **Marvis-TTS** • **Mask2Former**
- **MaskFormer** • **MeloTTS-French** • **MeloTTS-Spanish** • **Meta-FAIR** • **Meta-FAIR实验室**
- **MetricGAN-Plus** • **MiDaS-3.0** • **MiMo-Audio** • **MinerU2.5** • **Ming-Lite-Omni**
- **MiniCPM** • **MiniCPM-V** • **MiniCPM-V-2** • **MiniCPM-o** • **MiniCPM-o-2.6**
- **MiniCPM4.1** • **Mistral-Small** • **Mistral-Small-3.2** • **Mitra** • **Mitra-Regressor**
- **Mixedbread** • **MobileNetV3** • **MobileNetV3-Small** • **MobileViT-small** • **Mochi-1**
- **Molmo** • **Moonlight-16B** • **Moonlight-16B-A3B** • **Motion-LoRA** • **MusicGen**
- **NLLB-200** • **NVIDIA-Nemotron-Nano-9B-v2** • **NVIDIA模型** • **NYU-KITTI** • **Nanonets-OCR**
- **Nemotron** • **NextStep-1** • **NusaBert-ner-v1.3** • **OASIS-code-1.3B** • **OCRFlux**
- **OPUS-MT** • **OWLViT** • **OWLv2** • **OminiControl** • **OmniGen2**
- **OmniLMM-3B** • **OmniTab** • **OpenAI-CLIP** • **OpenMed-NER-PharmaDetect** • **OpenReasoning-Nemotron**
- **OpenVLA-OFT** • **Orsta-7B** • **PCQM4M-LSC** • **PaliGemma-3B** • **Parakeet-TDT**
- **Patch14-224** • **Pegasus** • **Phi-4-mini** • **Pi0** • **PickScorev1**
- **PyDevMini1** • **Qianfan-VL** • **Qwen-Image-Edit-2509** • **Qwen2-Audio** • **Qwen2-Audio-7B**
- **Qwen2-Audio-7B-Instruct** • **Qwen2-Audio-7B-Instruct-i1-GGUF** • **Qwen2-VL-2B-Instruct** • **Qwen2.5-14B-Instruct-1M** • **Qwen2.5-7B-Instruct**
- **Qwen2.5-Omni** • **Qwen2.5-Omni-3B** • **Qwen2.5-VL** • **Qwen2.5-VL-32B-Instruct** • **Qwen2.5-VL-32B-Instruct-AWQ**
- **Qwen2.5-VL-32B-Instruct-FP8-Dynamic** • **Qwen2.5-VL-3B-Instruct** • **Qwen3** • **Qwen3-1.7B-FP8** • **Qwen3-14B**
- **Qwen3-14B-FP8** • **Qwen3-14B-MLX-8bit** • **Qwen3-235B** • **Qwen3-235B-A22B** • **Qwen3-235B-A22B-MLX-6bit**
- **Qwen3-235B-A22B-Thinking-2507** • **Qwen3-30B** • **Qwen3-30B-A3B-Base** • **Qwen3-30B-A3B-MLX-8bit** • **Qwen3-32B**
- **Qwen3-32B-AWQ** • **Qwen3-32B-MLX-4bit** • **Qwen3-32B-MLX-6bit** • **Qwen3-32B-MLX-8bit** • **Qwen3-4B**
- **Qwen3-4B-Thinking** • **Qwen3-8B-MLX-6bit** • **Qwen3-8B-MLX-8bit** • **Qwen3-Coder** • **Qwen3-Coder-480B-A35B-Instruct**
- **Qwen3-Embedding-4B-GGUF** • **Qwen3-Next** • **Qwen3-Omni** • **Qwen3-Omni-30B-A3B-Captioner** • **Qwen3-VL-235B-A22B-Instruct**
- **Qwen3Guard-Gen** • **Qwen3Guard-Stream-4B** • **QwenLong-CPRS** • **RMBG-1.4** • **RT-DETR**
- **Realistic-Vision** • **Relation-Extraction-Chinese** • **ResNet18.a1in1k** • **Ring-mini** • **RolmOCR**
- **RuBERT** • **SAM-ViT** • **SAM-ViT-Huge** • **SAM-ViT-Large** • **SAM-ViT-base**
- **SAM2** • **SD-XL** • **SD-XL-Turbo** • **SEOcrate-4B** • **SRPO**
- **STSB** • **SWE-Dev-32B** • **SWE-Dev-9B** • **SWE-Dev-train** • **Seed-OSS**
- **SeedVR** • **SeedVR2** • **SegFormer-B0** • **SegFormer-B4** • **SigLIP**
- **SigLIP2-So400m** • **Silero-VAD** • **Smol-Vision** • **SmolLM3** • **Spatial-MLLM**
- **SpeechT5** • **Stability-AI** • **Stable-Diffusion** • **Stable-Diffusion-2-Inpainting** • **Stable-Video-Diffusion**
- **Step-Audio** • **Step-Audio-AQAA** • **Step3** • **StepFun-Formalizer** • **SuperPoint**
- **Surya-Layout** • **SynthLabsAI** • **SynthPose** • **T-one** • **T-pro-it-2.0-eagle**
- **T-tech** • **T2V-14B** • **T5-11B** • **T5-3B** • **T5-Base**
- **TAPAS** • **TAPAS-Tiny** • **TAPAS-large** • **TAPAS小型** • **TAPEX**
- **TAPEX-large** • **TC-Light** • **TF-Decision-Trees** • **TRELLIS** • **TRELLIS-text-base**
- **TRELLIS-text-large** • **TabPFN** • **TabPFNMix** • **Table-Transformer** • **Tar-7B**
- **Tifa-DeepSexV2** • **Tifa-Deepsex** • **Tifa-Deepsex-14b-CoT** • **TimeSformer** • **TinyTapas**
- **TinyTimeMixers** • **Tongyi-DeepResearch** • **TrOCR** • **TrOCR-large-printed** • **Trellis**
- **Trellis3D** • **UI-TARS** • **UI-TARS-1.5** • **UI-TARS-72B-DPO** • **UI-TARS-7B-SFT**
- **UIGENT3** • **ULTRA** • **Ultravox** • **UniVLA** • **Unsloth**
- **V-JEPA** • **V-JEPA-2** • **VGGT** • **VINCIE-3B** • **VLAC**
- **VQ-BeT** • **VQ-BeT-policy** • **Veena** • **Venice-Uncensored** • **VeriReason**
- **ViLT** • **ViT-Base-Patch14** • **ViViT** • **Video-R1** • **VideoLLaMA3**
- **VideoMAEv2-Base** • **VideoMAEv2-Large** • **VideoScore-v1.1** • **VisionReward** • **VitPose**
- **VitPose-Huge变体** • **VoxCPM** • **Voxtral-Mini** • **Voxtral-Mini-3B** • **Voxtral-Small**
- **WANLI** • **WTQ** • **Wan2.1** • **Wan2.1-Fun-14B-Control** • **Wan2.1-I2V**
- **Wan2.1-I2V-14B-480P** • **Wan2.1-T2V-14B** • **Wan2.114BVACE-GGUF** • **Wan2.1I2V14BFusionX** • **Wan2.1T2V**
- **Wan2.2** • **Wan2.2-T2V-A14B** • **WanVideo** • **Wav2Vec2-Base** • **WebSailor-3B**
- **Whisper** • **Whisper-large-v3-turbo** • **Whisper-medium** • **Whisper-tiny.en** • **WikiTableQuestions**
- **Wolf-Rayet-2B-Prime3** • **WorldPM** • **WorldPM-72B-RLHFLow** • **X-CLIP** • **XCodec2**
- **XLM-RoBERTa-large** • **XLMRoBERTalarge** • **XLMRobertalarge** • **YOLOS-small** • **YOLOS-tiny**
- **ZoeDepth** • **allenai** • **androidgen** • **arxiv2302.12288** • **autotrain**
- **autotrain-data-dragino-7-7** • **bagel-gguf** • **bart-large-cnn-samsum** • **bart-large-mnli-yahoo-answers** • **bert-base-cased-squad2**
- **bert-base-portuguese-cased** • **bge-reranker-v2-m3** • **cdimagenet64l2** • **chinese-hubert-base** • **chinese-hubert-large**
- **chronos-t5-small** • **cointegratednli-rus-translated-v2021** • **conjuncts** • **consistency-model** • **controlnet**
- **convnextv2nano.fcmaeftin22kin1k** • **cross-encoderms-marco-MiniLM-L6-v2** • **cross-encodernli-deberta-v3-large** • **ddpm-cifar10-32** • **ddpm-ema-church-256**
- **diffusers-ctcat256** • **dino-vits8** • **discogs-maest-30s-pw-73e-ts** • **distilbart-cnn-6-6** • **ditr-e15**
- **dreamshaper** • **dreamshaper-8-inpainting** • **emotion-recognition-wav2vec2-IEMOCAP** • **face-parsing** • **facebookbart-base**
- **flairner-english-fast** • **french-camembert-postag-model** • **glm-4vq** • **google-t5t5-large** • **googleddpm-church-256**
- **gpt-oss** • **gpt-oss-120b** • **gpt-oss-20b** • **gte-large-en-v1.5** • **gte-reranker-modernbert-base**
- **hidream** • **hiera-large** • **hoyoMusic** • **iGPT** • **ibm-granitegranite-timeseries-ttm-r1**
- **imagegpt-medium** • **jina-embeddings-v3** • **jina-embeddings-v4** • **mBART** • **mDeBERTa**
- **mDeBERTa-v3** • **marigold-normals** • **multi-qa-MiniLM-L6-cos-v1** • **mxbai-embed-large** • **mxbai-embed-large-v1**
- **neuralmind** • **nomic-embed-text-v1.5** • **nomic-embed-vision** • **opus-mt-en-de** • **opus-mt-en-fr**
- **opus-mt-es-en** • **opus-mt-fr-en** • **opus-mt-nl-en** • **opus-mt-ru-en** • **opus-mt-zh-en**
- **palmyra-mini** • **paraphrase-MiniLM-L6-v2** • **paraphrase-multilingual-MiniLM-L12-v2** • **pcolocautotrain-data-mikrotik-7-7** • **pcolocautotrain-dragino-7-7-max495m**
- **pcolocautotrain-mikrotik-7-7** • **pianotrans** • **punctuate-all** • **pyannotesegmentation** • **roberta-base-bne-capitel-ner**
- **robertuito-sentiment-analysis** • **rubert-base-cased-nli-threeway** • **sail-rvc** • **skops-digits** • **slimsam-77-uniform**
- **stable-diffusion-2-1** • **step3-fp8** • **vit-age-classifier** • **vitbasepatch16224.dino** • **vitlargepatch14reg4dinov2.lvd142m**
- **wav2vec2-large-robust-12-ft-emotion-msp-dim** • **wav2vec2-large-xlsr-53-japanese** • **wav2vec2-large-xlsr-53-portuguese** • **wav2vec2-large-xlsr-53-russian** • **xai-orggrok-2**
- **xlm-roberta-large-xnli-anli** • **xlm-roberta-ner-japanese** • **万2.1** • **印尼RoBERTa** • **字节大模型**
- **字节跳动Seed** • **密集预测Transformer** • **快手大模型** • **文心一言** • **智谱AI**
- **月之暗面** • **混元** • **混元视频** • **清影开源版** • **百度大模型**
- **米哈游音乐生成** • **腾讯大模型** • **视觉几何基础Transformer** • **豆包** • **轻量版v2**
- **通义千问** • **通义千问3** • **阿里大模型**

### 微调支持 (1个)

- **微调支持**

### 技术出处 (1个)

- **arxiv2410.13842**

### 技术基础 (2个)

- **Stable-Diffusion** • **runwayml**

### 技术文献 (1个)

- **arxiv2203.07378**

### 技术特性 (1206个)

- **1.5-cfg** • **1024x1024分辨率** • **1024分辨率** • **1024维嵌入** • **109B-MoE架构**
- **10亿样本预训练** • **12-6蒸馏** • **128K-tokens上下文** • **128K上下文** • **128K上下文长度**
- **128K长上下文** • **128k上下文** • **128专家8激活** • **131K上下文** • **131K上下文长度**
- **131K长上下文** • **13公开推荐数据源** • **13层气压层结构** • **16164压缩比** • **16K上下文**
- **16kHz采样率** • **16帧秒** • **1M上下文** • **200K上下文** • **20万实例数据集**
- **21128-词表** • **224x224分辨率** • **224x224视频预处理** • **22B激活** • **23K-tokens推理**
- **24层Transformer** • **256K上下文** • **256K长上下文** • **256K长文本理解** • **256批次训练**
- **262k上下文长度** • **26种语言** • **26语言支持** • **2比特量化** • **300-tokenss高速生成**
- **30秒音频限制** • **324标记编码** • **32K上下文** • **32K上下文窗口** • **32kHz音频**
- **32k上下文** • **32帧采样** • **36层网络** • **384维向量** • **384长度**
- **3D-VAE** • **48帧处理** • **4bit-量化** • **4bit推理** • **4bit量化**
- **4位2位无损量化** • **4位无损量化** • **4层解码** • **4步推理** • **4比特无损量化**
- **4比特量化** • **4码本** • **5.7T-tokens训练** • **512x512分辨率** • **512个token上下文**
- **512倍上采样** • **52关键点** • **570GB西班牙语** • **595K-合成图像训练** • **5T科学数据**
- **6200万-真实无标签图像** • **64K上下文** • **64K词元输出** • **64K输出标记** • **64k上下文**
- **64层网络** • **64帧视频处理** • **64帧采样** • **6bit量化** • **768维嵌入**
- **7亿样本预训练** • **8192-tokens** • **8192上下文** • **8192上下文NER** • **8K上下文**
- **8bit量化** • **8x8补丁** • **8亿图像文本对** • **8帧视频输入** • **8步生成**
- **8种语言** • **8语言支持** • **94层Transformer** • **960小时训练** • **96准确率**
- **A3B系列** • **A47B系列** • **AFD解耦** • **ANLI** • **APO对齐训练**
- **ASR模式** • **AWQ量化** • **Action-Operation-Sensitive** • **Adam优化器** • **Adjustable-decoder-layers**
- **Agentic-Data** • **AnglE损失函数** • **Any-to-Any** • **Apache-2.0-许可** • **Apache-2.0许可**
- **Apache-2.0许可证** • **Apache-License-2.0** • **AuT-预训练** • **AudioLM-架构** • **AutoThink**
- **BART架构** • **BBH推理** • **BC5CDR** • **BCE损失函数** • **BERT-RoPE-GLU**
- **BERT-base** • **BERT-large规模** • **BERT蒸馏** • **BEiT** • **BEiT权重初始化**
- **BEq验证** • **BF16推理** • **BLEU-26.9** • **BLEU-60.9** • **BLEU分数**
- **BLEU评估** • **BNE语料** • **Base版本** • **BiPali** • **BiSigLIP**
- **BrowseComp基准** • **ByteMorph-Bench** • **C-MTEB** • **C4数据集** • **CAPITEL数据集**
- **CC-BY-4.0许可证** • **CC100预训练** • **CLIP-H架构** • **CLIP主干网络** • **CLIP多模态**
- **CLIP检测** • **CLIP骨干网络** • **CLIcK** • **CLS标记特征** • **CLS标记表征**
- **CNN-Transformer融合** • **COCO-2017** • **COCO-预训练** • **COCO数据集** • **CPU实时推理**
- **CRPS优化** • **CTC模型** • **CTC解码** • **CVPR23** • **CVPR亮点论文**
- **CamemBERT** • **CameraBench** • **Cased模型** • **CfgDistill** • **ChatML-template**
- **ChatML模板** • **ChatTemplate输入** • **CoNLL-03** • **ColBERT策略** • **ColBERT风格**
- **Common-Voice-6.1-Russian** • **Common-Voice微调** • **Conformer** • **Consistency-Distillation** • **ControlNet原生支持**
- **Creative-Commons-4.0** • **CreativeML** • **CreativeML-Open-RAIL-M** • **CrossEncoder** • **DALL-E-3解码器**
- **DDIM** • **DETR** • **DETR等效模型** • **DINOv2** • **DINOv2骨干网络**
- **DISK特征点** • **DORA系统** • **DPO优化** • **DPO强化学习** • **DPO微调**
- **DPT架构** • **DPT框架** • **DPT框架扩展** • **DataComp-1B** • **DeepSeek-Sparse-Attention**
- **DeepSeekMoE** • **DevOpsEval** • **DiT架构** • **Diffusion** • **Diffusion-Model-Distillation**
- **DocVQA** • **EMA** • **EMA权重平均** • **ERA5再分析** • **Eagle3**
- **Eagle解码** • **EnCodec令牌器** • **EulerDisc调度器** • **FCMAE框架** • **FID指标**
- **FLD-5B数据集** • **FLUX量化版** • **FP16混合精度** • **FP8-Scale-训练** • **FP8混合精度**
- **FP8混合精度训练** • **FP8版本** • **FP8训练** • **FP8量化** • **FP8量化模型**
- **FSQ约束** • **Faithful-Speech** • **Fast-Sampling** • **FastConformer** • **FastConformer-TDT**
- **FinTabNet.c数据集** • **Flow-Matching** • **Fluent-Speech** • **Function-Call** • **FusionX**
- **GGUF** • **GGUF格式** • **GGUF模型** • **GGUF量化** • **GMACs**
- **GPQA基准** • **GQA-648-注意力头** • **GQA注意力** • **GRIT-ID-NER数据集** • **GRPO**
- **GRPO强化学习** • **GRPO框架** • **GRPO算法改进** • **GSPO** • **GUI感知**
- **Gemma-3-多模态** • **Gemma-3-开放权重** • **Gemma-3-指令调优** • **Gemma-3-轻量级** • **GenSelect**
- **Generative-Scoring** • **Greedy-decoding** • **Grounding-DINO-改进版** • **HTSAT** • **HiDream-safetensors**
- **Hiera架构** • **HoNY数据集** • **HuBERT模型** • **HugeNews数据集** • **Hugging-Face兼容tokenizer**
- **HumSpeechBlend数据集** • **Hungarian匹配** • **Hybrid-encoder** • **I2V-720p** • **ICDAR2019**
- **IDA训练** • **IEMOCAP数据集** • **INT4扩散模型** • **IQ2IQ3量化** • **IQ4XS**
- **IQ量化** • **Image-Segmentation** • **Image-Text-to-Text** • **Image-to-3D** • **ImageNet-1k**
- **ImageNet-1k微调** • **ImageNet-1k预训练** • **ImageNet-22k微调** • **IndoNLU** • **Instruct-2507**
- **InternViT** • **JAX兼容** • **JSON坐标输出** • **JSON模式生成** • **KD-MTP**
- **KMMLU** • **Keras预处理层** • **LAION-2B** • **LAMA-掩码** • **LAMB优化器**
- **LLM模式** • **LLaMA微调** • **LPIPS** • **LRM架构** • **LSTM-CRF**
- **LVD-142M数据集** • **LVIS数据集** • **Lean-4** • **Lean-4形式化** • **Librispeech预训练**
- **Liquid模型** • **LoRA微调** • **LoRA秩16** • **LoRA适配器** • **LoRa适配器**
- **MAE初始化** • **MFA注意力** • **MGRPO** • **MGRPO算法** • **MGRPO训练**
- **MIT** • **MIT开源** • **MIT开源协议** • **MIT许可证** • **MLM范式**
- **MLM预训练** • **MM-Grounding-DINO** • **MRoPE** • **MSE-0.005** • **MTEB**
- **MaskDecoder** • **Matryoshka-Representation-Learning** • **Matryoshka嵌入** • **Matryoshka表示学习** • **Mean-Pooling**
- **MiMo-Audio-Tokenizer** • **MiniLM** • **Mixture-of-Experts** • **MoE-8128** • **MoE架构**
- **MoE模型** • **MobileNetV2风格层** • **MoonViT** • **Motion-LoRAs** • **Multimodal-Heterogeneous-MoE**
- **Muon优化器** • **MusicCoCa** • **NYU数据集微调** • **NanoCodec** • **Nature论文**
- **NoPE位置编码** • **Nunchaku量化** • **OASIS-instruct数据合成算法** • **OFT微调** • **ONNX导出**
- **OPUS-数据集** • **OPUS数据集** • **OWLv2量化** • **Objects365-pretraining** • **OmniContext-基准测试**
- **OpenCLIP** • **OpenCLIP-ViTH** • **OpenCLIP框架** • **OpenFWI数据集** • **OpenRAIL-M**
- **PCQM4M-LSCv2** • **PD解耦** • **PD解耦技术** • **PD解耦推理** • **PEFT优化**
- **PKU-SafeRLHF** • **PMC预训练** • **PMP** • **PNDM** • **POS-NEG-NEU**
- **PaddlePaddle权重** • **PaliGemma-3B** • **Pick-a-Pic数据集** • **Pile-NER训练** • **PixMo数据集**
- **PromptEncoder** • **PubMedBERT** • **PubMed预训练** • **PubTables1M数据集** • **PubTables1M训练**
- **Q-Former** • **Q4KM-GGUF量化** • **Q4KM量化** • **Q4KS** • **Q6K**
- **Q80** • **Q80量化** • **QAT量化** • **QK重归一化** • **Qwen加训**
- **R2得分0.486** • **RLHFlow** • **RMSProp** • **RMSProp优化器** • **ROUGE-1指标**
- **RTL推理** • **RVC** • **RandAugment** • **ReAct推理范式** • **ReLU激活函数**
- **Replicate训练** • **ResNet-50-DETR** • **ResNet34架构** • **RoBERTa** • **RoBERTa权重初始化**
- **RoBERTuito** • **RoPE外推** • **Rust支持** • **SA-1B数据集** • **SA-1B预训练**
- **SAMSum数据集** • **SDEdit** • **SDXL-1.0-蒸馏** • **SEO推理模型** • **SFT微调**
- **SNAC音频** • **SOTA性能** • **SQL执行器** • **SQuAD2.0** • **SQuAD2.0-微调**
- **SVDQuant** • **SWIFT框架微调** • **Safetensors** • **SailorFog-QA** • **Scale-aware-interaction**
- **Segformer** • **SentencePiece** • **SentencePiece分词** • **Sigmoid损失函数** • **Sigmoid映射**
- **SoViT-400m架构** • **Something-Something-V2** • **SpectralMaskEnhancement** • **SpectroStream** • **Step-SRPO**
- **StepDistill** • **StepSRPO** • **Structured-3D-Latents** • **Subset数据集** • **Swin主干网络**
- **Synthetic-document-finetuning** • **T5-efficient-tiny** • **T5架构** • **TDT解码器** • **TITAN**
- **TMRoPE** • **TMRoPE位置编码** • **TP4并行** • **Tabular-Classification** • **Tabular回归**
- **Tailwind-CSS** • **Tatoeba测试** • **TaylorSeer** • **TeaCache** • **Think-on查询**
- **Thinker-Talker** • **Thinker-Talker架构** • **ThinkerTalker-设计** • **TinyTimeMixers** • **Transformer**
- **Transformers** • **Transformers视频** • **Transformer生物模型** • **Tunesformer** • **U-Net**
- **UE8M0-FP8精度** • **UI定位** • **UMRB基准** • **UPO优化** • **UR50D数据集**
- **USI蒸馏** • **US住房数据** • **Uncertainty-minimization-query-selection** • **UniGRPO** • **Universal-NER**
- **UnlabeledHybrid-1M** • **Unsloth-Dynamic-2.0** • **Unsloth提速** • **Unsloth量化** • **VACE**
- **VLM** • **VQAScore** • **ViT** • **ViT-B-编码器** • **ViT-B16**
- **ViT-B16架构** • **ViT-L-14** • **ViT-L-256** • **ViT-Large** • **ViT-g**
- **ViT-like-Transformer** • **ViTbase-骨干** • **ViT图像分类** • **ViT图像编码器** • **ViT大型骨干**
- **ViT大型骨干网络** • **ViT特征提取** • **Vision-Transformer** • **VisionEncoder** • **W4A8C8量化**
- **WMT-Europarl** • **WTQ微调** • **Wan-VAE** • **Wav2Vec2FeatureExtractor** • **WikiSQL微调**
- **X2I2-训练数据集** • **XLSR微调** • **XNLI** • **XNLI微调** • **YaRN**
- **YaRN-超长上下文** • **YaRN扩展** • **YaRN扩展上下文** • **YaRN技术** • **abc乐谱**
- **adam** • **artistic** • **arxiv-2506.03107** • **arxiv2107.07653** • **arxiv2303.1672**
- **arxiv2306.09683** • **arxiv2312.15503** • **arxiv2408.00714** • **arxiv2505.22705** • **behavior-generation**
- **bf16精度** • **bfloat16推理** • **brWaC** • **cnndailymail基准** • **deberta-v3-large**
- **dense-retrieval** • **exam-centric** • **f8-decoder** • **feature-extraction** • **forced-BOS-token**
- **fp816缩放版** • **fp8量化** • **fp8量化视频模型** • **function-calling** • **harmony-响应格式**
- **harmony响应格式** • **hypothesistemplate** • **i1-IQ1** • **i1-IQ2** • **i1-IQ3**
- **i1-IQ3XS** • **i1-IQ4** • **i1-IQ量化** • **i1-IQ量化版本** • **i1-IQ量化系列**
- **imatrix量化** • **int8量化视频模型** • **latent-actions** • **latent扩散模型** • **mlp**
- **mmproj-Q80** • **modernBERT** • **multilingual** • **multilingualNLI26lang2mil7** • **noVAE**
- **nvidiamit-b5** • **pyannote.audio** • **q4KM-量化** • **qk层归一化** • **regression**
- **sentence-transformers** • **seq2seq模型** • **seq2seq表格模型** • **speaker-segmentation** • **spm32k词表**
- **stable-diffusion** • **tabular** • **tabular-regression** • **textgenerationinference** • **tiktoken**
- **token-classification** • **token级分类** • **transformer-align** • **transformers模型** • **uncased**
- **vLLM推理加速** • **vllm高效推理** • **wav2vec2** • **xlm-roberta-base** • **xsum基准**
- **一步式推理** • **一步视频修复** • **一致性RMS更新** • **一致性模型** • **一致性蒸馏**
- **一致性解码** • **一致性训练** • **七子任务结构** • **万-VAE** • **三分类NLI**
- **三级严重程度分类** • **三级风险等级** • **三阶段预训练范式** • **上下文学习** • **下一个token预测**
- **下一令牌预测** • **下一句预测** • **下一帧分割预测** • **下一帧图像预测** • **专家混合语言模型**
- **专家集成** • **专用分词器** • **专用融合损失函数** • **两阶段TTS** • **两阶段扩散**
- **两阶段流水线** • **两阶段长上下文扩展** • **中文RoBERTa微调** • **中等轨迹** • **中间预训练**
- **主权AI** • **乘法门控** • **二分匹配** • **二分匹配损失** • **二进制量化**
- **人机任务联觉** • **人类偏好对齐** • **仓库级程序分析** • **代理强化学习** • **代理能力集成**
- **代码执行增强** • **令牌量化** • **任务中心化** • **任务适配器** • **任意分辨率**
- **任意长度1080P视频编解码** • **企鹅视频基准** • **优化微调** • **位置重置** • **低CO2排放**
- **低幻觉音频描述** • **低延迟** • **低延迟ASR** • **修正流** • **偏好建模**
- **偏好模型** • **像素预测** • **先验数据学习** • **全局处理** • **全局批调度**
- **全局批负载均衡损失** • **全局最优定位自蒸馏** • **全模态** • **全端到端音频交互** • **全自动数据合成流水线**
- **全词掩码** • **共享嵌入空间** • **关键词到标题增强** • **内存效率** • **内容安全**
- **决策森林模型** • **冷启动推理数据** • **冷启动数据** • **冷启动数据混合** • **冻结图像编码器**
- **减少重复生成** • **几何3D视觉** • **分层编码器** • **分数蒸馏** • **前沿视频理解**
- **前置归一化** • **加权矩阵量化** • **加权矩阵量化版本** • **加权量化版本** • **动作扩散策略**
- **动态分词器** • **动态分辨率** • **动态分辨率视频** • **动态分辨率视频理解** • **动态图像分辨率**
- **动态推理** • **动态视觉推理** • **动态计算机制** • **动态量化** • **匈牙利匹配**
- **区分大小写** • **升级视觉识别** • **单Transformer多模态** • **单一矢量量化** • **单样本推理**
- **单样本解决方案** • **单步生成** • **单轮音频输入** • **单阶段自回归** • **卷积码量化**
- **历史重采样** • **原生262K上下文** • **原生MXFP4量化** • **原生智能体** • **原生长上下文**
- **去噪分数匹配** • **去噪扩散概率模型** • **双分支插件模块** • **双向注意力** • **双向编码器**
- **双向表征** • **双模式推理** • **双码本音频分词器** • **双采样策略优化** • **双重掩码策略**
- **双阶段训练** • **反刍思考** • **反刍模型** • **反思模型** • **反思能力**
- **可引导性** • **可微分等值面提取** • **可控上下文优化** • **可提示分割** • **可配置推理强度**
- **可验证奖励强化学习** • **右填充查询** • **合成数据** • **合成数据微调** • **合成数据训练**
- **合成数据预训练** • **合成表格任务** • **合成语料库** • **后训练优化** • **后训练语料库**
- **噪声鲁棒语音** • **四阶段渐进式预训练** • **因果语言建模** • **因果语言模型** • **图Transformer**
- **图像Transformer** • **图像patch** • **图像文本对训练** • **图像补丁** • **图像补丁嵌入**
- **图像视频统一架构** • **图文交叉理解** • **图神经网络** • **块因果扩散Transformer** • **基于Llama的TTS**
- **增强多模态推理** • **增强对比类头** • **增量预训练** • **复杂动作生成能力** • **复杂卷积优化**
- **复杂运动生成** • **复杂逻辑推理** • **多GPU并行推理** • **多token预测** • **多专家并行协作**
- **多分辨率图像理解** • **多向量检索** • **多向量表示** • **多头潜在注意力** • **多尺度可变形注意力**
- **多尺度子带CQT判别器** • **多尺度梅尔频谱图损失** • **多尺度特征学习** • **多智能体协同** • **多标记预测**
- **多样化多模态能力** • **多格式视觉定位** • **多模态** • **多模态RAG** • **多模态令牌平衡**
- **多模态多语言** • **多模态大语言模型** • **多模态异构MoE** • **多模态异构MoE预训练** • **多模态扩散模型**
- **多模态推理** • **多模态目标检测** • **多模态视频模型** • **多模态试验模型** • **多模态语音**
- **多模态语音大语言模型** • **多模态预训练** • **多矩阵分解注意力** • **多码本设计** • **多视频输入**
- **多语言** • **多语言安全审查** • **多语言嵌入** • **多语言支持** • **多轮上下文学习**
- **大规模视频预训练** • **大规模预训练** • **大语言模型协同训练** • **大语言模型监督检测** • **奖励模型**
- **子目标分解** • **子领域变体** • **安全RLHF** • **完整思维链** • **实时安全监控**
- **密集特征提取** • **密集视觉任务标注** • **密集预测Transformer** • **对抗后训练** • **对抗扩散蒸馏**
- **对比学习** • **对比式语言-音频预训练** • **对话式指向** • **对象查询** • **对齐翻译模型**
- **小样本学习** • **少样本学习** • **层归一化** • **层次负载均衡** • **嵌入模型**
- **嵌入维度压缩** • **嵌套式嵌入** • **工具调用** • **工具调用优化** • **布局感知**
- **布局检测** • **并行多智能体** • **并行预测** • **幻觉率降低** • **序列到序列模型**
- **序列标注模型** • **开放数据政策** • **开放权重** • **开放词汇** • **开放词汇检测**
- **开放词汇表分类** • **开源多模态** • **开源智能体** • **开源模型** • **异构MoE**
- **异构MoE结构** • **异构混合并行** • **异构混合并行策略** • **引导蒸馏** • **引导蒸馏技术**
- **弱监督训练** • **强化学习** • **强化学习微调** • **强化学习推理** • **强化学习证明助手**
- **强化学习调度** • **强化微调** • **当前帧分割预测** • **微型预训练模型** • **微调加速**
- **微调模型** • **快速训练与推理** • **思维推理模式** • **思维模式** • **思维模式切换**
- **思维链** • **思维链增强** • **思维链开关** • **思维链推理** • **思维链融合**
- **思考模式** • **思考模式切换** • **思考范式** • **思考长度提升** • **思考预算控制**
- **情感控制** • **情感语调控制** • **感知任务的上下文学习** • **感知推理一体化** • **感知推理定位记忆集成**
- **感知语言模型** • **慢-快视频编码** • **成对比较机制** • **扩散Transformer** • **扩散先验**
- **扩散变换器** • **扩散对抗训练** • **扩散概率模型** • **扩散模型** • **扩散模型法线估计**
- **扩散模型蒸馏** • **拒绝采样** • **拒绝采样微调** • **持续预训练** • **指令微调**
- **指令微调数据集** • **指令微调模型** • **指令模型** • **指令跟随安全** • **指令遵循**
- **推理优化MoE** • **推理增强** • **推理效率提升** • **推理模式** • **推理演示代码**
- **推理能力** • **推理能力增强** • **推理规模扩展** • **推理轨迹** • **掩码生成策略**
- **掩码语言建模** • **掩码语言模型** • **提示词方法** • **提示驱动分割** • **教师强制**
- **数学自验证** • **数据掌控** • **数据稀缺训练** • **整流流转换器** • **文本Transformer**
- **文本到文本** • **文本到文本框架** • **文本到文本迁移转换器** • **文本对齐表征** • **文本嵌入**
- **文本提示遵循能力** • **旋转位置编码** • **无-flashattn-运行** • **无CFG视频生成** • **无CLIP无预训练LLM**
- **无G2P语音合成** • **无偏好调优语音模型** • **无分词器TTS** • **无分词器语音模型** • **无合成数据**
- **无审查版本** • **无教师蒸馏** • **无标注交互** • **无标注任务执行** • **无监督视觉预训练**
- **无监督预训练** • **无矢量量化** • **无辅助损失负载均衡** • **无辅助损失负载平衡** • **无重置版本**
- **无需微调** • **无需训练** • **时序编解码** • **时空注意力** • **时空理解**
- **时间一致性** • **时间序列基础模型** • **时间戳预测** • **智能体强化学习** • **智能体能力优化**
- **权重衰减** • **权重衰减优化** • **查询感知压缩** • **标点大小写转换** • **样本效率**
- **梯度提升树** • **模型蒸馏** • **模型融合** • **模态专项后训练** • **模态隔离路由**
- **欧几里得化图** • **每日四次同步运行** • **每秒50令牌** • **法律文本预训练** • **注意力-前馈网络解耦**
- **注意力统计池化** • **流匹配头** • **流式ASR** • **流式音频块输出** • **流式音频生成**
- **深度强化学习** • **深度思考** • **深度思考能力** • **深度推理** • **混合Liquid模型**
- **混合专家** • **混合专家架构** • **混合专家模型** • **混合快慢思考模式** • **混合思考模式**
- **混合推理模型** • **混合推理模式** • **混合架构** • **混合注意力** • **混合注意力机制**
- **混合液态模型架构** • **混合策略优化** • **混合长链思维** • **混合音频输入** • **渐进式有损解压缩**
- **滑动窗口变换** • **滑动窗口注意力** • **潜在-VAE-条件** • **潜在动作** • **潜在扩散**
- **潜在扩散模型** • **特定模态后训练** • **特征匹配损失** • **独立训练** • **猫式MLP解码器**
- **现代BERT架构** • **生成式安全分类** • **生成式渲染** • **生成式解决方案选择** • **生物医学BERT**
- **用户-物品交互** • **用户-物品理解** • **用户友好部署** • **电影感运动** • **电影级美学**
- **电影级美学效果** • **百万上下文** • **监督微调** • **直接响应模式** • **直接多步预测**
- **相对位置嵌入** • **真实世界代码数据集** • **知识推理融合** • **知识蒸馏** • **矩阵量化**
- **社区许可** • **神经SQL执行器** • **移除参数共享机制** • **稀疏专家模型** • **稀疏扩散Transformer**
- **稀疏检索** • **稀疏注意力** • **稀疏视角重建** • **稠密与延迟交互检索** • **稠密模型**
- **稠密模型与混合专家模型** • **空间感知** • **窗口并行推理** • **窗口注意力ViT** • **端到端3D重建**
- **端到端任务自动化** • **端到端多模态模型** • **端到端强化学习** • **端到端扩散自回归** • **端到端设计**
- **类ChatML对话模板** • **精准空间智能** • **系统提示词控制** • **纯Transformer图学习** • **线性加权评分**
- **线性化表格** • **线性探测** • **细粒度分布精化** • **细粒度多维度评估** • **细粒度音色控制**
- **细粒度音频分析** • **结构化3D潜变量** • **结构化输出** • **绝对深度** • **统一偏好优化**
- **统一偏好优化UPO** • **统一关系表示** • **统一多模态** • **统一模型** • **统一模态**
- **统一离散扩散架构** • **编码器-解码器** • **自举式生成** • **自举式预训练** • **自举标注技术**
- **自动语言检测** • **自回归TTS** • **自回归Transformer** • **自回归图像生成** • **自回归文本生成**
- **自回归模型** • **自回归生成** • **自回归解码器** • **自回归语言模型** • **自回归采样**
- **自定义CUDA内核** • **自定义维度** • **自我反思推理** • **自我改进训练** • **自我验证**
- **自监督DINOv2方法** • **自监督DINO方法** • **自监督学习** • **自监督方式** • **自监督视觉特征**
- **自监督预训练** • **自适应分层令牌压缩** • **自适应层级化token压缩** • **自适应推理** • **自适应窗口注意力**
- **蒙特卡洛树搜索** • **蒸馏模型** • **蒸馏版** • **融合CUDA内核** • **表格预训练**
- **表结构推理** • **规模扩展定律** • **视觉-语言-动作** • **视觉-语言-动作流模型** • **视觉-语言-动作能力**
- **视觉Transformer** • **视觉token化** • **视觉变换器** • **视觉基础模型** • **视觉定位**
- **视觉推理** • **视觉文本生成** • **视觉文本融合** • **视觉编码器** • **视觉编码解耦**
- **视觉语言模型** • **视频动态特征分析** • **视频掩码自编码器** • **视频生成训练流程** • **视频表示学习**
- **视频视觉变换器** • **视频语言模型** • **解耦图像分词器** • **解耦式视觉语言模型** • **训练效率优化**
- **训练数据规模扩展** • **记忆增强** • **词片段掩码** • **语义理解** • **语言一致性优化**
- **语音直接触发功能调用** • **语音触发调用** • **误检鲁棒** • **负责任AI工具包** • **贪婪解码**
- **超长上下文** • **超长序列支持** • **跨具身视频** • **跨模态向量量化** • **跨模态推理**
- **跨模态预训练** • **跨页表格合并** • **踏板检测** • **轨迹质量筛选** • **轻量化BERT**
- **轻量化摘要模型** • **轻量化模型** • **轻量级MLP解码头** • **轻量级SAM** • **轻量级卷积神经网络**
- **轻量级多模态** • **轻量级模型** • **轻量级重排序器** • **轻量级预测器** • **边缘实时推理**
- **进化思维链** • **连续tokens** • **连续令牌** • **连续令牌自回归** • **连续值扩散**
- **选择性推理** • **递归定理证明** • **遮蔽注意力Transformer** • **采样效率提升** • **重排序模型**
- **量化感知训练** • **量化标记序列** • **量化模型** • **量化转换版本** • **链式微调**
- **链式思维** • **长上下文** • **长上下文与视频理解** • **长上下文扩展** • **长上下文模型**
- **长上下文理解** • **长上下文音频理解** • **长丰富上下文** • **长思维** • **长文本上下文处理**
- **长文本理解** • **长时与丰富上下文建模** • **长期依赖建模** • **长视频上下文** • **长链思维链冷启动训练**
- **长音频上下文** • **降维64** • **随机抽样** • **随机森林建模** • **零中心层归一化**
- **零任务微调** • **零样本分割** • **零样本分类管道** • **零样本性能** • **零样本推理**
- **零样本法线估计** • **零样本深度** • **零样本编辑** • **零样本视频理解** • **零样本语音识别**
- **零样本预测** • **静态量化** • **静态量化版本** • **非思维模式** • **非思考型模型**
- **非思考模式** • **非语言音效** • **音乐预训练** • **音频-文本对** • **音频伪标记**
- **音频嵌入向量** • **音频特征提取** • **音频预训练** • **预训练时间序列模型** • **领域并行训练**
- **高保真度动态效果** • **高分辨率38402160** • **高分辨率文档压缩器** • **高密度音符转录** • **高效推理**
- **高效高清混合TI2V** • **高稀疏MoE** • **高级推理** • **高级空间感知** • **高质量相机运动数据集**
- **高质量语音**

### 授权协议 (1个)

- **Apache-License-2.0**

### 授权许可 (1个)

- **Apache-License-2.0**

### 推理特性 (1个)

- **可配置推理强度**

### 数据来源 (3个)

- **CSS10日语** • **Common-Voice日语** • **JSUT语音数据集**

### 数据规模 (1个)

- **20万实例**

### 数据集 (4个)

- **COCO-2017** • **ImageNet-ILSVRC-2012** • **OPUS数据集** • **Stockmark-NER数据集**

### 数据集来源 (1个)

- **MSP-Podcast**

### 文件格式 (1个)

- **GGUF**

### 智能体能力 (1个)

- **原生函数调用**

### 能力特性 (1个)

- **高分辨率支持**

### 训练技术 (1个)

- **GRPO强化学习**

### 训练数据 (9个)

- **COCO** • **IAM数据集** • **Kinetics-400** • **LLaVA-OneVision数据集** • **LLaVA-Video-178K数据集**
- **LibriTTS** • **SQuAD-v2** • **duie数据集** • **imagenet-21k**

### 训练数据集 (1个)

- **VideoChatGPT-Instruct**

### 训练策略 (1个)

- **合成数据增强**

### 许可协议 (1个)

- **Apache-2.0-许可**

### 许可证 (2个)

- **Apache-2.0** • **Apache-2.0-许可**

### 评估基准 (1个)

- **VideoMME基准**

### 评估指标 (2个)

- **BLEU评分** • **chr-F指标**

### 评测基准 (2个)

- **Screenspot-V2** • **WebClick基准**

### 语言类型 (1个)

- **English**

### 输入规格 (1个)

- **32x32图像**

### 输出格式 (1个)

- **主谓宾三元组**

### 部署工具 (203个)

- **2Bits量化** • **4bit量化** • **4比特量化TTS** • **6bit量化** • **API平台**
- **API调用** • **AWQ量化** • **AWQ量化模型** • **Amazon-SageMaker训练** • **Apache-2.0许可证**
- **Apache-License-2.0** • **AutoAWQ** • **AutoGluon** • **AutoGluon-Tabular** • **AutoTrain**
- **AutoVideoProcessor** • **Azure-NIM** • **Blackwell-GPU** • **CC-BY-4.0** • **CC-BY-4.0开源**
- **CPU推理** • **CUDA加速推理** • **Chat-Demo** • **Colab免费微调** • **Colab微调**
- **ComfyUI** • **ComfyUI-GGUF** • **ComfyUI-WanVideoWrapper** • **ComfyUI-gguf节点** • **ComfyUI兼容**
- **CoreML** • **DDIM调度** • **DDIM调度器** • **DDPM推理** • **Demo-APK**
- **Diffusers** • **Diffusers兼容** • **Diffusers库** • **Diffusers推理** • **Diffusers集成**
- **Diffusion-Single-File** • **DiffusionPipeline** • **Docling流水线** • **Ego4D预训练** • **ExtractiveReader**
- **FP8量化** • **FP8量化模型** • **Fairseq** • **FastDeploy** • **Flair框架**
- **Flax微调** • **FriendliAI平台** • **GGUF** • **GGUF格式** • **GGUF量化**
- **GGUF量化模型** • **GPTQ** • **GPTQ-Int4** • **Google-Colab微调** • **Google-Colab运行**
- **Gradio演示** • **Gradio界面** • **Gradio网页演示** • **Haystack** • **Haystack集成**
- **Hugging-Face-Spaces** • **Hugging-Face托管模型** • **Hugging-Face模型** • **Hugging-Face深度学习容器** • **Hugging-Face语音模型**
- **HuggingFace** • **HuggingFace-ONNX** • **HuggingFace-Transformers** • **HuggingFace-pipeline** • **HuggingFace-transformers**
- **HuggingFace兼容** • **HuggingFace推理** • **HuggingFace模型** • **HuggingFace镜像** • **HuggingSound**
- **JAX** • **Joblib** • **Joblib模型** • **Jupyter生物工具** • **Keras**
- **LM-Studio** • **LeRobot训练** • **LiteRT** • **Llasa微调** • **MIT开源**
- **MIT开源可商用** • **MIT许可证** • **MLX-4bit** • **MLX框架** • **MLX部署**
- **MLX量化** • **MLX音频库** • **MLflow-追踪** • **Mage平台** • **MaskFormerImageProcessor**
- **ModelScope-pipeline** • **NVIDIA开放模型许可** • **NeMo** • **NeMo-ASR** • **Nexa-SDK**
- **NextStepPipeline** • **Nomic-Atlas** • **OCRFlux-API** • **ONNX** • **ONNX导出**
- **ONNX推理** • **ONNX支持** • **ONNX部署** • **Ollama导出** • **Ollama部署**
- **Ollama量化** • **Ollama集成** • **OpenVINO兼容** • **OpenX数据集** • **PEFT**
- **PNDM调度器** • **PaddlePaddle** • **PaddlePaddle权重** • **PaddlePaddle版** • **PyTorch**
- **PyTorch实现** • **PyTorch权重** • **PyTorch部署** • **Python库** • **Q8量化**
- **QLoRA修复脚本** • **Safetensors** • **SageMaker部署** • **Sentence-Transformers** • **Sentence-Transformers嵌入**
- **SentenceTransformers** • **SpeechBrain** • **StreamLake** • **Swift集成** • **TensorFlow**
- **TensorFlow-NER模型** • **TensorFlow部署** • **TorchScript模型** • **Transformers.js** • **Transformers主分支**
- **Unsloth微调** • **Wav2Vec2FeatureExtractor** • **WebUI在线试用** • **Z.ai-API** • **ZeroGPU**
- **ZeroShotClassificationPipeline** • **autotrain** • **bfloat16推理** • **bnb-4bit** • **colpali-engine**
- **fp16量化** • **gguf-connector** • **joblib** • **joblib模型文件** • **lightx2v推理引擎**
- **llama.cpp** • **llama.cpp兼容** • **llama.cpp部署** • **pandas表格** • **pipeline-API**
- **pip安装** • **pysentimiento工具包** • **q5KM量化** • **rvc-runpod** • **schedulingddpm**
- **scikit-learn** • **sentence-transformers** • **sglang** • **stable-diffusion-diffusers** • **timm库**
- **timm框架** • **transformers.js** • **vLLM推理** • **vLLM部署** • **vllm**
- **vllm兼容** • **vllm加速推理** • **vllm推理** • **wav2vec2-sprint** • **单卡H100运行**
- **单卡RTX-4090运行** • **单块GPU运行** • **开源模型** • **微调** • **微调预训练**
- **本地推理** • **本地运行** • **本地部署** • **本地部署重排序** • **本地量化部署**
- **检查点推理** • **浏览器推理** • **消费级RTX4090** • **灵活部署方案** • **端侧部署**
- **笔记本部署** • **设备端部署** • **量化模型**

### 部署方式 (3个)

- **PT权重** • **本地推理** • **本地部署**

### 量化技术 (1个)

- **MXFP4-量化**

### 预处理技术 (1个)

- **SentencePiece分词**

### 预训练数据集 (1个)

- **ImageNet-1k**

## 详细结果


### deepseek-ai/Janus-Pro-1B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/Janus-Pro-1B

**关键词列表**:

- **Janus-Pro** (当前模型品牌名): 从项目名称直接提取的当前模型名称，符合用户搜索AI模型时的惯用品牌词
- **多模态** (技术特性): 模型核心定位是统一多模态理解和生成，是用户搜索相关模型时的关键技术标签
- **自回归模型** (技术特性): README明确说明是自回归框架，属于用户搜索模型架构时的高频技术词
- **文生图** (功能场景): 模型支持图像生成，且用户常搜索'文生图'作为AI生成图像的意图关键词
- **AI写作** (功能场景): 基于DeepSeek-LLM构建，具备语言理解与生成能力，符合AI写作类应用场景
- **7B参数** (参数规格): 模型基于DeepSeek-LLM-7b-base构建，7B是主流参数规模，用户常按此搜索模型
- **统一模型** (技术特性): README强调'统一多模态理解和生成'，'统一模型'是用户区分专用模型与通用模型的搜索关键词
- **本地部署** (部署工具): 模型开源且为轻量级（1B级别），用户有强烈本地部署需求，符合常见搜索意图

### deepseek-ai/DeepSeek-Prover-V1

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V1

**关键词列表**:

- **DeepSeek-Prover** (当前模型品牌名): 从项目名称直接提取的当前模型名称，符合品牌名简化规则（去版本号）
- **定理证明** (功能场景): 模型核心用途是自动形式化定理证明，用户会搜索该功能关键词
- **合成数据** (技术特性): 模型核心创新点是使用大规模合成数据训练，是区别于其他模型的关键技术
- **Lean-4** (技术特性): 模型专为Lean 4证明助手设计，是其形式化证明的专属技术生态，用户搜索定理证明时会关联该工具
- **AI数学助手** (功能场景): 模型用于解决数学竞赛题与形式化证明，可归纳为AI数学助手这一用户易搜场景
- **Transformer** (技术特性): 作为LLM基础架构，Transformer是用户搜索AI模型时高频技术关键词，且模型基于此架构

### deepseek-ai/DeepSeek-V2.5

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2.5

**关键词列表**:

- **DeepSeek-V2.5** (当前模型品牌名): 项目名称即为模型的官方品牌名
- **编程助手** (功能场景): 模型融合了 DeepSeek‑Coder‑V2‑Instruct 的编码能力，可用作编程助手
- **指令遵循** (功能场景): 模型在指令遵循（instruction following）上进行了提升，适合需要精准指令执行的场景
- **文本生成** (功能场景): 标签中包含 Text Generation，说明模型擅长通用文本生成任务

### QuantStack/Wan2.2-T2V-A14B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.2-T2V-A14B-GGUF

**关键词列表**:

- **Wan2.2-T2V-A14B** (当前模型品牌名): 从项目名称 QuantStack/Wan2.2-T2V-A14B-GGUF 中提取的当前模型核心名称，符合简化规则（保留品牌+核心标识，去后缀-GGUF）
- **文生视频** (功能场景): 模型标签为 Text-to-Video，对应中文用户高频搜索词'文生视频'，明确表达模型用途
- **ComfyUI** (部署工具): README明确指出模型需配合 ComfyUI-GGUF 节点使用，是用户部署时的关键搜索词
- **量化模型** (技术特性): README明确说明'这是一个量化模型'，符合用户搜索'量化模型'以寻找轻量部署方案的意图
- **GGUF** (技术特性): GGUF是模型文件格式，用户在搜索本地部署AI模型时高频使用该关键词，属于技术术语但非过度专业
- **Apache-License-2.0** (技术特性): 开源协议是用户筛选模型的重要依据，'Apache License 2.0'是用户在开源社区搜索可商用模型时的常用关键词

### deepseek-ai/JanusFlow-1.3B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/JanusFlow-1.3B

**关键词列表**:

- **JanusFlow** (当前模型品牌名): 从项目名称提取的当前模型名称
- **修正流** (技术特性): 当前模型结合了修正流这一生成模型中的前沿方法
- **图像生成** (功能场景): 当前模型支持图像生成功能
- **图像理解** (功能场景): 当前模型支持图像理解功能

### microsoft/deberta-v3-large

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/deberta-v3-large

**关键词列表**:

- **DeBERTa-v3-large** (当前模型品牌名): 从项目名称直接提取的当前模型全称，用户搜索AI模型时会精确使用该名称
- **DeBERTa** (当前模型品牌名): 模型系列通用简称，用户常搜索'DeBERTa'而非完整版本，属于高流量关键词
- **PyTorch** (部署工具): README明确提及使用HF transformers + PyTorch微调，用户会搜索该框架部署该模型
- **HuggingFace** (部署工具): 模型托管于HuggingFace生态，用户常通过'HuggingFace + 模型名'搜索部署方式
- **文本分类** (功能场景): 模型在MNLI等文本分类任务上表现优异，是用户搜索NLU模型时的典型应用场景
- **问答系统** (功能场景): 模型在SQuAD 2.0问答数据集上取得SOTA，用户搜索'问答系统模型'时会匹配该模型
- **掩码语言模型** (技术特性): 模型基于掩码语言建模（MLM）预训练，是NLP用户搜索模型时的关键技术标签

### google/pegasus-xsum

**URL**: https://ai.gitcode.com/hf_mirrors/google/pegasus-xsum

**关键词列表**:

- **Pegasus** (当前模型品牌名): 从项目名称google/pegasus-xsum提取的核心品牌名
- **文本摘要** (功能场景): README明确标注任务为summarization

### openai/whisper-tiny.en

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-tiny.en

**关键词列表**:

- **Whisper-tiny.en** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索轻量级语音识别模型时会使用此精确名称
- **英语语音识别** (功能场景): 模型明确标注为仅英文语音识别，是用户搜索英文ASR任务时的核心意图词
- **39M参数** (参数规格): 模型参数量为39M，属于轻量级主流规格，用户会搜索‘39M语音模型’寻找低资源部署方案
- **自动语音识别** (功能场景): README首句即定义模型用途为‘自动语音识别（ASR）’，是中文用户最直接的搜索关键词
- **Safetensors** (部署工具): 标签中明确包含Safetensors，是当前模型安全加载的格式，开发者常搜索此关键词优化部署

### Wan-AI/Wan2.2-TI2V-5B

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.2-TI2V-5B

**关键词列表**:

- **Wan2.2** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **图生视频** (功能场景): 模型支持图片生成视频的核心应用场景
- **MoE架构** (技术特性): 首次在视频扩散模型中引入的混合专家（Mixture‑of‑Experts）架构
- **5B参数** (参数规格): 模型规模为5B参数，用户常以参数量搜索模型

### gilf/french-camembert-postag-model

**URL**: https://ai.gitcode.com/hf_mirrors/gilf/french-camembert-postag-model

**关键词列表**:

- **french-camembert-postag-model** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索法语词性标注模型时最可能使用的精准关键词
- **法语词性标注** (功能场景): 模型的核心用途，用户在CSDN等平台搜索法语NLP任务时会直接使用该中文术语
- **CamemBERT** (技术特性): 模型基于CamemBERT架构，是法语NLP领域公认的基础模型名称，用户会搜索该技术术语
- **词性标注** (功能场景): 中文用户搜索NLP任务时常用'词性标注'这一通用术语，比英文'POS tagging'更符合中文搜索习惯

### Kwaipilot/KwaiCoder-AutoThink-preview

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/KwaiCoder-AutoThink-preview

**关键词列表**:

- **KwaiCoder-AutoThink-preview** (当前模型品牌名): 从项目名称提取的当前模型名称
- **AutoThink** (技术特性): 当前模型的核心技术特性，自动思考能力
- **StepSRPO** (技术特性): 当前模型使用的分步序列强化学习技术
- **Agentic-Data** (技术特性): 当前模型采用的智能体数据生成技术
- **KD-MTP** (技术特性): 当前模型使用的知识蒸馏和多token预测技术
- **动态调整推理深度** (功能场景): 当前模型根据输入难度动态调整推理深度的功能

### autogluon/tabpfn-mix-1.0-regressor

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/tabpfn-mix-1.0-regressor

**关键词列表**:

- **TabPFNMix** (当前模型品牌名): 从项目名称 'autogluon/tabpfn-mix-1.0-regressor' 中提取的核心模型品牌名，去掉版本号后为用户搜索的简洁标识
- **Tabular-Regression** (功能场景): README明确标注的标签，直接描述模型的核心应用场景，用户会搜索‘表格回归’相关AI模型
- **上下文学习** (技术特性): README明确提到采用‘融合上下文学习的预训练策略’，是模型的关键能力，非通用术语，具指向性
- **AutoGluon** (部署工具): 模型通过AutoGluon库调用，是用户使用该模型的唯一官方入口，搜索‘AutoGluon 回归’是典型用户意图
- **合成数据预训练** (技术特性): 模型通过‘从随机回归器混合生成的纯合成数据集进行预训练’，是其区别于其他模型的独特训练方式

### dandelin/vilt-b32-finetuned-vqa

**URL**: https://ai.gitcode.com/hf_mirrors/dandelin/vilt-b32-finetuned-vqa

**关键词列表**:

- **ViLT** (当前模型品牌名): 项目名称中明确出现的模型简称，用户会直接搜索
- **视觉问答** (功能场景): README核心用途“视觉问答”是用户高频搜索词
- **VQA模型** (功能场景): 视觉问答领域通用缩写，用户常用VQA模型作为关键词

### keras-io/TF_Decision_Trees

**URL**: https://ai.gitcode.com/hf_mirrors/keras-io/TF_Decision_Trees

**关键词列表**:

- **TF-Decision-Trees** (当前模型品牌名): 从项目名称 keras-io/TF_Decision_Trees 提取的当前模型名称
- **梯度提升树** (技术特性): 当前模型采用的核心算法
- **结构化数据分类** (功能场景): 模型专为结构化数据的二分类任务设计
- **Keras预处理层** (技术特性): 实现自定义Binary Target编码器作为Keras预处理层
- **决策森林模型** (技术特性): 通过指定输入特征构建的决策森林模型
- **US-Census-Income-Dataset** (功能场景): 模型训练使用的经典结构化数据集，用户会搜此数据集+模型组合

### Falconsai/text_summarization

**URL**: https://ai.gitcode.com/hf_mirrors/Falconsai/text_summarization

**关键词列表**:

- **Falconsai** (当前模型品牌名): 从项目名称 Fal​consai/text_summarization 中提取的模型品牌名称
- **摘要生成** (功能场景): 模型的核心任务是将输入文本压缩为有意义的摘要
- **微调模型** (技术特性): 模型在 T5‑Small 基础上经过微调，提升了摘要任务的表现

### TIGER-Lab/VideoScore-v1.1

**URL**: https://ai.gitcode.com/hf_mirrors/TIGER-Lab/VideoScore-v1.1

**关键词列表**:

- **VideoScore-v1.1** (当前模型品牌名): 从项目名称直接提取的当前模型正式名称，用户搜索AI视频评估模型时会使用此完整品牌名
- **视频质量评估** (功能场景): 模型核心用途是评估视频质量，符合用户搜索意图（如'如何评估AI生成视频质量'）
- **多模态视频评估** (功能场景): 模型基于文本-视频对齐进行评估，属于多模态任务，是用户在AI视频领域高频搜索的精准场景词
- **48帧处理** (技术特性): 模型支持48帧长视频推理，是区别于其他模型的显著技术优势，用户会搜索'支持长视频的AI评估模型'
- **文生视频评估** (功能场景): 模型用于评估AI生成的文本到视频内容，是生成式AI领域新兴且高搜索潜力的场景词

### FreedomIntelligence/BlenderLLM

**URL**: https://ai.gitcode.com/hf_mirrors/FreedomIntelligence/BlenderLLM

**关键词列表**:

- **BlenderLLM** (当前模型品牌名): 从项目名称 FreedomIntelligence/BlenderLLM 直接提取的当前模型唯一品牌名
- **CAD助手** (功能场景): 模型专为计算机辅助设计（CAD）场景优化，用户会搜索‘CAD助手’这类明确用途词
- **Text-to-3D** (功能场景): 模型核心能力之一是将文本生成3D模型，属于高价值垂直场景，用户会直接搜索该术语
- **自我改进训练** (技术特性): 模型采用‘自我改进’技术进行优化，是其区别于其他模型的核心训练方法
- **Blender-bpy** (功能场景): 模型针对Blender软件的bpy脚本环境优化，是其独特应用场景，用户会搜索‘Blender bpy’相关AI工具
- **3D建模AI** (功能场景): 模型用于3D建模自动化，符合用户搜索‘3D建模AI’这类具象化意图的关键词

### openbmb/MiniCPM-V

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-V

**关键词列表**:

- **MiniCPM-V** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **OmniLMM-3B** (当前模型品牌名): MiniCPM-V 的别名，README 中标注为 OmniLMM-3B
- **双语交互** (功能场景): 模型是首款支持中英双语多模态交互的终端部署模型
- **实时视频理解** (功能场景): 支持 iPad 端实时视频理解以及多模态直播功能
- **3B参数** (参数规格): 模型规模为 3B 参数（OmniLMM-3B）

### pcoloc/autotrain-dragino-7-7-max_495m-1860863627

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-dragino-7-7-max_495m-1860863627

**关键词列表**:

- **pcolocautotrain-dragino-7-7-max495m** (当前模型品牌名): 从项目名称提取的当前模型名称
- **单列回归** (功能场景): 当前模型的问题类型，即应用场景
- **tabular-regression** (功能场景): 标签中提及，表明模型用于表格回归任务
- **Joblib** (部署工具): 标签中提及，模型使用Joblib进行加载和部署
- **Transformers** (技术特性): 标签中提及，表明模型可能基于Transformer架构

### city96/Wan2.1-I2V-14B-480P-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/city96/Wan2.1-I2V-14B-480P-gguf

**关键词列表**:

- **Wan2.1-I2V-14B-480P** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定图像转视频模型的精准关键词
- **图像转视频** (功能场景): 对'Image-to-Video'的自然中文翻译，符合用户搜索意图，区别于通用'文生图'

### naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt

**URL**: https://ai.gitcode.com/hf_mirrors/naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt

**关键词列表**:

- **DUSt3R** (当前模型品牌名): 从项目名称提取的当前模型名称
- **几何三维视觉** (功能场景): 当前模型的核心功能，用户会直接搜索
- **图像转3D** (功能场景): README标签image-to-3d对应的功能
- **ViT-Large** (技术特性): 模型架构中包含ViT Large，用户会搜
- **512分辨率** (参数规格): 模型名称中512_dpt，用户会搜512分辨率模型

### BAAI/bge-reranker-v2-m3

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-reranker-v2-m3

**关键词列表**:

- **bge-reranker-v2-m3** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索多语言重排序模型时会精准使用此名称
- **多语言重排序** (功能场景): 模型核心功能是输入查询与文档并输出相关性分数，用户搜索‘多语言重排序’时明确指向此类模型
- **BGE重排序** (功能场景): BGE是该系列模型的通用品牌前缀，用户常以‘BGE重排序’作为关键词搜索相关模型，具有品牌辨识度
- **本地部署重排序** (部署工具): README强调‘易于部署，推理速度快’，用户常搜索‘本地部署重排序’以寻找可私有化部署的重排序方案
- **相关性打分** (功能场景): 模型直接输出查询与文档的相关性分数，这是其区别于嵌入模型的核心功能，用户搜索此术语精准匹配使用场景
- **轻量级重排序器** (技术特性): README多次强调‘轻量级’与‘推理速度快’，该词组合是用户在对比模型时常用的筛选关键词
- **Sigmoid映射** (技术特性): 模型输出通过Sigmoid映射到[0,1]区间，是其技术实现的独特细节，专业用户会以此为关键词检索实现方式

### CuriousMonkey7/HumAware-VAD

**URL**: https://ai.gitcode.com/hf_mirrors/CuriousMonkey7/HumAware-VAD

**关键词列表**:

- **HumAware-VAD** (当前模型品牌名): 项目名称即模型品牌名，直接体现模型身份
- **哼唱感知VAD** (功能场景): 模型专注于区分哼唱与真实语音的语音活动检测
- **实时语音活动检测** (功能场景): 模型支持实时处理，适用于在线语音分割场景
- **HumSpeechBlend数据集** (技术特性): 使用自定义的 HumSpeechBlend 数据集进行微调，提高哼唱场景下的检测准确率
- **TorchScript模型** (部署工具): 模型以 JIT TorchScript 形式保存，便于跨平台部署和高效推理
- **PyTorch实现** (部署工具): 模型基于 PyTorch 框架开发，符合主流深度学习生态

### ServiceNow-AI/Apriel-1.5-15b-Thinker

**URL**: https://ai.gitcode.com/hf_mirrors/ServiceNow-AI/Apriel-1.5-15b-Thinker

**关键词列表**:

- **Apriel-1.5-15b-Thinker** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多模态推理** (技术特性): 当前模型具备文本和图像推理能力，属于多模态推理模型
- **文本推理** (功能场景): 当前模型增强了文本推理能力
- **图像推理** (功能场景): 当前模型新增了图像推理支持
- **150亿参数** (参数规格): 当前模型的参数规模为150亿
- **单块GPU运行** (部署工具): 当前模型可在单块GPU上运行，内存效率极高

### openbmb/MiniCPM-Llama3-V-2_5-int4

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-Llama3-V-2_5-int4

**关键词列表**:

- **MiniCPM** (当前模型品牌名): 从项目名称提取的当前模型名称

### BAAI/bge-small-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-small-en-v1.5

**关键词列表**:

- **BGE-small-en-v1.5** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索英文句子嵌入模型时会使用此精确名称
- **句子相似度** (功能场景): 模型核心用途为计算英文句子间的语义相似度，是用户在检索场景中明确搜索的意图关键词
- **特征提取** (功能场景): 模型用于将文本转化为向量特征，是检索系统中用户常搜索的功能术语
- **sentence-transformers** (部署工具): 模型官方支持sentence-transformers库，是开发者部署该模型时最常使用的工具名称
- **dense-retrieval** (技术特性): 模型属于密集检索范式，是RAG系统中区别于稀疏检索的核心技术术语，用户会针对性搜索
- **MIT许可证** (部署工具): 开源协议是开发者选型时的关键筛选条件，MIT是高频搜索词，且为当前模型专属属性
- **C-MTEB** (技术特性): 模型在C-MTEB基准上评估，该基准是中文/英文检索领域权威评测集，用户搜索模型性能时会关联此术语

### BAAI/bge-base-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-base-en-v1.5

**关键词列表**:

- **BGE-base** (当前模型品牌名): 从项目名称提取的当前模型名称，去掉版本号更简洁
- **检索增强** (功能场景): README中明确提到“retrieval-augmented LLMs”，用户会搜此场景
- **文本嵌入** (功能场景): BGE系列主打文本向量化/嵌入，用户常用此关键词
- **向量检索** (功能场景): 模型用于密集检索，用户搜索“向量检索”可直接定位

### nvidia/Cosmos-Reason1-7B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/Cosmos-Reason1-7B

**关键词列表**:

- **Cosmos-Reason1** (当前模型品牌名): 项目名称中直接出现的模型名称
- **物理常识推理** (功能场景): 模型专注于物理常识理解，帮助机器人进行真实世界推理
- **嵌入式推理** (功能场景): 模型具备 Embodied Reasoning 能力，可用于嵌入式机器人决策
- **时空理解** (技术特性): 模型能够理解空间‑时间关系，是其核心技术特性之一
- **机器人规划模型** (功能场景): 模型可作为机器人规划模型，预测并生成下一步行动计划
- **视觉语言模型** (技术特性): 模型是 Vision‑Language Model（VLM），融合视觉与语言信息

### zai-org/GLM-4.5V

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5V

**关键词列表**:

- **智谱AI** (当前模型品牌名): GLM-4.5V是智谱AI推出的模型，根据国产大模型映射规则，GLM-4 → 提取为'智谱AI'
- **GUI智能体** (功能场景): 模型支持GUI智能体操作，是区别于普通VLM的特色应用场景，具有高区分度
- **视频理解** (功能场景): 原文明确列出模型能力覆盖'视频'理解，是用户常搜的多模态任务类型
- **文档理解** (功能场景): 模型支持文档理解任务，属于高频搜索的垂直应用场景，非通用词
- **SOTA性能** (技术特性): 模型在42项基准中取得同规模SOTA，'SOTA性能'是开发者搜索高性能模型时的常用关键词
- **开源模型** (部署工具): 项目强调开源，用户常搜索'开源多模态模型'或'开源视觉语言模型'，此词具明确搜索意图

### reducto/RolmOCR

**URL**: https://ai.gitcode.com/hf_mirrors/reducto/RolmOCR

**关键词列表**:

- **RolmOCR** (当前模型品牌名): 项目名称为reducto/RolmOCR，是当前模型的唯一品牌名称，符合用户搜索AI模型时的直接命名习惯
- **文档OCR** (功能场景): 模型核心用途是解析PDF和复杂文档的文本内容，用户搜索‘文档OCR工具’或‘PDF识别AI’时会精准匹配
- **AI文档解析** (功能场景): 用户常搜索‘AI文档解析’替代传统OCR，该词精准描述模型处理扫描件、表格、混合排版文档的智能能力
- **轻量化OCR** (功能场景): README强调‘内存占用更低、运行更快’，‘轻量化OCR’是用户对比模型时的高频搜索词，突出与传统OCR的差异优势

### THUDM/SWE-Dev-9B

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/SWE-Dev-9B

**关键词列表**:

- **SWE-Dev-9B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **软件工程任务** (功能场景): 当前模型面向软件工程任务，是其主要应用场景
- **开源智能体** (技术特性): 当前模型是一款开源智能体，体现了其技术特性
- **训练数据规模扩展** (技术特性): 当前模型通过训练数据规模扩展提升性能，是其重要技术特性
- **推理规模扩展** (技术特性): 当前模型通过推理规模扩展提升性能，是其重要技术特性
- **9B参数** (参数规格): 当前模型的参数规格为9B，是用户可能搜索的关键词

### THUDM/GLM-4-32B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4-32B-0414

**关键词列表**:

- **32B参数** (参数规格): 模型参数规模为320亿，属于主流参数规格，用户常搜索'32B参数'类模型
- **智能对话** (功能场景): 模型经过人类偏好对齐，专为对话场景优化，符合用户搜索'智能对话'模型的典型需求
- **深度思考** (技术特性): GLM-Z1-32B-0414和GLM-Z1-Rumination-32B-0414均强调'深度思考能力'，是该模型系列的独特技术标签
- **反刍思考** (技术特性): GLM-Z1-Rumination-32B-0414独有的'反刍思考'能力，对标OpenAI深度研究，是高区分度的原创技术术语

### lmms-lab/LLaVA-NeXT-Video-7B-DPO

**URL**: https://ai.gitcode.com/hf_mirrors/lmms-lab/LLaVA-NeXT-Video-7B-DPO

**关键词列表**:

- **LLaVA-NeXT-Video** (当前模型品牌名): 项目名称中直接出现的模型品牌名，用户搜索时会使用该名称定位模型
- **视频对话** (功能场景): 模型支持基于视频的交互式对话，是用户寻找视频聊天机器人的核心需求
- **多模态视频模型** (技术特性): 模型融合图像、文本与视频多模态信息，突出其独特的多模态视频处理能力
- **DPO微调** (技术特性): 采用 Direct Preference Optimization（DPO）进行微调，是该模型的关键训练技术
- **视频指令跟随** (功能场景): 模型在视频上进行指令跟随任务，满足用户对视频指令理解与执行的需求

### vidore/colSmol-256M

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colSmol-256M

**关键词列表**:

- **ColSmol** (当前模型品牌名): 从项目名称vidore/colSmol-256M提取的当前模型品牌名
- **视觉检索模型** (功能场景): README明确描述其为视觉语言模型，用于高效索引文档
- **ColBERT策略** (技术特性): 模型采用ColBERT式多向量表示，是核心创新点
- **256M参数** (参数规格): 模型名称中的256M即参数规模，用户常按参数规格搜索
- **文档检索** (功能场景): README强调其面向文档检索任务，用户会搜此场景
- **LoRA微调** (技术特性): 训练时使用LoRA适配器，是部署与复现的关键技术
- **PyTorch部署** (部署工具): README要求安装colpali-engine并配合PyTorch，用户会搜部署方式

### THUDM/GLM-Z1-32B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-Z1-32B-0414

**关键词列表**:

- **反刍模型** (技术特性): GLM-Z1-Rumination-32B-0414独有的'反刍能力'概念，对标OpenAI深度研究，是高度差异化且用户可能搜索的术语
- **函数调用** (功能场景): 模型在函数调用方面有强化训练，是AI智能体任务的核心能力，属于具体且非泛化的搜索关键词

### zai-org/GLM-4.5V-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5V-FP8

**关键词列表**:

- **思考模式** (技术特性): 模型独有开关功能，支持用户在快速响应与深度推理间切换，为显著差异化特性
- **视觉定位** (功能场景): 模型支持精确视觉元素定位（Grounding），并用边界框标记，是用户搜索具体能力时的高频意图
- **长文档解析** (功能场景): 明确提及用于研究报告分析与信息提取，属于垂直高价值应用场景，非泛泛的'文档理解'
- **FP8量化** (技术特性): 模型采用FP8精度部署，是其技术命名核心，用户搜索高效部署或低精度视觉模型时会使用该术语

### sshleifer/distilbart-xsum-12-6

**URL**: https://ai.gitcode.com/hf_mirrors/sshleifer/distilbart-xsum-12-6

**关键词列表**:

- **DistilBART** (当前模型品牌名): 从项目名称提取的当前模型名称
- **12-6蒸馏** (技术特性): 当前模型采用12层编码6层解码的蒸馏结构
- **306M参数** (参数规格): 当前模型的主流参数规模

### openai/diffusers-ct_imagenet64

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-ct_imagenet64

**关键词列表**:

- **consistency-model** (当前模型品牌名): 项目名称和标签中明确标识的模型类型，是当前模型的专属品牌名，用户搜索一致性模型时会直接使用该术语
- **单步生成** (技术特性): 模型核心优势是支持单步快速生成，区别于传统扩散模型的多步采样，是用户关注的关键技术点
- **图像修复** (功能场景): README明确提到模型支持零样本图像修复，是用户在AI图像编辑场景中会搜索的具体功能
- **超分辨率** (功能场景): 模型支持零样本超分辨率，属于图像生成领域的高频应用需求，用户会直接搜索该词

### cross-encoder/nli-deberta-v3-large

**URL**: https://ai.gitcode.com/hf_mirrors/cross-encoder/nli-deberta-v3-large

**关键词列表**:

- **cross-encodernli-deberta-v3-large** (当前模型品牌名): 从项目URL和名称提取的当前模型完整名称
- **Natural-Language-Inference** (功能场景): 当前模型的核心应用场景，即自然语言推理
- **deberta-v3-large** (技术特性): 当前模型基于的基础架构，体现技术特性
- **Zero-Shot-Classification** (功能场景): 当前模型支持的功能之一，零样本分类

### hustvl/yolos-small

**URL**: https://ai.gitcode.com/hf_mirrors/hustvl/yolos-small

**关键词列表**:

- **YOLOS-small** (当前模型品牌名): 项目名称中直接出现的模型名称，用户搜索时会使用该品牌名
- **目标检测** (功能场景): 模型专用于目标检测任务，是用户最常搜索的应用场景
- **COCO-2017** (技术特性): 模型在 COCO 2017 数据集上微调，数据集名称是模型的重要标识
- **小尺寸模型** (参数规格): 模型属于 small 规格，区别于 base、large 等尺寸，用户会依据尺寸搜索
- **二分匹配** (技术特性): 模型采用二分匹配损失进行训练，是其独特的技术特性
- **Hungarian匹配** (技术特性): 使用 Hungarian 算法实现最优匹配，是模型实现细节中用户可能关注的关键词

### unsloth/cogito-v2-preview-llama-109B-MoE

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/cogito-v2-preview-llama-109B-MoE

**关键词列表**:

- **Cogito-v2** (当前模型品牌名): 从项目名称 'cogito-v2-preview-llama-109B-MoE' 中提取的核心品牌名，符合简化规则（去版本后缀和参数）
- **109B-MoE架构** (技术特性): 模型规模为109B且采用MoE架构，是用户搜索大模型时关注的核心技术特征，符合主流参数规格与技术特性提取规则
- **自我反思推理** (技术特性): 模型支持‘在回答前进行自我反思’，这是区别于普通LLM的独特推理模式，用户会搜索此类智能行为特征
- **STEM辅助** (功能场景): 模型专门优化科学、技术、工程、数学领域，该词精准指向教育与科研用户搜索意图
- **长上下文模型** (技术特性): 支持最多1000万tokens上下文，属于用户在搜索处理长文档、代码库时会使用的高价值场景词
- **IDA训练** (技术特性): 迭代蒸馏与放大（IDA）是该模型独有的训练策略，具有高度区分度，非通用术语，符合独特性要求
- **多语言AI助手** (功能场景): 支持超30种语言，且为通用辅助模型，用户会搜索‘多语言AI助手’这类明确应用场景词

### diffusers/stable-diffusion-xl-1.0-inpainting-0.1

**URL**: https://ai.gitcode.com/hf_mirrors/diffusers/stable-diffusion-xl-1.0-inpainting-0.1

**关键词列表**:

- **SD-XL** (当前模型品牌名): 从项目名称提取的当前模型简称
- **1024分辨率** (技术特性): 模型在1024×1024高分辨率下训练，用户会搜
- **Diffusers** (部署工具): 官方示例基于Diffusers库调用，用户会搜
- **fp16量化** (部署工具): 官方提供fp16半精度权重，用户搜索轻量化部署

### Qwen/Qwen2.5-Omni-7B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B-AWQ

**关键词列表**:

- **通义千问** (当前模型品牌名): 项目名称为Qwen，根据国产大模型映射规则，必须转换为'通义千问'
- **阿里大模型** (当前模型品牌名): Qwen是阿里巴巴推出的系列大模型，'阿里大模型'是用户搜索的通用品牌词
- **实时音视频交互** (功能场景): 模型专为实时音视频交互设计，支持分块输入与即时响应，是区别于普通多模态模型的独特功能场景
- **流式语音生成** (功能场景): 模型在语音生成上强调自然度与流式输出，超越非流式方案，是用户寻找语音交互AI时的精准搜索词
- **AWQ量化模型** (部署工具): 模型采用AWQ 4比特量化，显著降低显存占用，用户搜索'AWQ量化模型'时会精准定位此类轻量化部署方案
- **Any-to-Any** (技术特性): 模型标签明确标注'Any-to-Any'，代表跨模态任意输入任意输出能力，是区别于传统多模态模型的独特技术标签

### facebook/dinov2-giant

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-giant

**关键词列表**:

- **DINOv2-giant** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索时会使用完整模型名
- **自监督视觉特征** (技术特性): 模型核心训练方式与能力，用户搜索无监督视觉表征时会使用该术语
- **视觉变换器** (技术特性): 模型架构类型，用户搜索ViT类模型时常用中文术语，具有明确搜索意图
- **图像特征提取** (功能场景): 模型主要用途，用户在寻找图像表征工具时会搜索该功能词
- **DINOv2** (当前模型品牌名): 模型系列名称，是DINOv2-giant的上位品牌，用户常搜索系列名而非仅巨型版
- **无监督预训练** (技术特性): 模型训练方式的关键标签，区别于有监督模型，是用户筛选模型的重要关键词
- **CLS标记特征** (技术特性): 模型输出特征的核心机制，专业用户在研究ViT特征提取时会搜索该术语

### unsloth/Qwen3-4B-Instruct-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-4B-Instruct-2507-GGUF

**关键词列表**:

- **4B参数** (参数规格): 模型名称中的 4B 表示约 4 B 参数规模，用户搜索时会关注参数大小
- **多语言** (技术特性): 模型显著扩展了跨语言长尾知识覆盖，用户常以“多语言”搜索此类模型
- **长文本理解** (技术特性): 模型原生支持 256K 上下文，提升了长文本理解能力，是重要卖点
- **GGUF量化模型** (部署工具): 模型以 GGUF 格式发布，属于量化模型，用户在本地部署或 Ollama 时会搜索此关键词

### lllyasviel/control_v11p_sd15_inpaint

**URL**: https://ai.gitcode.com/hf_mirrors/lllyasviel/control_v11p_sd15_inpaint

**关键词列表**:

- **ControlNet-v1-1** (当前模型品牌名): 从项目名称lllyasviel/control_v11p_sd15_inpaint中提取的核心模型版本名，是用户搜索该特定修复版ControlNet时的直接关键词
- **image-to-image** (功能场景): 模型支持以修复图像作为条件输入，属于图像到图像的控制生成，是技术用户搜索时使用的标准英文术语
- **Stable-Diffusion** (当前模型品牌名): 模型是专为Stable Diffusion系列（如sd1.5）设计的控制模块，虽非独立模型，但作为其核心扩展组件，用户搜索'ControlNet Stable Diffusion'时必含此词，且非其他模型名称
- **controlnet** (当前模型品牌名): 模型名称中的核心品牌词，用户在搜索ControlNet相关资源时会直接输入该词，是区别于其他控制结构的通用品牌标识

### amazon/chronos-bolt-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-bolt-tiny

**关键词列表**:

- **Chronos-Bolt** (当前模型品牌名): 从项目名称提取的当前模型名称
- **时间序列预测** (功能场景): 当前模型的核心应用场景
- **零样本预测** (功能场景): 用户搜索无需微调即可直接预测的能力
- **SageMaker部署** (部署工具): 当前模型支持Amazon SageMaker一键部署
- **T5架构** (技术特性): 当前模型基于T5编码器-解码器架构
- **Tiny模型** (参数规格): 当前模型为轻量级Tiny版本，适合资源受限场景

### unsloth/GLM-4.5-Air

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/GLM-4.5-Air

**关键词列表**:

- **GLM-4.5-Air** (当前模型品牌名): 从项目名称提取的当前模型名称
- **混合推理模型** (技术特性): 当前模型的核心技术特性，提供两种推理模式
- **智能体设计** (功能场景): 当前模型专为智能体设计，满足智能体应用的复杂需求
- **1060亿参数** (参数规格): 当前模型的总参数量，体现模型规模
- **FP8版本** (技术特性): 当前模型开源了FP8版本，体现技术细节
- **API调用** (部署工具): 当前模型提供API服务，可在Z.ai API平台或智谱AI开放平台使用

### cross-encoder/ms-marco-MiniLM-L6-v2

**URL**: https://ai.gitcode.com/hf_mirrors/cross-encoder/ms-marco-MiniLM-L6-v2

**关键词列表**:

- **cross-encoderms-marco-MiniLM-L6-v2** (当前模型品牌名): 从项目名称直接提取的完整模型标识，是用户搜索该特定重排序模型时的精准关键词
- **信息检索** (功能场景): 模型核心用途为信息检索（Information Retrieval），是用户在搜索重排序模型时最常使用的意图词
- **查询重排序** (功能场景): MS MARCO任务的核心是查询重排序（re-rank），该术语精准描述模型在检索系统中的作用，用户在技术博客中常搜索此词
- **SentenceTransformers** (部署工具): 模型官方推荐通过SentenceTransformers库调用，是用户部署该模型时最常使用的工具名称，具有明确指向性
- **MiniLM** (技术特性): 模型基于MiniLM架构，是其核心轻量化技术标识，区别于其他BERT类模型，具有区分度且用户会搜索
- **段落排序** (功能场景): 模型训练目标为对检索到的段落进行排序，是MS MARCO任务的直接表述，用户在搜索相关RAG或检索系统时会使用

### unsloth/gemma-3-270m-it-qat-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-qat-GGUF

**关键词列表**:

- **Gemma-3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **270M参数** (参数规格): 当前模型的轻量级参数规格，用户会搜
- **GGUF量化** (部署工具): 当前模型提供的量化格式，便于本地部署
- **Colab微调** (部署工具): 官方提供Colab免费微调入口，用户常搜
- **Unsloth提速** (技术特性): 官方强调2倍提速，用户关注训练加速

### speechbrain/metricgan-plus-voicebank

**URL**: https://ai.gitcode.com/hf_mirrors/speechbrain/metricgan-plus-voicebank

**关键词列表**:

- **MetricGAN-Plus** (当前模型品牌名): 项目名称中包含的完整模型名称，直接代表该模型
- **语音增强** (功能场景): 模型的核心任务是对语音进行增强处理
- **噪声抑制** (功能场景): 模型用于降低噪声，提高语音质量，属于常见的搜索需求
- **SpeechBrain** (部署工具): 模型基于 SpeechBrain 框架提供，用户会搜索该框架来使用模型
- **SpectralMaskEnhancement** (技术特性): 模型提供的 API 类名，体现其频谱掩码增强技术
- **VoiceBank** (功能场景): 模型在 VoiceBank 数据集上训练，用户常以数据集名称检索对应模型

### facebook/detr-resnet-50

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/detr-resnet-50

**关键词列表**:

- **DETR** (当前模型品牌名): 项目名称为facebook/detr-resnet-50，DETR是该模型的核心品牌名称，用户搜索目标检测模型时会直接使用'DETR'作为关键词
- **端到端目标检测** (功能场景): 模型的核心功能是端到端目标检测，这是用户在CSDN等平台搜索AI视觉任务时的明确意图关键词
- **object-detection** (功能场景): 英文术语'object-detection'是AI开发者在搜索模型时高频使用的标准术语，且为标签中明确标注的唯一有效功能词
- **coco** (功能场景): COCO是模型训练和评估的权威数据集，用户搜索目标检测模型时常结合'COCO'作为筛选条件，具有明确指向性
- **对象查询** (技术特性): 模型独有的'对象查询（object queries）'机制是DETR区别于传统检测模型的核心创新点，专业用户会以此为关键词检索技术细节
- **二分匹配损失** (技术特性): DETR特有的训练损失机制，用户在研究目标检测论文或复现模型时会搜索该术语，具有高度区分度

### Gen-Verse/MMaDA-8B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Gen-Verse/MMaDA-8B-Base

**关键词列表**:

- **MMaDA-8B** (当前模型品牌名): 从项目名称 'MMaDA-8B-Base' 简化提取，保留核心品牌标识与参数规模，符合用户搜索习惯（如SD-XL、DeepSeek-V2）
- **多模态扩散模型** (技术特性): 模型核心定义，用户搜索多模态生成类模型时会使用该术语，且为当前模型独有的架构标签
- **混合长链思维** (技术特性): 模型独创的CoT微调策略名称，具有高度区分度，用户搜索‘多模态思维链’时可能匹配此术语
- **UniGRPO** (技术特性): 模型专属强化学习算法名称，技术文档中唯一标识，符合‘模型自研技术’关键词提取规则
- **8B参数** (参数规格): 模型名称中含‘8B’，属于主流参数规模（7B/13B/32B等），用户常按参数规模筛选模型

### unslothai/1

**URL**: https://ai.gitcode.com/hf_mirrors/unslothai/1

**关键词列表**:

- **Unsloth** (当前模型品牌名): 从项目名称unslothai/1提取的当前模型品牌
- **微调加速** (技术特性): Unsloth核心卖点：训练/微调速度提升

### facebook/VGGT-1B

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/VGGT-1B

**关键词列表**:

- **VGGT** (当前模型品牌名): 从项目名称 'facebook/VGGT-1B' 中提取的核心模型名称，简洁品牌名，用户搜索时会直接使用
- **Image-to-3D** (功能场景): 模型核心功能是将图像直接转换为3D属性，属于明确的用户搜索意图场景，且未被高频词排除
- **视觉几何基础Transformer** (当前模型品牌名): 模型全称在标题中明确出现，是官方命名，用户可能搜索完整中文名称，且非通用术语
- **3D点轨迹** (功能场景): 模型独特输出能力，区别于普通3D重建，是用户在3D视觉领域可能精准搜索的技术点
- **相机外参** (功能场景): 模型直接推断的关键3D属性之一，属于专业但搜索意图明确的关键词，非通用词
- **相机内参** (功能场景): 与相机外参并列，是模型核心输出内容，用户在SLAM、NeRF等方向搜索时可能使用
- **点云图** (功能场景): 模型输出的关键3D表示形式，是3D视觉研究者常用搜索词，具有明确技术指向性
- **深度图** (功能场景): 模型直接生成的核心输出之一，属于CV领域高频搜索功能，且未被排除词列表覆盖

### impira/layoutlm-document-qa

**URL**: https://ai.gitcode.com/hf_mirrors/impira/layoutlm-document-qa

**关键词列表**:

- **LayoutLM** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文档问答** (功能场景): 当前模型的主要应用场景
- **SQuAD2.0** (技术特性): 当前模型基于SQuAD2.0数据集进行了调优
- **DocVQA** (技术特性): 当前模型基于DocVQA数据集进行了调优

### Qwen/Qwen3-1.7B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B-Base

**关键词列表**:

- **Qwen3** (当前模型品牌名): 从项目名称 Qwen3-1.7B-Base 提取的简洁系列名称
- **代码生成** (功能场景): 预训练语料中包含大量编程数据，模型可用于自动生成代码
- **STEM推理** (功能场景): 模型在 STEM（科学、技术、工程、数学）领域数据上进行强化训练，适用于专业推理任务
- **1.7B参数** (参数规格): 模型规模为 1.7 B 参数，用户常以参数规模搜索模型

### google/owlv2-base-patch16

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlv2-base-patch16

**关键词列表**:

- **OWLv2** (当前模型品牌名): 从项目名称 hf_mirrors/google/owlv2-base-patch16 中提取的模型核心名称，是用户搜索该模型时的直接关键词
- **零样本文本目标检测** (功能场景): 模型核心能力，用户搜索‘零样本检测’‘文本目标检测’等场景时会使用该短语，精准匹配需求
- **开放词汇目标检测** (功能场景): 论文标题核心术语，是该模型区别于传统检测模型的关键特性，用户在学术或工程场景中会直接搜索
- **多模态目标检测** (技术特性): 模型结合视觉与文本模态进行检测，是其技术本质，区别于纯视觉检测模型，具有高区分度
- **CLIP主干网络** (技术特性): 模型基于CLIP构建，是其架构核心，用户搜索‘CLIP用于检测’‘CLIP目标检测’时会关联该词
- **ViT-B16** (技术特性): 模型图像编码器明确使用ViT-B/16架构，是技术细节中用户可搜索的标准化术语，非泛泛参数
- **文本条件目标检测** (功能场景): 模型通过文本查询驱动检测，是其交互方式的精准描述，符合用户搜索意图如‘用文字找图中物体’
- **arxiv2306.09683** (技术特性): 论文唯一标识符，学术用户常直接搜索arxiv编号定位模型，具有高精准引流价值

### microsoft/tapex-large-finetuned-wikisql

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-large-finetuned-wikisql

**关键词列表**:

- **TAPEX** (当前模型品牌名): 从项目名称 'microsoft/tapex-large-finetuned-wikisql' 中提取的核心模型品牌名，是当前模型的唯一标识
- **table-question-answering** (功能场景): 模型明确用于表格问答场景，是用户搜索AI模型处理结构化数据时的高频意图词
- **SQL执行器** (技术特性): 模型核心创新是学习神经SQL执行器，属于独特技术特征，用户会搜索‘AI执行SQL’类需求
- **表格预训练** (技术特性): 模型提出‘Table Pre-training’概念，是区别于普通文本预训练的关键技术标签
- **BART架构** (技术特性): 模型基于BART架构，虽为通用架构，但在此模型中是核心实现基础，且用户会搜索‘BART+表格’组合
- **wikisql** (功能场景): 模型在WikiSQL数据集上微调，该数据集是表格问答领域的标准基准，用户常搜索‘wikisql模型’
- **arxiv2107.07653** (技术特性): 论文ID是学术用户搜索该模型的直接入口，具有高精准搜索价值，且非通用词

### google/tapas-tiny-finetuned-sqa

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-tiny-finetuned-sqa

**关键词列表**:

- **TAPAS** (当前模型品牌名): 模型所属的主品牌名称，直接来源于项目名称
- **TAPAS-Tiny** (当前模型品牌名): 模型的具体规格名称，标识为 Tiny 版本的 TAPAS
- **表格问答** (功能场景): 模型用于对表格数据进行问答，是用户搜索的核心应用场景
- **序列问答微调** (功能场景): 模型在 Sequence Question Answering（SQA）数据集上完成微调，体现其任务类型
- **相对位置嵌入** (技术特性): 模型采用的关键技术之一，用于在表格单元格中重置位置索引
- **位置重置** (技术特性): 模型的独特特性，区别于使用绝对位置嵌入的版本
- **中间预训练** (技术特性): 模型在掩码语言建模后进行的额外预训练步骤，提升了表格理解能力

### openai/imagegpt-small

**URL**: https://ai.gitcode.com/hf_mirrors/openai/imagegpt-small

**关键词列表**:

- **ImageGPT** (当前模型品牌名): 从项目名称 openai/imagegpt-small 直接提取的核心模型品牌名，是用户搜索该模型的唯一标识
- **线性探测** (技术特性): 模型支持通过提取特征用于线性分类器（如SVM、逻辑回归），这是ImageGPT区别于其他视觉模型的典型训练范式
- **imagenet-21k** (训练数据): 模型在ImageNet-21k（21,843类）上预训练，是其数据来源的关键标识，用户会用数据集名筛选模型
- **32x32图像** (输入规格): 模型专为32x32低分辨率图像设计，是其独特输入尺度，区别于主流高分辨率模型，具搜索区分度

### microsoft/tapex-large

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-large

**关键词列表**:

- **TAPEX-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **神经SQL执行器** (技术特性): 当前模型通过学习神经SQL执行器来实现表格预训练
- **表格推理能力** (功能场景): 当前模型旨在为现有模型赋予表格推理能力

### Bllossom/llama-3.2-Korean-Bllossom-AICA-5B

**URL**: https://ai.gitcode.com/hf_mirrors/Bllossom/llama-3.2-Korean-Bllossom-AICA-5B

**关键词列表**:

- **Bllossom-AICA-5B** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该模型的唯一官方标识
- **视觉-语言模型** (功能场景): 模型可作为视觉-语言模型使用，是其区别于纯文本模型的关键功能，用户会搜索此场景词
- **韩国语AI模型** (功能场景): 模型专为韩语优化，用户在搜索‘韩语大模型’‘韩国语LLM’时会使用此词，具有明确语言场景指向
- **OCR理解** (功能场景): 模型针对韩国语OCR、表格、图表解析优化，是其独特应用场景，用户会搜索‘支持OCR的AI模型’
- **选择性推理** (技术特性): 模型具备拒绝无关外部知识的RAG增强推理能力，是其区别于普通模型的独有技术特征

### ibm-granite/granite-timeseries-ttm-r2

**URL**: https://ai.gitcode.com/hf_mirrors/ibm-granite/granite-timeseries-ttm-r2

**关键词列表**:

- **Granite-TimeSeries-TTM-R2** (当前模型品牌名): 项目名称中直接出现的模型完整品牌名
- **TinyTimeMixers** (技术特性): 模型采用的紧凑型多元时间序列预测架构名称
- **多元时间序列预测** (功能场景): 模型的核心应用场景，针对多变量时间序列进行预测
- **少样本微调** (功能场景): 只需极少量训练数据即可对模型进行有效微调
- **分钟级点预测** (功能场景): 模型支持从分钟到小时粒度的点预测任务
- **7亿样本预训练** (技术特性): TTM‑r2 在约 7 亿时间序列样本上进行的大规模预训练
- **10亿样本预训练** (技术特性): TTM‑r2.1 进一步扩展至约 10 亿样本的预训练数据集

### moonshotai/Kimi-VL-A3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Instruct

**关键词列表**:

- **Kimi-VL** (当前模型品牌名): 项目名称中的核心品牌名，对应月之暗面开源视觉语言模型
- **月之暗面** (当前模型品牌名): MoonshotAI 官方中文品牌，用户搜索国产大模型时常用
- **长上下文** (技术特性): 支持128K超长上下文，用户寻找能读长文档的多模态模型
- **智能体** (功能场景): README 强调在OSWorld等多轮智能体任务表现突出，用户搜AI Agent相关模型

### Qwen/QwQ-32B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/QwQ-32B-AWQ

**关键词列表**:

- **推理模型** (功能场景): README明确说明QwQ是专为推理设计的模型，区别于通用指令模型，是核心功能定位
- **链式思维** (技术特性): README强调模型具备'思维推理能力'，这是其区别于普通模型的核心能力，符合'链式思维'用户搜索意图

### Qwen/Qwen3-14B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-AWQ

**关键词列表**:

- **14B参数** (参数规格): 模型拥有约 148 亿（≈14B）参数，是用户常搜索的规模标签
- **AWQ量化** (技术特性): 模型采用 4‑bit AWQ 量化方案，区别于普通 FP16/INT8 量化
- **思维模式** (功能场景): 模型独有的思维模式用于复杂逻辑推理、数学与代码生成
- **非思维模式** (功能场景): 模型提供的高效通用对话模式，适用于日常聊天与指令执行
- **百语言支持** (功能场景): 模型支持 100+ 语言与方言，满足多语言指令遵循与翻译需求

### Qwen/Qwen3-235B-A22B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-GGUF

**关键词列表**:

- **思维模式切换** (技术特性): 模型独创支持在'思维模式'与'非思维模式'间无缝切换，是其区别于其他模型的独家功能点
- **220亿参数** (参数规格): 激活参数为220亿，属于主流大模型规模（介于7B~70B之间），用户常按参数量筛选模型，且非冗余细节

### tencent/Hunyuan3D-1

**URL**: https://ai.gitcode.com/hf_mirrors/tencent/Hunyuan3D-1

**关键词列表**:

- **混元** (当前模型品牌名): 项目名称Hunyuan3D-1，按国产映射规则提取为混元
- **腾讯大模型** (当前模型品牌名): Hunyuan系列归属腾讯，用户搜索常用品牌词
- **文生3D** (功能场景): README明确支持text-to-3D生成，用户高频搜索词
- **图生3D** (功能场景): README明确支持image-to-3D生成，用户高频搜索词
- **两阶段扩散** (技术特性): README强调two-stage approach，区别于单阶段模型，具区分度
- **3D生成框架** (功能场景): README自称为unified framework for 3D generation，用户搜框架级方案

### pcoloc/autotrain-dragino-7-7-1860763606

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-dragino-7-7-1860763606

**关键词列表**:

- **autotrain** (当前模型品牌名): 项目名称中明确包含'autotrain'，是当前模型的训练平台品牌，用户搜索'autotrain 模型'或'autotrain 回归'时会直接指向此类工具训练的模型
- **joblib** (部署工具): 模型通过joblib加载，是该模型的核心部署方式，用户搜索'joblib 回归模型'或'joblib 部署'时会寻找此类可直接加载的预训练模型
- **tabular** (功能场景): 模型处理的是表格数据（tabular），用户在搜索'表格数据预测'、'tabular 数据建模'等场景时会使用此词，具有明确数据类型指向性
- **二氧化碳排放预测** (功能场景): 模型目标为预测二氧化碳排放量（克），这是其独特应用场景，用户可能搜索'二氧化碳排放 AI预测'、'碳排放回归模型'等长尾词
- **autotrain-data-dragino-7-7** (当前模型品牌名): 项目标签中包含此完整数据集名称，是当前模型训练数据的专属标识，可作为模型的衍生品牌名，用户搜索该名称时会精准定位本模型

### THUDM/GLM-4-32B-Base-0414

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4-32B-Base-0414

**关键词列表**:

- **GLM-4** (当前模型品牌名): 从项目名称提取的当前模型名称，且为智谱AI相关模型
- **智能体任务** (功能场景): 当前模型在智能体任务方面有良好表现，是用户可能搜索的功能场景
- **工程代码编写** (功能场景): 当前模型在工程代码编写方面取得良好效果，是用户可能关注的功能场景

### IIC/DocOwl2

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/DocOwl2

**关键词列表**:

- **DocOwl2** (当前模型品牌名): 从项目名称IIC/DocOwl2直接提取的当前模型简称，符合品牌名简化规则
- **免OCR文档理解** (功能场景): 模型核心功能是无需OCR即可理解多页文档，为用户搜索文档AI时的明确意图词
- **高分辨率文档压缩器** (技术特性): 模型独有的核心模块名称，具有技术区分度，用户可能搜索该专有技术名称
- **多页文档分析** (功能场景): 模型专为多页文档设计，是用户在办公自动化、PDF智能处理场景中的高频搜索词
- **图像-文本对话** (功能场景): 基于Image-Text-to-Text标签提炼，描述模型输入输出形式，区别于纯文本对话
- **324标记编码** (技术特性): 模型独特技术指标（每页仅324个token），体现高效压缩能力，用户可能搜索此具体参数

### deepset/xlm-roberta-large-squad2

**URL**: https://ai.gitcode.com/hf_mirrors/deepset/xlm-roberta-large-squad2

**关键词列表**:

- **XLMRoBERTalarge** (当前模型品牌名): 项目名称中直接包含的模型名称，用户搜索时会使用该品牌名
- **抽取式问答** (功能场景): 模型的核心任务是对文档进行抽取式问答，用户常以此关键词查找模型
- **多语言问答** (功能场景): 模型支持多语言（Multilingual），适用于跨语言问答场景
- **Haystack集成** (部署工具): README 中明确说明可在 Haystack 框架中直接使用，用户搜索时会关注该集成方式
- **MLflow-追踪** (部署工具): 训练过程提供 MLflow 链接，用户会搜索带有 MLflow 追踪的模型
- **SQuAD2.0-微调** (技术特性): 模型基于 SQuAD 2.0 数据进行微调，是用户关注的关键技术细节

### Qwen/Qwen3-8B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-8B-AWQ

**关键词列表**:

- **智能体能力** (功能场景): 具备复杂智能体任务执行能力

### pengzhendong/chinese-hubert-base

**URL**: https://ai.gitcode.com/hf_mirrors/pengzhendong/chinese-hubert-base

**关键词列表**:

- **chinese-hubert-base** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索中文语音模型时会使用此精确名称
- **中文语音预训练** (功能场景): 模型基于1万小时WenetSpeech中文语音数据预训练，是用户搜索中文语音AI时的核心意图关键词
- **HuBERT模型** (技术特性): 模型基于HuBERT架构，是语音领域专用的自监督预训练技术，具有明确技术辨识度
- **语音特征提取** (功能场景): 模型输出为音频特征向量，专用于语音表征学习，是用户部署语音识别前处理时的搜索关键词
- **无分词器语音模型** (技术特性): README明确指出该模型无分词器，区别于文本模型，是其独特设计特征，用户会据此筛选适用模型
- **Wav2Vec2FeatureExtractor** (部署工具): 模型需配合Hugging Face的Wav2Vec2FeatureExtractor使用，是实际部署时的关键工具链关键词

### AI-ModelScope/TRELLIS-image-large

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/TRELLIS-image-large

**关键词列表**:

- **TRELLIS** (当前模型品牌名): 从项目名称 'TRELLIS-image-large' 提取的核心品牌名，为当前模型唯一标识
- **3D生成** (功能场景): 用户搜索AI生成3D内容时的高频意图词，精准匹配模型用途
- **结构化3D潜变量** (技术特性): 论文核心创新点，用户搜索3D生成技术原理时会使用该术语
- **MIT** (技术特性): 模型采用MIT许可证，开源社区用户常以此作为筛选条件

### pengzhendong/chinese-hubert-large

**URL**: https://ai.gitcode.com/hf_mirrors/pengzhendong/chinese-hubert-large

**关键词列表**:

- **chinese-hubert-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **语音识别** (功能场景): 当前模型可用于语音识别任务，是主要应用场景
- **音频预训练** (技术特性): 当前模型基于音频数据进行预训练，是核心技术特性
- **专用分词器** (技术特性): 当前模型需创建专用分词器用于语音识别任务，是技术实现要点

### IIC/QwenLong-CPRS-7B

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/QwenLong-CPRS-7B

**关键词列表**:

- **QwenLong-CPRS** (当前模型品牌名): 项目名称中直接出现的模型名称，去除版本号后的简洁品牌名
- **长上下文优化** (功能场景): 模型核心功能是针对超长上下文进行高效优化
- **查询感知压缩** (技术特性): 模型采用查询感知的多粒度压缩技术，实现精细信息提取
- **可控上下文优化** (技术特性): 通过可控提示词和查询语句生成任务导向的紧凑上下文片段
- **窗口并行推理** (技术特性): 模型将长上下文切分为窗口并行处理，降低推理复杂度

### Xenova/discogs-maest-30s-pw-73e-ts

**URL**: https://ai.gitcode.com/hf_mirrors/Xenova/discogs-maest-30s-pw-73e-ts

**关键词列表**:

- **discogs-maest-30s-pw-73e-ts** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，是用户搜索该特定音频模型时的精准关键词
- **ONNX** (部署工具): 模型提供ONNX权重版本，专为网页端部署设计，是用户寻找可浏览器运行音频模型时的核心搜索词
- **Transformers.js** (部署工具): 模型明确兼容Transformers.js，是前端AI音频应用开发者搜索的关键技术栈
- **音频理解** (功能场景): Discogs-MaEST模型用于音乐元数据识别与音频内容理解，是其核心应用场景，用户会搜索此类语义词
- **网页端音频模型** (功能场景): 模型专为在浏览器中运行设计，区别于传统服务器部署，是用户寻找前端音频AI时的精准意图词
- **HuggingFace-ONNX** (部署工具): 模型通过HuggingFace发布ONNX格式，用户常组合搜索'HuggingFace + ONNX'寻找可直接加载的模型
- **音乐元数据识别** (功能场景): Discogs-MaEST模型用于自动识别音乐标签（如艺人、流派、年份），是其专业用途，用户会精准搜索该术语

### m-a-p/MERT-v1-330M

**URL**: https://ai.gitcode.com/hf_mirrors/m-a-p/MERT-v1-330M

**关键词列表**:

- **MERT-v1** (当前模型品牌名): 从项目名称提取的当前模型系列名称
- **音乐理解模型** (功能场景): 当前模型的核心用途
- **音频分类** (功能场景): 官方标签中明确列出的功能
- **330M参数** (参数规格): 当前模型具体参数规模
- **Fairseq** (部署工具): 官方支持的部署框架
- **MLM预训练** (技术特性): 当前模型采用的预训练范式

### tencent/HunyuanVideo

**URL**: https://ai.gitcode.com/hf_mirrors/tencent/HunyuanVideo

**关键词列表**:

- **混元视频** (当前模型品牌名): 项目名称中直接出现的模型品牌名，代表腾讯的大模型系列
- **FP8量化模型** (技术特性): 采用 FP8 量化显著节省显存，是模型独有的量化技术
- **多GPU并行推理** (技术特性): 提供多 GPU 序列并行推理，加速大规模视频生成
- **Diffusers集成** (部署工具): 模型已集成至 HuggingFace Diffusers，便于生态调用
- **Gradio网页演示** (部署工具): 提供基于 Gradio 的在线演示页面，方便用户快速体验
- **企鹅视频基准** (技术特性): 发布专属视频基准用于评估模型性能，体现模型的评测体系

### zai-org/CogVideoX1.5-5B-I2V

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B-I2V

**关键词列表**:

- **CogVideoX1.5-5B-I2V** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定视频生成模型时的精准关键词
- **图像到视频** (功能场景): I2V（Image-to-Video）的中文直译，是用户在CSDN等平台搜索视频生成技术时的高频意图表达
- **10秒视频生成** (功能场景): 模型支持5秒或10秒视频输出，'10秒视频生成'是用户明确搜索长视频生成能力的精准关键词
- **1360768视频** (功能场景): 模型支持1360*768高分辨率视频输出，该分辨率组合独特，是用户寻找高清视频生成模型时可能搜索的参数化表达
- **BF16推理** (技术特性): 模型推荐BF16精度推理，该精度在国产AI模型中作为性能与显存平衡的关键词被开发者关注
- **清影开源版** (当前模型品牌名): README明确指出是'清影同源的开源版本'，'清影开源版'是用户寻找该商业模型开源实现时的自然搜索词
- **5秒视频生成** (功能场景): 模型固定输出5秒或10秒视频，'5秒视频生成'是用户对比短时视频模型时的高频搜索短语

### PKU-Alignment/beaver-7b-v1.0-cost

**URL**: https://ai.gitcode.com/hf_mirrors/PKU-Alignment/beaver-7b-v1.0-cost

**关键词列表**:

- **Beaver-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **安全RLHF** (技术特性): 当前模型专为安全强化学习人类反馈设计
- **AI安全** (功能场景): 用户搜索AI安全相关模型时会用的词
- **偏好模型** (技术特性): 当前模型的核心定位是偏好打分模型
- **自回归语言模型** (技术特性): 当前模型的架构特征，用户会搜索

### openbmb/MiniCPM-V-4_5

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-V-4_5

**关键词列表**:

- **手机端GPT-4o级别** (功能场景): 描述了模型在手机端的应用场景和性能级别
- **高帧率视频理解** (功能场景): 当前模型支持高帧率视频理解的功能
- **长视频理解** (功能场景): 当前模型支持长视频理解的功能
- **混合快慢思考模式** (技术特性): 当前模型具备的独特技术特性
- **80亿参数量** (参数规格): 当前模型的参数量规格

### zai-org/glm-4-9b-chat-1m

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-1m

**关键词列表**:

- **1M上下文** (功能场景): 1M上下文长度（约200万中文字符）是该模型最突出的差异化功能，用户会搜索'长文本对话'或'1M上下文'模型
- **Function-Call** (技术特性): 支持自定义工具调用（Function Call）是该模型区别于普通对话模型的关键技术点，用户会搜索此术语
- **长文本推理** (功能场景): README明确提及'长文本推理'，且支持1M上下文，是用户寻找处理超长文档模型时的高频搜索词
- **代码执行** (功能场景): 模型支持代码执行功能，属于高价值AI助手场景，用户会搜索'能执行代码的AI模型'
- **26种语言** (功能场景): 支持26种语言是该模型的多语言能力亮点，用户搜索'多语言AI助手'时可能匹配此关键词

### stepfun-ai/StepFun-Formalizer-32B

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/StepFun-Formalizer-32B

**关键词列表**:

- **StepFun-Formalizer** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **Lean-4形式化** (技术特性): 模型专注于将自然语言数学问题转化为 Lean 4 形式化语句
- **数学自动形式化** (功能场景): 模型的核心应用是自动将数学题目进行形式化处理
- **知识推理融合** (技术特性): 模型通过融合知识推理提升自动形式化能力
- **vllm推理** (部署工具): README 中提供了基于 vllm 的调用示例，适合作为部署/推理方式关键词
- **BEq验证** (技术特性): 模型在主流基准上使用 BEq 验证进行评估，是独特的技术细节

### zai-org/cogagent-chat-hf

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/cogagent-chat-hf

**关键词列表**:

- **CogAgent** (当前模型品牌名): 项目名称为 zai-org/cogagent-chat-hf，模型核心品牌名为 CogAgent，符合简化命名规则，是用户搜索该模型的直接关键词
- **18B参数** (参数规格): 模型明确说明 CogAgent-18B 拥有 110亿视觉参数 + 70亿语言参数，总参数规模为18B，属于主流大模型规格，用户会搜索‘18B参数’定位该模型
- **多轮对话** (功能场景): 与‘智能对话’互补，‘多轮对话’是README中反复强调的核心能力，用户在搜索视觉问答之外的交互场景时会使用该词
- **CogAgent-9B** (当前模型品牌名): README中最新版本为 CogAgent-9B-20241220，‘CogAgent-9B’是该系列主流子版本，用户会搜索此简称来定位轻量级版本，符合品牌名简化规则

### zai-org/glm-edge-4b-chat

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-edge-4b-chat

**关键词列表**:

- **GLM-Edge-4B-Chat** (当前模型品牌名): 从项目名称直接提取的当前模型全称，符合用户搜索AI模型时的精确命名习惯

### zai-org/CogVideoX1.5-5B

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/CogVideoX1.5-5B

**关键词列表**:

- **CogVideoX** (当前模型品牌名): 项目名称中直接出现的模型品牌
- **Diffusers库** (部署工具): 模型基于 HuggingFace Diffusers 实现，便于快速部署
- **16帧秒** (技术特性): 模型生成视频的帧率上限，为 16 FPS

### unsloth/gpt-oss-120b-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gpt-oss-120b-bnb-4bit

**关键词列表**:

- **gpt-oss-120b** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简化规则（保留核心标识，去版本后缀）
- **gpt-oss** (当前模型品牌名): 模型系列通用名称，用户搜索时可能使用简称，且为官方统一品牌标识
- **120B参数** (参数规格): 模型核心参数规模为1200亿，属于主流大模型规格，用户会搜索此类规模关键词
- **bnb-4bit** (部署工具): 模型采用4-bit量化技术，是用户寻找低显存部署方案时的关键搜索词，且为当前模型专属技术标签
- **harmony响应格式** (技术特性): 模型训练和推理必须使用该专属格式，是区别于其他模型的核心交互特性，具有唯一性
- **AI智能体** (功能场景): README明确指出模型专为智能体任务设计，是用户寻找AI代理、自主决策模型时的精准搜索词
- **Apache-2.0-许可** (技术特性): 模型采用宽松开源协议，是开发者选择商用或定制模型时的重要筛选条件，具有高搜索价值
- **单卡H100运行** (部署工具): 用户关心能否在单张高端卡部署，该描述是模型部署门槛的核心卖点，非通用硬件词，指向明确

### ByteDance-Seed/M3-Agent-Control

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/M3-Agent-Control

**关键词列表**:

- **M3-Agent** (当前模型品牌名): 从项目仓库名称 “M3-Agent-Control” 提取的简洁模型品牌名
- **字节大模型** (当前模型品牌名): 项目所属组织 ByteDance-Seed 按映射规则对应为 “字节大模型”
- **智能体控制** (功能场景): 模型名称中含 “Agent‑Control”，表明其主要用于智能体（Agent）的控制任务

### zai-org/GLM-Z1-Rumination-32B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-Z1-Rumination-32B-0414

**关键词列表**:

- **GLM-Z1-Rumination** (当前模型品牌名): 从项目名称提取的当前模型名称
- **深度思考能力** (技术特性): 当前模型具备深度思考能力，是核心特性
- **反思模型** (技术特性): 当前模型是具备反思能力的深度推理模型，是独特技术特性
- **研究型写作** (功能场景): 当前模型在研究型写作上表现出显著提升，是应用场景
- **复杂检索任务** (功能场景): 当前模型在复杂检索任务上表现出显著提升，是应用场景

### ByteDance-Seed/M3-Agent-Memorization

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/M3-Agent-Memorization

**关键词列表**:

- **豆包** (当前模型品牌名): 项目名称为ByteDance-Seed，根据国产大模型映射规则，应提取为'豆包'
- **M3-Agent-Memorization** (当前模型品牌名): 项目名称核心标识，是模型的正式简称，用户可能直接搜索该完整名称
- **记忆增强** (技术特性): 模型名称'Memorization'明确指向记忆能力增强，是其核心创新点，符合用户搜索意图

### openai-community/gpt2

**URL**: https://ai.gitcode.com/hf_mirrors/openai-community/gpt2

**关键词列表**:

- **GPT-2** (当前模型品牌名): 项目名称即为模型的官方名称
- **因果语言建模** (技术特性): 模型采用因果（自回归）语言建模目标进行预训练
- **1.24亿参数** (参数规格): 该版本的 GPT-2 规模约为 1.24 亿参数，区别于更大或更小的变体
- **英语语言模型** (功能场景): 模型专注于英文语料的预训练，适用于英语文本任务

### unsloth/embeddinggemma-300m-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-GGUF

**关键词列表**:

- **EmbeddingGemma** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，用户搜索嵌入模型时会直接使用此名称
- **768维嵌入** (技术特性): 模型输出维度为768，是其关键技术特征，用户在比较嵌入模型精度时会搜索具体维度
- **Matryoshka嵌入** (技术特性): 模型采用MRL（Matryoshka表示学习）技术，支持动态截断至512/256/128维，属独特技术亮点，非通用术语
- **3亿参数嵌入模型** (参数规格): 3亿参数（300M）是该模型在小尺寸嵌入模型中的核心竞争力，属于用户可感知的主流规格区间
- **多语言嵌入** (功能场景): 模型在100+种语言上训练，用户搜索‘多语言嵌入’时精准匹配其跨语言语义理解能力

### zai-org/glm-4-9b-chat-1m-hf

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat-1m-hf

**关键词列表**:

- **网页浏览** (功能场景): 模型具备联网能力，用户会搜“AI 网页浏览”

### stepfun-ai/Step-Audio-2-mini

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/Step-Audio-2-mini

**关键词列表**:

- **Step-Audio** (当前模型品牌名): 从项目名称提取的当前模型品牌名
- **语音对话** (功能场景): README强调的智能语音对话能力
- **工具调用** (技术特性): 支持通过工具调用获取外部知识
- **多模态RAG** (技术特性): 结合文本与声学知识的检索增强生成

### google-t5/t5-base

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-base

**关键词列表**:

- **T5-Base** (当前模型品牌名): 从项目名称 'google-t5/t5-base' 提取的当前模型简洁品牌名，符合模型名称简化规则（去版本后缀，保留T5-Base）
- **文本到文本** (技术特性): T5模型最核心的技术创新点，全文反复强调的统一框架，用户搜索NLP统一架构时会用此关键词
- **机器翻译** (功能场景): README明确列出T5-Base可用于机器翻译，是其核心下游用途之一，具有明确搜索意图
- **情感分析** (功能场景): README明确提及T5可用于分类任务如情感分析，是企业级NLP应用高频需求，具备搜索价值
- **2.2亿参数** (参数规格): 模型明确标注2.2亿参数，属于中等规模主流参数量（介于7B与32B之间），用户常按参数规模筛选模型

### sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

**URL**: https://ai.gitcode.com/hf_mirrors/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

**关键词列表**:

- **paraphrase-multilingual-MiniLM-L12-v2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **句子映射** (功能场景): 模型能将句子和段落映射到稠密向量空间，属于核心功能场景
- **语义搜索** (功能场景): 模型可用于语义搜索任务，是用户可能搜索的功能场景
- **聚类任务** (功能场景): 模型可用于聚类任务，是用户可能搜索的功能场景
- **384维向量** (技术特性): 模型将句子和段落映射到384维的稠密向量空间，是独特的技术特性

### deepseek-ai/DeepSeek-R1-Distill-Qwen-14B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B

**关键词列表**:

- **DeepSeek-R1** (当前模型品牌名): 从项目名称直接提取的核心模型品牌名，是用户搜索该模型的首要关键词
- **自我验证** (技术特性): 模型在无SFT前提下实现的独有推理行为，是论文强调的突破性能力，具有高区分度
- **强化学习** (技术特性): 模型采用纯强化学习（RL）训练，无需SFT预处理，是其技术路径的关键词，用户会搜索‘纯RL训练模型’
- **蒸馏模型** (技术特性): 当前模型是DeepSeek-R1的蒸馏版本，‘蒸馏模型’是用户寻找轻量级高性能模型时的高频搜索词，且未被高频词排除
- **AI编程助手** (功能场景): README明确指出模型在代码任务上表现优异，‘AI编程助手’是用户搜索代码生成类模型的典型意图词

### mixedbread-ai/mxbai-embed-large-v1

**URL**: https://ai.gitcode.com/hf_mirrors/mixedbread-ai/mxbai-embed-large-v1

**关键词列表**:

- **Mixedbread** (当前模型品牌名): 模型发布者的品牌名称，直接出现在项目名称中
- **mxbai-embed-large** (当前模型品牌名): 从项目全称 mixedbread-ai/mxbai-embed-large-v1 提取的简洁模型名称
- **句子嵌入** (功能场景): 模型的核心功能是生成句子级别的向量表示，用于相似度匹配和检索
- **Matryoshka-Representation-Learning** (技术特性): README 中提到的独特学习方法，提升嵌入层次结构的表达能力
- **二进制量化** (技术特性): 模型支持的二进制量化特性，可在检索任务中显著压缩存储和加速计算
- **检索任务** (功能场景): 模型专为检索场景设计，需要在查询时使用特定提示词
- **512维嵌入** (参数规格): 模型默认输出 512 维向量，是用户常关注的维度规格

### deepseek-ai/DeepSeek-V3

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3

**关键词列表**:

- **DeepSeek-V3** (当前模型品牌名): 从项目名称直接提取的当前模型官方名称，用户搜索AI模型时会直接输入此名称
- **多标记预测** (技术特性): 模型独创的训练目标（MTP），在README中被强调为提升性能与推理加速的核心创新，具有高区分度
- **无辅助损失负载平衡** (技术特性): DeepSeek-V3首创的负载平衡策略，是其训练稳定、性能优越的关键技术，术语独特，用户可能搜索‘无辅助损失 MoE’
- **671B参数** (参数规格): 模型总参数量为6710亿，属于主流大模型规格（600B+），符合‘主流规格’提取规则，且具明确区分度
- **DeepSeekMoE** (技术特性): 模型专有MoE模块名称，在README中被明确提及为自研架构，具有品牌技术标识性，非通用术语

### deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

**关键词列表**:

- **DeepSeek-R1-Distill-Qwen-1.5B** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **反思能力** (技术特性): 当前模型展示出的独特技术特性，用户可能感兴趣
- **1.5B参数** (参数规格): 当前模型的参数规格，用户可能搜索特定参数的模型

### deepseek-ai/deepseek-vl2-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/deepseek-vl2-tiny

**关键词列表**:

- **DeepSeek-VL2-Tiny** (当前模型品牌名): 项目名称中直接给出的模型完整品牌名
- **光学字符识别** (功能场景): 模型支持 OCR（光学字符识别），属于重要的视觉-文本任务
- **文档表格图表理解** (功能场景): 模型能够理解文档、表格和图表内容，是其核心多模态能力之一
- **Mixture-of-Experts** (技术特性): 模型采用 MoE（Mixture-of-Experts）架构，区别于普通密集模型
- **10亿激活参数** (参数规格): 模型拥有约 1 B（10 亿）激活参数，是用户关注的规模指标

### deepseek-ai/DeepSeek-Coder-V2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Base

**关键词列表**:

- **DeepSeek-Coder-V2** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该模型的核心关键词
- **128K上下文** (技术特性): 128K上下文长度是模型关键能力，虽为数字但属于主流用户关注的上下文长度规格，非纯技术细节（如8192），在AI编程领域具高搜索价值
- **236B参数** (参数规格): 236B是当前模型的总参数规模，属于主流大模型参数层级，开发者常按此规模筛选模型
- **338种编程语言** (功能场景): 支持338种编程语言是该模型在代码领域的突出优势，用户搜索‘支持多语言的AI编程模型’时会匹配此关键词
- **DeepSeek-V2** (当前模型品牌名): DeepSeek-Coder-V2基于DeepSeek-V2持续预训练，品牌名‘DeepSeek-V2’是其母模型，用户常搜索该系列模型
- **代码语言模型** (功能场景): 模型本质是代码领域的专用语言模型，是开发者精准搜索AI编程工具时的高频语义词

### facebook/musicgen-small

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/musicgen-small

**关键词列表**:

- **MusicGen** (当前模型品牌名): 项目名facebook/musicgen-small中的核心品牌名
- **文生音乐** (功能场景): README明确描述为“文本转音乐模型”，用户会搜“文生音乐”
- **音频提示生成** (功能场景): 支持“音频 Prompt”方式生成音乐，用户会搜“音频提示生成”
- **300M参数** (参数规格): README标题直接给出“小型-300M”，用户会按参数规模搜索
- **32kHz音频** (技术特性): 使用32kHz EnCodec标记器，音质指标易被搜索
- **HuggingFace推理** (部署工具): README提供HuggingFace Colab与Transformers调用示例

### deepseek-ai/DeepSeek-R1-Distill-Qwen-32B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B

**关键词列表**:

- **AI推理** (功能场景): 模型专为推理任务优化，README多次强调其在数学、代码、推理任务上的表现，符合用户搜索‘AI推理’的意图
- **强化学习推理** (技术特性): 模型采用无SFT的纯强化学习训练方式，是其区别于其他模型的创新点，用户会搜索该组合词寻找前沿推理模型

### audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim

**URL**: https://ai.gitcode.com/hf_mirrors/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim

**关键词列表**:

- **wav2vec2-large-robust-12-ft-emotion-msp-dim** (当前模型品牌名): 从项目名称直接提取的完整模型名称，是用户搜索该特定情感识别模型时最可能使用的精准关键词
- **语音情感识别** (功能场景): 模型核心用途是预测激发度、支配度和效价，属于明确的语音情感识别场景，用户会直接搜索此中文术语
- **维度情感分析** (功能场景): 模型输出为三维连续值（激发度、支配度、效价），区别于传统分类，'维度情感分析'是该技术的独特表述，具有区分度
- **MSP-Podcast** (数据集来源): 模型在MSP-Podcast数据集上微调，该数据集是语音情感领域知名公开数据集，专业用户会以此为关键词检索相关模型
- **wav2vec2** (技术特性): 模型基于Wav2Vec2架构，虽为基础框架，但作为当前模型的技术根基，且未被列为强制排除词，是用户搜索语音模型时的高关联词
- **音频特征提取** (技术特性): 模型接收原始音频输入并输出情感向量，本质是端到端音频特征提取，区别于传统MFCC等方法，具技术独特性
- **ONNX导出** (部署工具): README明确提及提供ONNX导出，是工业部署关键能力，用户搜索'语音情感模型 ONNX'时会精准匹配
- **arxiv2203.07378** (技术文献): 论文编号是该模型的唯一学术标识，研究者常直接搜索arxiv编号获取模型细节，具有极高精准引流价值

### deepseek-ai/deepseek-vl2

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/deepseek-vl2

**关键词列表**:

- **DeepSeek-VL2** (当前模型品牌名): 从项目名称提取的当前模型名称

### deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

**关键词列表**:

- **数学推理** (功能场景): 模型在数学推理基准上表现突出，用户会以“数学推理”寻找具备此能力的模型
- **指令模型** (技术特性): 提供指令式交互能力，用户在搜索指令模型时会关注此类关键词
- **16B参数** (参数规格): 模型的总参数量为 16B，用户常以参数规模（如 16B 参数）筛选模型

### jonathandinu/face-parsing

**URL**: https://ai.gitcode.com/hf_mirrors/jonathandinu/face-parsing

**关键词列表**:

- **face-parsing** (当前模型品牌名): 项目名称 jonathandinu/face-parsing 的核心标识，用户搜索面部解析模型时会直接使用该名称
- **图像分割** (功能场景): 模型实现的是语义分割任务，专用于人脸区域划分，是用户搜索人脸分析类AI工具时的核心意图词
- **CelebAMask-HQ** (当前模型品牌名): 模型训练所用的专属数据集，是该模型的标志性训练基础，用户在搜索高质量人脸解析模型时会关联此数据集名称
- **Segformer** (技术特性): 模型基于Segformer架构，是当前模型的核心技术骨架，用户搜索基于Transformer的语义分割模型时会使用该词
- **ONNX推理** (部署工具): 模型提供ONNX格式用于网页端推理，是区别于其他仅支持PyTorch模型的独特部署方式
- **人脸解析** (功能场景): 中文用户搜索该模型最直接的意图词，精准对应模型用途，且非通用词，具有明确指向性
- **nvidiamit-b5** (技术特性): 模型基于NVIDIA微调的MIT-B5编码器，是该模型的技术底座，用户搜索特定backbone的分割模型时会使用该关键词

### deepseek-ai/DeepSeek-Prover-V1.5-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V1.5-Base

**关键词列表**:

- **蒙特卡洛树搜索** (技术特性): RMaxTS是模型独有的证明路径探索策略
- **强化学习证明助手** (技术特性): RLPAF强化学习框架是模型核心亮点
- **形式化数学语言** (功能场景): 模型聚焦形式化数学语言训练，用户会搜

### openai/whisper-medium.en

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-medium.en

**关键词列表**:

- **Whisper-medium** (当前模型品牌名): 从项目名称提取的当前模型名称，用户直接搜索Whisper系列时会用
- **语音翻译** (功能场景): Whisper多语言版本支持的功能，吸引有翻译需求的用户
- **769M参数** (参数规格): medium模型独有规模，用户对比大小时会精确搜索
- **无需微调** (技术特性): 强调开箱即用，吸引想省去训练步骤的开发者

### deepseek-ai/DeepSeek-R1-Zero

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Zero

**关键词列表**:

- **DeepSeek-R1-Zero** (当前模型品牌名): 从项目名称直接提取的当前模型名称，是本项目的核心发布模型

### ByteDance/AnimateDiff-Lightning

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance/AnimateDiff-Lightning

**关键词列表**:

- **AnimateDiff-Lightning** (当前模型品牌名): 项目名称即模型的官方品牌名
- **文本生成视频** (功能场景): 模型的核心任务是将文本描述转化为视频
- **Motion-LoRAs** (技术特性): 使用 Motion LoRA 进一步增强运动细节和流畅度
- **EulerDisc调度器** (技术特性): 模型默认使用 EulerDisc 采样调度器进行高质量视频生成

### deepseek-ai/DeepSeek-Coder-V2-Instruct-0724

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Coder-V2-Instruct-0724

**关键词列表**:

- **指令微调模型** (技术特性): 模型提供指令微调版本（Instruct），是开发者部署时的关键筛选条件，具有明确使用场景

### nlpaueb/legal-bert-base-uncased

**URL**: https://ai.gitcode.com/hf_mirrors/nlpaueb/legal-bert-base-uncased

**关键词列表**:

- **LEGAL-BERT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **法律自然语言处理** (功能场景): 当前模型主要应用于法律自然语言处理领域
- **法律文本预训练** (技术特性): 当前模型通过法律文本进行预训练，具有独特性
- **子领域变体** (技术特性): 当前模型提供了子领域变体，如CONTRACTS-、EURLEX-、ECHR-等
- **轻量级模型** (技术特性): 当前模型提供了一个轻量级版本，仅为BERT-BASE大小的33%

### deepseek-ai/Janus-Pro-7B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/Janus-Pro-7B

**关键词列表**:

- **统一多模态** (技术特性): 模型核心创新点，原文明确强调‘统一多模态理解和生成’，是区别于其他模型的关键技术标签
- **视觉编码解耦** (技术特性): 模型独有的架构设计术语，原文核心创新，用户搜索多模态模型架构时可能使用该精准表述
- **多模态理解** (功能场景): 模型核心能力之一，与‘文生图’形成互补场景，且非高频词，具有搜索价值

### deepseek-ai/DeepSeek-V2-Lite

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V2-Lite

**关键词列表**:

- **DeepSeek-V2-Lite** (当前模型品牌名): 项目名称即模型的官方品牌名称
- **多头潜在注意力** (技术特性): 独创的 MLA（Multi‑Head Latent Attention）机制提升推理效率
- **聊天模型** (功能场景): 模型提供对话能力，适用于智能聊天与对话系统
- **API平台** (部署工具): 模型支持通过 API 平台进行调用，便于线上服务集成

### ant-research/MagicQuill-models

**URL**: https://ai.gitcode.com/hf_mirrors/ant-research/MagicQuill-models

**关键词列表**:

- **MagicQuill** (当前模型品牌名): 项目名称直接来源于模型名称，是用户搜索该特定图像编辑系统的唯一品牌标识
- **智能交互式图像编辑** (功能场景): 模型核心功能是通过极简交互实现图像编辑，该短语精准描述用户搜索意图，且未被高频词库覆盖
- **图像插入** (功能场景): README明确列出‘插入元素’为关键操作，是用户可能直接搜索的具体编辑动作
- **对象擦除** (功能场景): README明确提及‘擦除对象’作为核心交互方式，属于具体、高意图的图像编辑关键词
- **多模态大语言模型** (技术特性): 模型依赖MLLM实时理解用户交互意图，是区别于传统扩散模型的核心技术点，非通用词
- **双分支插件模块** (技术特性): 模型独有的结构设计，用于增强扩散先验的控制精度，属于独特技术术语，非高频词
- **扩散先验** (技术特性): 模型使用‘经过精心学习的扩散先验’实现精准编辑，是技术文档中的专有概念，非泛用词

### deepseek-ai/DeepSeek-R1-Distill-Qwen-7B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B

**关键词列表**:

- **DeepSeek-R1-Distill-Qwen-7B** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **冷启动数据** (技术特性): 当前模型在RL之前整合的独特数据

### IIC/gme-Qwen2-VL-2B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/gme-Qwen2-VL-2B-Instruct

**关键词列表**:

- **Any2Any检索** (功能场景): 模型核心能力是文本、图像、图文对之间的任意互检索，是用户搜索多模态检索时的精准意图词
- **视觉文档检索** (功能场景): 模型在文档截图、学术论文等视觉文档场景表现卓越，是区别于通用多模态模型的独特应用场景
- **动态图像分辨率** (技术特性): 模型支持自适应图像分辨率输入，是其区别于固定分辨率模型的关键技术亮点
- **多模态检索增强生成** (功能场景): 模型明确应用于RAG场景中的多模态检索增强生成，是高价值专业用户搜索词
- **2.21B参数** (参数规格): 当前模型参数规模为2.21B，属于轻量级多模态模型，用户会搜索此类小参数高效模型
- **UMRB基准** (技术特性): 模型在自研通用多模态检索基准UMRB上达SOTA，是专业用户识别该模型的权威指标词

### baidu/ERNIE-4.5-21B-A3B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-PT

**关键词列表**:

- **文心一言** (当前模型品牌名): ERNIE是百度大模型品牌，根据国产大模型映射规则，必须提取为'文心一言'
- **百度大模型** (当前模型品牌名): ERNIE是百度自研大模型系列，'百度大模型'是用户搜索国产大模型时的通用意图词
- **异构MoE** (技术特性): 模型核心创新点，原文明确提及'多模态异构MoE预训练'，是区别于普通MoE的独特架构
- **跨模态推理** (功能场景): 模型支持文本与视觉联合理解与推理，是用户搜索多模态AI能力时的直接意图词
- **统一偏好优化** (技术特性): 原文独创的强化学习方法（UPO），用于后训练优化，具有技术辨识度且非通用术语
- **视觉语言理解** (功能场景): 模型明确针对VLM（视觉语言模型）优化，是用户搜索图文理解类AI时的精准搜索词
- **4位无损量化** (技术特性): 模型提出4位/2位无损量化算法，是推理优化的关键亮点，非泛泛的'量化模型'高频词
- **模态隔离路由** (技术特性): ERNIE 4.5独有架构设计，用于解决多模态训练干扰，技术术语独特且具搜索价值

### dreamerwhite/surya_layout3

**URL**: https://ai.gitcode.com/hf_mirrors/dreamerwhite/surya_layout3

**关键词列表**:

- **Surya-Layout** (当前模型品牌名): 从项目名称 surya_layout3 提取的简洁品牌名
- **文档布局模型** (功能场景): 模型用于文档的布局检测与解析，符合用户搜索“文档布局模型”
- **OCR布局** (功能场景): 模型面向 OCR 场景的版面分析，用户常以 “OCR布局” 为关键词检索
- **TensorFlow** (部署工具): 模型基于 TensorFlow 框架，可通过 TensorFlow 环境进行部署
- **布局检测** (技术特性): 模型的核心技术是对文档进行布局检测，用户会搜索该技术关键词
- **Creative-Commons-4.0** (技术特性): 模型采用 CC‑BY‑NC‑SA 4.0 许可证，用户在寻找可再利用模型时会使用此关键词
- **文档结构分析** (功能场景): 模型能够解析文档结构，满足用户对 “文档结构分析” 的搜索需求

### deepseek-ai/DeepSeek-V3-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3-Base

**关键词列表**:

- **FP8训练** (技术特性): 首创FP8混合精度训练，极具话题性
- **无辅助损失负载均衡** (技术特性): 创新负载均衡策略，差异化亮点

### Qwen/Qwen3-30B-A3B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-8bit

**关键词列表**:

- **Qwen3-30B-A3B-MLX-8bit** (当前模型品牌名): 从项目名称直接提取的完整模型标识，是用户在GitCode等平台搜索该特定版本的精准关键词
- **激活参数3.3B** (参数规格): 模型采用MoE架构，激活参数量为3.3B，是区别于全参数激活模型的关键技术指标，用户会搜索此类稀疏激活模型
- **MLX部署** (部署工具): 模型专为Apple MLX框架优化，是少数支持MLX的千亿级大模型，吸引Apple生态开发者搜索
- **131K上下文** (技术特性): 通过YaRN扩展至131,072 tokens上下文，是当前开源模型中罕见的超长上下文能力，用户会搜索长文本处理模型
- **智能体工具集成** (功能场景): 模型在思维与非思维模式下均支持与外部工具精准交互，是AI智能体开发者的高价值搜索词

### zai-org/glm-4v-9b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4v-9b

**关键词列表**:

- **高分辨率视觉** (功能场景): 支持 1120×1120 高分辨率图像理解，用户会搜
- **中英双语对话** (功能场景): 具备中英双语多轮对话能力，满足多语言需求
- **图表理解** (功能场景): README 明确列出的经典任务之一，用户搜索意图明确
- **文字识别** (功能场景): OCRBench 评测任务，用户会直接搜索

### baidu/ERNIE-4.5-300B-A47B-2Bits-TP2-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-TP2-Paddle

**关键词列表**:

- **2比特量化** (技术特性): 模型实现4比特/2比特无损量化，'2比特量化'是用户关注轻量化部署的核心搜索词，且未被高频词库排除
- **UPO优化** (技术特性): 模型使用独创的'统一偏好优化（UPO）'方法，是区别于DPO/SFT的自研技术，具有高区分度，用户搜索模型优化技术时可能使用
- **PD解耦** (技术特性): 模型采用'动态角色切换的PD解耦技术'提升推理效率，该术语为ERNIE 4.5特有，非通用术语，具备搜索价值
- **47B激活参数** (参数规格): 模型明确标注'每个token激活参数量为47B'，47B属于非主流但具区分度的激活参数规格，用户搜索MoE模型时会关注激活参数而非总参数

### moonshotai/Kimi-K2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-K2-Base

**关键词列表**:

- **Kimi-K2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Kimi** (当前模型品牌名): MoonshotAI映射为Kimi，是当前模型的品牌名
- **专家混合语言模型** (技术特性): 当前模型采用专家混合（MoE）架构，是其核心技术特性
- **智能体能力优化** (技术特性): 当前模型针对智能体能力进行了精心优化，是其独特技术点
- **1万亿参数** (参数规格): 当前模型的总参数量达1万亿，是其主要参数规格
- **320亿激活参数** (参数规格): 当前模型的激活参数达320亿，是区别于其他模型的重要参数

### baidu/ERNIE-4.5-21B-A3B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Paddle

**关键词列表**:

- **4比特量化** (技术特性): 模型实现4比特/2比特无损量化，'4比特量化'是主流用户关注的高效推理关键词，且未被高频词列表排除

### Qwen/Qwen3-235B-A22B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-4bit

**关键词列表**:

- **235B参数** (参数规格): 模型总参数量为 235B，用户常以参数规模搜索模型
- **多语言支持** (功能场景): 模型支持 100+ 语言与方言，适用于多语言翻译和跨语言对话
- **MLX-4bit** (部署工具): 模型已量化为 4bit 并集成在 MLX 框架中，适合用户搜索量化部署方式
- **YaRN扩展上下文** (技术特性): 通过 YaRN 将原生 32k 上下文扩展至 131k，提升长文本处理能力

### Qwen/WorldPM-72B-RLHFLow

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/WorldPM-72B-RLHFLow

**关键词列表**:

- **WorldPM-72B-RLHFLow** (当前模型品牌名): 项目名称直接对应当前模型全称，是唯一标识该模型的专属名称，符合用户搜索特定模型的意图
- **偏好建模** (技术特性): 模型核心创新点，是论文提出的专有技术方向，用户搜索‘偏好建模模型’时会精准匹配
- **规模扩展定律** (技术特性): 模型研究的核心理论发现，具有学术独特性，是区别于通用RLHF模型的关键术语
- **奖励模型** (技术特性): 模型本质是reward model，属于RLHF关键组件，用户搜索‘奖励模型’时会指向此类技术实现
- **PMP** (技术特性): 论文中提出的‘Preference Modeling Paradigm’缩写，是该模型独有的技术术语，具有高区分度
- **WorldPM** (当前模型品牌名): 模型简称，已在README中作为核心品牌标识重复使用，用户可能搜索‘WorldPM模型’而非全称
- **RLHFlow** (技术特性): 模型所属技术框架名称，是项目所属生态的专有标签，区别于通用RLHF，具有唯一性
- **72B参数** (参数规格): 模型规模为72B，属于主流大模型参数量级（介于32B与175B之间），用户会搜索‘72B模型’定位此类规模

### baidu/ERNIE-4.5-VL-28B-A3B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-PT

**关键词列表**:

- **28B参数** (参数规格): 当前模型公开参数规模，用户会搜“28B参数”

### baidu/ERNIE-4.5-VL-28B-A3B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Base-Paddle

**关键词列表**:

- **ERNIE-4.5-VL** (当前模型品牌名): 从项目名称提取的当前模型名称，且为ERNIE 4.5系列中的特定版本
- **A3B系列** (技术特性): 当前模型中的特定系列，具有独特技术特点
- **Multimodal-Heterogeneous-MoE** (技术特性): 当前模型采用的多模态异构MoE预训练技术，是其核心创新点
- **Image-Text-to-Text** (功能场景): 当前模型支持的功能场景，涉及图像和文本的转换
- **PaddlePaddle权重** (技术特性): 当前模型使用的特定框架权重，区别于其他模型

### baidu/ERNIE-4.5-VL-28B-A3B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Base-PT

**关键词列表**:

- **多模态异构MoE** (技术特性): 模型核心创新点，强调'异构'与'MoE'结合的多模态架构，是区别于普通多模态模型的独特技术标签
- **模态专项后训练** (技术特性): 模型采用专属模态微调策略（如VLM强化视觉语言理解），是区别于通用微调的独特训练方法，具有搜索辨识度

### THUDM/androidgen-glm-4-9b

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/androidgen-glm-4-9b

**关键词列表**:

- **AndroidGen** (当前模型品牌名): 项目名称核心品牌，模型专属名称，用户搜索AI安卓智能体时会直接使用
- **androidgen** (当前模型品牌名): 项目标签中明确使用的小写形式，搜索引擎会收录大小写变体，需保留作为独立关键词
- **Android智能体** (功能场景): 模型核心用途是驱动Android应用的自主智能体，用户搜索‘安卓智能体’‘手机AI代理’等词时会匹配
- **无标注任务执行** (技术特性): 模型独特能力：无需人工标注交互数据即可在Android应用中执行任务，属于高区分度技术亮点
- **AI手机助手** (功能场景): 模型用于消息、时钟、邮件、设置等手机应用操作，用户会搜索‘AI手机助手’‘安卓AI助手’等场景词
- **数据稀缺训练** (技术特性): 论文标题明确提及‘under data scarcity’，是模型核心创新点，用户搜索‘低数据训练AI’‘少样本智能体’时可能匹配

### baidu/ERNIE-4.5-300B-A47B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-PT

**关键词列表**:

- **300B参数** (参数规格): 模型规模为 300 B 参数，是该模型最显著的规格特征
- **图文理解** (功能场景): 模型同时处理文本和视觉信息，适用于图文理解任务
- **A47B系列** (技术特性): 模型名称中的 A47B 表示其所属的 MoE‑A47B 系列，是唯一的系列标识
- **PT权重** (部署方式): 模型提供的 Transformer‑style PyTorch 权重格式，适合 PyTorch 环境部署

### baidu/ERNIE-4.5-VL-424B-A47B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Paddle

**关键词列表**:

- **424B参数** (参数规格): 超大参数规模极具话题性，吸引技术爱好者点击
- **PaddlePaddle版** (部署工具): 项目带-Paddle后缀，表明提供Paddle权重，方便检索对应部署方案

### Qwen/Qwen3-14B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-4bit

**关键词列表**:

- **Qwen3-14B** (当前模型品牌名): 从项目名称提取的当前模型名称，14B参数版本
- **MLX量化** (部署工具): 当前模型采用Apple MLX框架的4bit量化部署
- **131K上下文长度** (技术特性): 通过YaRN扩展支持超长131072 tokens上下文

### Intel/dpt-hybrid-midas

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/dpt-hybrid-midas

**关键词列表**:

- **DPT-Hybrid** (当前模型品牌名): 从项目名称 Intel/dpt-hybrid-midas 中直接提取的当前模型专属名称，是论文中提出的具体模型版本
- **单目深度估计** (功能场景): 模型的核心功能，用户搜索AI视觉任务时高频使用的精准术语，非通用词且未被高频词列表排除
- **视觉Transformer** (技术特性): 模型采用ViT作为骨干网络，是其核心技术架构，区别于传统CNN模型，具有独特性且未被高频词列表覆盖
- **密集预测Transformer** (技术特性): 模型全称中的核心术语，直接来自论文标题，是该模型的技术标签，具有学术辨识度且未被高频词列表包含
- **MiDaS-3.0** (当前模型品牌名): README明确指出DPT-Hybrid即MiDaS 3.0，是该模型在社区中的通用别名，用户搜索时可能使用此名称
- **零样本深度估计** (功能场景): 模型支持的核心使用方式，是用户在寻找无需微调的深度估计方案时的精准搜索词，区别于‘微调模型’场景

### Qwen/Qwen3-32B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-6bit

**关键词列表**:

- **Qwen3-32B-MLX-6bit** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **智能体功能** (功能场景): 当前模型具备的专业智能体能力，可精准对接外部工具
- **因果语言模型** (技术特性): 当前模型的类型描述

### unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF

**关键词列表**:

- **Qwen3-235B** (当前模型品牌名): 直接取自项目名称，简化后的模型系列名称
- **Instruct-2507** (技术特性): 模型的指令微调版本号，体现其专注于指令遵循的特性
- **逻辑推理** (功能场景): 模型在逻辑推理任务上的能力被明确提及
- **代码编写** (功能场景): 模型支持代码生成与编程相关任务，是用户常搜索的场景
- **256K上下文** (技术特性): 模型支持 256K 长上下文理解，属于显著的技术卖点
- **GGUF格式** (技术特性): 模型以 GGUF 量化格式发布，用户在搜索模型文件格式时会使用该词

### Helsinki-NLP/opus-mt-fr-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-fr-en

**关键词列表**:

- **opus-mt-fr-en** (当前模型品牌名): 项目名称即模型唯一标识，用户搜索法英翻译模型时会直接使用此名称
- **法英翻译** (功能场景): 用户搜索‘法语转英语’‘法英翻译模型’等意图明确的场景词，符合中文搜索习惯
- **SentencePiece** (技术特性): 模型预处理核心技术，非通用术语，用户在研究翻译模型预处理时会搜索此专有名词
- **OPUS数据集** (技术特性): 模型训练所用的公开数据集名称，专业用户会通过‘OPUS数据集 翻译模型’进行检索
- **transformer-align** (技术特性): 模型架构名称，区别于普通Transformer，是该模型的特定对齐技术，具区分度
- **Helsinki-NLP** (当前模型品牌名): 模型发布机构名称，专业用户常通过机构名搜索其开源模型，如‘Helsinki-NLP 翻译模型’
- **JAX** (部署工具): 模型支持的推理框架之一，非高频词（已排除PyTorch/HuggingFace），JAX用户会针对性搜索

### google/owlv2-base-patch16-ensemble

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlv2-base-patch16-ensemble

**关键词列表**:

- **零样本文本条件目标检测** (功能场景): 当前模型的核心功能和应用场景
- **CLIP骨干网络** (技术特性): 当前模型采用的核心技术架构
- **ViT-B16架构** (技术特性): 当前模型图像编码器采用的架构
- **开放词汇表分类** (技术特性): 当前模型实现的核心技术特性

### nvidia/bigvgan_v2_44khz_128band_512x

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/bigvgan_v2_44khz_128band_512x

**关键词列表**:

- **BigVGAN** (当前模型品牌名): 从项目名称提取的当前神经声码器品牌名
- **神经声码器** (功能场景): 当前模型的核心用途：将声学特征转为高保真音频
- **44kHz采样率** (参数规格): 当前模型支持的高保真音频输出规格，用户会搜
- **512倍上采样** (技术特性): 当前模型独特的512×上采样能力，区别于普通声码器
- **CUDA加速推理** (部署工具): 官方提供融合CUDA内核，实现推理加速，用户部署时关注
- **Gradio演示** (部署工具): 官方内置Gradio交互式本地演示，方便快速体验
- **多语言语音合成** (功能场景): 训练数据覆盖多语言语音，支持跨语种音频生成

### Alibaba-NLP/gte-large-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/gte-large-en-v1.5

**关键词列表**:

- **gte-large-en-v1.5** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该特定嵌入模型时的精准关键词
- **长上下文检索** (功能场景): 模型在LoCo基准中表现优异，突出支持长文本检索能力，是区别于普通嵌入模型的核心应用场景
- **MTEB** (技术特性): 模型在MTEB基准中取得SOTA，该术语是AI研究人员和工程师评估嵌入模型时的权威指标关键词
- **BERT-RoPE-GLU** (技术特性): 模型采用的独特主干架构组合，是技术用户区分该模型与普通BERT嵌入模型的关键技术标识
- **8192上下文** (技术特性): 虽然禁止提取纯数字，但'8192上下文'作为模型支持的上下文长度术语，在AI社区中已被广泛用作搜索词，具有明确指向性且非通用描述
- **英语嵌入模型** (功能场景): 模型专为英语设计，用户在寻找高质量英语文本嵌入时会使用此组合词，具有明确语言指向性

### THUDM/GLM-4.1V-9B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4.1V-9B-Thinking

**关键词列表**:

- **GLM-4.1V** (当前模型品牌名): 项目名称中直接出现的模型品牌标识，用户搜索时会使用该名称定位模型
- **思维链推理** (技术特性): 模型采用思维链推理范式，是其核心技术创新点，用户会以此关键词搜索
- **64k上下文** (技术特性): 支持超长64k上下文，是模型在长文本推理方面的显著特性
- **4K图像支持** (功能场景): 模型可处理最高4K分辨率的任意宽高比图像，适用于高分辨率视觉任务
- **中英双语** (功能场景): 模型同时支持中文和英文双语输入输出，满足多语言使用需求

### Intel/zoedepth-nyu-kitti

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/zoedepth-nyu-kitti

**关键词列表**:

- **ZoeDepth** (当前模型品牌名): 从项目名称 Intel/zoedepth-nyu-kitti 中提取的核心模型名称，是用户搜索该深度估计模型的唯一品牌标识
- **度估计** (功能场景): 中文用户搜索深度估计任务时最常用的核心功能词，直接对应模型的 metric depth estimation 能力
- **零样本深度** (技术特性): 模型核心创新点 'zero-shot transfer' 的中文提炼，区别于需微调的模型，具有高区分度
- **DPT框架** (技术特性): 模型基于 DPT 架构进行适配，是技术实现的关键基础，用户搜索相关架构时会使用该术语
- **绝对深度** (技术特性): 模型实现的是 'absolute depth estimation'（绝对深度估计），与相对深度形成鲜明对比，是技术关键词
- **NYU-KITTI** (当前模型品牌名): 模型微调所用的权威数据集名称，构成模型的完整标识，专业用户常以此组合搜索特定版本
- **arxiv2302.12288** (当前模型品牌名): 论文唯一标识符，研究者和工程师常直接搜索arxiv编号定位模型，具有极高精准引流价值

### facebook/dinov2-base

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-base

**关键词列表**:

- **Vision-Transformer** (技术特性): 当前模型的核心架构，用户常搜ViT或Vision Transformer
- **下游任务微调** (功能场景): 用户想基于DINOv2做分类、检测等下游任务时的搜索词

### laion/CLIP-ViT-H-14-laion2B-s32B-b79K

**URL**: https://ai.gitcode.com/hf_mirrors/laion/CLIP-ViT-H-14-laion2B-s32B-b79K

**关键词列表**:

- **CLIP-ViT-H-14** (当前模型品牌名): 从项目名称提取的当前模型名称
- **LAION-2B** (技术特性): 模型训练基于LAION-2B数据集，是模型的重要技术特性
- **OpenCLIP框架** (技术特性): 模型通过OpenCLIP框架训练，是模型的核心技术特性
- **零样本图像分类** (功能场景): 模型的主要直接用途之一，用户会搜索此类功能
- **图文检索** (功能场景): 模型的直接用途之一，用户可能搜索此类应用场景
- **图像生成引导** (功能场景): 模型的下游用途之一，用户可能对此感兴趣

### Gen-Verse/MMaDA-8B-MixCoT

**URL**: https://ai.gitcode.com/hf_mirrors/Gen-Verse/MMaDA-8B-MixCoT

**关键词列表**:

- **MMaDA-8B-MixCoT** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定模型时的精准关键词

### tsmatz/xlm-roberta-ner-japanese

**URL**: https://ai.gitcode.com/hf_mirrors/tsmatz/xlm-roberta-ner-japanese

**关键词列表**:

- **xlm-roberta-ner-japanese** (当前模型品牌名): 项目名称即模型的完整品牌名
- **日本語固有表現抽出** (功能场景): 模型专注于日语的固有表現（命名实体）抽取任务
- **Japanese-NER** (功能场景): 模型的核心任务——日语命名实体识别（英文表述）
- **Stockmark-NER数据集** (数据集): 模型在该公司提供的日语维基百科NER数据集上完成微调
- **token-classification-pipeline** (使用方式): 官方示例展示了使用 HuggingFace pipeline 进行标记分类的调用方式

### sshleifer/distilbart-cnn-6-6

**URL**: https://ai.gitcode.com/hf_mirrors/sshleifer/distilbart-cnn-6-6

**关键词列表**:

- **distilbart-cnn-6-6** (当前模型品牌名): 从项目名称提取的当前模型名称
- **230百万参数** (参数规格): 当前模型的参数规模，具有区分度
- **cnndailymail** (功能场景): 当前模型训练数据集之一，体现应用场景

### google/ddpm-celebahq-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-celebahq-256

**关键词列表**:

- **DDPM** (当前模型品牌名): 项目名称为google/ddpm-celebahq-256，DDPM是该模型的核心品牌名称，用户搜索扩散模型时会直接使用该缩写
- **无条件图像生成** (功能场景): README明确提到'unconditional-image-generation'，是该模型的核心用途，用户会搜索‘无条件图像生成模型’这类精准意图词
- **DDIM** (技术特性): DDIM是该模型支持的专属推理调度器之一，区别于DDPM，是用户在优化推理速度时会搜索的关键技术词
- **PNDM** (技术特性): PNDM是该模型支持的另一种高效推理调度器，与DDIM并列，属于该模型独有的部署选项，具有区分度
- **256x256图像生成** (功能场景): 模型专为256x256分辨率的CelebAHQ数据集设计，该分辨率是用户寻找高清人脸生成模型时的明确搜索维度
- **扩散概率模型** (技术特性): README核心术语，描述模型底层技术原理，是学术和工程用户搜索扩散模型类AI生成技术时的高频精准词
- **去噪分数匹配** (技术特性): README中提出的创新理论关联，属于该模型独有的技术亮点，非通用词，具有高区分度

### Diankun/Spatial-MLLM-subset-sft

**URL**: https://ai.gitcode.com/hf_mirrors/Diankun/Spatial-MLLM-subset-sft

**关键词列表**:

- **Spatial-MLLM** (当前模型品牌名): 项目名称中直接出现的模型名称
- **视觉空间智能** (功能场景): 论文标题强调模型在视觉空间智能方面的提升
- **Video-Text-to-Text** (功能场景): 标签中列出的任务类型，表示模型支持视频到文本的转换
- **SFT微调** (技术特性): 模型文件名包含 “subset‑sft”，表明使用了指令微调（SFT）技术
- **Subset数据集** (技术特性): 模型基于子集数据进行训练，体现了特定数据筛选策略
- **空间感知** (技术特性): 模型核心目标是提升对视觉空间信息的感知与理解

### valhalla/distilbart-mnli-12-1

**URL**: https://ai.gitcode.com/hf_mirrors/valhalla/distilbart-mnli-12-1

**关键词列表**:

- **DistilBart** (当前模型品牌名): 项目名中的核心品牌名，用户会直接搜索
- **MNLI零样本分类** (功能场景): README明确标注的Zero-Shot Classification场景
- **无教师蒸馏** (技术特性): README提到的核心技术，用户会搜蒸馏方法
- **12层蒸馏** (参数规格): README表格中反复出现的层数规格，用户会搜

### HiDream-ai/HiDream-E1-1

**URL**: https://ai.gitcode.com/hf_mirrors/HiDream-ai/HiDream-E1-1

**关键词列表**:

- **HiDream-E1** (当前模型品牌名): 从项目名称直接提取的当前模型主名称，是用户搜索该模型的核心关键词
- **HiDream-E1.1** (当前模型品牌名): 项目最新开源版本，具有独立发布记录，是用户搜索最新版时的精准关键词
- **图像编辑** (功能场景): 模型核心用途为图像编辑，是用户在CSDN等平台搜索AI图像工具时的高频意图词，且未被高频词列表排除
- **稀疏扩散Transformer** (技术特性): 模型技术报告中明确提出的原创架构名称，具有高度区分度，非通用术语，用户可能搜索该技术实现
- **arxiv2505.22705** (技术特性): 模型对应论文的唯一arXiv编号，技术研究者常通过此编号直接搜索模型技术细节，具有强指向性且非通用
- **HiDream.ai** (当前模型品牌名): 项目标签中明确出现的品牌标识，是用户搜索该厂商旗下模型时的直接入口词，且未被高频词列表覆盖

### CIDAS/clipseg-rd64-refined

**URL**: https://ai.gitcode.com/hf_mirrors/CIDAS/clipseg-rd64-refined

**关键词列表**:

- **CIDASclipseg-rd64-refined** (当前模型品牌名): 从项目名称提取的当前模型名称
- **CLIPSeg** (当前模型品牌名): 模型的核心名称，用户可能直接搜索
- **降维64** (技术特性): 模型具有降维64的特性，是区别于其他模型的技术点
- **零样本图像分割** (功能场景): 模型适用于零样本图像分割，是其主要应用场景
- **单样本图像分割** (功能场景): 模型也适用于单样本图像分割，扩展了其应用场景
- **复杂卷积优化** (技术特性): 模型经过复杂卷积优化，是其技术上的独特之处

### jonatasgrosman/wav2vec2-large-xlsr-53-japanese

**URL**: https://ai.gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-japanese

**关键词列表**:

- **wav2vec2-large-xlsr-53-japanese** (当前模型品牌名): 从项目名称直接提取的完整模型标识，是用户搜索日语语音识别模型时最可能使用的精确关键词
- **日语语音识别** (功能场景): 模型的核心用途，用户在CSDN等平台搜索日语ASR时会使用此明确场景词
- **XLSR微调** (技术特性): 模型基于XLSR-53进行日语微调，'XLSR微调'是区别于通用语音模型的独特技术标签
- **Common-Voice日语** (数据来源): 模型训练使用Common Voice日语数据集，该数据集名称是专业用户识别模型可靠性的关键搜索词
- **HuggingSound** (部署工具): 文档推荐的专用推理库，是该模型生态中独特且可搜索的部署方式，非通用HuggingFace
- **JSUT语音数据集** (数据来源): JSUT是日语语音领域权威公开数据集，专业用户会以此作为筛选模型的关键词
- **CSS10日语** (数据来源): CSS10日语子集是模型训练的重要数据源，具有领域独特性，非通用词，适合精准引流

### dbmdz/bert-large-cased-finetuned-conll03-english

**URL**: https://ai.gitcode.com/hf_mirrors/dbmdz/bert-large-cased-finetuned-conll03-english

**关键词列表**:

- **BERT-large** (当前模型品牌名): 模型名称中包含的品牌和规模标识，用户搜索时常用此词定位模型
- **CoNLL-03** (功能场景): 模型在 CoNLL‑03 数据集上微调，用户常以数据集名称搜索对应的实体识别模型
- **英文实体识别** (功能场景): 模型用于英文命名实体识别（NER），这是用户最直接的使用场景关键词
- **Cased模型** (技术特性): 模型采用大小写敏感（cased）方式，对大小写有区分，属于显著的技术特性
- **TensorFlow部署** (部署工具): 标签中包含 TensorFlow，说明模型可直接在 TensorFlow 环境下部署使用
- **340M参数** (参数规格): BERT‑large 约有 340 百万参数，参数规模是用户在搜索时关注的关键信息

### QuantStack/FLUX.1-Kontext-dev-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/FLUX.1-Kontext-dev-GGUF

**关键词列表**:

- **FLUX-Kontext** (当前模型品牌名): 从项目名称提取的当前模型核心品牌名
- **图像到图像** (功能场景): 标签明确image-to-image，用户搜图生图或图像到图像时会匹配
- **FLUX量化版** (技术特性): 强调这是FLUX官方模型的量化版本，用户搜FLUX量化版可直接定位

### QuantStack/Wan2.1_14B_VACE-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.1_14B_VACE-GGUF

**关键词列表**:

- **Wan2.114BVACE-GGUF** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ComfyUI-GGUF** (部署工具): 当前模型可配合使用的自定义节点工具
- **Q80量化** (技术特性): 当前模型上传的量化版本特性
- **Text-to-Video** (功能场景): 当前模型的核心功能场景

### mradermacher/Wolf-Rayet-2B-Prime3-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Wolf-Rayet-2B-Prime3-i1-GGUF

**关键词列表**:

- **Wolf-Rayet-2B-Prime3** (当前模型品牌名): 完整的模型名称，直接来源于项目名称
- **i1-IQ1** (技术特性): 模型提供的 IQ1 量化等级，区别于其他量化级别
- **i1-IQ2** (技术特性): 模型提供的 IQ2 量化等级，适用于不同存储需求
- **i1-IQ3** (技术特性): 模型提供的 IQ3 量化等级，兼顾质量与体积
- **i1-IQ4** (技术特性): 模型提供的最高等级 IQ4 量化，推荐优先选择
- **加权矩阵量化** (技术特性): README 中提到的核心量化方法，区别于普通量化

### Kwaipilot/KAT-V1-40B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/KAT-V1-40B

**关键词列表**:

- **KAT** (当前模型品牌名): 项目README中明确给出的当前模型简称
- **Kwaipilot-AutoThink** (当前模型品牌名): 项目README中给出的完整品牌名
- **40B参数** (参数规格): 项目名称中直接标注的主流规格
- **思维链开关** (技术特性): 模型核心卖点：可显式控制是否触发思维链
- **Step-SRPO** (技术特性): README中提到的后训练关键技术
- **Think-on查询** (技术特性): 模型训练阶段引入的推理数据标签
- **LiveCodeBench-Pro** (功能场景): README中突出强调的编程评测场景

### mradermacher/Qwen2-Audio-7B-Instruct-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-Instruct-GGUF

**关键词列表**:

- **Qwen2-Audio-7B-Instruct** (当前模型品牌名): 项目名称中的完整模型标识，是当前模型的唯一品牌名，符合用户搜索AI音频模型时的精确关键词习惯
- **audio-text-to-text** (功能场景): 模型核心功能是音频到文本的对话理解，属于用户搜索‘语音转文字AI’‘音频问答模型’等场景的精准术语，且未在高频排除词列表中
- **Q4KM** (参数规格): 模型提供Q4_K_M等具体量化精度版本，属于用户在寻找‘轻量级音频模型’‘低显存推理’时会搜索的精确量化规格，非通用参数词
- **Q80** (参数规格): Q8_0是该模型中质量最佳的量化版本，用户在追求高精度音频理解时会搜索该具体量化格式，具有明确区分度
- **mmproj-Q80** (技术特性): 多模态投影文件（mmproj）是该音频模型的关键组件，Q8_0为其量化形式，属于模型独有的技术模块，非通用术语
- **音频对话模型** (功能场景): 基于audio-text-to-text功能提炼的自然中文搜索词，用户可能搜索‘能听懂语音的AI对话模型’，此词精准匹配意图且未被高频排除

### facebook/musicgen-medium

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/musicgen-medium

**关键词列表**:

- **文本到音乐** (功能场景): 模型的核心任务是将文字描述转换为音乐音频
- **单阶段自回归** (技术特性): 模型采用单阶段自回归 Transformer 架构进行生成
- **并行预测** (技术特性): 通过在码本间引入微小延迟实现的并行预测能力
- **4码本** (技术特性): 模型使用 4 个 EnCodec 码本进行音频分解与重建

### pysentimiento/robertuito-sentiment-analysis

**URL**: https://ai.gitcode.com/hf_mirrors/pysentimiento/robertuito-sentiment-analysis

**关键词列表**:

- **robertuito-sentiment-analysis** (当前模型品牌名): 从项目名称提取的当前模型名称
- **西班牙语情感分析** (功能场景): 当前模型的应用场景和功能
- **RoBERTuito** (技术特性): 当前模型采用的基础模型名称
- **POS-NEG-NEU** (技术特性): 当前模型使用的标签类型
- **pysentimiento工具包** (部署工具): 当前模型的使用方式

### maya-research/Veena

**URL**: https://ai.gitcode.com/hf_mirrors/maya-research/Veena

**关键词列表**:

- **Veena** (当前模型品牌名): 项目名称为Maya-research/Veena，是当前模型的唯一官方名称，符合用户搜索AI模型时直接输入品牌名的意图
- **印地语TTS** (功能场景): 模型专为印地语文本转语音设计，用户搜索‘印地语TTS’是明确的地域语言需求，具有高度场景针对性且非高频词
- **语码混合TTS** (功能场景): 模型原生支持印地语与英语混合输入，这一特性在TTS领域具有独特性，是用户寻找多语言混合语音合成时的精准搜索词
- **SNAC音频** (技术特性): 模型使用SNAC神经编解码器输出24kHz音频，SNAC是其核心技术组件，非通用术语，具有技术辨识度且未在排除列表中
- **自回归TTS** (技术特性): 模型基于自回归变换器架构，‘自回归TTS’是用户在比较TTS模型架构时可能搜索的精准技术标签，区别于流式或非自回归TTS
- **4音色TTS** (功能场景): 模型提供kavya、agastya、maitri、vinaya四种独特音色，‘4音色TTS’是用户寻找多音色语音合成时的高意图搜索词，具差异化
- **低延迟TTS** (功能场景): 模型在H100上延迟低于80ms，‘低延迟TTS’是生产部署用户的核心关注点，非泛泛形容词，具有明确性能指向性
- **4比特量化TTS** (部署工具): 模型支持4比特量化优化，专为生产部署设计，该术语精准描述其轻量化部署能力，非通用‘量化模型’，避开了高频词

### vidore/colpali-v1.2

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colpali-v1.2

**关键词列表**:

- **ColPali** (当前模型品牌名): 项目名称即为模型品牌名，直接提取
- **视觉检索** (功能场景): 模型用于从文档的视觉特征中建立索引，实现图像‑文本检索
- **BiSigLIP** (技术特性): 基于 SigLIP 微调得到的 BiSigLIP 是模型构建过程中的关键步骤
- **BiPali** (技术特性): 将图像块嵌入 PaliGemma‑3B 后形成的 BiPali 为模型的核心表示方式
- **右填充查询** (技术特性): 本版本在查询编码中使用右填充以修复无关标记问题
- **colpali-engine** (部署工具): 模型基于 colpali-engine==0.2.0 进行训练和加载，可直接用于推理部署

### mradermacher/Orsta-7B-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Orsta-7B-i1-GGUF

**关键词列表**:

- **Orsta-7B** (当前模型品牌名): 项目名称直接给出的模型品牌与规格
- **视觉模型** (功能场景): README明确标注为视觉模型，用户会搜
- **VLM** (技术特性): 标签中的视觉-语言模型缩写，技术圈常用
- **IQ1S** (参数规格): 超小2GB量化版，极客用户会精确搜索

### mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF

**关键词列表**:

- **SEOcrate-4B** (当前模型品牌名): 从项目名称 mradermacher/SEOcrate-4B_grpo_new_01-i1-GGUF 中提取的核心品牌名称，去除了冗余后缀，符合简洁品牌名规范
- **SEO写作** (功能场景): 模型基于SEO相关数据集（seo-grpo-reasoning-dataset）微调，核心用途为生成优化搜索引擎的文本内容，用户会搜索‘SEO写作’这类精准场景词
- **IQ2IQ3量化** (技术特性): 模型提供IQ2_XS、IQ3_S等特有量化等级，是其区别于普通Q4/Q2模型的关键技术标签，用户会搜索此类专业量化标识
- **知识图谱SEO** (功能场景): 标签包含schema.org、knowledge-graph、ontology，表明模型专为结构化SEO与知识图谱内容生成设计，是高度垂直的场景词
- **4bit推理** (技术特性): 模型为4bit量化版本，虽‘4bit’本身是通用词，但结合‘推理’形成‘4bit推理’作为用户搜索低资源部署时的高频意图组合，且未在禁用词列表中
- **SEO推理模型** (技术特性): 模型基于grpo（可能为‘guided reasoning for SEO’）微调，具备SEO场景下的推理能力，‘SEO推理模型’是独特且未被高频使用的精准组合词

### google/ddpm-cifar10-32

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-cifar10-32

**关键词列表**:

- **ddpm-cifar10-32** (当前模型品牌名): 从项目名称提取的当前模型名称
- **去噪扩散概率模型** (技术特性): 当前模型的核心技术特性描述
- **DDPM推理** (部署工具): 当前模型使用的推理方式，与模型紧密相关
- **渐进式有损解压缩** (技术特性): 当前模型支持的一种技术特性，具有区分度

### facebook/timesformer-base-finetuned-k400

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/timesformer-base-finetuned-k400

**关键词列表**:

- **TimeSformer** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频分类** (功能场景): 当前模型在Kinetics-400上微调，专用于视频动作识别
- **时空注意力** (技术特性): TimeSformer的核心创新，用Transformer同时建模空间与时间信息
- **Kinetics-400** (功能场景): 模型已在Kinetics-400数据集上完成微调，可直接用于400类动作识别
- **Transformers视频** (技术特性): 基于HuggingFace Transformers的视频理解模型，易于调用
- **224分辨率** (参数规格): 模型输入固定为224×224分辨率，方便部署与调优

### mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF

**关键词列表**:

- **GCIRS-Reasoning** (当前模型品牌名): 从项目名称 mradermacher/GCIRS-Reasoning-1.5B-R1-GGUF 中提取的核心品牌名，去掉版本号后为简洁识别名
- **IQ4XS** (技术特性): 模型提供独特的IQ4_XS量化版本，属于非主流但高区分度的量化类型，用户会专门搜索此类低比特高效格式
- **Q4KS** (技术特性): 模型推荐的Q4_K_S是其重点标注的高性能量化选项，区别于通用Q4，具有明确的性能导向标签
- **Q6K** (技术特性): 模型明确标注Q6_K为'质量非常好'，是用户寻找中高精度量化时可能搜索的特定层级
- **科学推理** (功能场景): 标签含'science, math, finance'，综合提炼为'科学推理'，是模型核心用途，非通用'智能对话'或'编程助手'

### ByteDance-Seed/SeedVR-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR-7B

**关键词列表**:

- **SeedVR** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **视频修复** (功能场景): 模型的核心应用场景是对受损视频进行修复
- **任意分辨率修复** (功能场景): 模型支持在任意分辨率下进行视频修复，区别于固定分辨率的传统方法
- **一步视频修复** (技术特性): 论文标题中提出的 One‑Step Video Restoration 技术
- **Diffusion** (技术特性): 模型基于扩散（Diffusion）Transformer 架构实现视频修复
- **视频生成训练流程** (技术特性): 采用最先进的视频生成训练流程，提升修复质量和一致性

### mradermacher/BetaCeti-Beta-4B-Prime1-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/BetaCeti-Beta-4B-Prime1-i1-GGUF

**关键词列表**:

- **BetaCeti-Beta-4B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **加权矩阵量化版本** (技术特性): 当前模型版本的核心技术特性
- **静态量化版本** (技术特性): 当前模型提供的另一种量化技术特性
- **i1-IQ量化** (技术特性): 当前模型提供的量化版本类型
- **text-generation-inference** (功能场景): 当前模型的应用场景，文本生成推理

### kredor/punctuate-all

**URL**: https://ai.gitcode.com/hf_mirrors/kredor/punctuate-all

**关键词列表**:

- **punctuate-all** (当前模型品牌名): 项目名称为kredor/punctuate-all，直接提取为模型品牌名，简洁且唯一
- **自动标点** (功能场景): 模型核心功能是为无标点文本自动添加标点符号，用户会搜索'自动标点'这类明确需求词
- **多语言标点** (功能场景): 支持12种欧洲语言的标点恢复，'多语言标点'是用户在处理跨语言文本时的精准搜索词
- **xlm-roberta-base** (技术特性): 模型基于微调后的xlm-roberta-base，是其技术核心且区别于其他标点模型的唯一架构标识
- **文本标点修复** (功能场景): 用户常搜索'文本标点修复'来解决无标点输入文本的可读性问题，精准匹配模型用途
- **WMT-Europarl** (技术特性): 模型训练数据源自WMT/Europarl语料，是其训练背景的关键标识，专业用户会据此检索

### nari-labs/Dia-1.6B-0626

**URL**: https://ai.gitcode.com/hf_mirrors/nari-labs/Dia-1.6B-0626

**关键词列表**:

- **Dia** (当前模型品牌名): 项目名称即为 Dia，直接提取为模型品牌名
- **文本转语音** (功能场景): 模型的核心功能是将文字转为自然语音
- **情感语调控制** (技术特性): 支持通过音频条件精准调节情感与语调，是模型的关键技术特性
- **非语言音效生成** (功能场景): 能够生成笑声、咳嗽、清嗓等非语言音效，拓展了使用场景
- **Gradio界面** (部署工具): 提供交互式 Gradio UI，方便本地快速启动和使用
- **ZeroGPU** (部署工具): 模型已上线 ZeroGPU 空间，可免显卡在线体验
- **1.6B参数** (参数规格): 模型规模为 1.6 B 参数，属于中等规模的 TTS 模型

### MohamedRashad/Voxtral-Small-24B-2507-transformers

**URL**: https://ai.gitcode.com/hf_mirrors/MohamedRashad/Voxtral-Small-24B-2507-transformers

**关键词列表**:

- **Voxtral-Small** (当前模型品牌名): 从项目名称 'MohamedRashad/Voxtral-Small-24B-2507-transformers' 中提取的核心模型品牌名，去除了冗余版本号，符合简洁品牌名规范
- **语音转录** (功能场景): 模型核心功能之一，用户会直接搜索‘语音转录模型’这类意图明确的场景词，且非高频禁用词
- **语音问答** (功能场景): 模型支持‘通过音频直接提问’，这是独特功能点，用户可能搜索‘语音问答AI’或‘语音提问模型’
- **多语言语音** (功能场景): 模型支持8种主流语言的自动检测与转录，用户会搜索‘多语言语音转录’等组合词，具有明确区分度
- **32k上下文** (参数规格): 32k token上下文长度是模型处理长音频（30分钟）的核心支撑，属于主流规格范畴，非技术细节，用户会搜索‘长上下文语音模型’
- **语音摘要** (功能场景): 模型内置‘音频生成结构化摘要’功能，是区别于普通ASR工具的独特卖点，搜索意图明确
- **语音调用API** (功能场景): 模型支持‘基于口语意图直接触发API’，属于前沿应用场景，用户可能搜索‘语音控制API’或‘语音触发工作流’

### mgalkin/ultra_3g

**URL**: https://ai.gitcode.com/hf_mirrors/mgalkin/ultra_3g

**关键词列表**:

- **ULTRA** (当前模型品牌名): 项目名称为mgalkin/ultra_3g，核心品牌名为ULTRA
- **知识图谱补全** (功能场景): README明确说明ULTRA用于知识图谱的链接预测/补全任务
- **零样本推理** (技术特性): ULTRA可在50+图谱上零样本运行，无需额外训练
- **图神经网络** (技术特性): ULTRA基于改进的NBFNet图神经网络架构
- **统一关系表示** (技术特性): ULTRA通过关系交互学习统一可迁移的关系表示
- **16.9万参数** (参数规格): README指出检查点参数量约16.9万，轻量化模型

### moojink/openvla-7b-oft-finetuned-libero-spatial-object-goal-10

**URL**: https://ai.gitcode.com/hf_mirrors/moojink/openvla-7b-oft-finetuned-libero-spatial-object-goal-10

**关键词列表**:

- **OpenVLA-OFT** (当前模型品牌名): 项目名称中的核心品牌，用户会直接搜索
- **视觉语言动作模型** (功能场景): 模型主打VLA能力，用户用此词找同类机器人模型
- **LIBERO任务套件** (功能场景): README高频提及的机器人 benchmark，开发者常搜
- **机器人动作生成** (功能场景): 明确落地场景，用户搜索机器人动作方案
- **OFT微调** (技术特性): 论文与仓库共同强调的优化微调方法，技术关键词
- **PEFT优化** (技术特性): 标签与描述均提到的高效微调技术，吸引调参用户

### mistralai/Magistral-Small-2507

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Magistral-Small-2507

**关键词列表**:

- **Magistral-Small-2507** (当前模型品牌名): 从项目名称提取的当前模型名称
- **推理能力** (技术特性): 当前模型新增的核心技术特性
- **Apache-2.0许可证** (技术特性): 当前模型采用的开放许可证类型
- **240亿参数** (参数规格): 当前模型的参数规模
- **本地量化部署** (部署工具): 当前模型支持本地量化后适配特定硬件的部署方式

### SWivid/F5-TTS

**URL**: https://ai.gitcode.com/hf_mirrors/SWivid/F5-TTS

**关键词列表**:

- **F5-TTS** (当前模型品牌名): 项目名称直接来源于SWivid/F5-TTS，是当前模型的唯一官方品牌名，用户搜索TTS模型时会直接使用该名称
- **Flow-Matching** (技术特性): 论文标题明确指出模型基于'Flow Matching'技术，是区别于传统自回归或扩散模型的核心创新点，用户会搜索该技术关键词寻找同类模型
- **文生语音** (功能场景): F5-TTS是文本到语音生成模型，'文生语音'是中文用户对TTS的自然搜索词，且未被列入强制排除词列表，具有明确搜索意图
- **F5TTSv1Base** (当前模型品牌名): 模型文件夹名称为F5TTS_v1_Base，是模型版本的官方标识，用户在部署时会搜索该具体版本名，且未被高频词排除
- **E2-TTS** (当前模型品牌名): README中明确将E2 TTS与F5-TTS并列作为可下载模型，属于同一项目体系下的独立模型名称，非对比模型，可独立提取
- **Faithful-Speech** (技术特性): 论文标题中'Faithful Speech'是模型核心目标之一，代表高保真语音生成，是区别于普通TTS的差异化技术表述，用户可能搜索该短语
- **Fluent-Speech** (技术特性): 论文标题中与'Faithful'并列的'Fluent'是模型设计的另一核心目标，代表语音自然流畅性，属于模型专属技术标签，非通用词

### MohamedRashad/Voxtral-Mini-3B-2507-transformers

**URL**: https://ai.gitcode.com/hf_mirrors/MohamedRashad/Voxtral-Mini-3B-2507-transformers

**关键词列表**:

- **Voxtral-Mini** (当前模型品牌名): 项目名称中出现的模型品牌名称，直接代表该模型
- **音频转录** (功能场景): 模型提供高质量的语音转文本能力，是核心使用场景
- **音频摘要** (功能场景): 模型能够基于音频生成结构化摘要，满足信息提取需求
- **自动语言检测** (技术特性): 模型可自动识别音频语言并切换相应的转录/翻译模型
- **语音触发调用** (技术特性): 支持通过口语意图直接触发后端功能或 API 调用的交互方式
- **长音频上下文** (技术特性): 凭借 32k token 上下文，模型可处理长达 30‑40 分钟的音频

### Kwai-Keye/Keye-VL-8B-Preview

**URL**: https://ai.gitcode.com/hf_mirrors/Kwai-Keye/Keye-VL-8B-Preview

**关键词列表**:

- **Keye-VL** (当前模型品牌名): 从项目名称提取的当前模型名称
- **快手大模型** (当前模型品牌名): Kwai Keye团队出品，映射为快手大模型
- **短视频理解** (功能场景): 专为短视频理解设计的核心能力
- **冷启动数据混合** (技术特性): 模型后训练阶段的核心创新策略
- **KC-MMBench** (功能场景): 官方发布的短视频评测基准

### laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K

**URL**: https://ai.gitcode.com/hf_mirrors/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K

**关键词列表**:

- **CLIP-ViT-L-14** (当前模型品牌名): 从项目名称直接提取的核心模型标识，是用户搜索CLIP视觉-文本模型时的精准关键词
- **DataComp.XL** (当前模型品牌名): 模型训练所用的专属数据集名称，构成模型唯一标识，区别于普通CLIP模型，具有高区分度
- **OpenCLIP** (技术特性): 模型基于的开源框架名称，是技术社区中用于区分OpenAI CLIP与开源实现的关键术语
- **DataComp-1B** (技术特性): 模型训练所用的专属大规模数据集名称，具有唯一性，是研究者关注数据质量时的搜索词
- **线性探针图像分类** (下游用途): README中明确提及的特定微调方式，属于专业研究者搜索的精准技术场景，非通用词

### ChatDOC/OCRFlux-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ChatDOC/OCRFlux-3B

**关键词列表**:

- **OCRFlux** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **PDF转Markdown** (功能场景): 模型的核心功能是将 PDF 与图像转换为纯 Markdown 文本
- **跨页表格合并** (技术特性): 首个开源实现跨页表格与段落自动合并的独特特性
- **OCRFlux-API** (部署工具): 提供直接调用的推理 API，方便在代码中使用模型
- **vllm高效推理** (技术特性): 基于 vllm 实现的高效大规模文档推理加速

### dphn/Dolphin-Mistral-24B-Venice-Edition

**URL**: https://ai.gitcode.com/hf_mirrors/dphn/Dolphin-Mistral-24B-Venice-Edition

**关键词列表**:

- **Dolphin-Mistral-24B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Venice-Uncensored** (当前模型品牌名): 当前模型在Venice.ai上的上线名称
- **无审查版本** (技术特性): 当前模型的核心技术特性，强调无审查
- **可引导性** (技术特性): 当前模型的核心技术特性，强调用户可引导
- **系统提示词控制** (技术特性): 当前模型允许用户设置系统提示词，掌控模型行为
- **数据掌控** (技术特性): 当前模型允许用户掌控自己的数据

### zai-org/GLM-4.5-Air-Base

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5-Air-Base

**关键词列表**:

- **智能体模型** (功能场景): README明确指出‘专为智能体设计’，是该模型的专属应用场景，非通用对话模型
- **120亿激活参数** (参数规格): 120亿是GLM-4.5-Air的显著激活参数规模，属于主流可搜索规格，且区别于高频词32B/7B

### Robertooo/autotrain-hmaet-2037366891

**URL**: https://ai.gitcode.com/hf_mirrors/Robertooo/autotrain-hmaet-2037366891

**关键词列表**:

- **AutoTrain回归模型** (当前模型品牌名): 项目由AutoTrain训练，单列回归是其核心标识
- **HMAET回归** (当前模型品牌名): 项目名中hmaet为模型专属代号，用户搜hmaet可直达
- **R2得分0.486** (技术特性): 决定系数R²是回归模型性能的直接指标，用户常搜具体数值
- **MSE-0.005** (技术特性): 均方误差数值极低，体现模型精度，是技术选型的搜索关键词
- **joblib模型文件** (部署工具): 模型以joblib格式发布，用户搜索该关键词可找到直接可用的权重文件
- **单列回归预测** (功能场景): README明确任务类型，用户需要单变量回归模型时会用此词

### sentence-transformers/multi-qa-MiniLM-L6-cos-v1

**URL**: https://ai.gitcode.com/hf_mirrors/sentence-transformers/multi-qa-MiniLM-L6-cos-v1

**关键词列表**:

- **multi-qa-MiniLM-L6-cos-v1** (当前模型品牌名): 完整的模型名称，用户在搜索具体模型时会直接使用
- **Sentence-Similarity** (功能场景): 模型可用于句子相似度计算，符合搜索、匹配等任务需求
- **ONNX支持** (部署工具): 模型提供 ONNX 导出，便于跨平台部署和加速推理
- **OpenVINO兼容** (部署工具): 支持 OpenVINO，可在 Intel 硬件上高效运行

### LiquidAI/LFM2-350M

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M

**关键词列表**:

- **LFM2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Liquid模型** (技术特性): 当前模型自称的“新型混合 Liquid 模型”架构
- **边缘AI** (功能场景): 专为边缘人工智能和设备端部署设计
- **乘法门控** (技术特性): 士独有的乘法门控机制
- **RAG应用** (功能场景): 官方建议用于检索增强生成场景
- **350M参数** (参数规格): 当前模型具体参数规模，用户会搜
- **CPU推理** (部署工具): 强调可在CPU上高效运行，用户关心部署

### ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q8

**关键词列表**:

- **Tifa-DeepSexV2** (当前模型品牌名): 项目名称中唯一标识的当前模型品牌，符合简化命名规则，且为用户搜索该特定模型的直接关键词
- **MGRPO** (技术特性): 模型核心创新算法，作者强调其独特性与性能突破，属非通用技术术语，用户可能搜索该缩写以寻找同类方法
- **角色扮演** (功能场景): README明确指出‘提供卓越的角色扮演体验’，是模型核心应用场景，非泛用词，具有明确搜索意图
- **100万字上下文** (功能场景): 模型突出能力描述，虽含数字但属于用户可感知的‘长上下文’需求场景，非纯技术参数，符合‘用户搜长对话模型’的意图
- **Q8量化** (部署工具): 模型提供Q8版本并推荐使用，Q8是GGUF量化等级中用户实际部署时关注的精度-性能平衡点，具操作指向性
- **Crazy版本** (功能场景): 作者明确预告将发布‘Crazy版本’，属模型自身独有的版本分类术语，具有话题性和搜索独特性
- **MGRPO训练** (技术特性): 作者重点描述MGRPO训练效率低但效果强，该组合词是模型训练方法的专有表达，非通用术语，具区分度
- **DeepSex** (功能场景): 模型名称核心词，作者专门解释‘性’的哲学含义，暗示其用于深度人性/性格模拟，非字面色情，是用户搜索该类角色模型的关键词

### ByteDance-Seed/Tar-1.5B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Tar-1.5B

**关键词列表**:

- **视觉理解** (功能场景): 当前模型通过文本对齐表征统一视觉理解与生成，视觉理解是核心功能场景
- **视觉生成** (功能场景): 当前模型通过文本对齐表征统一视觉理解与生成，视觉生成是核心功能场景
- **文本对齐表征** (技术特性): 当前模型通过文本对齐表征统一视觉理解与生成，文本对齐表征是核心技术特性

### zai-org/GLM-4.5-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5-FP8

**关键词列表**:

- **GLM-4.5** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **直接响应模式** (技术特性): 模型提供的快速直接回答方式，与思考模式形成对比
- **3550B参数** (参数规格): 模型的主参数规模，区别于常见的7B/32B规格
- **1060B参数** (参数规格): 轻量版 GLM-4.5‑Air 的参数规模，提供更小模型选项

### city96/Wan2.1-T2V-14B-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/city96/Wan2.1-T2V-14B-gguf

**关键词列表**:

- **Wan2.1-T2V-14B** (当前模型品牌名): 从项目名称 city96/Wan2.1-T2V-14B-gguf 直接提取的当前模型唯一品牌名，符合简化规则（去后缀-gguf后仍保留核心标识）

### edbeeching/decision-transformer-gym-hopper-medium

**URL**: https://ai.gitcode.com/hf_mirrors/edbeeching/decision-transformer-gym-hopper-medium

**关键词列表**:

- **Decision-Transformer** (当前模型品牌名): 项目标题直接给出的模型名称
- **Gym-Hopper** (功能场景): 模型专为Gym Hopper连续控制环境训练，用户会搜具体环境
- **中等轨迹** (技术特性): 训练数据来自中等水平轨迹，是模型特色
- **连续控制** (功能场景): Hopper环境属于连续控制任务，用户搜索关键词
- **深度强化学习** (技术特性): Decision Transformer属于深度强化学习范畴

### jadechoghari/mar

**URL**: https://ai.gitcode.com/hf_mirrors/jadechoghari/mar

**关键词列表**:

- **MAR** (当前模型品牌名): 项目名称即为模型品牌名，直接提取
- **自回归图像生成** (功能场景): 模型的核心生成方式，用户搜索时会使用该描述
- **无矢量量化** (技术特性): 模型创新点之一，区别于传统 VQ‑based 方法
- **连续值扩散** (技术特性): 模型在连续值空间中进行扩散建模的关键技术
- **DiffusionPipeline** (部署工具): HuggingFace 提供的管线接口，用户可直接调用生成图像

### OpenGVLab/InternVideo2_5_Chat_8B

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVideo2_5_Chat_8B

**关键词列表**:

- **InternVideo2.5** (当前模型品牌名): 项目名称明确为OpenGVLab/InternVideo2_5_Chat_8B，模型正式名称为InternVideo2.5，符合品牌名提取规则且无版本号冗余
- **视频多模态大语言模型** (功能场景): 模型核心定位为视频多模态大语言模型（MLLM），是用户搜索视频理解类AI时的精准意图词，且未在高频排除词列表中
- **长丰富上下文** (技术特性): 模型核心创新点为LRC（Long Rich Context）建模能力，是区别于其他视频模型的独特技术标签，用户可能搜索‘长上下文视频模型’
- **自适应层级化token压缩** (技术特性): HiCo技术为模型独有，虽为技术术语，但‘自适应层级化token压缩’是其官方命名，具备高区分度，可吸引专业用户搜索技术实现
- **密集视觉任务标注** (技术特性): 模型通过TPO引入密集视觉标注，是区别于通用视频模型的关键训练方法，具备技术独特性

### ByteDance-Seed/Tar-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Tar-7B

**关键词列表**:

- **Tar-7B** (当前模型品牌名): 项目名称直接给出的当前模型简称，用户会搜
- **视觉理解生成统一** (功能场景): 模型核心卖点：把视觉理解与生成合二为一，用户搜“统一视觉模型”等词

### stanfordmimi/synthpose-vitpose-huge-hf

**URL**: https://ai.gitcode.com/hf_mirrors/stanfordmimi/synthpose-vitpose-huge-hf

**关键词列表**:

- **SynthPose** (当前模型品牌名): 从项目名称提取的当前模型名称
- **VitPose-Huge变体** (当前模型品牌名): 从项目描述中提取的当前模型变体名称
- **姿态估计** (功能场景): 当前模型的主要应用场景
- **生物力学分析** (功能场景): 当前模型在生物力学领域的应用场景
- **合成数据微调** (技术特性): 当前模型通过合成数据进行微调的技术特性
- **52个标记点预测** (功能场景): 当前模型可预测的标记点数量，体现其功能特性

### stanfordmimi/synthpose-vitpose-base-hf

**URL**: https://ai.gitcode.com/hf_mirrors/stanfordmimi/synthpose-vitpose-base-hf

**关键词列表**:

- **VitPose** (当前模型品牌名): 项目使用的骨干网络名称，用户会搜索
- **人体姿态估计** (功能场景): 模型核心任务，用户搜索意图明确
- **运动捕捉** (功能场景): README中强调针对运动捕捉系统微调
- **52关键点** (技术特性): 模型可预测52个关键点，用户会搜规格

### lerobot/pi0

**URL**: https://ai.gitcode.com/hf_mirrors/lerobot/pi0

**关键词列表**:

- **Pi0** (当前模型品牌名): 项目名称为lerobot/pi0，模型官方名称为Pi0，是当前模型的唯一品牌标识
- **视觉-语言-动作流模型** (技术特性): 论文中明确描述的核心架构，是Pi0区别于其他机器学习模型的独特技术定义
- **LeRobot** (当前模型品牌名): Pi0是LeRobot生态中的官方模型，LeRobot作为平台名称被用户用于搜索机器人控制模型
- **机器人控制** (功能场景): 模型核心用途是通用机器人控制，用户搜索机器人AI时会使用该明确场景词
- **视觉-语言-动作** (技术特性): 模型输入输出三模态结构的简明概括，是Pi0技术方案的关键词组合，非通用术语
- **AI机器人** (功能场景): 用户在CSDN等平台搜索机器人AI解决方案时常用该通俗组合词，指向明确应用场景

### PekingU/rtdetr_r101vd_coco_o365

**URL**: https://ai.gitcode.com/hf_mirrors/PekingU/rtdetr_r101vd_coco_o365

**关键词列表**:

- **RT-DETR** (当前模型品牌名): 模型卡片中直接使用的模型名称
- **Real-time-object-detection** (功能场景): 模型定位为实时目标检测任务，用户常以此场景搜索
- **Hybrid-encoder** (技术特性): 论文提出的高效混合编码器，用于提升多尺度特征处理速度
- **Uncertainty-minimization-query-selection** (技术特性): 为解码器提供高质量初始查询的核心机制，提升检测精度
- **Adjustable-decoder-layers** (技术特性): 支持在不重新训练的情况下灵活调节速度与精度
- **Objects365-pretraining** (技术特性): 在Objects365数据集上进行预训练，显著提升AP表现
- **Scale-aware-interaction** (技术特性): 解耦尺度内交互与跨尺度融合的设计，提高检测速度

### clefourrier/graphormer-base-pcqm4mv1

**URL**: https://ai.gitcode.com/hf_mirrors/clefourrier/graphormer-base-pcqm4mv1

**关键词列表**:

- **Graphormer** (当前模型品牌名): 从项目名称 clefourrier/graphormer-base-pcqm4mv1 中提取的核心模型品牌名，是该模型的唯一标识，用户搜索图神经网络模型时会直接使用此名称
- **图分类** (功能场景): 模型明确用于图分类任务，是用户在AI领域搜索图神经网络应用场景时的核心关键词，具有明确搜索意图
- **分子建模** (功能场景): README明确指出该模型最可能应用于分子建模，是化学AI与图学习交叉领域的高价值垂直场景词，区别于通用图任务
- **图Transformer** (技术特性): 模型本质是图结构上的Transformer架构，该术语是学术界和工业界对这类模型的通用技术标签，用户会用此词搜索相关模型
- **PCQM4M-LSC** (当前模型品牌名): 模型在PCQM4M-LSC数据集上预训练并夺冠，该名称是模型训练背景的核心标识，属于模型专属的权威数据集名称，具有高区分度
- **KDD-CUP-2021** (当前模型品牌名): 模型在KDD CUP 2021量子预测赛道获得第一名，该赛事名称是模型权威性的关键背书，用户搜索竞赛冠军模型时会使用此关键词

### Qwen/Qwen2.5-VL-32B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-32B-Instruct

**关键词列表**:

- **Qwen2.5-VL-32B-Instruct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **智能代理功能** (功能场景): 当前模型具备的智能代理能力
- **事件捕捉** (功能场景): 当前模型新增的事件捕捉能力
- **结构化输出生成** (功能场景): 当前模型支持内容结构化输出

### timm/vit_base_patch14_dinov2.lvd142m

**URL**: https://ai.gitcode.com/hf_mirrors/timm/vit_base_patch14_dinov2.lvd142m

**关键词列表**:

- **ViT-Base-Patch14** (当前模型品牌名): 从项目名称 vit_base_patch14_dinov2.lvd142m 提取的简洁模型品牌名
- **LVD-142M数据集** (技术特性): 模型在大规模 LVD-142M 数据集上进行预训练
- **timm库** (部署工具): 模型通过 timm 库创建并提供预训练权重，便于在 PyTorch 环境中使用
- **86.6M参数** (参数规格): 模型拥有约 86.6M 参数，属于中等规模的视觉 Transformer

### Helsinki-NLP/opus-mt-nl-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-nl-en

**关键词列表**:

- **opus-mt-nl-en** (当前模型品牌名): 从项目名称提取的当前模型名称
- **荷兰语翻译** (功能场景): 当前模型专用于荷兰语到英语的翻译任务
- **SentencePiece分词** (技术特性): 当前模型采用SentencePiece进行预处理分词
- **BLEU-60.9** (技术特性): Tatoeba测试集上取得的显著BLEU分数，体现翻译质量

### BAAI/bge-m3

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-m3

**关键词列表**:

- **BGE-M3** (当前模型品牌名): 项目名称为BAAI/bge-m3，直接提取模型品牌名，简洁且为用户搜索核心词
- **混合检索** (功能场景): BGE-M3核心功能是同时支持密集+稀疏检索的混合检索，是用户寻找多方法检索模型时的关键搜索词
- **长文档嵌入** (功能场景): 支持8192 token长文本，是用户寻找处理论文、报告等长内容嵌入模型时的高价值搜索词
- **稀疏检索** (技术特性): BGE-M3原生支持稀疏检索（类似BM25），区别于普通嵌入模型，是其独特技术卖点
- **多向量检索** (技术特性): BGE-M3独有的多向量表示能力，是区别于单向量模型的关键技术特征，用户搜高级检索技术时会用
- **重排序器** (功能场景): 模型推荐搭配bge-reranker做重排序，'重排序器'是RAG流程中高频搜索术语，且为BGE-M3推荐管道核心组件
- **嵌入模型** (技术特性): BGE-M3本质是嵌入模型，用户搜索'嵌入模型'时会寻找这类通用但高需求的模型类型，且非高频排除词

### facebook/mms-lid-256

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/mms-lid-256

**关键词列表**:

- **MMS-LID-256** (当前模型品牌名): 项目名称中直接给出的模型品牌名
- **语言识别** (功能场景): 模型的核心任务是对音频进行语言（语种）识别
- **1B参数** (参数规格): 检查点包含约 1 B（十亿）参数
- **256语言** (功能场景): 模型支持对 256 种语言进行识别
- **HuggingFace-Transformers** (部署工具): 模型可通过 HuggingFace Transformers 库进行加载和推理

### DAMO-NLP-SG/VideoLLaMA3-7B

**URL**: https://ai.gitcode.com/hf_mirrors/DAMO-NLP-SG/VideoLLaMA3-7B

**关键词列表**:

- **VideoLLaMA3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频语言模型** (技术特性): 模型定位与官方标签一致
- **序列视频数据洞察** (功能场景): README强调的独特卖点
- **动态视觉推理** (技术特性): README提到的高阶能力

### amazon/chronos-bolt-small

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-bolt-small

**关键词列表**:

- **直接多步预测** (技术特性): 当前模型采用直接多步预测方法

### nomic-ai/nomic-embed-text-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/nomic-ai/nomic-embed-text-v1.5

**关键词列表**:

- **nomic-embed-text-v1.5** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索嵌入模型时会使用此完整名称
- **feature-extraction** (技术特性): 模型核心功能是文本特征提取，属于技术关键词，用户在寻找文本向量化工具时会搜索此术语
- **transformers.js** (部署工具): 模型支持在浏览器端通过transformers.js运行，是前端AI开发者搜索轻量级JS嵌入模型时的关键词
- **English** (语言类型): 模型专为英文文本优化，用户在寻找英文语义嵌入模型时会明确搜索此语言标签，具有区分度

### facebook/mbart-large-50-many-to-many-mmt

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/mbart-large-50-many-to-many-mmt

**关键词列表**:

- **mBART** (当前模型品牌名): 项目名称中包含的模型品牌名称，直接对应 facebook/mbart-large-50-many-to-many-mmt
- **多语言机器翻译** (功能场景): 模型能够在 50 种语言之间进行翻译，核心应用场景是多语言机器翻译
- **跨语言翻译** (功能场景): 支持任意语言对的直接翻译，体现跨语言（many‑to‑many）能力
- **forced-BOS-token** (技术特性): 使用 forced_bos_token_id 参数强制目标语言 ID 为首个生成标记，是模型的关键技术特性
- **50语言支持** (功能场景): 模型覆盖 50 种语言，强调其广泛的语言覆盖范围
- **Rust支持** (技术特性): 模型的发布标签中包含 Rust，表明可以在 Rust 环境中使用
- **JAX兼容** (技术特性): 发布标签中包含 JAX，说明模型兼容 JAX 框架

### Qwen/Qwen2.5-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-7B-Instruct

**关键词列表**:

- **Qwen2.5-7B-Instruct** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **长文本生成** (功能场景): 支持8K令牌输出，用户会搜长文本生成
- **结构化输出** (功能场景): 擅长JSON等结构化输出，用户会搜结构化输出

### autogluon/tabpfn-mix-1.0-classifier

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/tabpfn-mix-1.0-classifier

**关键词列表**:

- **表格基础模型** (功能场景): 模型在README中明确自称为'表格基础模型'，是用户在搜索表格数据AI解决方案时的精准意图词，区别于通用大模型
- **Tabular-Classification** (功能场景): 标签中明确列出，是用户在AI领域搜索表格分类任务时的标准化术语，具有明确搜索意图且未被列入强制排除词
- **3700万参数** (参数规格): 模型参数规模为3700万，属于中等规模表格模型的典型参数量，用户会搜索此类规模的轻量级表格模型，且未在高频排除词列表中

### ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q4

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-DeepsexV2-7b-MGRPO-GGUF-Q4

**关键词列表**:

- **MGRPO算法** (技术特性): 模型采用的创新训练算法，是核心技术卖点
- **百万字上下文** (功能场景): 模型支持约100万字的长上下文能力，适用于超长文本交互
- **角色扮演体验** (功能场景): 模型专注于提供高质量的角色扮演对话场景
- **WebUI在线试用** (部署工具): 提供基于 WebUI 的在线交互界面，免安装直接体验
- **Demo-APK** (部署工具): 提供 Android 客户端 Demo，方便移动端快速体验模型

### lmms-lab/LLaVA-Video-7B-Qwen2

**URL**: https://ai.gitcode.com/hf_mirrors/lmms-lab/LLaVA-Video-7B-Qwen2

**关键词列表**:

- **LLaVA-Video-7B-Qwen2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **32K上下文窗口** (技术特性): 当前模型具有32K tokens的上下文窗口，是其技术特点之一
- **64帧视频处理** (技术特性): 当前模型最多支持处理64帧视频，是其技术能力体现
- **LLaVA-Video-178K数据集** (训练数据): 当前模型在LLaVA-Video-178K数据集上训练，是其训练数据来源
- **LLaVA-OneVision数据集** (训练数据): 当前模型也在LLaVA-OneVision数据集上训练，是其另一训练数据来源

### Prior-Labs/TabPFN-v2-reg

**URL**: https://ai.gitcode.com/hf_mirrors/Prior-Labs/TabPFN-v2-reg

**关键词列表**:

- **TabPFN** (当前模型品牌名): 从项目名称提取的当前模型名称
- **表格回归** (功能场景): README明确指出的核心用途
- **小数据预测** (功能场景): 用户搜索小样本表格任务时的常用词
- **无需训练** (技术特性): README强调无需任务特定训练即可推理
- **Nature论文** (技术特性): 顶级期刊背书，用户会搜模型+论文关键词
- **pip安装** (部署工具): README给出的极简安装方式，用户常搜

### naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric

**URL**: https://ai.gitcode.com/hf_mirrors/naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric

**关键词列表**:

- **MASt3R** (当前模型品牌名): 从项目名称 naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric 中提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词
- **图像到3D匹配** (功能场景): 模型核心用途为从图像实现三维几何匹配与定位，用户搜索‘图像到3D匹配’或‘3D图像定位’时会精准找到该模型，且非通用词
- **几何3D视觉** (技术特性): DUSt3R论文标题为‘Geometric 3D Vision Made Easy’，MASt3R继承其几何建模特性，‘几何3D视觉’是用户搜索三维重建类模型时的精准术语
- **3D重建** (功能场景): MASt3R用于从单图或多图恢复3D结构，是3D重建领域的主流应用场景，用户常搜索该词寻找相关模型，且未在高频排除词列表中
- **猫式MLP解码器** (技术特性): 模型名称中‘catmlp’指‘concatenated MLP’，中文语境下可译为‘猫式MLP’（音译+意译结合），是该模型独有的解码器结构，具有区分度

### unsloth/gemma-3-27b-it-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-27b-it-GGUF

**关键词列表**:

- **27B参数** (参数规格): 模型的参数规模为27B，用户常以参数大小检索模型
- **Unsloth微调** (部署工具): 提供基于 Unsloth 的免费微调 Notebook，适合用户快速微调模型
- **Ollama导出** (部署工具): 模型支持导出为 Ollama 可直接部署的格式，满足本地或云端部署需求
- **llama.cpp兼容** (部署工具): 模型可在 llama.cpp 环境中运行，提供轻量级本地推理方案
- **负责任AI工具包** (技术特性): 随模型提供的 Responsible Generative AI Toolkit，帮助用户安全使用模型
- **文本图像生成** (功能场景): Gemma 3 具备处理文本与图像输入并生成输出的能力，适用于文本‑图像混合任务

### BAAI/bge-large-en-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-large-en-v1.5

**关键词列表**:

- **BGE** (当前模型品牌名): 项目名称为BAAI/bge-large-en-v1.5，BGE是该系列模型的官方品牌名称，且为用户搜索嵌入模型时的核心关键词
- **sentence-similarity** (功能场景): README明确标注为sentence-similarity，是用户搜索语义相似度计算、文本匹配场景时的直接搜索词
- **BGE-Embedding** (当前模型品牌名): README中将BGE Embedding作为项目子名称使用，是用户区分BGE系列模型的常用搜索组合词
- **arxiv2312.15503** (技术特性): 该arXiv编号是BGE-large-en-v1.5的官方论文标识，研究者常直接搜索arXiv编号定位模型

### clefourrier/graphormer-base-pcqm4mv2

**URL**: https://ai.gitcode.com/hf_mirrors/clefourrier/graphormer-base-pcqm4mv2

**关键词列表**:

- **Graphormer-base-pcqm4mv2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图分类模型** (功能场景): 当前模型的主要应用场景是图分类任务
- **PCQM4M-LSCv2** (技术特性): 当前模型是基于PCQM4M-LSCv2预训练的

### tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa

**URL**: https://ai.gitcode.com/hf_mirrors/tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa

**关键词列表**:

- **LayoutLMv2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **OCR问答** (功能场景): 结合OCR与问答的细分场景
- **Adam优化器** (技术特性): 训练日志中明确列出的优化器，用户可能搜索

### monologg/koelectra-small-v2-distilled-korquad-384

**URL**: https://ai.gitcode.com/hf_mirrors/monologg/koelectra-small-v2-distilled-korquad-384

**关键词列表**:

- **KoELECTRA** (当前模型品牌名): 项目名称核心品牌，用户直接搜索KoELECTRA找韩国版ELECTRA
- **KorQuAD** (功能场景): 模型专为韩国问答数据集KorQuAD训练，用户搜KorQuAD即可定位该模型
- **蒸馏版** (技术特性): 项目名称带distilled，表明是轻量蒸馏模型，用户搜蒸馏版可快速找到小体积高精度方案
- **384长度** (技术特性): 模型后缀明确384，用户需要短文本高速推理时会直接搜384长度
- **韩语问答** (功能场景): 面向韩语问答任务，用户搜韩语问答即可发现该模型
- **LiteRT** (部署工具): 标签含LiteRT，表明支持移动端推理，用户搜LiteRT部署可找到该模型

### zai-org/SWE-Dev-32B

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/SWE-Dev-32B

**关键词列表**:

- **SWE-Dev-32B** (当前模型品牌名): 项目名称直接指向的当前模型全称，是用户搜索该特定模型时最可能使用的关键词
- **软件工程智能体** (功能场景): 模型核心定位是面向软件工程任务的AI智能体，属于明确、独特且用户可能搜索的功能场景词
- **SWE-bench** (功能场景): 模型性能评估基准，是开发者在搜索AI编程模型时会关联的专有评估体系，具有高度场景指向性
- **强化微调** (技术特性): 模型提升性能的关键技术手段（RFT），是区别于普通微调的特定训练方法，用户可能搜索相关优化技术
- **SWE-Dev-train** (当前模型品牌名): 项目中明确列出的配套训练数据集名称，作为模型生态的一部分，是开发者可能搜索的专属资源标识

### zai-org/GLM-Z1-9B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-Z1-9B-0414

**关键词列表**:

- **用户友好部署** (技术特性): README中提到该模型支持非常用户友好的本地部署功能
- **指令跟随** (功能场景): README中提到该模型在指令跟随方面进行了性能增强
- **工程代码** (功能场景): README中提到该模型在工程代码方面进行了性能增强

### openai/diffusers-cd_cat256_l2

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-cd_cat256_l2

**关键词列表**:

- **扩散模型蒸馏** (技术特性): 模型通过蒸馏扩散模型训练，是其核心技术路径，用户研究生成模型演进时会搜索此术语
- **U-Net** (技术特性): 模型明确使用U-Net作为参数化架构，是生成模型中高频但非泛滥的技术词，具区分度
- **零样本编辑** (技术特性): 模型支持无需训练的零样本图像编辑，是Consistency Models的核心创新点，搜索意图明确
- **FID指标** (技术特性): 论文中重点提及FID作为评估标准，专业用户搜索模型性能时会使用该术语，非泛滥词

### stepfun-ai/NextStep-1-Large-Pretrain

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large-Pretrain

**关键词列表**:

- **NextStep-1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **流匹配头** (技术特性): 当前模型独有的1.57亿参数流匹配头，是其独特架构
- **连续tokens** (技术特性): 模型支持连续图像tokens，区别于传统离散tokens
- **高保真图像合成** (功能场景): 模型在文本到图像任务中的突出表现
- **NextStepPipeline** (部署工具): 官方提供的推理管道，方便开发者调用

### internlm/internlm-xcomposer2d5-7b

**URL**: https://ai.gitcode.com/hf_mirrors/internlm/internlm-xcomposer2d5-7b

**关键词列表**:

- **InternLM-XComposer2.5** (当前模型品牌名): 项目名称中包含的模型全称，直接代表该模型的品牌标识
- **图文组合** (功能场景): 模型专注于图像与文本的组合与创作，是其核心应用场景
- **超长上下文** (技术特性): 模型通过 RoPE 外推支持最高 96K 长上下文，突出其超长序列处理能力
- **RoPE外推** (技术特性): 使用 RoPE（旋转位置编码）进行上下文长度外推，是模型的关键技术创新
- **图文交叉理解** (技术特性): 模型在 24K 交叉图文上下文上进行训练，具备深度图文交叉理解能力

### ByteDance-Seed/Seed-OSS-36B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Seed-OSS-36B-Base

**关键词列表**:

- **代理智能** (功能场景): README中'agent'能力直接对应中文用户搜索词'代理智能'，是当前模型独特卖点，非高频词
- **开发者友好** (功能场景): README明确提及'versatile developer-friendly features'，是开发者群体搜索模型时的精准意图词
- **36B参数** (参数规格): 模型名称含36B，属于主流参数规模（介于7B与671B之间），用户会搜索此规格模型，且未被排除列表禁用

### unsloth/gpt-oss-20b-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gpt-oss-20b-GGUF

**关键词列表**:

- **gpt-oss-20b** (当前模型品牌名): 从项目名称提取的当前模型名称
- **210亿参数** (参数规格): 当前模型的参数规模，属于参数规格

### Salesforce/blip-image-captioning-base

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip-image-captioning-base

**关键词列表**:

- **BLIP** (当前模型品牌名): 项目名称中包含的模型品牌名称
- **图像字幕** (功能场景): 模型的核心任务是为图像生成文字描述（image captioning）
- **自举式预训练** (技术特性): BLIP 采用的 bootstrapped（自举式）预训练方式，能够在噪声数据上生成并过滤 caption
- **ViTbase-骨干** (技术特性): 模型使用 Vision Transformer（ViT）base 作为视觉特征提取网络
- **COCO-预训练** (技术特性): 模型在 COCO 数据集上进行大规模图像‑文本预训练
- **跨模态检索** (功能场景): BLIP 在图像‑文本检索任务上取得显著提升，可用于跨模态搜索
- **零样本视频语言** (功能场景): 模型能够零样本迁移到视频‑语言任务，展示强大的泛化能力
- **VQA-提升** (功能场景): 在视觉问答（VQA）任务上，BLIP 提升了评估分数，体现多任务适用性

### Qwen/Qwen3-1.7B-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B-FP8

**关键词列表**:

- **Qwen3-1.7B-FP8** (当前模型品牌名): 项目名称直接定义的当前模型唯一标识，FP8量化版本具有明确区分度，符合用户搜索具体模型变体的意图
- **32K上下文** (参数规格): 32,768上下文长度属于主流长上下文规格，用户会搜索‘32K上下文’寻找长文本处理模型，且未被高频词列表排除
- **智能体工具对接** (功能场景): 模型支持在思维/非思维模式下与外部工具精准对接，是智能体任务中的关键能力，区别于普通对话模型
- **多语言指令理解** (功能场景): 支持100+语言的指令理解与翻译，是当前模型在多语言场景下的核心应用价值，用户会搜索该短语寻找多语言AI

### distilbert/distilbert-base-uncased

**URL**: https://ai.gitcode.com/hf_mirrors/distilbert/distilbert-base-uncased

**关键词列表**:

- **DistilBERT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **BERT蒸馏** (技术特性): 当前模型采用知识蒸馏技术，从BERT压缩而来
- **掩码语言建模** (功能场景): 当前模型支持MLM任务，用于文本补全
- **下一句预测** (功能场景): 当前模型支持NSP任务，用于句子关系判断
- **英文预训练** (功能场景): 当前模型专为英文语料预训练，适合英文NLP任务
- **轻量化BERT** (技术特性): 当前模型比BERT更小更快，适合资源受限场景

### inclusionAI/Ling-1T

**URL**: https://ai.gitcode.com/hf_mirrors/inclusionAI/Ling-1T

**关键词列表**:

- **Ling-1T** (当前模型品牌名): 从项目名称提取的当前模型名称
- **高效推理** (技术特性): 当前模型的核心技术特性，强调高效推理能力
- **进化思维链** (技术特性): 当前模型在中期训练与后期训练阶段采用的技术流程
- **视觉美学感知** (功能场景): 当前模型在视觉推理和前端代码生成任务上的独特能力
- **万亿参数** (参数规格): 当前模型的总参数量达到1万亿，具有显著区分度

### unsloth/gemma-3-270m-it-unsloth-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-unsloth-bnb-4bit

**关键词列表**:

- **4bit量化** (部署工具): 当前模型已做BNB 4bit量化，用户搜‘4bit量化’找现成模型
- **笔记本部署** (部署工具): README强调可在笔记本运行，用户搜‘笔记本部署’找低资源方案

### pyannote/segmentation

**URL**: https://ai.gitcode.com/hf_mirrors/pyannote/segmentation

**关键词列表**:

- **pyannotesegmentation** (当前模型品牌名): 项目名称直接对应模型唯一标识，用户搜索AI说话人分割模型时会直接使用此完整名称
- **说话人分割** (功能场景): 模型核心功能，中文用户搜索语音分析、音频处理时高频使用的精准术语
- **语音活动检测** (功能场景): 模型支持的核心任务，是音频处理领域独立搜索词，区别于通用语音识别
- **重叠语音检测** (功能场景): README明确提及'overlapped-speech-detection'，是说话人分割的关键应用场景，具技术独特性
- **pyannote.audio** (技术特性): 模型依赖的专用框架名称，用户在部署或二次开发时会搜索该工具链
- **speaker-segmentation** (技术特性): 英文技术术语，专业用户在GitHub、学术论文或英文技术博客中搜索该模型时的精准关键词

### Qwen/Qwen3-32B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B

**关键词列表**:

- **思考模式切换** (技术特性): 模型能够在同一实例内无缝切换思考模式与非思考模式，提升复杂推理和通用对话的表现
- **代理能力集成** (技术特性): 在思考和非思考模式下均支持与外部工具的精准集成，实现高级基于代理的任务
- **100语言支持** (功能场景): 模型覆盖百余种语言和方言，具备强大的多语言指令遵循和翻译能力
- **YaRN-超长上下文** (技术特性): 通过 YaRN 技术将上下文长度扩展至 131,072 tokens，适用于长文档处理
- **64层网络** (技术特性): 模型拥有 64 层深度，提供更丰富的特征表达能力
- **GQA-648-注意力头** (技术特性): 使用 Grouped Query Attention，查询头 64、KV 头 8，提升推理效率和质量

### stabilityai/stable-video-diffusion-img2vid-xt-1-1

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-video-diffusion-img2vid-xt-1-1

**关键词列表**:

- **Stable-Video-Diffusion** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Stability-AI** (当前模型品牌名): 模型所属公司品牌
- **社区许可** (技术特性): 模型独有的商业使用条款

### facebook/mask2former-swin-large-cityscapes-semantic

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/mask2former-swin-large-cityscapes-semantic

**关键词列表**:

- **Mask2Former** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Cityscapes语义分割** (功能场景): 当前模型基于Cityscapes语义分割数据集训练，是其应用场景
- **Swin主干网络** (技术特性): 当前模型采用Swin主干网络，是核心技术特性
- **多尺度可变形注意力** (技术特性): 当前模型用多尺度可变形注意力Transformer替代像素解码器，是关键技术特性
- **遮蔽注意力Transformer** (技术特性): 当前模型采用带有遮蔽注意力的Transformer解码器，是重要技术特性

### moonshotai/Kimi-VL-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Thinking

**关键词列表**:

- **Kimi-VL-A3B-Thinking** (当前模型品牌名): 模型完整名称是用户搜索高精度模型时可能使用的精确关键词，虽带后缀但为当前模型唯一标识，且未被高频词库排除
- **长思维** (技术特性): 模型名称中明确提及‘Thinking’，且README强调‘长思维变体’，是区别于普通VLM的核心技术标签，用户会搜索‘长思维模型’
- **MoonViT** (技术特性): 模型自研视觉编码器名称，是区别于其他VLM的独特技术组件，用户可能搜索‘MoonViT模型’以获取高清视觉理解能力
- **多图像理解** (功能场景): README明确列出‘多图像理解’为模型能力之一，是具体、非泛化的应用场景，区别于通用‘多模态’高频词
- **智能体交互** (功能场景): 模型在OSWorld等任务中表现突出，‘智能体交互’是用户搜索AI代理、自动化任务时的精准意图词，非泛泛的‘智能对话’

### notmahi/dobb-e

**URL**: https://ai.gitcode.com/hf_mirrors/notmahi/dobb-e

**关键词列表**:

- **DobbE** (当前模型品牌名): 项目名称即为模型的品牌名称
- **居家预训练模型** (功能场景): 模型专为家庭环境的预训练表征（HPR）设计，面向居家机器人视觉任务
- **HoNY数据集** (技术特性): 模型使用的专属纽约家居（HoNY）数据集，是其核心训练资源
- **ResNet34架构** (技术特性): 模型基于轻量级的 ResNet34 网络构建，体现其网络结构特点
- **timm框架** (部署工具): 模型可通过 timm 库一键加载，提供便捷的本地或 API 部署方式
- **机器人视觉** (功能场景): 模型面向机器人在家庭环境中的视觉感知任务，属于机器人视觉应用

### Qwen/Qwen2.5-Omni-7B-GPTQ-Int4

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B-GPTQ-Int4

**关键词列表**:

- **Qwen2.5-Omni** (当前模型品牌名): 从项目名称提取的当前模型名称
- **全模态** (技术特性): 当前模型支持文本、图像、音频、视频全模态感知与生成
- **GPTQ-Int4** (部署工具): 量化方案关键词，用户搜索低显存部署方案时常用
- **Thinker-Talker架构** (技术特性): 当前模型独有的端到端架构名称，具有区分度
- **实时音视频对话** (功能场景): 用户搜索可实时交互的音视频AI模型时的直接需求

### google/tapas-large-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-large-finetuned-wtq

**关键词列表**:

- **WTQ** (当前模型品牌名): 模型在WikiTable Questions (WTQ) 数据集上微调，WTQ是该模型的专属任务标签，具有高度区分性
- **链式微调** (技术特性): 模型采用在SQA→WikiSQL→WTQ上的链式微调策略，是其训练流程的独特技术术语，用户搜索模型训练方法时可能使用
- **TAPAS-large** (当前模型品牌名): 模型的具体版本名称，是用户在搜索大参数量TAPAS模型时的直接关键词，且未被高频词库排除
- **无重置版本** (技术特性): 模型提供'无重置'（绝对位置嵌入）的对比版本，该术语在文档中明确区分，是用户比较模型变体时的搜索词

### facebook/maskformer-swin-large-coco

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/maskformer-swin-large-coco

**关键词列表**:

- **MaskFormer** (当前模型品牌名): 从项目名称提取的当前模型名称
- **全景分割** (功能场景): 当前模型在COCO全景分割任务上训练，用户会搜此功能
- **实例分割** (功能场景): MaskFormer支持实例分割，用户搜索意图明确
- **语义分割** (功能场景): 当前检查点可直接用于语义分割任务
- **COCO数据集** (技术特性): 模型基于COCO全景分割数据集训练，用户会搜此关键词
- **MaskFormerImageProcessor** (部署工具): Hugging Face提供的专用处理器，用户部署时会搜索

### google/tapas-small-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/google/tapas-small-finetuned-wtq

**关键词列表**:

- **TAPAS小型** (当前模型品牌名): 模型名称中包含 TAPAS 且为 small 版本，提取为简洁品牌名
- **WikiTable-Questions** (功能场景): 模型在 WikiTable Questions (WTQ) 数据集上进行微调，用户常以该数据集名称搜索相关模型
- **WTQ微调** (技术特性): 模型在 WTQ 任务上进行的微调，是用户搜索时常用的关键词

### google/owlv2-large-patch14-ensemble

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlv2-large-patch14-ensemble

**关键词列表**:

- **Open-World-Localization** (功能场景): 当前模型的核心功能描述，用户可能搜索此类技术名称
- **zero-shot-object-detection** (功能场景): 当前模型的核心应用场景，用户可能搜索此类技术术语
- **CLIP多模态** (技术特性): 当前模型使用的多模态技术，用户可能搜索此类技术组合
- **ViT-like-Transformer** (技术特性): 当前模型使用的视觉特征提取技术，用户可能搜索此类技术细节

### facebook/dinov2-small

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-small

**关键词列表**:

- **DINOv2-small** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索时会使用该完整轻量版名称
- **ViT特征提取** (功能场景): 模型主要用途是作为ViT编码器提取图像特征，非分类模型，该组合词具明确搜索意图
- **CLS标记表征** (技术特性): 模型使用[CLS]标记输出图像语义向量，是其特征提取机制的关键技术点，具独特性
- **无监督视觉预训练** (技术特性): 模型训练方式的核心描述，区别于有监督模型，是用户研究自监督视觉学习时的高频精准词

### timm/mobilenetv3_small_100.lamb_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/mobilenetv3_small_100.lamb_in1k

**关键词列表**:

- **MobileNetV3-Small** (当前模型品牌名): 从项目名称 mobilenetv3_small_100.lamb_in1k 中提取的模型名称，去掉版本号和后缀
- **图像分类** (功能场景): 模型用于 ImageNet‑1k 上的图像分类任务，是其主要应用场景
- **LAMB优化器** (技术特性): 训练时采用的 LAMB 优化器，是模型的核心训练技术之一
- **EMA权重平均** (技术特性): 模型训练中使用的 EMA（指数移动平均）权重策略，提高了模型稳定性
- **RMSProp优化器** (技术特性): 模型实现中提供的 RMSProp 优化器选项，模拟 TensorFlow 1.0 行为
- **2.5M-参数** (参数规格): 模型总参数量约为 2.5 百万，是区分模型规模的重要指标
- **ImageNet-1k** (技术特性): 模型在 ImageNet‑1k 数据集上训练完成，标明了其数据来源和基准

### openbmb/MiniCPM-o-2_6

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-o-2_6

**关键词列表**:

- **MiniCPM-o** (当前模型品牌名): 项目名称为openbmb/MiniCPM-o-2_6，根据规则需简化为品牌名MiniCPM-o，且为当前模型唯一标识
- **实时语音对话** (功能场景): README明确提及'realtime speech conversation'，是用户搜索语音交互类AI模型时的精准意图词，非泛用'智能对话'
- **语音克隆** (功能场景): 标签中含'voice cloning'，属于模型专属能力，用户会主动搜索该术语寻找可模仿声音的AI工具
- **OCR** (功能场景): 模型支持文本识别，且在多模态模型中OCR是高价值细分场景，非通用'图像理解'，具有搜索区分度
- **ASR** (功能场景): 标签明确包含'asr'，指自动语音识别，是语音类模型的核心功能词，用户常搜索该缩写词寻找语音转文字工具
- **TTS** (功能场景): 标签含'tts'，指文本转语音，模型支持端到端语音生成，该缩写词是技术用户搜索语音合成模型的高频精准词
- **多图输入** (功能场景): 标签含'multi-image'，翻译为中文'多图输入'，指模型可同时处理多张图像，区别于单图输入模型，具独特搜索价值

### timm/resnet18.a1_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/resnet18.a1_in1k

**关键词列表**:

- **ResNet18.a1in1k** (当前模型品牌名): 从项目名称提取的当前模型名称
- **特征骨干网络** (功能场景): 当前模型在深度学习中的角色定位
- **ReLU激活函数** (技术特性): 当前模型使用的激活函数类型
- **BCE损失函数** (技术特性): 当前模型训练过程中使用的损失函数

### w11wo/indonesian-roberta-base-posp-tagger

**URL**: https://ai.gitcode.com/hf_mirrors/w11wo/indonesian-roberta-base-posp-tagger

**关键词列表**:

- **印尼RoBERTa** (当前模型品牌名): 项目名称中的indonesian-roberta-base，指向印尼语RoBERTa变体
- **印尼语NLP** (功能场景): 专为印尼语设计的NLP模型，满足印尼语处理需求
- **IndoNLU** (技术特性): 基于IndoNLU数据集微调，体现印尼语理解能力
- **96准确率** (技术特性): README给出0.9625的F1/准确率，突出高精度表现
- **Flax微调** (部署工具): 基于flax-community版本微调，支持Flax框架部署

### Xenova/slimsam-77-uniform

**URL**: https://ai.gitcode.com/hf_mirrors/Xenova/slimsam-77-uniform

**关键词列表**:

- **slimsam-77-uniform** (当前模型品牌名): 项目名称直接来源，是当前模型的唯一标识名称，用户搜索特定轻量级SAM模型时会使用此全称
- **掩码生成** (功能场景): 模型核心用途是图像掩码生成，属于用户明确搜索的AI图像分割任务关键词
- **轻量级SAM** (技术特性): 模型名称'slimsam'暗示其轻量化设计，'SAM'是Segment Anything Model的通用缩写，组合词精准描述模型定位
- **浏览器推理** (部署工具): 基于Transformers.js部署，意味着可在浏览器中直接运行，是区别于传统GPU部署的差异化使用场景

### deepseek-ai/DeepSeek-V3-0324

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3-0324

**关键词列表**:

- **高级推理** (技术特性): 模型在推理基准（MMLU‑Pro、GPQA 等）上显著提升，体现其强大的推理能力
- **前端网页开发** (功能场景): README 中提到改进了代码可执行性和更美观的网页/游戏前端，适用于前端开发场景
- **多轮交互改写** (功能场景): 模型增强了多轮交互式文本改写能力，适合对话式编辑与写作
- **中文写作优化** (功能场景): 提升了中文中长篇写作的风格与内容质量，面向中文写作需求
- **翻译质量提升** (功能场景): 模型在翻译任务上进行了优化，提供更高质量的机器翻译
- **代码执行增强** (技术特性): 改进了代码的可执行性，使模型在生成可运行代码时更可靠

### amazon/chronos-t5-base

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-t5-base

**关键词列表**:

- **Chronos-T5** (当前模型品牌名): 从项目名称直接提取的当前模型品牌名，是用户搜索该时间序列模型的核心关键词
- **时间序列基础模型** (技术特性): README明确提及'time series foundation models'，是该模型的定位关键词，具有区分度
- **自回归采样** (技术特性): 模型推理阶段的核心机制，原文明确描述，属于技术关键词且未在高频排除列表中
- **量化标记序列** (技术特性): Chronos独创的输入转换方式，将时间序列转为标记序列，是区别于其他模型的关键技术点
- **概率预测** (功能场景): 模型输出形式的核心特征，用户搜索‘AI概率预测’时可能匹配，非通用词且未被排除

### speechbrain/emotion-recognition-wav2vec2-IEMOCAP

**URL**: https://ai.gitcode.com/hf_mirrors/speechbrain/emotion-recognition-wav2vec2-IEMOCAP

**关键词列表**:

- **emotion-recognition-wav2vec2-IEMOCAP** (当前模型品牌名): 从项目名称提取的当前模型名称
- **情感识别** (功能场景): 当前模型的主要应用场景
- **IEMOCAP数据集** (技术特性): 当前模型训练所使用的数据集
- **注意力统计池化** (技术特性): 当前模型提取嵌入特征所采用的技术

### Wan-AI/Wan2.1-VACE-14B

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-VACE-14B

**关键词列表**:

- **Wan2.1** (当前模型品牌名): 项目名称直接给出的当前模型品牌名
- **视频编辑** (功能场景): 模型官方强调的多任务能力，用户会直搜
- **视觉文本生成** (技术特性): 官方亮点功能，中英文文字直接出现在视频中，差异化卖点

### dima806/fairface_age_image_detection

**URL**: https://ai.gitcode.com/hf_mirrors/dima806/fairface_age_image_detection

**关键词列表**:

- **FairFace-Age-Detection** (当前模型品牌名): 从项目仓库名称 fairface_age_image_detection 提取的模型品牌名称，直接指代该模型
- **年龄段图像分类** (功能场景): 模型的核心任务是对人脸图像进行年龄段分类，用户常以此关键词搜索相关模型
- **ViT** (技术特性): 使用 Vision Transformer（ViT）进行特征提取，是模型的关键技术特性
- **FairFace-数据集** (当前模型品牌名): 模型基于公开的 FairFace 数据集进行训练，用户常以数据集名称定位相应模型
- **Kaggle-Age-Classification-Notebook** (功能场景): README 中提供的 Kaggle Notebook 链接是模型使用示例，搜索该关键词可直接找到模型实现细节

### facebook/sam-vit-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam-vit-large

**关键词列表**:

- **SAM-ViT-Large** (当前模型品牌名): 从项目名称 'facebook/sam-vit-large' 直接提取的模型全称，是用户搜索该特定版本时的精准关键词
- **零样本分割** (技术特性): 论文强调模型具备‘零样本迁移到新图像分布和任务’的能力，是SAM区别于传统分割模型的核心卖点
- **可提示分割** (技术特性): 模型采用‘可提示式设计’，支持点、框等交互式输入，这是SAM提出的新范式，具有高度区分度
- **SA-1B数据集** (技术特性): 模型训练基于1100万图像+10亿掩码的SA-1B数据集，该数据集是SAM项目的核心资产，用户会搜索该专有名称
- **VisionEncoder** (技术特性): 模型三大模块之一，基于ViT架构，是技术文档中高频提及的组件，吸引关注架构细节的开发者
- **MaskDecoder** (技术特性): 模型核心组件，负责生成掩码，是理解SAM工作原理的关键模块，技术社区常以此为关键词检索

### Salesforce/blip-image-captioning-large

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip-image-captioning-large

**关键词列表**:

- **BLIP-image-captioning-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像描述生成** (功能场景): 当前模型的主要应用场景
- **自举标注技术** (技术特性): 当前模型使用的核心技术特性
- **视觉语言理解与生成** (功能场景): 当前模型的核心功能
- **ViT大型骨干网络** (技术特性): 当前模型采用的基础架构

### openbmb/MiniCPM4.1-8B

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM4.1-8B

**关键词列表**:

- **MiniCPM4.1** (当前模型品牌名): 项目名称中直接出现的模型品牌，用户搜索时会使用该名称
- **稀疏注意力** (技术特性): 模型采用可训练稀疏注意力机制，是其核心创新点，用户会以此技术特性搜索
- **思维链** (技术特性): MiniCPM4.1 支持融合思维链（Chain‑of‑Thought），是区别于其他模型的关键特性
- **GPTQ** (部署工具): 模型提供 GPTQ 量化格式，用户在寻找量化模型时会使用该关键词
- **AutoAWQ** (部署工具): 提供 AutoAWQ 量化格式，属于模型独有的部署/量化选项，用户会专门搜索
- **Eagle3** (技术特性): MiniCPM4.1‑8B‑Eagle3 为专用加速模型，具备独特的 Eagle3 技术，用户搜索时会使用该名称

### facebook/detr-resnet-101

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/detr-resnet-101

**关键词列表**:

- **DETR-resnet-101** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，是用户搜索该特定目标检测模型时最可能使用的关键词
- **匈牙利匹配** (技术特性): 实现二分匹配损失的核心算法，是DETR区别于其他检测模型的标志性技术点，搜索量稳定且专业
- **COCO目标检测** (功能场景): 模型训练和评估所用的权威数据集，用户搜索‘COCO目标检测模型’时会精准匹配该模型
- **DETR模型** (当前模型品牌名): 模型所属家族的通用名称，用户常以‘DETR模型’为关键词搜索该类架构，且不与高频词冲突

### LLM-Research/Molmo-7B-D-0924

**URL**: https://ai.gitcode.com/hf_mirrors/LLM-Research/Molmo-7B-D-0924

**关键词列表**:

- **Molmo** (当前模型品牌名): 从项目名称提取的当前模型名称
- **PixMo数据集** (技术特性): 当前模型独有的训练数据来源，用户会搜
- **开源多模态** (技术特性): 强调完全开源的多模态能力，区别于闭源方案
- **图像文本对训练** (技术特性): 描述训练方式，用户想了解数据来源

### Helsinki-NLP/opus-mt-en-fr

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-en-fr

**关键词列表**:

- **opus-mt-en-fr** (当前模型品牌名): 项目仓库名称即模型的官方标识
- **英法机器翻译** (功能场景): 模型专注于英文到法文的机器翻译任务
- **BLEU评分** (评估指标): 在公开测试集上使用 BLEU 进行翻译质量评估
- **chr-F指标** (评估指标): 模型报告的 chr‑F 分数用于衡量字符层面的翻译准确度
- **对齐翻译模型** (技术特性): 采用对齐（alignment）技术的 Transformer‑align 架构，实现源‑目标语言的高效对齐

### stabilityai/stable-video-diffusion-img2vid

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-video-diffusion-img2vid

**关键词列表**:

- **latent扩散模型** (技术特性): 模型采用latent扩散架构，是技术文档中明确描述的核心方法论，区别于普通扩散模型，具有专业搜索价值
- **时间一致性** (技术特性): 模型通过微调f8-decoder增强视频帧间时间一致性，是该模型在生成视频时的关键技术亮点，用户会为高质量视频生成搜索此术语
- **14帧视频** (参数规格): 模型固定生成14帧短视频，是明确的输出规格参数，用户在对比不同视频生成模型时会搜索帧数规格
- **576x1024分辨率** (参数规格): 模型输出视频具有明确的576x1024分辨率，是用户评估视频质量与适用场景时的重要量化指标，非通用描述
- **f8-decoder** (技术特性): 模型专门微调了f8-decoder以提升视频生成质量，是该模型独有的技术组件，具有区分度且未被高频词覆盖

### microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224

**关键词列表**:

- **BiomedCLIP** (当前模型品牌名): 从项目名称提取的当前模型名称
- **生物医学视觉语言** (功能场景): 当前模型的应用领域，体现其处理生物医学视觉语言任务的能力
- **PubMedBERT** (技术特性): 当前模型采用的文本编码器，是其技术特点之一

### Salesforce/blip2-opt-2.7b-coco

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip2-opt-2.7b-coco

**关键词列表**:

- **BLIP-2** (当前模型品牌名): 从项目名称 Salesforce/blip2-opt-2.7b-coco 中提取的核心模型品牌名，符合用户搜索AI模型时的习惯，简洁且唯一
- **Q-Former** (技术特性): BLIP-2独有的架构组件，用于桥接视觉与语言嵌入空间，是区别于其他视觉语言模型的关键技术名词，用户在深度研究时会搜索
- **冻结图像编码器** (技术特性): 模型训练的核心策略，区别于端到端训练的多模态模型，是技术型用户搜索高效训练方法时的关键词
- **OPT-2.7b** (参数规格): 当前模型使用的语言模型规模为2.7B参数，属于主流小规模LLM，符合‘参数规格’维度且未被高频词排除（排除的是7B/32B等）

### Helsinki-NLP/opus-mt-zh-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-zh-en

**关键词列表**:

- **opus-mt-zh-en** (当前模型品牌名): 项目名称中直接给出的模型标识，唯一对应本模型
- **中英翻译** (功能场景): 模型的核心任务是中文 → 英文的机器翻译
- **spm32k词表** (技术特性): 模型使用 32k 大小的 SentencePiece 词表进行编码
- **CC-BY-4.0许可证** (技术特性): 模型遵循 CC-BY-4.0 开源许可证，便于二次使用和再分发
- **文本到文本生成** (功能场景): 模型支持从输入文本生成目标语言文本，属于文本到文本的生成任务

### amazon/chronos-t5-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-t5-tiny

**关键词列表**:

- **T5-efficient-tiny** (技术特性): 基于T5-efficient-tiny架构，800万参数，用户会搜轻量版本
- **800万参数** (参数规格): 超小参数量，适合边缘部署，用户会按参数规模筛选模型
- **令牌量化** (技术特性): 将连续时间序列离散化为令牌，是Chronos独有的技术关键词

### ValueFX9507/Tifa-Deepsex-14b-CoT-Q8

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-Deepsex-14b-CoT-Q8

**关键词列表**:

- **Tifa-Deepsex** (当前模型品牌名): 从项目名称提取的当前模型品牌名
- **小说文本生成** (功能场景): 增量训练0.4T小说内容，面向小说创作需求

### stabilityai/stable-diffusion-2-1

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-diffusion-2-1

**关键词列表**:

- **stable-diffusion-2-1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本到图像生成** (功能场景): 当前模型的核心功能，根据文本提示生成和修改图像
- **潜在扩散模型** (技术特性): 当前模型使用的技术类型，具有独特性
- **OpenCLIP-ViTH** (技术特性): 当前模型使用的固定预训练文本编码器，具有技术独特性
- **CreativeML-Open-RAIL-M** (技术特性): 当前模型使用的许可证类型，具有区分度

### stabilityai/stable-diffusion-2-inpainting

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-diffusion-2-inpainting

**关键词列表**:

- **Stable-Diffusion-2-Inpainting** (当前模型品牌名): 从项目名称提取的完整模型名称，唯一标识该模型
- **文本引导编辑** (功能场景): 支持使用文本提示对已有图像进行局部编辑和修改
- **掩码生成策略** (技术特性): 采用 LAMA 提出的掩码生成策略，提升编辑质量
- **LAMA-掩码** (技术特性): 使用 LAMA 方法生成的掩码，与潜在 VAE 表示结合形成条件输入
- **潜在-VAE-条件** (技术特性): 将掩码图像的潜在 VAE 表示作为额外条件，提高生成一致性

### Wan-AI/Wan2.2-I2V-A14B

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.2-I2V-A14B

**关键词列表**:

- **图像生成视频** (功能场景): 模型专为Image-to-Video（I2V）设计，用户搜索时会使用‘图像生成视频’这一明确意图词，区别于通用‘文生图’
- **720P24fps** (功能场景): 模型明确支持720P分辨率24帧率视频生成，是用户在寻找高清视频生成模型时的核心搜索词，具高区分度
- **电影级美学** (技术特性): 模型通过精细标注数据实现电影级风格生成，是区别于其他模型的独特卖点，非泛泛形容词，具搜索价值
- **复杂运动生成** (技术特性): 模型在运动表现上显著升级，该术语直接来自原文，是用户寻找高质量动作视频生成时的精准搜索词
- **I2V-A14B** (当前模型品牌名): 项目名称中明确包含I2V-A14B，为Wan2.2系列下专用于图像到视频的子模型，是独立可搜索的型号名称
- **16164压缩比** (技术特性): 模型采用16×16×4压缩比的VAE架构，是技术文档中明确提及的、区别于其他模型的结构特征，用户搜索视频压缩效率时可能使用

### LiquidAI/LFM2-350M-ENJP-MT

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-ENJP-MT

**关键词列表**:

- **日英翻译** (功能场景): 模型主打日语英语双向实时翻译
- **边缘翻译** (功能场景): 近实时、小体量，适合端侧与边缘部署场景
- **Liquid** (当前模型品牌名): 项目命名空间中的品牌关键词
- **实时翻译** (功能场景): 强调低延迟的在线翻译体验，用户高频搜索词

### openai/whisper-base.en

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-base.en

**关键词列表**:

- **Whisper** (当前模型品牌名): 模型官方名称，直接来源于项目名称
- **弱监督训练** (技术特性): 模型使用大规模弱监督标注的 68 万小时语音数据进行训练
- **74M参数** (参数规格): 该 base 版本模型的参数量约为 74 百万
- **序列到序列模型** (技术特性): 采用 Transformer 编码器‑解码器的 seq2seq 结构实现语音‑文本映射

### nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0

**关键词列表**:

- **Frame-VAD** (当前模型品牌名): 从项目名称 'Frame_VAD_Multilingual_MarbleNet_v2.0' 中提取的核心品牌名，简化为用户易搜索的 'Frame-VAD'，是模型的唯一标识
- **多语言VAD** (功能场景): 模型支持中、英、法、德、俄、西六种语言，'多语言VAD'是区别于单语言VAD模型的关键搜索词，用户会用此组合词筛选多语言支持的模型
- **MarbleNet** (当前模型品牌名): 模型架构名称，是论文和项目中明确提出的专有名称，用户在查阅VAD技术文献时会搜索此术语
- **实时VAD** (功能场景): README明确指出模型适用于实时场景，'实时VAD'是开发者在构建语音交互系统时的核心搜索词，区别于离线处理模型
- **误检鲁棒** (技术特性): 模型通过噪声训练显著降低误检，'误检鲁棒'是语音处理工程师在评估VAD模型时的专业搜索词，具有技术区分度
- **NeMo** (部署工具): 模型集成于NVIDIA NeMo框架，是开发者在NVIDIA生态中搜索语音模型时的关键工具词，具有平台指向性

### Qwen/Qwen2.5-Omni-7B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-7B

**关键词列表**:

- **TMRoPE位置编码** (技术特性): 当前模型创新的时间对齐多模态RoPE技术

### stepfun-ai/Step-Audio-AQAA

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/Step-Audio-AQAA

**关键词列表**:

- **Step-Audio-AQAA** (当前模型品牌名): 从项目名称提取的当前模型名称
- **全端到端音频交互** (技术特性): 当前模型的核心技术特性，直接处理音频输入并生成语音响应
- **细粒度音色控制** (技术特性): 当前模型支持句子级的情感语调、语速等声音特征调整
- **多语言与方言支持** (功能场景): 当前模型的应用场景，涵盖中文（含四川话、粤语）、英语、日语等
- **复杂任务处理** (功能场景): 当前模型擅长语音情感控制、角色扮演、逻辑推理等复杂音频交互
- **双码本音频分词器** (技术特性): 当前模型架构中的核心模块之一，包含语言分词器和语义分词器
- **1300亿参数** (参数规格): 当前模型的参数量级，体现模型规模

### zai-org/glm-edge-v-5b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-edge-v-5b

**关键词列表**:

- **GLM-Edge-V-5B** (当前模型品牌名): 从项目名称直接提取的当前模型全称，符合品牌名提取规则，且未被高频词列表排除
- **图像描述** (功能场景): 模型支持'image-to-text'任务，用户会搜索'图像描述'这类明确的多模态应用需求，区别于泛用的'文生图'等高频词
- **轻量级多模态** (技术特性): 模型为5B参数规模，强调轻量级部署能力，且支持图像+文本输入，'轻量级多模态'是其核心差异化技术标签，未在高频词列表中
- **本地推理** (部署工具): 代码示例明确使用transformers本地加载模型，强调无需API的本地运行，区别于'本地部署'高频词，'本地推理'更精准描述用户搜索意图
- **bfloat16推理** (技术特性): 模型明确使用torch.bfloat16进行推理，这是其性能与显存优化的关键技术点，用户会搜索该精度类型以匹配硬件环境，非通用词
- **ChatTemplate输入** (技术特性): 代码使用apply_chat_template处理多轮对话结构，表明模型支持结构化对话输入，是区别于普通文本模型的特征，用户会搜索该术语

### mlx-community/gemma-3-12b-it-qat-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/mlx-community/gemma-3-12b-it-qat-4bit

**关键词列表**:

- **12B参数** (参数规格): 模型规模为 12 B 参数，用户常以参数大小搜索模型
- **QAT量化** (技术特性): 使用 Quantization‑Aware Training（QAT）进行量化，区别于普通后置量化
- **图文对话** (功能场景): 模型支持图像‑文本‑到‑文本的多模态对话任务

### zai-org/glm-4-9b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b

**关键词列表**:

- **GLM-4V-9B** (当前模型品牌名): 当前模型的多模态版本，用户会搜索完整型号

### zai-org/glm-edge-v-2b

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-edge-v-2b

**关键词列表**:

- **GLM-Edge-V-2B** (当前模型品牌名): 从项目名称直接提取的当前模型全称，符合简洁品牌名规范（虽含版本号，但'GLM-Edge'是品牌子系列，2B是核心区分参数，且未被高频词列表排除）
- **ChatML模板** (技术特性): 代码中使用'apply_chat_template'，表明采用ChatML格式对话结构，是GLM系列特有部署特征，用户搜索'ChatML模型'有明确意图

### openai/diffusers-ct_cat256

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-ct_cat256

**关键词列表**:

- **diffusers-ctcat256** (当前模型品牌名): 从项目名称提取的当前模型名称
- **一致性模型** (技术特性): 当前模型的核心技术特性，论文中提出的新型模型家族
- **零样本数据编辑** (功能场景): 当前模型支持零样本数据编辑，如图像修复、上色和超分辨率，是应用场景之一
- **独立训练** (技术特性): 当前模型可以作为独立的生成模型进行训练，是区别于其他蒸馏模型的特点

### unsloth/gemma-3-270m-it-torchao-fp8

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-torchao-fp8

**关键词列表**:

- **指令调优** (功能场景): Gemma‑3 提供指令调优变体，适用于指令式对话与任务完成
- **Google-Colab微调** (部署工具): 官方提供免费 Google Colab 笔记本用于微调 Gemma‑3，用户常以此关键词搜索
- **开放权重** (技术特性): 模型以开放权重形式发布，便于二次开发和自定义部署

### ByteDance-Seed/Seed-OSS-36B-Base-woSyn

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/Seed-OSS-36B-Base-woSyn

**关键词列表**:

- **原生长上下文** (技术特性): 模型原生支持512K长上下文，是其核心差异化技术特性，用户可能搜索'长上下文模型'等意图
- **思考预算控制** (技术特性): 模型独有'灵活控制思考预算'功能，属于用户搜索推理效率优化时可能使用的精准术语
- **智能体智能** (功能场景): 模型在工具使用和问题解决等智能体任务中表现卓越，'智能体智能'是其明确的功能场景标签
- **无合成数据** (技术特性): 模型版本明确标注'woSyn'（无合成数据），为研究社区提供独特数据纯净性选项，具高区分度
- **Seed-OSS** (当前模型品牌名): 项目名称核心标识为Seed-OSS，是模型系列官方品牌名，用户可能直接搜索该术语

### Kwaipilot/SRPO-Qwen-32B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/SRPO-Qwen-32B

**关键词列表**:

- **SRPO** (当前模型品牌名): 项目名称中的核心算法品牌，用户会直接用SRPO搜索
- **历史重采样** (技术特性): SRPO独有的HR机制，解决低效样本问题，技术亮点
- **双阶段训练** (技术特性): SRPO专为数学+代码设计的训练范式，差异化关键词
- **GRPO框架** (技术特性): SRPO基于分组相对策略优化，技术爱好者检索词

### unsloth/grok-2

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/grok-2

**关键词列表**:

- **Grok-2** (当前模型品牌名): 项目名称为unsloth/grok-2，直接提取模型品牌名，符合用户搜索AI模型时的命名习惯
- **sglang** (部署工具): README明确指出模型用于SGLang原生支持，是用户部署Grok-2时的关键工具，具有独特性且未被高频词列表排除
- **tiktoken** (技术特性): 模型原生使用tiktoken格式，而本项目提供Hugging Face兼容版，这是其核心技术差异点，用户会搜索‘tiktoken模型转换’等关键词
- **Hugging-Face兼容tokenizer** (技术特性): 项目核心价值是提供HF兼容的tokenizer，解决官方缺失问题，是用户搜索‘Grok-2 tokenizer怎么用’时的精准意图词
- **xai-orggrok-2** (当前模型品牌名): 虽然来自xai-org，但这是Grok-2的官方源头名称，用户在搜索模型来源时会直接使用该完整路径，且未被高频词列表排除

### unsloth/gemma-3-270m-it-qat

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-qat

**关键词列表**:

- **量化感知训练** (技术特性): 当前模型采用QAT技术，用户会搜QAT或量化感知训练
- **指令微调** (技术特性): 当前模型为指令微调版本，用户会搜指令微调模型

### stepfun-ai/NextStep-1-Large

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large

**关键词列表**:

- **连续令牌自回归** (技术特性): 模型采用连续令牌的自回归预测方式进行图像生成

### zai-org/GLM-4-9B-0414

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4-9B-0414

**关键词列表**:

- **GLM-Z1** (当前模型品牌名): 从项目README中提取的另一款当前模型名称
- **报告生成** (功能场景): 当前模型在报告生成任务中表现优异

### lerobot/vqbet_pusht

**URL**: https://ai.gitcode.com/hf_mirrors/lerobot/vqbet_pusht

**关键词列表**:

- **VQ-BeT** (当前模型品牌名): 从项目名称 lerobot/vqbet_pusht 中提取的核心模型名称，是论文《Behavior Generation with Latent Actions》提出的原创模型，具有唯一性
- **PushT** (功能场景): 模型专为 gym-pusht 环境中的 PushT 机器人推物任务训练，是其唯一应用场景，用户搜索机器人控制任务时会使用此环境名
- **latent-actions** (技术特性): 模型基于论文核心概念 'Latent Actions'（隐式动作）进行行为生成，是区别于其他机器人策略模型的关键技术点
- **VQ-BeT-policy** (当前模型品牌名): 项目标签中明确出现 'vqbet-policy'，是模型在LeRobot生态中的具体策略类型名称，具有技术辨识度
- **robotic-manipulation** (功能场景): PushT环境属于机器人操作（robotic manipulation）任务，是机器人领域高频搜索场景，且未被列入强制排除词
- **behavior-generation** (技术特性): 论文标题与模型核心目标为 'Behavior Generation'，是区别于传统强化学习或模仿学习的范式关键词

### lzkhhh/ITDR-LLaMA3.2-3B

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-LLaMA3.2-3B

**关键词列表**:

- **ITDR-LLaMA3.2-3B** (当前模型品牌名): 完整的模型名称，直接来源于项目名
- **推荐系统微调** (功能场景): 模型专注于提升推荐领域大语言模型的性能，属于推荐系统的微调任务
- **用户-物品交互** (功能场景): 数据集涵盖用户与物品的交互信息，是推荐任务的关键要素
- **20万实例** (数据规模): 数据集规模约20万条实例，用户常以实例数量评估数据集价值
- **7子任务** (任务细分): ITDR 数据集在两大核心任务下细分为7个子任务，体现任务丰富性

### lerobot/diffusion_pusht

**URL**: https://ai.gitcode.com/hf_mirrors/lerobot/diffusion_pusht

**关键词列表**:

- **Diffusion-Policy** (当前模型品牌名): 项目核心模型名称，直接对应论文与代码
- **PushT环境** (功能场景): 模型专为gym-pusht机器人推箱子任务训练
- **动作扩散策略** (技术特性): 论文提出的Visuomotor策略学习方法
- **LeRobot训练** (部署工具): 使用LeRobot框架一键训练与评估
- **175k步检查点** (参数规格): 提供已训练175k步的现成权重

### unsloth/NVIDIA-Nemotron-Nano-9B-v2-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/NVIDIA-Nemotron-Nano-9B-v2-GGUF

**关键词列表**:

- **NVIDIA-Nemotron-Nano-9B-v2** (当前模型品牌名): 从项目名称直接提取的完整模型名称，是用户搜索该特定模型时的精准关键词
- **Nemotron** (当前模型品牌名): NVIDIA官方模型系列名，简洁品牌标识，用户可能搜索‘Nemotron’而非完整名称
- **混合架构** (技术特性): 模型采用Mamba-2 + MLP + 仅4个Attention层的混合架构，是其核心独特设计，非通用术语
- **推理轨迹** (技术特性): 模型通过先生成推理轨迹再输出答案的机制，是其区别于普通LLM的核心功能特性
- **Unsloth-Dynamic-2.0** (技术特性): 模型使用Unsloth Dynamic 2.0量化技术实现精度提升，是项目独有的优化技术名称
- **6语言支持** (功能场景): 明确支持英语、德语、西班牙语、法语、意大利语、日语6种语言，是用户筛选多语言模型的明确指标
- **NVIDIA开放模型许可** (部署工具): 模型明确标注使用NVIDIA开放模型许可，是企业用户关注的合规部署关键词，具法律区分度

### lzkhhh/ITDR-GLM-4-9B

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-GLM-4-9B

**关键词列表**:

- **ITDR-GLM-4-9B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **指令微调数据集** (技术特性): 当前模型构建所依赖的核心技术特性
- **用户-物品理解** (功能场景): 当前模型数据集涵盖的另一核心根任务
- **推荐系统增强** (功能场景): 当前模型的主要应用场景和功能

### Lykon/dreamshaper-7

**URL**: https://ai.gitcode.com/hf_mirrors/Lykon/dreamshaper-7

**关键词列表**:

- **DreamShaper-7** (当前模型品牌名): 项目名称为 lykon/dreamshaper-7，模型品牌名为 DreamShaper-7，是当前模型的唯一标识名称，简洁且用户搜索模型时直接使用
- **stable-diffusion** (技术特性): 模型基于 Stable Diffusion 架构，是用户搜索文生图模型时的核心技术标签，且未被列为高频排除词（排除词中无此词）
- **artistic** (功能场景): README 明确标注为 artistic，代表该模型擅长生成艺术风格图像，是用户寻找风格化AI绘图模型时的明确搜索意图词
- **anime** (功能场景): README 标签中包含 anime，表明该模型在动漫风格生成上有优化，是区别于通用SD模型的特色场景，用户会针对性搜索
- **dreamshaper** (当前模型品牌名): 模型名称的核心词，用户常简化搜索为 'dreamshaper'，是品牌名的通用简称，具有高搜索辨识度且未被排除
- **text-to-image** (功能场景): README 明确使用该术语，是AI图像生成领域的标准搜索关键词，未被高频排除词列表包含，且精准描述模型核心功能
- **stable-diffusion-diffusers** (部署工具): 标签中独立出现，表明该模型专为 Hugging Face Diffusers 框架优化，是技术用户搜索部署方案时的精准关键词

### jonatasgrosman/wav2vec2-large-xlsr-53-portuguese

**URL**: https://ai.gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-portuguese

**关键词列表**:

- **wav2vec2-large-xlsr-53-portuguese** (当前模型品牌名): 项目名称直接给出的当前模型唯一标识
- **葡萄牙语语音识别** (功能场景): 模型专为葡萄牙语语音转文字场景微调
- **Common-Voice微调** (技术特性): 基于Mozilla Common Voice 6.1数据微调，用户搜此关键词找同款
- **16kHz采样率** (技术特性): 模型强制要求16kHz音频输入，用户需按此规格准备数据
- **wav2vec2-sprint** (部署工具): 作者开源的训练与推理脚本仓库，用户搜此关键词可复现微调

### genmo/mochi-1-preview

**URL**: https://ai.gitcode.com/hf_mirrors/genmo/mochi-1-preview

**关键词列表**:

- **Mochi-1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频生成模型** (功能场景): 当前模型的主要功能是生成视频
- **高保真度动态效果** (技术特性): 当前模型在初步评估中展现出高保真度的动态效果
- **文本提示遵循能力** (技术特性): 当前模型具有出色的文本提示遵循能力

### facebook/nllb-200-distilled-600M

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/nllb-200-distilled-600M

**关键词列表**:

- **NLLB-200** (当前模型品牌名): 从项目名称提取的当前模型名称
- **低资源语言** (功能场景): 模型专为低资源语言研究设计
- **600M参数** (参数规格): 当前蒸馏版模型的具体参数规模
- **200种语言** (功能场景): 模型支持的语言数量，用户搜索时会关注
- **BLEU评估** (技术特性): 模型性能评估指标，用户搜索时会关注

### ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4

**URL**: https://ai.gitcode.com/hf_mirrors/ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4

**关键词列表**:

- **Tifa-Deepsex-14b-CoT** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，是用户搜索该特定模型的精准关键词
- **增量预训练** (技术特性): 模型使用‘增量预训练0.4T小说内容’，是其训练策略的独特技术点，非通用术语
- **DPO强化学习** (技术特性): 模型使用DPO（Direct Preference Optimization）作为核心训练方法，区别于普通RLHF，具有技术辨识度

### MoritzLaurer/mDeBERTa-v3-base-mnli-xnli

**URL**: https://ai.gitcode.com/hf_mirrors/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli

**关键词列表**:

- **mDeBERTa** (当前模型品牌名): 模型名称的核心品牌标识，直接来源于项目名称
- **零样本分类** (功能场景): 模型支持 zero‑shot classification，可用于无需标注数据的分类任务
- **多语言自然语言推理** (功能场景): 模型能够在 100 种语言上执行 NLI（自然语言推理），是其核心应用
- **XNLI微调** (技术特性): 在跨语言 NLI 数据集 XNLI 上进行微调，提升多语言推理能力

### myshell-ai/MeloTTS-French

**URL**: https://ai.gitcode.com/hf_mirrors/myshell-ai/MeloTTS-French

**关键词列表**:

- **MeloTTS-French** (当前模型品牌名): 从项目名称提取的当前模型名称，且特指法语版本
- **多语言文本转语音** (功能场景): 当前模型的主要功能，支持多种语言文本转语音
- **CPU实时推理** (技术特性): 当前模型的技术特性，足以实现CPU实时推理
- **中英文混合发音** (功能场景): 当前模型支持中文发音人中英文混合，是其独特功能
- **高质量语音** (技术特性): 当前模型提供高质量的语音输出，是其重要特性

### baidu/ERNIE-4.5-0.3B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-PT

**关键词列表**:

- **0.3B参数** (参数规格): 0.3B是轻量级主流规模，用户会搜索小参数模型用于边缘部署，符合规则且非高频
- **FP8混合精度** (技术特性): 模型训练中使用的独特精度策略，非通用词，具技术辨识度
- **卷积码量化** (技术特性): 模型推理中使用的专有量化算法，区别于常规4位/2位量化，具独特性

### lzkhhh/ITDR-Qwen2.5-7B

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-Qwen2.5-7B

**关键词列表**:

- **ITDR** (当前模型品牌名): 项目名称中的唯一品牌标识，用户搜索时会直接使用该名称定位模型
- **推荐指令微调** (功能场景): 模型专注于通过指令微调提升推荐系统性能，是用户搜索的核心应用场景
- **用户物品交互** (功能场景): 数据集涵盖用户‑物品交互任务，用户常以此关键词查找针对推荐的LLM解决方案
- **20万实例数据集** (技术特性): 大规模（约20万条）指令微调实例是模型的显著优势，具备高区分度
- **13公开推荐数据源** (技术特性): 整合了13个公开推荐数据集，体现数据覆盖广度，用户会关注此类数据来源描述
- **七子任务结构** (技术特性): 数据集设计为7个子任务，覆盖用户‑物品理解与交互两大核心任务，具备独特的任务划分

### baidu/ERNIE-4.5-21B-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Thinking

**关键词列表**:

- **21B参数** (参数规格): 当前模型总参数量210亿，用户会搜21B参数
- **3B激活** (参数规格): 每个token仅激活30亿参数，用户关注轻量推理
- **128K长上下文** (技术特性): 支持131072 token超长上下文，用户会搜128K
- **FastDeploy** (部署工具): 官方推荐用FastDeploy 2.2快速上线服务

### Qwen/Qwen3-8B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-8B-MLX-8bit

**关键词列表**:

- **Qwen3-8B-MLX-8bit** (当前模型品牌名): 项目名称直接定义的当前模型全称，是用户精准搜索该特定版本的唯一标识
- **多语言指令遵循** (功能场景): 明确强调支持100+语言的指令遵循能力，区别于一般‘多语言’描述，聚焦用户搜索‘多语言AI模型’的精准意图

### baidu/ERNIE-4.5-21B-A3B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Base-PT

**关键词列表**:

- **ERNIE-4.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **异构混合并行** (技术特性): 当前模型在训练时采用的高效扩展基础设施技术
- **PD解耦技术** (技术特性): 当前模型在推理时采用的资源利用优化技术

### Helsinki-NLP/opus-mt-en-de

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-en-de

**关键词列表**:

- **opus-mt-en-de** (当前模型品牌名): 项目唯一标识，用户直接搜模型名
- **英德翻译** (功能场景): 模型核心用途，用户高频搜索意图
- **BLEU-26.9** (技术特性): 亮眼指标，用户对比模型性能时常用

### baidu/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle

**关键词列表**:

- **MoE-300B** (参数规格): 300B是当前模型的显性参数规模，属于主流大模型规格（百亿级），且'MoE-300B'组合具有技术区分度，未被高频词覆盖
- **多模态预训练** (技术特性): 模型核心训练方式，原文强调'Multimodal Heterogeneous MoE Pre-Training'，是功能级关键词，非泛泛的'多模态'，具有搜索价值
- **PaddlePaddle** (部署工具): 模型明确使用PaddlePaddle权重（非PyTorch），是用户部署时的关键技术选型词，且未在排除列表中
- **W4A8C8量化** (技术特性): W4A8C8是模型的量化配置（4位权重、8位激活、8位累积），属于模型特有的高效推理标识，非通用术语，具有技术辨识度

### Qwen/Qwen3-4B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-4B-MLX-4bit

**关键词列表**:

- **MLX框架** (部署工具): 模型兼容最新的 MLX 框架（≥ 0.25.2），可直接在 MLX 环境中运行
- **YaRN扩展** (技术特性): 通过 YaRN 技术将原生 32,768 token 上下文扩展至 131,072 token
- **多语言指令** (功能场景): 模型支持 100+ 语言与方言的指令遵循与翻译，适用于多语言任务

### Qwen/Qwen3-14B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-6bit

**关键词列表**:

- **智能体集成** (功能场景): 具备与外部工具精准集成的专业智能体能力
- **131K长上下文** (技术特性): 通过YaRN扩展支持131,072 token超长上下文
- **6bit量化** (部署工具): 当前模型提供6bit低比特量化版本，适合本地部署

### Qwen/Qwen3-32B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-8bit

**关键词列表**:

- **Qwen3-32B-MLX-8bit** (当前模型品牌名): 项目名称直接定义的当前模型全称，是用户搜索该特定版本的唯一标识符，符合模型名称提取规则且未被高频词排除

### Qwen/Qwen3-235B-A22B-Instruct-2507

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Instruct-2507

**关键词列表**:

- **非思考模式** (技术特性): 模型仅支持非思考模式，是该模型独有的运行方式，用户会据此搜索
- **256K长文本理解** (技术特性): 模型支持256K级别的长文本理解，属于独特的能力点，易被用户作为搜索词
- **2350B参数** (参数规格): 模型总参数量约2350亿（2350B），是区分不同大模型规模的重要搜索词
- **多语言长尾覆盖** (功能场景): 模型对多语言长尾知识的覆盖率提升，是用户关注的语言能力特性
- **原生262K上下文** (技术特性): 模型原生支持262,144 token 上下文长度，属于显著的上下文能力特征

### baidu/ERNIE-4.5-300B-A47B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-Base-Paddle

**关键词列表**:

- **ERNIE-4.5-300B-A47B-Base** (当前模型品牌名): 从项目名称直接提取的完整模型标识，是用户搜索该特定Paddle版本模型的精准关键词
- **A47B** (当前模型品牌名): 模型名称中的核心架构代号，代表MoE结构的特定变体，是技术社区中用于区分ERNIE 4.5子系列的唯一标识
- **文本补全** (功能场景): README明确指出Base模型仅支持文本补全（text completion），且强调需使用completion API，这是其核心功能定位
- **多模态异构MoE预训练** (技术特性): 模型核心技术创新点，原文唯一描述的技术术语，具有高度区分度，非通用词，用户搜索技术细节时可能使用
- **ERNIE4.5** (当前模型品牌名): 模型主版本名，用户在搜索ERNIE系列时可能使用简化版名称，且未被列入强制排除词库

### baidu/ERNIE-4.5-VL-424B-A47B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-Base-PT

**关键词列表**:

- **异构MoE结构** (技术特性): 当前模型采用的关键架构设计，区别于其他MoE模型
- **FP8混合精度训练** (技术特性): 当前模型在训练阶段采用的高效计算技术
- **4比特无损量化** (技术特性): 当前模型在推理阶段实现的量化技术，提升部署效率

### Qwen/Qwen3-30B-A3B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-6bit

**关键词列表**:

- **Qwen3-30B** (当前模型品牌名): 项目名称中包含的模型品牌，直接标识该模型
- **复杂逻辑推理** (功能场景): 在复杂逻辑推理任务中表现突出，是用户常搜索的应用场景
- **30B参数** (参数规格): 模型总参数约 30.5B，属于大规模语言模型

### Qwen/Qwen3-14B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-MLX-8bit

**关键词列表**:

- **Qwen3-14B-MLX-8bit** (当前模型品牌名): 项目名称直接定义的当前模型全称，是用户在GitCode等平台搜索该特定版本时的精准关键词
- **8bit量化** (技术特性): 模型采用8bit量化，是低资源设备运行大模型的关键技术标签，用户常搜索'8bit量化模型'以适配消费级设备
- **GQA注意力** (技术特性): 模型使用分组查询注意力（GQA），是提升推理效率的架构创新，区别于标准多头注意力，专业用户会搜索'GQA模型'

### mistralai/Mistral-Small-3.2-24B-Instruct-2506

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Mistral-Small-3.2-24B-Instruct-2506

**关键词列表**:

- **Mistral-Small-3.2** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简化规则（去版本号后缀）
- **减少重复生成** (技术特性): 模型针对无限生成问题的专项改进，是用户在对比模型时的关键搜索词
- **24B参数** (参数规格): 24B是主流大模型参数规模，用户常搜索‘24B参数模型’进行性能与成本权衡
- **Mistral-Small** (当前模型品牌名): 模型系列通用名称，用户可能搜索‘Mistral-Small’而非完整版本号，具搜索泛化性

### baidu/ERNIE-4.5-300B-A47B-2Bits-TP4-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-TP4-Paddle

**关键词列表**:

- **2Bits量化** (部署工具): 极低比特量化方案，用户搜‘2bit量化模型’高匹配
- **TP4并行** (技术特性): 独特张量并行配置，开发者搜‘TP4部署’精准命中

### moonshotai/Kimi-Audio-7B

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-Audio-7B

**关键词列表**:

- **Kimi-Audio** (当前模型品牌名): 项目名直接给出的当前模型品牌
- **音频问答** (功能场景): README 明确列出的核心功能之一
- **音频描述** (功能场景): README 明确列出的核心功能之一
- **声音事件分类** (功能场景): README 明确列出的核心功能之一
- **端到端语音对话** (功能场景): README 明确列出的核心功能之一

### Qwen/Qwen3-8B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-8B-MLX-6bit

**关键词列表**:

- **Qwen3-8B-MLX-6bit** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **82亿参数** (参数规格): 当前模型的参数量，具有区分度且用户可能搜索

### Helsinki-NLP/opus-mt-es-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-es-en

**关键词列表**:

- **opus-mt-es-en** (当前模型品牌名): 项目名称直接来源于Helsinki-NLP的官方模型命名，是用户在GitCode或Hugging Face搜索该西班牙语-英语翻译模型时最可能使用的精确关键词
- **西班牙语-英语翻译** (功能场景): 用户搜索翻译模型时常用‘语言对+翻译’结构，如‘西班牙语-英语翻译’，这是明确的搜索意图，且未被高频词库排除
- **OPUS翻译模型** (功能场景): OPUS是该模型系列的权威数据来源品牌，用户在学术或工程场景中常搜索‘OPUS翻译模型’以区分其他数据集训练的模型
- **Tatoeba测试** (技术特性): 模型在Tatoeba测试集上达到59.6 BLEU，该测试集是开放翻译评估的权威基准，专业用户会搜索‘Tatoeba翻译模型’来定位高质量免费模型

### baidu/ERNIE-4.5-300B-A47B-Base-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-Base-PT

**关键词列表**:

- **ERNIE-4.5-Base** (当前模型品牌名): 直接取自项目名称，标识该模型的品牌与版本
- **跨模态预训练** (技术特性): 模型在文本与视觉两种模态上联合预训练，提升跨模态推理能力
- **稀疏专家模型** (技术特性): 采用 MoE（Mixture‑of‑Experts）稀疏专家结构，实现高效大规模学习
- **PyTorch权重** (部署工具): “-PT” 版本提供 Transformer‑style 的 PyTorch 权重，便于在 PyTorch 环境中部署

### cointegrated/rubert-base-cased-nli-threeway

**URL**: https://ai.gitcode.com/hf_mirrors/cointegrated/rubert-base-cased-nli-threeway

**关键词列表**:

- **rubert-base-cased-nli-threeway** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，用户搜索俄语NLI模型时会精准使用此全称
- **俄语自然语言推理** (功能场景): 模型核心用途是俄语文本的蕴含/矛盾/中立判断，用户搜索俄语NLI时会使用此中文意图词
- **俄语零样本分类** (功能场景): 模型支持俄语文本的零样本推理，是其区别于通用NLI模型的关键应用场景
- **RuBERT** (当前模型品牌名): 模型基于RuBERT架构，是该系列在俄语NLI任务中的具体实现，用户会搜索此缩写
- **NLI俄语** (功能场景): 用户常以'功能+语言'组合搜索（如NLI俄语），此为高意图短语且未被高频词库覆盖
- **三分类NLI** (技术特性): 模型输出为蕴含、矛盾、中立三类，区别于二分类NLI，是其独特技术特征
- **cointegratednli-rus-translated-v2021** (当前模型品牌名): 项目标签中明确列出，是该模型的训练数据集/前身名称，属于模型自身标识的一部分

### nvidia/OpenReasoning-Nemotron-32B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-32B

**关键词列表**:

- **OpenReasoning-Nemotron** (当前模型品牌名): 从项目名称提取的当前模型名称，去掉版本号后更简洁
- **科学问题求解** (功能场景): README突出模型在科学问题求解上的能力
- **64K输出标记** (技术特性): README提到模型支持高达64K输出，是用户关心的超长输出能力
- **GenSelect** (技术特性): README提到的生成式解决方案选择机制，是模型独有的多智能体协同技术
- **CC-BY-4.0** (部署工具): 用户搜索商业可商用模型时常用许可证作为关键词

### ibm-granite/granite-timeseries-ttm-r1

**URL**: https://ai.gitcode.com/hf_mirrors/ibm-granite/granite-timeseries-ttm-r1

**关键词列表**:

- **ibm-granitegranite-timeseries-ttm-r1** (当前模型品牌名): 从项目URL和名称提取的当前模型完整名称
- **微型预训练模型** (技术特性): 当前模型首次提出的概念，具有区分度
- **少样本预测** (功能场景): 当前模型在少样本预测任务中的表现是其特点之一
- **轻量级预测器** (技术特性): 描述了当前模型的轻量级特性，具有区分度
- **分钟级到小时级分辨率** (功能场景): 当前模型支持的特定时间分辨率，具有应用场景指向性

### jonatasgrosman/wav2vec2-large-xlsr-53-russian

**URL**: https://ai.gitcode.com/hf_mirrors/jonatasgrosman/wav2vec2-large-xlsr-53-russian

**关键词列表**:

- **wav2vec2-large-xlsr-53-russian** (当前模型品牌名): 项目名称中完整的模型标识，直接对应当前模型
- **俄语语音识别** (功能场景): 模型专注于俄语的语音转文字任务，是用户搜索的核心功能
- **自动语音转文字** (功能场景): 模型实现的主要应用场景，即将语音自动转写为文本
- **Common-Voice-6.1-Russian** (技术特性): 模型在该公开俄语数据集上进行微调，体现了训练数据来源
- **CTC解码** (技术特性): 模型采用 Connectionist Temporal Classification 进行序列预测，是关键技术

### laion/CLIP-ViT-B-32-laion2B-s34B-b79K

**URL**: https://ai.gitcode.com/hf_mirrors/laion/CLIP-ViT-B-32-laion2B-s34B-b79K

**关键词列表**:

- **CLIP-ViT-B-32** (当前模型品牌名): 从项目名称直接提取的核心模型标识，是用户搜索CLIP视觉-语言模型时最可能使用的简洁品牌名

### t-tech/T-one

**URL**: https://ai.gitcode.com/hf_mirrors/t-tech/T-one

**关键词列表**:

- **T-one** (当前模型品牌名): 项目名称为t-tech/T-one，直接提取模型品牌名，简洁且为用户搜索核心词
- **流式ASR** (技术特性): 模型核心卖点是‘流式语音识别’，‘流式ASR’是行业常用缩写，用户搜索ASR时会加‘流式’限定
- **电话语音识别** (功能场景): 模型明确针对电话领域优化，‘电话语音识别’是精准垂直场景词，区别于通用ASR
- **Conformer** (技术特性): 模型使用Conformer声学架构，是区别于普通RNN/Transformer的差异化技术点，用户会搜索该架构名称
- **低延迟ASR** (技术特性): 项目反复强调‘低延迟’，是电话场景的核心需求，‘低延迟ASR’是用户真实搜索意图词
- **T-tech** (当前模型品牌名): 项目由T-Software DC开发，品牌为T-tech，作为开发方名称，具有识别度且非高频词
- **俄语STT** (功能场景): STT（Speech-to-Text）是ASR的同义词，用户在搜索俄语语音转文字时可能使用‘俄语STT’，语义精准且非高频词

### t-tech/T-pro-it-2.0-eagle

**URL**: https://ai.gitcode.com/hf_mirrors/t-tech/T-pro-it-2.0-eagle

**关键词列表**:

- **T-pro-it-2.0-eagle** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Eagle解码** (技术特性): 当前模型采用Eagle 2推测解码技术
- **推理加速** (功能场景): 模型主打推理阶段加速，用户会搜此场景
- **1层Transformer** (参数规格): 极简1层结构，用户关注轻量级模型

### nvidia/bigvgan_v2_22khz_80band_256x

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/bigvgan_v2_22khz_80band_256x

**关键词列表**:

- **BigVGAN-v2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自定义CUDA内核** (技术特性): 当前模型的核心技术特性之一
- **多尺度子带CQT判别器** (技术特性): 当前模型采用的技术特性，具有独特性
- **多尺度梅尔频谱图损失** (技术特性): 当前模型采用的技术特性，具有独特性
- **22kHz采样率** (参数规格): 当前模型支持的音频采样率，具有区分度

### baidu/ERNIE-4.5-VL-424B-A47B-PT

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-424B-A47B-PT

**关键词列表**:

- **ERNIE-VL** (当前模型品牌名): 项目名中的ERNIE-4.5-VL简写，用户直接搜ERNIE-VL即可定位
- **PD解耦推理** (技术特性): 动态角色切换的PD解耦为ERNIE 4.5独创推理优化，关键词稀缺

### timm/mobilenetv3_large_100.ra_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/mobilenetv3_large_100.ra_in1k

**关键词列表**:

- **MobileNetV3** (当前模型品牌名): 模型名称中包含的品牌名，直接对应项目的核心模型
- **RandAugment** (技术特性): 使用的随机增强数据增强方案，是模型训练的关键技术
- **RMSProp** (技术特性): 模型采用的优化器，提升收敛效率
- **EMA** (技术特性): 模型在训练中使用的指数移动平均权重策略
- **5.5M参数** (参数规格): 模型的参数规模约为 5.5 百万，帮助用户快速判断模型大小

### microsoft/xclip-base-patch32

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/xclip-base-patch32

**关键词列表**:

- **X-CLIP** (当前模型品牌名): 从项目名称 microsoft/xclip-base-patch32 提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词
- **视频-文本检索** (功能场景): 模型明确支持的典型应用场景，用户会搜索‘视频-文本检索模型’这类精准需求，且未被高频词库排除
- **零样本视频理解** (技术特性): 模型基于对比学习实现零样本能力，是其区别于传统视频模型的核心技术亮点，用户会搜索‘零样本视频’相关模型
- **224x224视频预处理** (技术特性): 模型训练/验证中明确使用的固定分辨率预处理方式，是工程用户搜索‘视频预处理标准’时的精准匹配词
- **8帧视频输入** (技术特性): 模型处理视频时的固定帧数设计，是区别于其他视频模型（如16帧、32帧）的显著技术参数，用户会据此筛选模型

### google/siglip-so400m-patch14-384

**URL**: https://ai.gitcode.com/hf_mirrors/google/siglip-so400m-patch14-384

**关键词列表**:

- **SigLIP** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Sigmoid损失函数** (技术特性): 当前模型使用的独特损失函数
- **SoViT-400m架构** (技术特性): 当前模型采用的架构

### openai/clip-vit-base-patch16

**URL**: https://ai.gitcode.com/hf_mirrors/openai/clip-vit-base-patch16

**关键词列表**:

- **CLIP** (当前模型品牌名): 项目名称中明确出现的核心品牌名
- **对比学习** (技术特性): 模型通过对比损失函数训练以最大化图文相似度
- **图文匹配** (功能场景): CLIP核心能力在于图像与文本的跨模态匹配
- **OpenAI-CLIP** (当前模型品牌名): README中多次出现OpenAI CLIP，作为品牌完整称呼

### microsoft/kosmos-2-patch14-224

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/kosmos-2-patch14-224

**关键词列表**:

- **Kosmos-2** (当前模型品牌名): 从项目名称 'microsoft/kosmos-2-patch14-224' 中提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词
- **图像接地** (功能场景): 模型核心功能为 '<grounding>' 指令驱动的图像与文本对齐，中文用户搜索 '图像接地' 或 '图像定位' 时意图明确，区别于通用图像描述
- **图像字幕生成** (功能场景): 模型支持基于图像生成自然语言描述，'图像字幕生成' 是用户在CSDN等平台搜索图像理解任务时的常用中文术语，区别于 '文生图' 等高频词
- **HuggingFace-transformers** (部署工具): README明确使用HuggingFace transformers库加载模型，该组合是开发者部署该模型的关键路径，且 'HuggingFace transformers' 作为整体术语未被高频词列表禁止
- **Patch14-224** (当前模型品牌名): 模型名称中的 'patch14-224' 是其视觉编码器的关键配置标识，技术用户会通过此后缀精准搜索该变体，具有区分度且未被高频词覆盖

### fofr/kontext-make-person-real

**URL**: https://ai.gitcode.com/hf_mirrors/fofr/kontext-make-person-real

**关键词列表**:

- **Kontext** (当前模型品牌名): 从项目名称 “kontext‑make‑person‑real” 中提取的模型品牌名
- **人物真实化** (功能场景): LoRA 的核心功能是让人物看起来更真实
- **Diffusers兼容** (部署工具): README 明确说明可在 Diffusers 环境中使用
- **ComfyUI兼容** (部署工具): README 中指出可与 ComfyUI 配合使用
- **Replicate训练** (技术特性): 模型在 Replicate 平台的 fast‑flux‑kontext‑trainer 上完成训练
- **LoRA秩16** (技术特性): LoRA 的秩（rank）设置为 16，体现其技术细节

### llava-hf/LLaVA-NeXT-Video-7B-hf

**URL**: https://ai.gitcode.com/hf_mirrors/llava-hf/LLaVA-NeXT-Video-7B-hf

**关键词列表**:

- **多视频输入** (技术特性): 模型支持在单次提示中传入多个视频片段，是其区别于其他视觉语言模型的独特功能点
- **32帧采样** (技术特性): 模型对视频统一采用32帧采样策略，是其架构设计中的关键参数，用户在技术对比时可能搜索该具体配置
- **VideoChatGPT-Instruct** (训练数据集): 模型使用了100K VideoChatGPT-Instruct数据进行微调，该数据集名称具有唯一性，是区别于其他视频模型的训练标识
- **VideoMME基准** (评估基准): 模型在VideoMME基准上达到领先水平，该基准名称是视频理解领域专业用户会搜索的评估指标关键词

### vidore/colqwen2-v0.1

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colqwen2-v0.1

**关键词列表**:

- **ColQwen2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ColBERT风格** (技术特性): 当前模型生成文本与图像多向量表示的技术特性
- **图像patch** (技术特性): 当前模型生成图像patch数量的技术特性

### facebook/vjepa2-vitg-fpc64-256

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-256

**关键词列表**:

- **V-JEPA-2** (当前模型品牌名): 项目名称中直接给出的模型品牌名称
- **视频检索** (功能场景): 模型支持基于视频特征的检索任务
- **视频编码器** (功能场景): 模型可作为视觉语言模型（VLM）的视频编码器使用
- **64帧采样** (技术特性): 模型在推理时默认使用64帧进行视频采样，体现其帧级处理能力
- **大规模预训练** (技术特性): 模型通过大规模数据和参数进行预训练，提升视频理解性能

### TencentARC/InstantMesh

**URL**: https://ai.gitcode.com/hf_mirrors/TencentARC/InstantMesh

**关键词列表**:

- **InstantMesh** (当前模型品牌名): 项目自身名称，用户会直接搜索
- **单图生成3D网格** (功能场景): README核心卖点，用户搜索意图明确
- **稀疏视角重建** (技术特性): 技术关键词，体现模型独特能力
- **LRM架构** (技术特性): 模型底层架构，技术用户会搜
- **可微分等值面提取** (技术特性): 创新模块，技术深度用户关注点
- **10秒出3D** (功能场景): 突出速度优势，用户高频搜索
- **图像到3D** (功能场景): 简洁描述任务类型，搜索常用

### deepset/bert-large-uncased-whole-word-masking-squad2

**URL**: https://ai.gitcode.com/hf_mirrors/deepset/bert-large-uncased-whole-word-masking-squad2

**关键词列表**:

- **BERT-large-SQuAD2** (当前模型品牌名): 项目名称核心词，用户直接搜模型简称
- **Haystack** (部署工具): 官方示例框架，用户想快速跑通Demo
- **ExtractiveReader** (部署工具): Haystack组件名，用户查找代码片段常用
- **英语问答模型** (功能场景): 明确语言+任务，精准匹配搜索需求

### hustvl/yolos-tiny

**URL**: https://ai.gitcode.com/hf_mirrors/hustvl/yolos-tiny

**关键词列表**:

- **YOLOS-tiny** (当前模型品牌名): 从项目名称提取的当前模型名称

### distilbert/distilbert-base-uncased-distilled-squad

**URL**: https://ai.gitcode.com/hf_mirrors/distilbert/distilbert-base-uncased-distilled-squad

**关键词列表**:

- **知识蒸馏** (技术特性): 模型通过知识蒸馏技术从 BERT‑base 压缩而来，是其核心技术亮点
- **SQuAD微调** (功能场景): 模型在 SQuAD v1.1 数据集上进行微调，专用于英文阅读理解问答
- **66M参数** (参数规格): DistilBERT‑base 的参数规模约为 66 百万，用户常以参数量搜索模型
- **英文问答** (功能场景): 模型面向英文阅读理解任务，适用于英文问答系统

### laion/clap-htsat-fused

**URL**: https://ai.gitcode.com/hf_mirrors/laion/clap-htsat-fused

**关键词列表**:

- **CLAP-HTSAT-FUSED** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，简洁且为用户搜索该模型时的精准关键词
- **零样本音频分类** (功能场景): 模型在README中明确强调的核心应用场景，且是用户寻找音频AI模型时的明确搜索意图
- **文本到音频检索** (功能场景): 模型在实验中表现卓越的专属任务，区别于通用音频分类，具有高区分度和搜索价值
- **对比式语言-音频预训练** (技术特性): 模型的核心技术命名，是论文提出的原创方法，非通用术语，具有唯一性和专业搜索价值
- **LAION-Audio-630K** (当前模型品牌名): 与模型绑定的专属数据集，常与模型一同被搜索，是该模型生态的关键组成部分，非通用数据集名称
- **音频-文本对** (技术特性): 模型训练所依赖的核心数据结构，是区别于其他音频模型（如仅用音频标签）的关键特征
- **HTSAT** (技术特性): 模型中使用的特定音频编码器名称，是CLAP-HTSAT-FUSED区别于其他CLAP变体（如CLAP-OpenCLIP）的专属技术组件
- **关键词到标题增强** (技术特性): 模型独有的文本增强技术，在README中被明确列为提升性能的关键设计，具有高度独特性

### akasharidas/ddpm-cifar10-32-dot.in.name

**URL**: https://ai.gitcode.com/hf_mirrors/akasharidas/ddpm-cifar10-32-dot.in.name

**关键词列表**:

- **扩散模型** (技术特性): 当前模型采用的去噪扩散概率模型技术
- **CIFAR10生成** (功能场景): 模型在无条件CIFAR10数据集上实现高质量图像合成
- **DDIM调度器** (部署工具): README推荐的推理加速调度器之一
- **PNDM调度器** (部署工具): README推荐的推理加速调度器之一
- **图像合成** (功能场景): 当前模型的核心用途：高质量图像合成

### facebook/sam-vit-base

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam-vit-base

**关键词列表**:

- **SAM-ViT-base** (当前模型品牌名): 从项目名称 'facebook/sam-vit-base' 直接提取的模型品牌名，简洁且为用户搜索该模型的精准关键词
- **提示驱动分割** (技术特性): 模型通过点、框等提示输入控制分割结果，这一交互方式是SAM的标志性设计，用户会用此词搜索可交互分割模型
- **ViT图像编码器** (技术特性): 模型使用基于ViT的图像编码器，是其架构核心组件，用户搜索‘ViT图像编码器’时可能寻找类似结构的分割模型

### QuantStack/Wan2.1_T2V_14B_FusionX_VACE-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.1_T2V_14B_FusionX_VACE-GGUF

**关键词列表**:

- **Wan2.1T2V** (当前模型品牌名): 直接取自项目名称，代表模型的核心品牌标识
- **FusionX** (技术特性): 模型名称中包含的 FusionX 技术，体现其独特的融合架构
- **VACE** (技术特性): 模型名称中的 VACE 组件，标识特定的视觉编码增强技术
- **Video-to-Video** (功能场景): 模型能够对已有视频进行再生成或风格迁移的功能

### microsoft/trocr-large-printed

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/trocr-large-printed

**关键词列表**:

- **TrOCR-large-printed** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像Transformer** (技术特性): 当前模型编码器部分使用的技术
- **文本Transformer** (技术特性): 当前模型解码器部分使用的技术
- **BEiT权重初始化** (技术特性): 当前模型图像编码器权重初始化的方式
- **RoBERTa权重初始化** (技术特性): 当前模型文本解码器权重初始化的方式
- **自回归生成** (技术特性): 当前模型文本解码器的生成方式

### facebook/vjepa2-vitg-fpc64-384

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-384

**关键词列表**:

- **V-JEPA** (当前模型品牌名): 从项目名称提取的模型品牌名，已去除版本号
- **大规模视频预训练** (技术特性): 模型在海量视频数据上进行预训练，体现其规模优势
- **前沿视频理解** (技术特性): 模型在视频理解能力上达到业界前沿水平
- **视频表示学习** (技术特性): 模型能够学习高质量的视频表示，用于多种下游任务

### mradermacher/VeriReason-Qwen2.5-7b-SFT-Reasoning-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/VeriReason-Qwen2.5-7b-SFT-Reasoning-i1-GGUF

**关键词列表**:

- **VeriReason** (当前模型品牌名): 项目名称核心品牌标识，是当前模型独有的命名，符合用户搜索AI模型时对品牌名的直接检索习惯
- **Verilog** (功能场景): 模型专用于Verilog硬件描述语言推理，是其核心应用场景，用户会搜索'Verilog AI'或'Verilog推理模型'等关键词
- **RTL推理** (功能场景): 模型针对RTL（寄存器传输级）设计进行推理优化，是区别于通用代码模型的专属能力，用户可能搜索'RTL AI推理'
- **IQ量化** (技术特性): 模型提供IQ1_S、IQ3_XS等独特IQ量化版本，是GGUF中区别于普通Q2/Q3量化的技术标签，用户会搜索'IQ量化模型'
- **i1-IQ3XS** (技术特性): 模型特有的量化子版本名称，是用户在对比不同量化精度时可能直接搜索的精确标签，具有高区分度
- **推理增强** (技术特性): 模型名称含'Reasoning'，且经过SFT强化推理能力，是区别于基础代码模型的核心特性，用户会搜索'推理增强AI模型'

### LGAI-EXAONE/EXAONE-4.0-1.2B

**URL**: https://ai.gitcode.com/hf_mirrors/LGAI-EXAONE/EXAONE-4.0-1.2B

**关键词列表**:

- **EXAONE-4.0** (当前模型品牌名): 从项目名称提取的当前模型名称
- **1.2B参数** (参数规格): 当前模型的小型端侧规格
- **推理模式** (技术特性): 模型内置的推理与非推理双模式
- **智能体工具** (功能场景): 面向智能体AI时代的工具调用能力
- **混合注意力** (技术特性): 局部+全局混合注意力机制
- **端侧部署** (部署工具): 专为端侧应用设计的轻量模型
- **韩语支持** (功能场景): 原生支持韩语等多语言生成

### TahaDouaji/detr-doc-table-detection

**URL**: https://ai.gitcode.com/hf_mirrors/TahaDouaji/detr-doc-table-detection

**关键词列表**:

- **DETR表格检测** (当前模型品牌名): 项目名称核心词，用户会直接搜模型简称
- **无边框表格识别** (功能场景): 模型主打能力，解决文档中难检的无边框表格
- **ICDAR2019** (技术特性): 训练数据集关键词，学术与工程用户常用检索词
- **文档表格检测** (功能场景): 明确场景，用户搜索文档OCR/版面分析时的精准需求
- **ResNet-50-DETR** (技术特性): 模型底座信息，开发者搜索DETR变体时的常见组合词
- **表格目标检测** (功能场景): 将表格作为目标检测对象，贴合CV工程师的检索习惯

### LiquidAI/LFM2-700M

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-700M

**关键词列表**:

- **边缘AI模型** (功能场景): README明确强调'专为边缘人工智能和设备端部署而设计'，这是该模型最核心的差异化定位，用户会搜索此类场景词
- **CPU推理模型** (功能场景): 模型在CPU上解码和预填充速度比Qwen3快2倍，且明确支持CPU部署，这是其独特优势，用户会搜索'CPU推理模型'这类部署场景
- **混合Liquid模型** (技术特性): LFM2是全新混合Liquid架构，具备乘法门控和短卷积，'混合Liquid模型'是其独有的技术命名，具有高区分度
- **700M参数模型** (参数规格): 模型参数为742M，接近700M主流规格，用户常搜索'700M参数模型'这类近似规格词，且未被高频词列表排除
- **设备端AI** (功能场景): README多次提及'设备端部署'，适用于智能手机、笔记本、车辆等，'设备端AI'是用户在边缘计算场景中的高频搜索词
- **轻量级大模型** (功能场景): 虽参数700M，但性能超越同等规模模型，且强调内存效率，符合'轻量级大模型'这一新兴搜索趋势，区别于传统'小模型'表述

### autogluon/mitra-regressor

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/mitra-regressor

**关键词列表**:

- **Mitra-Regressor** (当前模型品牌名): 项目名称中直接出现的模型完整名称
- **AutoGluon-Tabular** (部署工具): 模型通过 AutoGluon 的 Tabular 接口提供，用户常以此名称搜索模型的使用方式
- **12层模型** (参数规格): 模型结构为 12 层深度的网络，用户在搜索模型规模时会关注层数信息

### mradermacher/Qwen2-Audio-7B-Instruct-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-Instruct-i1-GGUF

**关键词列表**:

- **Qwen2-Audio-7B-Instruct-i1-GGUF** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **i1-IQ量化系列** (技术特性): 当前模型提供的特定量化版本系列，具有存储空间优化特点

### Alibaba-NLP/WebSailor-3B

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/WebSailor-3B

**关键词列表**:

- **WebSailor-3B** (当前模型品牌名): 从项目名称直接提取的当前模型名称，符合简化规则（保留主名称，省略版本后缀）
- **网络导航代理** (功能场景): 模型核心用途是执行网络导航与信息检索任务，用户会搜索此类具体场景词，且未在高频排除列表中
- **SailorFog-QA** (技术特性): 模型独有的数据合成流程名称，代表其创新性任务生成机制，是区别于其他代理模型的关键技术标签
- **双采样策略优化** (技术特性): 模型提出的专有强化学习算法（DUPO），是训练范式的核心创新，具有唯一性和搜索价值
- **拒绝采样微调** (技术特性): 模型训练中使用的特定微调方法（RFT），是实现冷启动的关键技术术语，非通用词，具区分度
- **代理强化学习** (技术特性): 模型采用的核心训练范式，区别于普通LLM微调，是用户搜索AI代理模型时的精准意图关键词
- **BrowseComp基准** (技术特性): 模型在权威高难度基准上验证性能，该基准名称是领域内专业用户搜索评估模型时的关键词

### google-t5/t5-3b

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-3b

**关键词列表**:

- **T5-3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **30亿参数** (参数规格): 当前模型的主流参数规模
- **文档摘要** (功能场景): T5支持文档自动摘要

### Qwen/Qwen3-235B-A22B-Thinking-2507-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8

**关键词列表**:

- **长上下文理解** (技术特性): 支持 256K 级别的长上下文，提升思考长度和信息保持能力
- **人类偏好对齐** (技术特性): 通过对齐训练，使生成内容更符合人类价值观和使用偏好
- **思考长度提升** (技术特性): 相较于前代模型，思考长度显著增加，支持更深层次的链式思考

### microsoft/table-transformer-structure-recognition

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/table-transformer-structure-recognition

**关键词列表**:

- **Table-Transformer** (当前模型品牌名): 从项目名称提取的当前模型名称
- **表格结构识别** (功能场景): 当前模型的主要应用场景
- **DETR等效模型** (技术特性): 当前模型与DETR等效，是其技术特性
- **层归一化** (技术特性): 当前模型采用DETR的'normalize before'设置，即层归一化
- **PubTables1M训练** (技术特性): 当前模型在PubTables1M数据集上进行训练

### Prior-Labs/TabPFN-v2-clf

**URL**: https://ai.gitcode.com/hf_mirrors/Prior-Labs/TabPFN-v2-clf

**关键词列表**:

- **小样本表格学习** (功能场景): 模型专注于在小规模表格数据上实现高性能，符合用户搜索“小样本表格学习”
- **先验数据学习** (技术特性): 模型采用基于先验数据的学习方法，是其独特技术亮点
- **零任务微调** (技术特性): 无需针对特定任务进行微调即可直接使用，体现模型的即插即用特性

### bartowski/LLaMA-Mesh-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/bartowski/LLaMA-Mesh-GGUF

**关键词列表**:

- **LLaMA-Mesh** (当前模型品牌名): 项目名称直接来源于该模型，是用户搜索该特定模型的唯一品牌标识
- **imatrix量化** (技术特性): 模型明确使用imatrix方法进行量化，是区别于普通Q4/Q8量化的独特技术点，用户会搜索‘imatrix量化模型’以获取高精度低显存方案
- **LM-Studio** (部署工具): README明确指出‘可在LM Studio中运行’，这是该模型的专属部署平台，用户会搜索‘LM Studio可用模型’来匹配工具
- **Q6KL** (参数规格): Q6_K_L是该模型特有的高精度量化级别（嵌入与输出层用Q8_0），属于非通用量化标签，用户会搜索该具体格式以获取高质量轻量模型
- **Q5KL** (参数规格): Q5_K_L是该模型提供的另一独特量化版本，强调嵌入层保留Q8_0精度，属于细粒度量化标签，区别于普通Q5，具有搜索价值
- **mesh-generation** (功能场景): 标签中‘mesh-generation’是Text-to-3D的具体实现形式，属于专业术语但用户在AI建模圈中会直接搜索该词寻找3D网格生成模型

### HKUSTAudio/xcodec2

**URL**: https://ai.gitcode.com/hf_mirrors/HKUSTAudio/xcodec2

**关键词列表**:

- **XCodec2** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **语音令牌化器** (功能场景): README中明确给出的模型定位
- **每秒50令牌** (技术特性): 用户会搜索的量化速率指标
- **单一矢量量化** (技术特性): 模型核心量化技术，用户可能直接搜索
- **多语言语音重建** (功能场景): README强调的多语言高质量语音重建能力
- **Llasa微调** (部署工具): README新增的微调说明，用户会搜索如何微调

### ByteDance-Seed/SeedVR2-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR2-7B

**关键词列表**:

- **单步视频修复** (功能场景): 模型能够在一次前向传播完成高清视频的修复任务
- **对抗后训练** (技术特性): 采用对抗训练机制提升生成质量与分布匹配能力
- **自适应窗口注意力** (技术特性): 动态调整注意力窗口尺寸以适配不同分辨率，解决窗口不连贯问题
- **特征匹配损失** (技术特性): 引入新型特征匹配损失函数，增强视频时序一致性

### fixie-ai/ultravox-v0_6-llama-3_3-70b

**URL**: https://ai.gitcode.com/hf_mirrors/fixie-ai/ultravox-v0_6-llama-3_3-70b

**关键词列表**:

- **Ultravox** (当前模型品牌名): 从项目名称 fixie-ai/ultravox-v0_6-llama-3_3-70b 中提取的核心模型品牌名，且未被高频词列表排除
- **语音到文本** (功能场景): 模型核心能力是接收语音输入并生成文本输出，属于用户明确搜索的场景（如‘语音转文字AI’），且非高频词
- **多模态语音** (技术特性): 模型明确为‘多模态语音大语言模型’，结合语音与文本输入，具有独特性，未在高频词列表中出现
- **噪声鲁棒语音** (技术特性): v0.6版本特别在噪声数据上训练，可识别并输出((noise))，是该模型独有的鲁棒性特征，用户可能搜索‘抗噪语音识别模型’
- **印地语语音识别** (功能场景): v0.6在印地语语音数据上专项增强，是该模型区别于其他语音模型的明确语言支持特性，非通用词
- **音频伪标记** (技术特性): 模型使用<|audio|>伪标记处理语音输入，是其架构核心机制，技术独特，非通用术语

### mradermacher/Qwen2-Audio-7B-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/Qwen2-Audio-7B-i1-GGUF

**关键词列表**:

- **Qwen2-Audio-7B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **i1-IQ量化版本** (技术特性): 当前模型提供的特定量化版本，具有独特性
- **音频-文本转文本** (功能场景): 当前模型的主要功能，描述其应用场景

### qwbu/univla-7b

**URL**: https://ai.gitcode.com/hf_mirrors/qwbu/univla-7b

**关键词列表**:

- **UniVLA** (当前模型品牌名): 项目名称直接给出的模型品牌名
- **具身智能** (功能场景): 模型主打跨具身形态的动作学习，用户会搜具身智能相关方案
- **潜在动作** (技术特性): 论文核心创新点，用户想了解潜在动作如何实现通用策略
- **跨具身视频** (技术特性): 模型训练数据来源，用户会搜如何利用跨具身视频训练机器人
- **任务中心化** (技术特性): 论文提出的动作提取方法，用户会搜任务中心化相关实现
- **OpenX数据集** (部署工具): 官方预训练数据之一，用户想下载或复现OpenX实验
- **Ego4D预训练** (部署工具): 官方预训练数据之二，用户会搜Ego4D在机器人模型上的用法

### unsloth/Kimi-K2-Instruct-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Kimi-K2-Instruct-GGUF

**关键词列表**:

- **Kimi-K2-Instruct** (当前模型品牌名): 项目名称中明确包含'Kimi-K2-Instruct'，是模型的完整指令微调版本名称，用户搜索具体指令型变体时会使用该完整命名，符合品牌名提取规则
- **MoE模型** (技术特性): 模型明确为混合专家（MoE）架构，且参数规模达1万亿，'MoE模型'是用户搜索稀疏激活大模型时的高频技术词，未被禁止列表覆盖
- **Muon优化器** (技术特性): 模型使用独家的Muon优化器进行训练，是区别于其他模型的核心技术亮点，非通用术语，具有高度区分度且未被高频词列表包含

### ByteDance-Seed/SeedVR2-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR2-3B

**关键词列表**:

- **SeedVR2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **一步式推理** (技术特性): 单步扩散对抗后训练，显著降低计算成本
- **扩散对抗训练** (技术特性): 当前模型采用的核心训练方法

### lovis93/Motion-Lora-Camera-Push-In-Wan-14B-720p-I2V

**URL**: https://ai.gitcode.com/hf_mirrors/lovis93/Motion-Lora-Camera-Push-In-Wan-14B-720p-I2V

**关键词列表**:

- **Motion-LoRA** (当前模型品牌名): 从项目名称 “Motion-Lora-Camera-Push-In‑Wan‑14B‑720p‑I2V” 中提取的简洁模型品牌名
- **Push-in-camera** (功能场景): 模型的触发词，用于生成推镜式运动镜头，用户搜索时会直接使用该关键词
- **I2V-720p** (技术特性): 模型基于 Wan 2.1 的 I2V（图像‑到‑视频）架构，支持 720p 超高清输出
- **电影感运动** (技术特性): 模型专注于生成具有电影质感的推镜运动效果，区别于普通运动 LoRA

### pcoloc/autotrain-mikrotik-7-7-1860563588

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-mikrotik-7-7-1860563588

**关键词列表**:

- **pcolocautotrain-mikrotik-7-7** (当前模型品牌名): 从项目名称提取的当前模型名称
- **二氧化碳排放量预测** (功能场景): 根据模型训练目的推测的功能场景，具有独特性

### adrientoupet/SeedVR2_comfyUI

**URL**: https://ai.gitcode.com/hf_mirrors/adrientoupet/SeedVR2_comfyUI

**关键词列表**:

- **视频超分** (功能场景): 模型专注于视频分辨率提升，是典型的“视频超分”应用场景
- **GGUF模型** (技术特性): 仓库提供 GGUF 格式的模型权重，是模型的独特文件格式特性
- **额外upscale模型** (功能场景): 本仓库提供的额外 upscale 模型用于进一步提升视频质量，区别于主模型

### skt/A.X-3.1

**URL**: https://ai.gitcode.com/hf_mirrors/skt/A.X-3.1

**关键词列表**:

- **A.X-3.1** (当前模型品牌名): 项目名称为skt/A.X-3.1，模型正式名称为A.X 3.1，是当前模型的唯一品牌标识
- **韩语大模型** (功能场景): 模型专为韩语理解与企业部署优化，是用户搜索韩语AI时的核心意图词，且未在高频排除词列表中
- **主权AI** (技术特性): 模型强调由SKT完全自主开发，涵盖架构、数据、训练全流程，'主权AI'是其核心差异化定位术语
- **34B参数** (参数规格): 模型参数量为34B，属于主流大模型规格，且未被高频排除词（如7B/32B/671B）覆盖，具有区分度
- **KMMLU** (技术特性): 模型在KMMLU（韩语版MMLU）基准上取得69.2分，该基准是韩语评估的权威专有指标，非通用术语
- **CLIcK** (技术特性): 模型在CLIcK（韩语文化语境理解基准）上达77.4分，为SKT自研的专属评估基准，具有唯一性和搜索价值
- **YaRN** (技术特性): 模型通过YaRN技术扩展上下文至131K，该技术名称是具体技术实现词，非通用术语，用户可能搜索'YaRN 长上下文'
- **TITAN** (技术特性): 模型全程运行于SKT自研超级计算基础设施TITAN，是其专属硬件生态标签，具有品牌独特性

### TeslaYang123/TC-Light

**URL**: https://ai.gitcode.com/hf_mirrors/TeslaYang123/TC-Light

**关键词列表**:

- **TC-Light** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **视频重光照** (功能场景): TC-Light的核心功能是操纵视频光照分布
- **sim2real** (功能场景): TC-Light专为具身智能体的sim2real数据增强设计
- **长视频处理** (功能场景): 支持在单卡A100上处理300帧1280×720长视频
- **生成式渲染** (技术特性): TC-Light是一种生成式渲染器，用于真实世界迁移

### prs-eth/marigold-normals-v1-1

**URL**: https://ai.gitcode.com/hf_mirrors/prs-eth/marigold-normals-v1-1

**关键词列表**:

- **marigold-normals** (当前模型品牌名): 从项目名称 prs-eth/marigold-normals-v1-1 中提取的核心品牌名，去掉版本号后为用户搜索模型的直接关键词
- **单目法向量估计** (功能场景): 模型核心用途，用户在计算机视觉领域搜索表面法线生成时会使用该精准术语
- **法线图生成** (功能场景): 对'单目法向量估计'的通俗表达，符合工程师和研究者在图像分析中搜索'法线图'的搜索习惯
- **扩散模型法线估计** (技术特性): 模型基于扩散架构实现法线估计，是区别于传统CNN方法的独特技术标签，用户会搜索此类组合词
- **零样本法线估计** (技术特性): README明确标注'zero-shot'，且法线估计领域中零样本能力是重要卖点，具有区分度
- **图像分析** (功能场景): 模型应用于图像分析任务，是CVPR论文中的官方描述，非泛泛词汇，且未被高频词列表排除
- **in-the-wild-法线估计** (功能场景): README明确使用'in-the-wild'描述模型适用场景，是学术界和工业界用于指代真实场景图像分析的专有术语，具有高区分度

### google-t5/t5-large

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-large

**关键词列表**:

- **google-t5t5-large** (当前模型品牌名): 从项目URL和名称中提取的当前模型名称
- **文本到文本迁移转换器** (技术特性): 当前模型的核心技术特性描述
- **7.7亿参数** (参数规格): 当前模型的参数规模描述
- **问答任务** (功能场景): 当前模型的应用场景之一

### OmniGen2/OmniGen2

**URL**: https://ai.gitcode.com/hf_mirrors/OmniGen2/OmniGen2

**关键词列表**:

- **OmniGen2** (当前模型品牌名): 项目名称即为模型的品牌名，用户搜索时会直接使用该名称
- **TeaCache** (技术特性): 最新更新中提到 OmniGen2 支持 TeaCache 以实现更快速推理，属于模型的加速特性
- **TaylorSeer** (技术特性): OmniGen2 同时支持 TaylorSeer 加速推理，是模型独有的性能优化组件
- **X2I2-训练数据集** (技术特性): 项目公开的 X2I2 数据集是 OmniGen2 训练使用的专属数据资源，具备搜索价值
- **OmniContext-基准测试** (技术特性): OmniGen2 提供的 OmniContext 基准测试集用于模型评估，用户会以此关键词查找评测信息
- **解耦图像分词器** (技术特性): 模型采用独立的图像分词器设计，是区别于其他多模态模型的关键技术点
- **无-flashattn-运行** (技术特性): OmniGen2 可在无需 flash‑attn 的环境下运行，满足显存受限设备的部署需求

### unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF

**关键词列表**:

- **思维推理模型** (功能场景): README强调推理能力，用户搜“思维”找此类模型
- **256K长上下文** (技术特性): 超长上下文是显著卖点，用户会按此规格搜索

### deepset/bert-base-cased-squad2

**URL**: https://ai.gitcode.com/hf_mirrors/deepset/bert-base-cased-squad2

**关键词列表**:

- **bert-base-cased-squad2** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索特定SQuAD2微调BERT模型时会使用此完整名称
- **SQuAD-v2** (训练数据): 模型训练所用的权威数据集名称，专业用户会以此为关键词筛选支持未回答问题的问答模型
- **BERT-base** (技术特性): 模型基础架构名称，用户区分不同规模BERT变体时会搜索此通用术语（非高频词，因未在排除列表中）

### joeddav/xlm-roberta-large-xnli

**URL**: https://ai.gitcode.com/hf_mirrors/joeddav/xlm-roberta-large-xnli

**关键词列表**:

- **XLMRobertalarge** (当前模型品牌名): 从项目名称提取的模型主体名称，去除后缀‑xnli，保持简洁
- **ZeroShot-Classification** (功能场景): 模型专用于零样本文本分类，可直接用于跨语言标签推断
- **跨语言文本推理** (功能场景): 支持 15 种语言的自然语言推理任务，适用于多语言文本理解
- **ZeroShotClassificationPipeline** (部署工具): 可通过 HuggingFace 的 zero‑shot‑classification 管道直接调用，使用便捷
- **15语言支持** (功能场景): 模型覆盖英、法、西、德、希、保、俄、土、阿、越、泰、中文、印、斯瓦、乌等 15 种语言

### intfloat/multilingual-e5-large-instruct

**URL**: https://ai.gitcode.com/hf_mirrors/intfloat/multilingual-e5-large-instruct

**关键词列表**:

- **E5-large** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多语言文本嵌入** (功能场景): 当前模型的核心功能
- **MS-MARCO段落排序** (功能场景): 官方示例场景，用户会搜
- **ONNX部署** (部署工具): README标签中明确支持ONNX
- **1024维嵌入** (技术特性): 模型输出维度，用户关心
- **24层Transformer** (技术特性): 模型架构深度，用户会搜

### Kwaipilot/OASIS-code-1.3B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/OASIS-code-1.3B

**关键词列表**:

- **OASIS-code-1.3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **代码嵌入模型** (功能场景): 当前模型的主要功能和应用场景
- **仓库级程序分析** (技术特性): 当前模型采用的独特技术之一
- **OASIS-instruct数据合成算法** (技术特性): 当前模型的核心技术特性之一
- **专用融合损失函数** (技术特性): 当前模型采用的独特技术之一
- **代码搜索效率** (功能场景): 当前模型在代码搜索方面的应用场景和优势

### moonshotai/Kimi-Audio-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-Audio-7B-Instruct

**关键词列表**:

- **混合音频输入** (技术特性): 模型创新架构特征，使用‘连续声学+离散语义令牌’双模输入，技术术语但用户会搜索相关论文或实现
- **流式音频生成** (技术特性): 基于流匹配的分块流式解码，是低延迟音频生成的关键技术，区别于传统批量生成，具独特性

### Qwen/Qwen3-Embedding-4B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Embedding-4B-GGUF

**关键词列表**:

- **Qwen3-Embedding-4B-GGUF** (当前模型品牌名): 项目名称直接对应当前模型完整标识，符合用户搜索具体模型版本的意图
- **重排模型** (功能场景): 模型支持排序/重排任务，是区别于普通嵌入模型的独特功能点
- **自定义维度** (技术特性): 支持32-2560任意嵌入维度，是区别于固定维度模型的核心技术亮点
- **多语言检索** (功能场景): 模型主打100+语言的跨语言检索能力，是明确可搜索的应用场景，非泛泛'多语言'
- **代码检索** (功能场景): 模型明确支持代码检索，属于垂直细分场景，用户会针对性搜索，且未被高频词覆盖

### JacobLinCool/MP-SENet-DNS

**URL**: https://ai.gitcode.com/hf_mirrors/JacobLinCool/MP-SENet-DNS

**关键词列表**:

- **MP-SENet** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **语音降噪** (功能场景): README标签明确指向denoising与speech-enhancement
- **音频去噪** (功能场景): 用户搜索音频降噪模型时常用关键词
- **DNS挑战** (功能场景): 项目名含DNS，指向Deep Noise Suppression挑战赛场景
- **MIT开源** (部署工具): 许可证为MIT，用户搜索可商用开源模型时会用

### openai/imagegpt-large

**URL**: https://ai.gitcode.com/hf_mirrors/openai/imagegpt-large

**关键词列表**:

- **iGPT** (当前模型品牌名): 模型简称，便于用户搜索
- **自监督学习** (技术特性): 当前模型使用的核心技术方法
- **像素预测** (技术特性): 当前模型的核心任务，即根据已出现的像素值预测下一个像素值
- **条件图像生成** (功能场景): 当前模型的应用场景之一，可执行条件图像生成

### lysandre/tiny-tapas-random-sqa

**URL**: https://ai.gitcode.com/hf_mirrors/lysandre/tiny-tapas-random-sqa

**关键词列表**:

- **TinyTapas** (当前模型品牌名): 从项目名称提取的简洁模型名称
- **随机抽样** (技术特性): 模型在训练/推理时采用随机抽样策略以提升鲁棒性
- **轻量化模型** (技术特性): 模型体积小、参数量低，适合资源受限环境
- **SQA任务** (功能场景): 模型面向语义问答（Semantic Question Answering）任务
- **Python库** (部署工具): 模型以 Python 库形式提供，便于在项目中直接调用

### microsoft/tapex-large-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-large-finetuned-wtq

**关键词列表**:

- **WikiTableQuestions** (当前模型品牌名): 模型在该数据集上微调，该数据集名称已成为该模型的标志性应用场景，用户常以数据集名搜索对应模型
- **表结构推理** (技术特性): 模型专为处理表格中跨行跨列的逻辑推理设计，如计算差值、排序、时间序列对比等，是其核心能力的精准描述
- **seq2seq表格模型** (技术特性): 模型基于BART的编码器-解码器结构，专门针对表格输入输出设计，区别于纯文本seq2seq模型，是技术圈内精准搜索词

### OpenGVLab/InternVL3-78B

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVL3-78B

**关键词列表**:

- **InternVL3** (当前模型品牌名): 项目名称直接给出的系列品牌名
- **78B参数** (参数规格): 当前模型超大参数规模，用户会搜
- **工业图像分析** (功能场景): 模型官方强调的新场景，垂直行业用户会搜
- **3D视觉感知** (功能场景): InternVL3独有的3D理解能力，用户会搜

### microsoft/tapex-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-base

**关键词列表**:

- **表格事实验证** (功能场景): 模型支持对表格数据进行事实真伪验证
- **合成语料库** (技术特性): 模型使用自动生成的合成语料库进行大规模训练

### google/ddpm-church-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-church-256

**关键词列表**:

- **googleddpm-church-256** (当前模型品牌名): 从项目URL和名称中提取的当前模型标识
- **高质量图像生成** (功能场景): 当前模型的主要应用场景和功能
- **schedulingddpm** (部署工具): 当前模型推理时使用的特定调度器名称
- **unconditional-image-generation** (功能场景): 当前模型的无条件图像生成功能描述

### nvidia/bigvgan_v2_24khz_100band_256x

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/bigvgan_v2_24khz_100band_256x

**关键词列表**:

- **音频生成** (功能场景): 模型用于从文本或特征生成高质量音频，是用户在AI音频应用中高频搜索的场景词，且未被高频词列表排除
- **融合CUDA内核** (技术特性): 模型核心优化点，用户搜索'高性能音频生成模型'或'CUDA加速声码器'时可能使用该术语，具技术区分度
- **44-kHz音频** (参数规格): 支持最高44 kHz采样率是模型关键配置，属于用户在高保真音频生成场景中会搜索的明确参数规格
- **Hugging-Face-Spaces** (部署工具): 模型已集成Hugging Face Spaces提供在线体验，是用户寻找'在线试听AI声码器'时的关键部署入口词

### google/ddpm-cat-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-cat-256

**关键词列表**:

- **图像去噪** (功能场景): DDPM主打的图像生成与去噪能力，用户搜索意图明确
- **256分辨率** (参数规格): 模型输出256×256像素，用户常搜“256图像生成”
- **LSUN猫数据集** (功能场景): 模型专用于猫图像生成，用户会搜“猫图生成模型”

### nvidia/segformer-b4-finetuned-cityscapes-1024-1024

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/segformer-b4-finetuned-cityscapes-1024-1024

**关键词列表**:

- **SegFormer-B4** (当前模型品牌名): 项目名称中直接包含的模型名称，已简化为品牌名
- **CityScapes微调** (功能场景): 模型在 CityScapes 数据集上完成微调，体现其专注的语义分割场景
- **1024x1024分辨率** (技术特性): 模型在 1024×1024 高分辨率下进行训练和推理，区别于低分辨率模型
- **轻量级MLP解码头** (技术特性): 采用轻量级全 MLP 解码头，提升推理效率且保持分割精度
- **分层编码器** (技术特性): 使用分层式 Transformer 编码器结构，是 SegFormer 的关键创新点
- **ImageNet-1k预训练** (技术特性): 模型的编码器在 ImageNet‑1k 上预训练后再进行下游微调，提升特征表达能力

### neuralmind/bert-base-portuguese-cased

**URL**: https://ai.gitcode.com/hf_mirrors/neuralmind/bert-base-portuguese-cased

**关键词列表**:

- **BERTimbau-Base** (当前模型品牌名): 项目官方名称，是该葡萄牙语BERT模型的专属品牌标识，区别于其他BERT变体
- **bert-base-portuguese-cased** (当前模型品牌名): 模型在Hugging Face和GitCode上的正式名称，用户搜索模型时会直接使用此完整标识
- **巴西葡萄牙语NLP** (功能场景): 明确指向该模型服务的语言场景（巴西葡萄牙语）和任务类型（NLP），用户会搜索特定语言的NLP模型
- **命名实体识别** (功能场景): 模型在README中明确列出的三大下游任务之一，是用户寻找语言理解模型时的明确搜索意图
- **句子文本相似度** (功能场景): 模型在README中明确宣称的高性能任务，属于具体NLP应用场景，非通用词，具区分度
- **文本蕴含识别** (功能场景): 模型三大核心任务之一，专业但用户（如NLP研究者、开发者）会直接搜索该术语
- **neuralmind** (当前模型品牌名): 模型发布机构名称，是该系列模型的唯一生产方，用户搜索时可能直接使用机构名+语言关键词
- **brWaC** (技术特性): 模型训练所用的专属巴西葡萄牙语语料库名称，具有唯一性，是该模型的技术标识，非通用术语

### Qwen/Qwen3-30B-A3B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-MLX-4bit

**关键词列表**:

- **100语言** (功能场景): 模型支持 100+ 语言与方言，满足多语言应用需求

### openai/diffusers-cd_imagenet64_l2

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-cd_imagenet64_l2

**关键词列表**:

- **cdimagenet64l2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **一致性蒸馏** (技术特性): 当前模型训练过程的核心技术
- **一致性训练** (技术特性): 当前模型从头开始训练的核心技术
- **图像超分辨率** (功能场景): 当前模型的应用场景

### moonshotai/Kimi-K2-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-K2-Instruct

**关键词列表**:

- **32B激活参数** (参数规格): MoE架构下实际激活的参数量，用户关注
- **前沿知识** (功能场景): README强调模型在最新知识上的表现

### Qwen/Qwen3-32B-MLX-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-MLX-4bit

**关键词列表**:

- **Qwen3-32B-MLX-4bit** (当前模型品牌名): 项目名称直接定义的模型全称，是用户在GitCode等平台搜索该特定版本时的精准关键词
- **32.8B参数** (参数规格): 32.8B是当前模型精确参数量，属于主流大模型规模区间，用户会搜索'30B级模型'寻找性能与资源平衡的选项，且未被高频词库排除

### baidu/ERNIE-4.5-300B-A47B-FP8-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-FP8-Paddle

**关键词列表**:

- **层次负载均衡** (技术特性): 模型在训练过程中的层次化负载均衡调度方案
- **多专家并行协作** (技术特性): 模型在推理时的多专家并行协作机制，提升推理吞吐

### google/ddpm-ema-celebahq-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-ema-celebahq-256

**关键词列表**:

- **CelebA-HQ-256** (功能场景): 专精人脸高清生成，256×256分辨率，用户搜CelebA-HQ找人脸模型
- **DDIM调度** (部署工具): 官方推荐加速采样器，用户搜DDIM找快速推理方案

### jinaai/jina-embeddings-v4

**URL**: https://ai.gitcode.com/hf_mirrors/jinaai/jina-embeddings-v4

**关键词列表**:

- **jina-embeddings-v4** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该模型的唯一官方标识，且未被高频词列表排除
- **文本到视觉文档检索** (功能场景): 模型明确支持'Text-to-Visual Document (T→VD) retrieval'，是其核心独特应用场景，非通用词，未在高频词列表中
- **稠密与延迟交互检索** (技术特性): 模型独家支持两种检索模式（单向量稠密 + 多向量延迟交互），为技术用户搜索时的关键区分点，非通用术语
- **视觉丰富文档嵌入** (功能场景): 模型专为含图表、表格、插图的复杂文档设计，该短语精准描述其目标场景，具有高度区分度
- **嵌入维度压缩** (技术特性): 模型支持无损压缩至128维，且明确列出套娃维度（128/256/512/1024/2048），是工程部署时的重要搜索词
- **任务适配器** (技术特性): 模型提供检索、文本匹配、代码等任务的动态适配器，为推理时可选功能，属独特架构设计，非通用词

### baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle

**关键词列表**:

- **异构混合并行策略** (技术特性): 当前模型在训练时采用的高效并行策略
- **4位2位无损量化** (技术特性): 当前模型在推理方面实现的量化算法特性
- **特定模态后训练** (技术特性): 当前模型针对特定模态进行的后训练优化

### sentence-transformers/paraphrase-MiniLM-L6-v2

**URL**: https://ai.gitcode.com/hf_mirrors/sentence-transformers/paraphrase-MiniLM-L6-v2

**关键词列表**:

- **paraphrase-MiniLM-L6-v2** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，是用户搜索该特定模型时最可能使用的关键词
- **Sentence-Transformers** (部署工具): 模型依赖的专用框架名称，用户在寻找可直接加载的句子嵌入模型时会搜索该工具名
- **Mean-Pooling** (技术特性): 模型在HuggingFace Transformers中必须使用的池化方式，是技术用户实现非sentence-transformers部署时的关键搜索词

### baidu/ERNIE-4.5-21B-A3B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-21B-A3B-Base-Paddle

**关键词列表**:

- **vLLM推理** (部署工具): README中明确提及的推理方式，用户部署时搜索

### LGAI-EXAONE/EXAONE-4.0-32B

**URL**: https://ai.gitcode.com/hf_mirrors/LGAI-EXAONE/EXAONE-4.0-32B

**关键词列表**:

- **滑动窗口注意力** (技术特性): 局部注意力实现方式为滑动窗口注意力，区别于普通注意力机制，用户可能会针对该特性搜索
- **QK重归一化** (技术特性): 模型在注意力层引入 QK 重归一化，提升下游任务性能，是模型的独特创新点
- **FriendliAI平台** (部署工具): 模型可直接在 FriendliAI 上体验和部署，是模型的官方部署渠道
- **30.95B参数** (参数规格): 模型的参数规模约 30.95B，属于大模型规格，用户在搜索参数规模时会使用该描述

### microsoft/table-transformer-structure-recognition-v1.1-all

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/table-transformer-structure-recognition-v1.1-all

**关键词列表**:

- **PubTables1M数据集** (技术特性): 当前模型训练所使用的数据集之一
- **FinTabNet.c数据集** (技术特性): 当前模型训练所使用的数据集之一
- **前置归一化** (技术特性): 当前模型采用的技术特性

### nvidia/audio-flamingo-3

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/audio-flamingo-3

**关键词列表**:

- **Audio-Flamingo-3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音频语言模型** (功能场景): 当前模型的核心定位
- **语音对话系统** (功能场景): AF3-Chat版主打端到端语音对话
- **长上下文音频理解** (技术特性): 支持最长10分钟音频输入
- **音频问答推理** (功能场景): 官方列出的典型应用
- **交互式音效设计** (功能场景): 面向开发者的创意场景

### sshleifer/distilbart-cnn-12-6

**URL**: https://ai.gitcode.com/hf_mirrors/sshleifer/distilbart-cnn-12-6

**关键词列表**:

- **CNN新闻摘要** (功能场景): 模型专注于对 CNN/DailyMail 数据集进行新闻文本摘要
- **模型蒸馏** (技术特性): DistilBART 通过蒸馏技术在保持性能的同时大幅压缩模型体积
- **轻量化摘要模型** (技术特性): 相较于原始 BART，模型更轻量，适合资源受限环境的摘要任务
- **HuggingFace兼容** (部署工具): 模型可直接通过 HuggingFace Transformers 库加载和使用

### facebook/sam2-hiera-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam2-hiera-large

**关键词列表**:

- **SAM2** (当前模型品牌名): 项目名称为facebook/sam2-hiera-large，核心品牌标识为SAM2，是当前模型的官方简称，用户搜索AI分割模型时会直接使用此名称
- **任意分割** (功能场景): README明确提到'图像与视频中的任意分割'，这是SAM2区别于其他分割模型的核心功能表述，用户会搜索'任意分割AI'这类意图明确的词
- **视频分割** (功能场景): 模型支持视频级分割，且在README中单独列出视频预测代码，是区别于静态图像分割模型（如SAM1）的关键差异化功能
- **hiera-large** (当前模型品牌名): 模型全称为'sam2-hiera-large'，'hiera-large'是其架构变体名称，在技术社区中常作为独立关键词用于区分不同规模版本
- **Mask-Generation** (功能场景): 标签中明确标注'Mask Generation'，是用户在图像处理、CV工程中搜索分割结果输出时的高频术语，具象且非通用
- **arxiv2408.00714** (技术特性): 论文编号是该模型唯一官方学术标识，研究者和工程师常直接搜索arxiv编号定位模型，具有强指向性和低竞争性

### timm/convnextv2_nano.fcmae_ft_in22k_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/convnextv2_nano.fcmae_ft_in22k_in1k

**关键词列表**:

- **convnextv2nano.fcmaeftin22kin1k** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **ConvNeXt-V2** (当前模型品牌名): 模型类型名称，代表模型架构
- **FCMAE框架** (技术特性): 当前模型使用的预训练框架
- **ImageNet-22k微调** (技术特性): 当前模型在ImageNet-22k数据集上进行了微调
- **ImageNet-1k微调** (技术特性): 当前模型在ImageNet-1k数据集上进行了微调

### vidore/colpali-v1.3

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colpali-v1.3

**关键词列表**:

- **PaliGemma-3B** (技术特性): 模型基于的VLM骨架，技术向用户常用此关键词定位模型
- **256批次训练** (技术特性): 训练配置亮点，开发者复现或对比模型时会搜索具体批次规模

### flair/ner-english-fast

**URL**: https://ai.gitcode.com/hf_mirrors/flair/ner-english-fast

**关键词列表**:

- **flairner-english-fast** (当前模型品牌名): 项目名称直接对应模型标识符，是用户在GitCode或AI社区搜索该特定模型时的精确关键词
- **英文命名实体识别** (功能场景): 用户搜索AI模型时常用‘英文NER’或‘英文命名实体识别’这类明确任务词，该模型专为英文实体识别设计，具有明确场景指向性
- **LSTM-CRF** (技术特性): 该模型采用LSTM-CRF架构，是区别于Transformer类NER模型的核心技术标签，搜索者常通过架构关键词筛选模型
- **序列标注模型** (技术特性): NER属于序列标注任务，该词是NLP领域对这类模型的通用技术分类，用户在学术或工程场景中常搜索此术语
- **Flair框架** (部署工具): 模型必须通过Flair库加载，用户会搜索‘Flair框架 NER’来寻找兼容该生态的模型，具有工具链指向性
- **token-classification** (技术特性): 该标签是Hugging Face生态中对NER任务的标准术语，技术用户在搜索模型时会使用此标准任务分类词

### nvidia/segformer-b0-finetuned-ade-512-512

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/segformer-b0-finetuned-ade-512-512

**关键词列表**:

- **SegFormer-B0** (当前模型品牌名): 模型名称直接来源于项目名，标识该模型的具体版本
- **ADE20K数据集** (功能场景): 模型在 ADE20K 数据集上进行微调，是用户搜索该数据集对应分割模型时的关键词
- **512x512分辨率** (技术特性): 模型在 512×512 分辨率下进行微调，适用于高分辨率图像分割需求
- **NVIDIA模型** (当前模型品牌名): 模型由 NVIDIA 官方发布，品牌属性是用户检索时的重要标签

### merve/smol-vision

**URL**: https://ai.gitcode.com/hf_mirrors/merve/smol-vision

**关键词列表**:

- **Smol-Vision** (当前模型品牌名): 项目标题直接给出的品牌名称
- **视觉模型压缩** (功能场景): README核心卖点：压缩、优化视觉模型
- **ColPali微调** (功能场景): README突出展示的微调示例，用户会搜具体微调方案
- **Gemma-3n全模态微调** (功能场景): README强调支持音频-文本-图像全模态微调
- **OmniEmbed视频RAG** (功能场景): README最新示例：任意模态视频RAG实现
- **QLoRA修复脚本** (部署工具): README特别提到已修复QLoRA相关问题，用户会搜修复版脚本
- **OWLv2量化** (技术特性): README示例中用Optimum量化零样本目标检测模型OWLv2

### distilbert/distilbert-base-cased-distilled-squad

**URL**: https://ai.gitcode.com/hf_mirrors/distilbert/distilbert-base-cased-distilled-squad

**关键词列表**:

- **squad** (功能场景): 模型在SQuAD v1.1数据集上微调，专用于问答任务，用户搜索'QA模型'或'squad模型'时会精准匹配此关键词
- **轻量级问答模型** (功能场景): 模型定位为轻量、快速的问答系统，符合用户对'轻量级问答'的搜索意图，且未被高频词列表覆盖
- **DistilBERT-base-cased** (当前模型品牌名): 模型的完整基础名称，虽含后缀但属于官方命名体系，用户在搜索具体微调版本时会使用该完整名称，且未被高频词排除
- **问答模型** (功能场景): 模型用途明确为问答（question-answering），是用户在CSDN等平台搜索AI问答系统时的高频意图词，且未被高频词列表禁止
- **Hugging-Face模型** (部署工具): 模型由Hugging Face官方发布，用户常搜索'Hugging Face模型'来寻找可直接加载的预训练模型，该词具平台指向性且未被高频词排除

### facebook/bart-base

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/bart-base

**关键词列表**:

- **facebookbart-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **seq2seq模型** (技术特性): 当前模型属于seq2seq架构，是其核心特性
- **双向编码器** (技术特性): 当前模型包含双向编码器，是其技术特点之一
- **自回归解码器** (技术特性): 当前模型包含自回归解码器，是其技术特点之一
- **文本重建** (功能场景): 当前模型的预训练过程包括文本重建任务

### openai/whisper-large-v3-turbo

**URL**: https://ai.gitcode.com/hf_mirrors/openai/whisper-large-v3-turbo

**关键词列表**:

- **Whisper-large-v3-turbo** (当前模型品牌名): 从项目名称直接提取的当前模型唯一名称，是用户搜索该优化版本的精准关键词
- **语音转文字** (功能场景): 用户搜索ASR模型时最常用的中文意图词，对应Whisper的核心功能，且未被列入高频排除词
- **零样本语音识别** (技术特性): 模型README明确强调的原创能力，具有技术区分度，非通用术语，未被高频词库覆盖
- **4层解码** (技术特性): Whisper-large-v3-turbo区别于原版的核心技术改动，用户可能搜索‘轻量版Whisper’或‘低层数语音模型’时使用
- **97种语言语音转录** (功能场景): 模型支持多语言转录的明确卖点，用户在搜索‘多语言ASR’或‘支持97种语言的语音模型’时可能使用
- **Hugging-Face语音模型** (部署工具): 模型通过Hugging Face Transformers部署，用户常搜‘Hugging Face 语音识别’，该词未被高频排除词库覆盖

### facebook/sam2.1-hiera-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam2.1-hiera-large

**关键词列表**:

- **提示分割** (功能场景): 用户通过点、框、文本等提示即可生成分割结果
- **Hiera架构** (技术特性): SAM2 采用 Hiera 分层视觉骨干网络，提升效率与精度

### microsoft/git-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/git-base

**关键词列表**:

- **GIT** (当前模型品牌名): 模型官方名称 GIT（Generative Image-to-Text）
- **Git-base** (当前模型品牌名): 项目在 GitHub/HuggingFace 上的完整模型标识
- **教师强制** (技术特性): 模型在训练时采用 Teacher‑forcing 方法
- **双向注意力** (技术特性): 在处理图像 tokens 时使用双向注意力掩码
- **8亿图像文本对** (技术特性): 模型预训练使用约 800 million 对图像‑文本数据

### QuantStack/Wan2.1_I2V_14B_FusionX-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/QuantStack/Wan2.1_I2V_14B_FusionX-GGUF

**关键词列表**:

- **Wan2.1I2V14BFusionX** (当前模型品牌名): 从项目名称提取的当前模型名称
- **图像到视频转换** (功能场景): 当前模型的核心功能，将图像转换为视频
- **量化转换版本** (技术特性): 当前模型是量化转换版本，具有技术独特性

### nateraw/vit-age-classifier

**URL**: https://ai.gitcode.com/hf_mirrors/nateraw/vit-age-classifier

**关键词列表**:

- **vit-age-classifier** (当前模型品牌名): 项目名称为nateraw/vit-age-classifier，直接提取模型唯一品牌名，简洁且为用户搜索该模型的精准关键词
- **人脸年龄分类** (功能场景): 模型核心功能是对人脸进行年龄分类，该词是用户在CSDN等平台搜索AI人脸分析模型时的典型搜索词，具有明确意图且未被高频词库覆盖
- **ViT图像分类** (技术特性): 模型基于Vision Transformer（ViT）实现图像分类，'ViT图像分类'是用户搜索视觉Transformer在图像任务中应用时的常用组合词，区别于通用'图像分类'，具有技术特异性
- **人脸年龄识别** (功能场景): 与'人脸年龄分类'语义相近但表达更贴近中文搜索习惯（如'识别'比'分类'更常用于安防、社交场景），且未被列入高频排除词库，具有搜索增量价值
- **HuggingFace模型** (部署工具): 模型托管于HuggingFace，用户常搜索'HuggingFace模型'来查找可直接加载的预训练模型，该词是部署入口级关键词，且未被排除（排除词为'HuggingFace'单独词，非组合词）

### Intel/dpt-large

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/dpt-large

**关键词列表**:

- **DPT-Large** (当前模型品牌名): 项目名称为Intel/dpt-large，模型官方名称为DPT-Large，是当前模型的唯一品牌标识

### unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF

**关键词列表**:

- **Qwen3-Coder** (当前模型品牌名): 项目核心模型名称，用户直接搜索
- **480B参数** (参数规格): 超大参数规模，极具辨识度
- **智能体编码** (功能场景): 官方强调的核心能力，用户会搜

### autogluon/mitra-classifier

**URL**: https://ai.gitcode.com/hf_mirrors/autogluon/mitra-classifier

**关键词列表**:

- **Mitra** (当前模型品牌名): 从项目名称提取的当前模型名称
- **表格分类** (功能场景): 当前模型专用于表格数据的分类任务
- **7200万参数** (参数规格): 当前模型参数量级，介于7B与32B之间，具有区分度

### Disya/UIGEN-T3-14B-Preview-Q4_K_M-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Disya/UIGEN-T3-14B-Preview-Q4_K_M-GGUF

**关键词列表**:

- **UIGENT3** (当前模型品牌名): 从项目仓库名称 Disya/UIGEN‑T3‑14B‑Preview‑Q4_K_M‑GGUF 中提取的简化模型名称
- **UI生成** (功能场景): 模型专注于根据文本提示自动生成网页界面和 UI 代码
- **Tailwind-CSS** (技术特性): 模型输出的前端样式采用 Tailwind CSS 框架，具备轻量化、可定制的特性
- **llama.cpp** (部署工具): 模型以 GGUF 格式提供，可直接通过 llama.cpp 的 CLI 或服务器模式本地部署运行
- **Q4KM量化** (技术特性): 模型采用 Q4_K_M 量化方式，兼顾显存占用与推理速度
- **HTML生成** (功能场景): 模型能够根据指令输出完整的 HTML 页面代码，适用于快速原型开发
- **textgenerationinference** (技术特性): 模型支持高效的文本生成推理接口，可用于对话式或指令式文本输出

### vidore/colqwen2-v1.0

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colqwen2-v1.0

**关键词列表**:

- **多向量表示** (技术特性): 模型生成‘ColBERT风格的文本与图像多向量表示’，这是区别于传统单向量检索的核心技术特征，具有独特性且未被高频词覆盖
- **图像补丁** (技术特性): 模型以‘图像补丁（image patches）’为基本处理单元，最大支持768个，这是视觉语言检索中的专业术语，具有区分度且未被高频词排除
- **合成数据增强** (训练策略): 训练中使用Claude-3 Sonnet生成的伪问题构建合成数据集，这是模型训练的独特数据策略，属于高价值差异化关键词
- **零样本泛化** (功能场景): 模型训练数据为全英文，专门用于研究非英语语言的零样本泛化能力，这是用户在评估跨语言检索模型时会搜索的核心场景

### LiquidAI/LFM2-1.2B

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B

**关键词列表**:

- **LFM2-1.2B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **边缘人工智能** (功能场景): 当前模型专为边缘人工智能和端侧部署设计
- **混合液态模型架构** (技术特性): 当前模型采用具备乘法门控机制和短卷积结构的全新混合液态模型架构
- **快速训练与推理** (技术特性): 当前模型在训练速度和推理速度上有显著提升
- **多语言能力** (功能场景): 当前模型在多语言能力方面表现优异
- **灵活部署方案** (部署工具): 当前模型可高效运行于多种硬件平台，支持灵活部署

### julien-c/skops-digits

**URL**: https://ai.gitcode.com/hf_mirrors/julien-c/skops-digits

**关键词列表**:

- **skops-digits** (当前模型品牌名): 从项目名称 'julien-c/skops-digits' 直接提取的模型唯一标识，用户搜索特定分类模型时会使用该名称
- **tabular-classification** (功能场景): 模型明确标注的标签，代表其核心用途是结构化表格数据分类，是用户搜索AI表格建模时的精准关键词
- **scikit-learn** (部署工具): 模型基于scikit-learn构建，是用户寻找传统机器学习框架下可部署分类模型时的关键搜索词，且未被禁用高频词列表覆盖
- **adam** (技术特性): 模型使用adam优化器作为核心训练算法，是机器学习从业者搜索优化器配置时的高频技术关键词，且未被禁用
- **mlp** (技术特性): 根据hidden_layer_sizes=(100,)和activation=relu可推断为多层感知机（MLP），是用户搜索传统神经网络结构时的精准术语

### facebook/vjepa2-vitl-fpc64-256

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitl-fpc64-256

**关键词列表**:

- **AutoVideoProcessor** (部署工具): 官方提供的视频处理工具，用于加载和预处理视频输入

### ecmwf/aifs-ens-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/ecmwf/aifs-ens-1.0

**关键词列表**:

- **AIFS-ENS** (当前模型品牌名): 项目名称为ecmwf/aifs-ens-1.0，模型官方名称为AIFS ENS，是当前模型的唯一品牌标识
- **集成预报** (功能场景): 模型核心功能是生成概率性集成天气预报，用户搜索‘气象集成预报’或‘AI集成天气模型’时会使用该词
- **滑动窗口变换** (技术特性): 模型采用‘滑动窗口变换处理器’作为关键技术组件，属于独特架构设计，非通用术语
- **CRPS优化** (技术特性): 模型通过最小化连续分级概率评分（CRPS）进行训练，这是气象AI领域专业但非泛滥的优化目标术语
- **气象AI预报** (功能场景): 用户搜索‘AI做天气预报’‘气象预测AI’等意图明确的场景词，该词精准对应模型用途且未被高频词库覆盖
- **ERA5再分析** (技术特性): 模型训练依赖ECMWF的ERA5再分析数据，这是气象AI领域特有数据源，具有高区分度

### calcuis/bagel-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/calcuis/bagel-gguf

**关键词列表**:

- **bagel-gguf** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多模态试验模型** (技术特性): 当前模型具备多模态试验能力，是区别于其他模型的技术特性
- **文本转图像** (功能场景): 当前模型支持文本转图像功能，是用户可能搜索的功能场景
- **图像编辑识别** (功能场景): 当前模型支持图像编辑和识别功能，是用户可能搜索的功能场景
- **gguf-connector** (部署工具): 当前模型使用gguf-connector运行，是部署该模型所需的工具
- **fp816缩放版** (技术特性): 当前模型提供fp8/16缩放版本，是区别于其他模型的技术特性

### philschmid/bart-large-cnn-samsum

**URL**: https://ai.gitcode.com/hf_mirrors/philschmid/bart-large-cnn-samsum

**关键词列表**:

- **bart-large-cnn-samsum** (当前模型品牌名): 模型名称直接来源于项目仓库名，唯一标识当前模型
- **SAMSum数据集** (技术特性): 模型在公开的 SAMSum 对话摘要数据集上进行微调
- **Amazon-SageMaker训练** (部署工具): 模型使用 Amazon SageMaker 平台完成训练
- **Hugging-Face深度学习容器** (部署工具): 训练过程基于 Hugging Face 官方深度学习容器
- **FP16混合精度** (技术特性): 超参数中启用了 fp16，提升训练效率并降低显存占用
- **ROUGE-1指标** (技术特性): 模型在评估时使用 ROUGE‑1 作为主要质量指标

### MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli

**URL**: https://ai.gitcode.com/hf_mirrors/MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli

**关键词列表**:

- **NLI模型** (功能场景): 自然语言推理（NLI）是该模型的垂直领域，用户在学术或工程场景中搜索‘NLI模型’时会精准定位该模型
- **MNLI-FEVER-ANLI** (当前模型品牌名): 模型微调所用的三大核心数据集组合，构成该模型的独特标识，是区别于其他DeBERTa模型的关键特征
- **LingNLI** (当前模型品牌名): 模型微调所用的专属数据集，非通用术语，具有高度区分度，是该模型在语言学推理任务中的独特标签
- **WANLI** (当前模型品牌名): 模型微调所用的对抗性自然语言推理数据集，是该模型在ANLI基准上表现优异的关键训练来源，具独特性

### google/owlvit-large-patch14

**URL**: https://ai.gitcode.com/hf_mirrors/google/owlvit-large-patch14

**关键词列表**:

- **OWLViT** (当前模型品牌名): 项目名称核心词，用户直接搜索模型简称
- **零样本目标检测** (功能场景): 模型主打能力，用户用此词找无需训练的检测方案
- **开放词汇检测** (功能场景): 突出任意文本提示即可检测，精准匹配搜索意图
- **ViT-L-14** (技术特性): CLIP视觉主干规格，开发者常按架构型号检索
- **文本条件检测** (功能场景): 强调用文本查询驱动检测，符合技术博客关键词习惯
- **CLIP检测** (技术特性): 依托CLIP实现检测，用户会组合CLIP+检测搜索

### amazon/chronos-t5-small

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-t5-small

**关键词列表**:

- **chronos-t5-small** (当前模型品牌名): 从项目名称提取的当前模型名称
- **预训练模型** (功能场景): 当前模型是预训练的时间序列预测模型

### ETH-CVG/lightglue_superpoint

**URL**: https://ai.gitcode.com/hf_mirrors/ETH-CVG/lightglue_superpoint

**关键词列表**:

- **LightGlue** (当前模型品牌名): 项目名称直接给出的当前模型名称
- **SuperPoint** (当前模型品牌名): 与LightGlue配套使用的特征提取模型，同属当前项目
- **图像匹配** (功能场景): README明确指出的核心应用场景
- **单应性估计** (功能场景): README列出的典型任务之一
- **局部特征匹配** (功能场景): LightGlue专门解决的任务，用户搜索意图明确
- **位姿估计** (功能场景): 通过匹配结果估计图像间位姿，是SLAM与3D重建常用需求
- **自适应推理** (技术特性): LightGlue可根据图像对难度动态调整计算量，突出卖点

### dmis-lab/biobert-large-cased-v1.1-squad

**URL**: https://ai.gitcode.com/hf_mirrors/dmis-lab/biobert-large-cased-v1.1-squad

**关键词列表**:

- **BioBERT** (当前模型品牌名): 项目名称为biobert-large-cased-v1.1-squad，核心品牌名为BioBERT，是该模型家族的唯一标识，用户搜索生物医学问答模型时会直接使用此名称
- **生物医学问答** (功能场景): 模型专为生物医学领域问答任务优化，区别于通用QA，是其核心应用场景，用户在医学AI领域搜索时会使用此精准词组
- **PubMed预训练** (技术特性): 模型在PubMed文献语料上进行专项预训练，是其区别于通用BERT的关键技术特征，专业用户会以此作为筛选条件
- **PMC预训练** (技术特性): 模型同时在PMC（PubMed Central）生物医学全文库上训练，该数据源专属于生物医学AI，是其独特训练背景，具有高区分度
- **BioBERT-v1.0** (当前模型品牌名): 模型基于BioBERT v1.0架构演进，该版本号在学术论文与社区中被广泛引用，是用户检索该模型系列的常用关键词
- **生物医学BERT** (技术特性): 用户常将‘生物医学+BERT’组合搜索，该词精准描述模型类型，是领域内非品牌用户的自然搜索词，且未被高频词库覆盖

### mistralai/Voxtral-Small-24B-2507

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Voxtral-Small-24B-2507

**关键词列表**:

- **音频翻译** (功能场景): 模型能够将音频内容直接翻译成目标语言，属于独特的音频处理能力
- **长音频理解** (功能场景): 凭借 32k token 上下文，模型可处理长达 30‑40 分钟的音频
- **vllm兼容** (部署工具): 模型推荐使用 vllm 部署，满足高效推理需求

### Salesforce/blip-vqa-capfilt-large

**URL**: https://ai.gitcode.com/hf_mirrors/Salesforce/blip-vqa-capfilt-large

**关键词列表**:

- **BLIP-vqa-capfilt-large** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，用户搜索该具体模型时会使用此完整名称
- **自举式生成** (技术特性): BLIP论文提出的独特训练机制，通过合成字幕+噪声过滤提升性能，是该模型的技术创新点
- **ViT大型骨干** (技术特性): 模型明确使用ViT-Large作为视觉编码器，是其架构关键特征，区别于其他使用ViT-Base或ResNet的模型

### openbmb/MiniCPM-V-2

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/MiniCPM-V-2

**关键词列表**:

- **MiniCPM-V-2** (当前模型品牌名): 从项目名称提取的当前模型名称
- **MiniCPM-o-2.6** (当前模型品牌名): README中最新开源的模型版本名称
- **多模态直播** (功能场景): MiniCPM-o 2.6版本支持的新功能
- **iPad端实时视频理解** (功能场景): MiniCPM-V 2.6版本支持的新功能
- **vLLM推理加速** (技术特性): MiniCPM-V 2.0版本支持的技术特性
- **SWIFT框架微调** (技术特性): MiniCPM-V 2.0版本支持的技术特性

### depth-anything/Depth-Anything-V2-Large

**URL**: https://ai.gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Large

**关键词列表**:

- **Depth-Anything-V2** (当前模型品牌名): 从项目名称提取的当前模型名称，去掉冗余后缀
- **相对深度** (功能场景): README标签中提到的深度类型，用户会搜索
- **微调预训练** (部署工具): README提到“使用预训练模型进行微调”，用户会搜

### kankur0007/2DseisvelGenerator

**URL**: https://ai.gitcode.com/hf_mirrors/kankur0007/2DseisvelGenerator

**关键词列表**:

- **2DseisvelGenerator** (当前模型品牌名): 项目名称直接定义的模型品牌，用户搜索地球科学AI生成模型时可能直接使用此名称
- **地震速度模型生成** (功能场景): 模型核心功能是生成合成地震速度模型，属于地球物理领域特异性应用场景，非通用词
- **全波形反演** (功能场景): 模型明确服务于FWI任务，是地球物理专业用户搜索AI辅助反演时的关键术语
- **OpenFWI数据集** (技术特性): 模型训练基于该特定公开数据集，专业用户会搜索‘OpenFWI + AI生成’组合关键词
- **地震数据偏差减少** (功能场景): 模型核心目标是降低合成数据偏差，属于高价值专业痛点，非通用表述
- **地震信号合成** (功能场景): 模型生成的是地震信号对应的速度场，该短语精准描述其输出内容，专业用户会搜索

### NexaAIDev/Qwen2-Audio-7B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/NexaAIDev/Qwen2-Audio-7B-GGUF

**关键词列表**:

- **Qwen2-Audio** (当前模型品牌名): 项目名称中直接出现的模型完整名称，用户搜索时会使用该品牌名
- **语音聊天** (功能场景): 模型支持直接的语音对话交互，是用户常搜索的使用场景
- **说话人识别** (功能场景): 模型具备辨别并响应不同说话人的能力，属于核心功能关键词
- **噪声检测** (功能场景): 模型能够检测背景噪声并作出响应，是音频处理常见需求
- **音乐分析** (功能场景): 模型支持对音乐及声音进行分析，覆盖音频内容理解的典型场景
- **Nexa-SDK** (部署工具): 官方提供的本地推理框架，用户在搜索本地部署方案时会使用该名称
- **AudioLM-架构** (技术特性): 模型基于 AudioLM 技术，实现音频‑文本联合建模，是独特的技术标签
- **q4KM-量化** (技术特性): 默认提供的高效量化版本，用户在寻找轻量化模型时会关注该量化方式

### facebook/dinov2-large

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dinov2-large

**关键词列表**:

- **ViT-large** (参数规格): 对应项目名中的large规模，用户会搜ViT-large

### unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF

**关键词列表**:

- **Qwen3-Coder-480B-A35B-Instruct** (当前模型品牌名): 从项目名称直接提取的完整模型名称，是当前模型的唯一标识，用户搜索高参数代码模型时会精确使用此名称
- **百万上下文** (技术特性): 模型核心亮点是上下文长度从256K扩展至100万，'百万上下文'是用户搜索长上下文代码模型时的高频表达，且未被高频词列表禁止
- **A35B-Instruct** (当前模型品牌名): A35B-Instruct是模型名称的子组件，代表其指令微调架构，在模型全称中具有辨识度，用户可能搜索该子型号以区分不同变体

### FluidInference/silero-vad-coreml

**URL**: https://ai.gitcode.com/hf_mirrors/FluidInference/silero-vad-coreml

**关键词列表**:

- **Silero-VAD** (当前模型品牌名): 从项目名称提取的当前模型名称
- **CoreML** (部署工具): Apple平台专用部署格式
- **iOS实时语音** (功能场景): 主要使用场景之一
- **macOS语音识别** (功能场景): 另一主要使用场景
- **Swift集成** (部署工具): iOS/macOS开发者常用语言

### mradermacher/GCIRS-Reasoning-1.5B-R1-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/GCIRS-Reasoning-1.5B-R1-i1-GGUF

**关键词列表**:

- **GCIRS-Reasoning-1.5B** (当前模型品牌名): 从项目名称提取的当前模型核心名称
- **加权量化版本** (技术特性): 当前模型版本特性，区别于其他版本
- **矩阵量化** (技术特性): 当前模型版本的技术特性描述

### ByteDance-Seed/VINCIE-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/VINCIE-3B

**关键词列表**:

- **VINCIE-3B** (当前模型品牌名): 项目名称为ByteDance-Seed/VINCIE-3B，根据规则提取模型简洁品牌名，且未在强制排除列表中
- **视频驱动的上下文图像编辑** (功能场景): 模型核心创新功能，用户可能搜索‘视频驱动图像编辑’或‘上下文图像编辑’这类具体应用场景，具有高度区分度
- **块因果扩散Transformer** (技术特性): 模型独有的架构设计，非通用术语，是论文提出的核心技术，具有技术独特性
- **多轮图像编辑** (功能场景): 论文提出的新基准与核心应用场景，非通用词，用户可能搜索‘多轮图像编辑模型’以寻找同类工具
- **下一帧图像预测** (技术特性): 模型训练的三大代理任务之一，属于模型特有的学习目标，非通用AI术语，具备区分度
- **当前帧分割预测** (技术特性): 模型训练的专属代理任务，与视频驱动编辑直接相关，是区别于其他图像编辑模型的关键技术点
- **下一帧分割预测** (技术特性): 与上一条构成完整视频上下文建模体系，是VINCIE-3B独有的训练机制，非通用词汇

### BCCard/Qwen2.5-VL-32B-Instruct-FP8-Dynamic

**URL**: https://ai.gitcode.com/hf_mirrors/BCCard/Qwen2.5-VL-32B-Instruct-FP8-Dynamic

**关键词列表**:

- **Qwen2.5-VL-32B-Instruct-FP8-Dynamic** (当前模型品牌名): 项目完整名称，用户会按全称搜索
- **vLLM部署** (部署工具): 官方示例明确使用vLLM进行高效推理
- **视觉-文本** (功能场景): 模型输入类型，用户搜索视觉文本多模态场景
- **动态量化** (技术特性): 模型名称中的Dynamic体现的动态量化能力
- **BC-Card** (当前模型品牌名): 模型开发方品牌，用户可能直接搜索

### chancharikm/qwen2.5-vl-7b-cam-motion-preview

**URL**: https://ai.gitcode.com/hf_mirrors/chancharikm/qwen2.5-vl-7b-cam-motion-preview

**关键词列表**:

- **Cam-Motion-Preview** (当前模型品牌名): 从项目名称提取的模型品牌名，去除版本号和冗余信息
- **Camera-motion-classification** (功能场景): 模型的核心应用场景之一，用于在视频中对相机运动进行分类
- **Video-Text-Retrieval** (功能场景): 模型支持的视频文本检索任务，属于主要使用场景
- **CameraBench** (技术特性): 模型在该公开基准上进行评估，体现其技术定位
- **VQAScore** (技术特性): 用于衡量相机运动字幕检索质量的评分方法，模型采用该指标
- **Generative-Scoring** (技术特性): 模型提供的生成式评分机制，可用于分类和检索任务
- **高质量相机运动数据集** (技术特性): 模型在该高质量公开数据集上进行微调，提升任务表现

### zai-org/GLM-4.5

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5

**关键词列表**:

- **3550亿参数** (参数规格): 当前模型GLM-4.5的总参数规模，具有区分度
- **320亿活跃参数** (参数规格): 当前模型GLM-4.5的活跃参数规模，体现模型能力
- **MIT开源协议** (技术特性): 当前模型的开源协议，可用于商业用途和二次开发

### llava-hf/llava-1.5-7b-hf

**URL**: https://ai.gitcode.com/hf_mirrors/llava-hf/llava-1.5-7b-hf

**关键词列表**:

- **LLaVA-1.5-7B** (当前模型品牌名): 从项目名称 hf_mirrors/llava-hf/llava-1.5-7b-hf 提取的完整模型品牌名，符合简化规则（保留版本号但去后缀-hf），是用户搜索该特定版本的精准关键词
- **图像问答** (功能场景): 模型用于根据图像内容回答问题，是用户在CSDN等平台搜索‘图像问答AI’‘图片提问模型’等意图的精准场景词，区别于泛用的‘文生图’或‘视觉问答’（后者被禁）
- **多图像输入** (功能场景): 模型支持‘多图像和多提示生成’，这是其区别于其他视觉语言模型的独特功能，用户可能搜索‘支持多图输入的AI模型’，该词具有区分度
- **LLaMA微调** (技术特性): 模型基于LLaMA/Vicuna微调，虽禁止提取‘LLaMA’，但‘LLaMA微调’作为技术路径描述未被禁用，且是技术社区中对这类模型的常见搜索词

### bralynn/pydevmini1

**URL**: https://ai.gitcode.com/hf_mirrors/bralynn/pydevmini1

**关键词列表**:

- **PyDevMini1** (当前模型品牌名): 项目名称即模型品牌名，用户搜索时会直接使用
- **262k上下文长度** (技术特性): 原生上下文长度达262,144 token，属于长上下文特性，具备搜索价值
- **36层网络** (技术特性): 模型拥有 36 层深度，层数信息常被用于区分模型规模

### Qwen/Qwen3-Next-80B-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Next-80B-A3B-Thinking

**关键词列表**:

- **Qwen3-Next** (当前模型品牌名): 项目名称核心品牌标识，符合国产大模型映射规则（Qwen → 通义千问），但‘Qwen3-Next’是该系列全新命名，未在高频词列表中，具有唯一性
- **混合注意力机制** (技术特性): 模型核心创新点，特指‘门控DeltaNet + 门控注意力’组合，非通用术语，用户搜索‘混合注意力模型’时可能精准匹配
- **高稀疏MoE** (技术特性): 模型关键架构创新，强调‘高稀疏’特性以降低FLOPs，区别于普通MoE，是专业用户搜索高效推理模型时的精准关键词
- **多token预测** (技术特性): 模型独有预训练技术（MTP），提升推理速度，非通用术语，用户搜索‘多token预测模型’可精准定位该模型
- **80B参数** (参数规格): 模型参数规模为80B，属于主流大模型规格（介于32B与175B之间），未在高频词列表中，具有区分度
- **GSPO** (技术特性): 模型专属强化学习优化技术（GSPO），用于解决混合注意力与高稀疏MoE在RL中的稳定性问题，技术术语独特，搜索量低但精准
- **零中心层归一化** (技术特性): 模型稳定性优化关键技术，全称‘零中心带权重衰减的层归一化’，术语专业且非通用，可吸引研究型用户搜索‘零中心layernorm模型’

### unsloth/ERNIE-4.5-21B-A3B-Thinking-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/ERNIE-4.5-21B-A3B-Thinking-GGUF

**关键词列表**:

- **3B激活参数** (参数规格): MoE架构下每个token仅激活3B，用户关注轻量推理

### inclusionAI/Ming-Lite-Omni-1.5

**URL**: https://ai.gitcode.com/hf_mirrors/inclusionAI/Ming-Lite-Omni-1.5

**关键词列表**:

- **Ming-Lite-Omni** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **语音合成** (功能场景): 模型新增高质量实时语音输出能力，用户高频搜索
- **203亿参数** (参数规格): 总参数量级显眼，用户会搜‘200亿参数大模型’
- **MRoPE** (技术特性): 模型自研三维时空编码技术，技术爱好者会检索

### calcuis/hunyuanimage-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/calcuis/hunyuanimage-gguf

**关键词列表**:

- **图像精炼** (功能场景): README明确提到对模糊/低质量图像进行精炼/锐化处理，是该模型独有的核心功能，非通用词
- **轻量版v2** (当前模型品牌名): 模型明确区分'v2'轻量化版本，且强调8步生成、60-70%加载节省，是区别于标准版的独立产品形态
- **8步生成** (技术特性): 蒸馏模型仅需8步即可输出，是该模型在推理效率上的独特卖点，用户会搜索'几步生成'类关键词
- **ComfyUI-gguf节点** (部署工具): 模型明确依赖ComfyUI的gguf节点加载，是部署方式的精准描述，区别于泛泛的'ComfyUI'（已被排除）
- **1.5-cfg** (技术特性): README以'cfg=1.5'作为演示参数，是该模型在低cfg下仍保持高质量输出的特殊配置，具区分度

### Alpha-VLLM/Lumina-DiMOO

**URL**: https://ai.gitcode.com/hf_mirrors/Alpha-VLLM/Lumina-DiMOO

**关键词列表**:

- **Lumina-DiMOO** (当前模型品牌名): 从项目名称提取的当前模型名称
- **统一离散扩散架构** (技术特性): 当前模型采用的独特技术架构
- **多样化多模态能力** (技术特性): 当前模型支持广泛的多模态任务，是其核心特性之一
- **采样效率提升** (技术特性): 当前模型展现出卓越的采样效率，并设计了定制化缓存方法进一步提升速度
- **图像编辑对比** (功能场景): 当前模型支持图像编辑等任务，展示其多模态生成与理解能力

### google/pegasus-large

**URL**: https://ai.gitcode.com/hf_mirrors/google/pegasus-large

**关键词列表**:

- **C4数据集** (技术特性): 模型训练使用的核心数据集，用户会搜
- **HugeNews数据集** (技术特性): 模型训练使用的另一核心数据集，用户会搜
- **xsum基准** (技术特性): README中列出的权威评测基准，用户验证模型效果时会搜
- **cnndailymail基准** (技术特性): README中列出的权威评测基准，用户验证模型效果时会搜

### microsoft/speecht5_tts

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/speecht5_tts

**关键词列表**:

- **SpeechT5** (当前模型品牌名): 从项目名称 microsoft/speecht5_tts 中提取的当前模型唯一品牌名，是用户搜索TTS模型时的核心关键词
- **统一模态** (技术特性): 模型核心创新点为'统一模态编码器-解码器框架'，是SpeechT5区别于其他TTS模型的独特技术标签
- **跨模态向量量化** (技术特性): 论文中提出的独家方法，用于对齐语音与文本语义空间，具有高区分度且未被高频词库覆盖
- **LibriTTS** (训练数据): 模型微调所用的专属数据集，用户搜索特定TTS模型时会关联数据源，属于模型专属标识
- **编码器-解码器** (技术特性): 模型架构核心组件，虽为通用术语，但结合SpeechT5的统一模态设计，构成用户搜索该模型的技术关键词组合

### iSEE-Laboratory/llmdet_large

**URL**: https://ai.gitcode.com/hf_mirrors/iSEE-Laboratory/llmdet_large

**关键词列表**:

- **LLMDet** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **大语言模型协同训练** (技术特性): 模型通过与大型语言模型协同训练提升检测能力
- **检查点推理** (部署工具): 提供的检查点仅用于推理，适合直接部署使用
- **Zero-Shot-Object-Detection** (功能场景): 模型的英文描述关键词，便于国际化搜索

### apple/mobilevit-small

**URL**: https://ai.gitcode.com/hf_mirrors/apple/mobilevit-small

**关键词列表**:

- **MobileViT-small** (当前模型品牌名): 从项目名称提取的当前模型名称
- **轻量级卷积神经网络** (技术特性): 当前模型的核心技术特性描述
- **低延迟** (技术特性): 当前模型的技术特性之一
- **MobileNetV2风格层** (技术特性): 当前模型结合的技术特性之一
- **全局处理** (技术特性): 当前模型使用的transformers进行全局处理的技术特性

### microsoft/TRELLIS-text-large

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/TRELLIS-text-large

**关键词列表**:

- **TRELLIS-text-large** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，简洁且为用户搜索该模型的核心关键词
- **3D生成模型** (功能场景): 描述模型本质用途，用户会搜索‘3D生成模型’来寻找类似TRELLIS的工具，非通用词且未被排除
- **Structured-3D-Latents** (技术特性): 论文中提出的核心技术术语，是该模型区别于其他3D生成模型的独特技术概念，具有高区分度
- **Trellis** (当前模型品牌名): 模型简称，与全称TRELLIS-text-large形成品牌关联，用户可能搜索简写形式

### openai/diffusers-cd_bedroom256_lpips

**URL**: https://ai.gitcode.com/hf_mirrors/openai/diffusers-cd_bedroom256_lpips

**关键词列表**:

- **Consistency-Distillation** (技术特性): 模型采用一致性蒸馏（Consistency Distillation）技术，实现噪声到图像的直接映射
- **CD-Bedroom256** (当前模型品牌名): 项目名称中包含的唯一标识，表示针对 256×256 LSUN Bedroom 数据集的 CD（Consistency Distillation）模型
- **LPIPS** (技术特性): 模型在训练和评估中使用 LPIPS 作为感知相似度指标，区别于常规的像素误差
- **Onestep-Generation** (功能场景): 模型支持一步采样即可生成高质量图像，满足极速生成需求
- **Zeroshot-Image-Editing** (功能场景): 模型能够在无需额外微调的情况下完成图像修复、着色等零样本编辑任务
- **Fast-Sampling** (技术特性): 相较于传统扩散模型，模型显著降低采样步骤，实现快速图像生成
- **Diffusion-Model-Distillation** (技术特性): 模型通过蒸馏预训练的扩散模型获得一致性模型，提升生成效率与质量

### MachineLearningLM/MachineLearningLM-7B-v1

**URL**: https://ai.gitcode.com/hf_mirrors/MachineLearningLM/MachineLearningLM-7B-v1

**关键词列表**:

- **MachineLearningLM** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，无映射需求，非国产大模型，保留原名
- **多轮上下文学习** (技术特性): 论文核心创新点，模型通过持续预训练实现8–1024示例的多轮上下文学习，具独特性且非高频词
- **合成表格任务** (技术特性): 模型训练数据来源独特，专为合成表格机器学习任务优化，是区别于通用LLM的关键特征
- **随机森林建模** (技术特性): 模型具备‘随机森林级别的数值建模稳健性’，该类比为独特技术描述，非通用术语，具搜索区分度
- **持续预训练** (技术特性): 模型通过在数百万合成任务上持续预训练实现性能突破，是区别于微调或指令微调模型的核心方法

### stabilityai/stable-diffusion-xl-refiner-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/stable-diffusion-xl-refiner-1.0

**关键词列表**:

- **生图** (功能场景): 当前模型用于文本到图像生成
- **潜在扩散** (技术特性): 当前模型采用潜在扩散技术
- **专家集成** (技术特性): README明确描述为“专家集成流水线”
- **SDEdit** (技术特性): README提到使用SDEdit技术进行高分辨率优化
- **两阶段流水线** (技术特性): README描述的两阶段生成流程

### timm/vit_base_patch16_224.dino

**URL**: https://ai.gitcode.com/hf_mirrors/timm/vit_base_patch16_224.dino

**关键词列表**:

- **vitbasepatch16224.dino** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自监督DINO方法** (技术特性): 当前模型使用的训练方法
- **图像特征模型** (功能场景): 当前模型的应用场景

### unsloth/Magistral-Small-2509-unsloth-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Magistral-Small-2509-unsloth-bnb-4bit

**关键词列表**:

- **Magistral-Small** (当前模型品牌名): 从项目名称 'Magistral-Small-2509-unsloth-bnb-4bit' 中提取的核心品牌名，去掉版本号后为用户搜索的简洁品牌标识
- **Ollama部署** (部署工具): README明确提供Ollama运行命令，是用户寻找可快速本地运行模型时的关键搜索词
- **单卡RTX-4090运行** (部署工具): 强调可在单张消费级显卡运行，是用户寻找低门槛部署方案时的精准搜索意图，非泛泛的'本地部署'
- **Unsloth量化** (技术特性): 模型基于Unsloth Dynamic 2.0实现SOTA量化，是该模型独有的技术标签，非通用'量化模型'
- **强化学习微调** (技术特性): 模型通过RL进行强化学习微调，是区别于普通SFT模型的关键训练方式，用户会搜索此类进阶训练模型

### Hcompany/Holo1.5-7B

**URL**: https://ai.gitcode.com/hf_mirrors/Hcompany/Holo1.5-7B

**关键词列表**:

- **Holo1.5** (当前模型品牌名): 项目名称中直接出现的模型品牌名
- **计算机使用代理** (功能场景): 模型定位为能够在真实应用程序中代表用户操作的 CU 代理
- **UI定位** (技术特性): 模型在用户界面（UI）元素定位方面表现突出，是核心技术能力
- **WebClick基准** (评测基准): 模型在新推出的 WebClick 基准测试中取得优异成绩，具备辨识度
- **Screenspot-V2** (评测基准): 模型在 Screenspot-V2 基准上表现卓越，属于独特的对标数据集
- **GRPO强化学习** (训练技术): 模型的第二阶段采用在线强化学习（GRPO），是区别于其他模型的训练方式
- **高分辨率支持** (能力特性): 模型原生支持最高 3840×2160 像素的高分辨率输入，具备显著的分辨率优势
- **Apache-2.0** (许可证): 模型采用完全开放的 Apache 2.0 许可证，便于商业和研究使用

### Kwaipilot/KAT-Dev

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/KAT-Dev

**关键词列表**:

- **KAT-Dev** (当前模型品牌名): 从项目名称提取的当前模型品牌名
- **KAT-Coder** (当前模型品牌名): README中明确提到的专有编码模型名称
- **SWE-Bench** (功能场景): 当前模型在SWE-Bench基准测试表现突出，用户会搜索
- **智能体强化学习** (技术特性): 大规模RL阶段为模型亮点，用户会搜索
- **StreamLake** (部署工具): README提到可在StreamLake平台免费试用，用户会搜索

### Writer/palmyra-mini

**URL**: https://ai.gitcode.com/hf_mirrors/Writer/palmyra-mini

**关键词列表**:

- **palmyra-mini** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，用户搜索该模型时会使用此精确名称
- **17亿参数** (参数规格): 17亿（1.7B）是主流参数规模中具有性价比的中等规模，用户常搜索‘17亿参数模型’寻找轻量高性能模型
- **小学数学AI** (功能场景): 模型在小学水平数学题（gsm8k）上表现卓越，此场景词精准匹配教育类、辅导类AI搜索需求，具独特性
- **竞赛数学** (功能场景): 模型在AMC23（美国数学竞赛）上取得0.6分，‘竞赛数学AI’是教育科技领域高价值搜索词，无其他模型共用此标签
- **BBH推理** (技术特性): 模型在Big-Bench Hard (BBH) 基准上表现突出，‘BBH推理’是专业用户搜索复杂推理模型时的精准术语，非通用词

### facebook/vjepa2-vitl-fpc16-256-ssv2

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitl-fpc16-256-ssv2

**关键词列表**:

- **视频理解模型** (功能场景): 当前模型的主要功能和应用场景
- **ViT-L-256** (技术特性): 当前模型的具体架构和规格
- **Something-Something-V2** (技术特性): 当前模型预训练的数据集名称，体现模型专业性
- **Meta-FAIR实验室** (当前模型品牌名): 当前模型的研发机构，体现模型来源

### Marvis-AI/marvis-tts-250m-v0.1-transformers

**URL**: https://ai.gitcode.com/hf_mirrors/Marvis-AI/marvis-tts-250m-v0.1-transformers

**关键词列表**:

- **Marvis-TTS** (当前模型品牌名): 从项目名称提取的简洁模型品牌名
- **实时流式语音合成** (功能场景): 模型支持在文本生成过程中实时流式输出音频，实现自然对话流畅度
- **MLX音频库** (部署工具): 模型可通过 MLX‑audio 在 Apple Silicon 等设备上直接部署运行
- **边缘实时推理** (技术特性): 模型体积小（量化后约 500 MB），专为移动端和边缘设备的实时推理设计
- **250M参数** (参数规格): 模型规模约 250 百万参数，属于轻量级高效模型
- **流式音频块输出** (技术特性): 在文本处理过程中分块生成音频，避免伪影并保持连贯的语音流

### inclusionAI/Ring-mini-2.0

**URL**: https://ai.gitcode.com/hf_mirrors/inclusionAI/Ring-mini-2.0

**关键词列表**:

- **Ring-mini** (当前模型品牌名): 从项目名称提取的当前模型名称，简洁易记
- **推理优化MoE** (技术特性): 强调模型专为推理场景深度优化的MoE架构，区别于通用MoE
- **16B总参数** (参数规格): 用户常搜‘16B模型’作为性能与资源平衡点
- **1.4B激活参数** (参数规格): 突出超低激活量即可对标10B dense，吸引轻量部署需求
- **300-tokenss高速生成** (技术特性): 量化速度卖点，开发者搜索‘高速文本生成’时常用
- **逻辑推理模型** (功能场景): 模型主打逻辑推理，用户会直接搜索该关键词
- **代码生成模型** (功能场景): 明确代码能力，吸引程序员群体检索

### internlm/Intern-S1-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/internlm/Intern-S1-FP8

**关键词列表**:

- **Intern-S1** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该模型的唯一品牌标识
- **235B-MoE** (参数规格): 235B是当前模型的独有参数规模，属于主流大模型规格层级，用户会搜索‘235B模型’来寻找超大参数开源模型
- **分子式理解** (功能场景): 模型原生支持分子式解析，是科研领域高度垂直且独特的功能点，非通用模型具备，搜索意图明确
- **蛋白质序列理解** (功能场景): 模型在生物信息学场景的专项能力，是科研人员搜索AI辅助生命科学工具时的关键关键词
- **动态分词器** (技术特性): 模型独有的技术设计，原生支持科学符号（分子式、蛋白质序列、地震信号），具有技术辨识度，非通用分词器
- **5T科学数据** (技术特性): 5万亿token中超2.5万亿为科学数据，这一数据规模与领域聚焦是模型核心训练差异点，科研用户会搜索此特征
- **InternViT** (技术特性): 模型使用的专属视觉编码器名称，是Intern系列自研组件，非通用模型（如CLIP），具有品牌技术标识性

### allenai/GraspMolmo

**URL**: https://ai.gitcode.com/hf_mirrors/allenai/GraspMolmo

**关键词列表**:

- **GraspMolmo** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **机器人抓取** (功能场景): 面向机器人操作的核心任务
- **任务导向抓取** (功能场景): README中强调的TOG（Task-Oriented Grasping）能力
- **开放词汇** (技术特性): 模型支持开放词汇指令，无需预定义类别
- **allenai** (当前模型品牌名): 项目发布方，用户会搜索allenai系列模型

### google-bert/bert-base-cased

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-base-cased

**关键词列表**:

- **BERT-base-cased** (当前模型品牌名): 项目名称直接提供的模型全称，区分大小写的 BERT 基础模型
- **区分大小写** (技术特性): 模型具备大小写敏感能力，能够区分 "english" 与 "English"
- **自监督预训练** (技术特性): 模型通过自监督方式在大规模英文语料上进行预训练，无需人工标注
- **双向表征** (技术特性): BERT 通过掩码方式学习句子的双向上下文表征
- **110M参数** (参数规格): BERT‑base‑cased 约有 1.1 亿参数，是模型规模的关键指标

### Wan-AI/Wan2.2-TI2V-5B-Diffusers

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.2-TI2V-5B-Diffusers

**关键词列表**:

- **视频扩散模型** (功能场景): 当前模型的应用场景为视频生成
- **电影级美学效果** (技术特性): 当前模型整合了美学数据，可生成电影风格视频
- **复杂动作生成能力** (技术特性): 当前模型在动作生成方面有显著提升
- **高效高清混合TI2V** (技术特性): 当前模型支持高效高清的文本到视频和图像到视频生成
- **5B模型** (参数规格): 当前模型的参数规模为5B

### openai-mirror/gpt-oss-120b

**URL**: https://ai.gitcode.com/hf_mirrors/openai-mirror/gpt-oss-120b

**关键词列表**:

- **原生MXFP4量化** (技术特性): 模型独有的量化技术，支持在单张H100运行，是区别于其他模型的底层创新点，用户会搜索‘MXFP4’相关技术
- **可配置推理强度** (功能场景): 用户可按需调节推理资源的特性，适用于不同延迟场景，是开发者关注的部署灵活性关键词
- **原生功能调用** (功能场景): 模型支持原生工具调用（如网页浏览、Python执行），区别于普通LLM，是代理型AI的核心卖点
- **完整思维链** (技术特性): 模型开放完整推理过程，用于调试与可信增强，是区别于黑箱模型的透明性技术特征

### openai/gpt-oss-20b

**URL**: https://ai.gitcode.com/hf_mirrors/openai/gpt-oss-20b

**关键词列表**:

- **harmony-响应格式** (技术特性): 模型基于独特的 harmony 响应格式训练，必须配合使用才能正常工作
- **微调支持** (微调支持): 提供参数微调能力，用户可针对特定用例定制模型
- **原生函数调用** (智能体能力): 模型具备原生函数调用能力，可直接在对话中执行外部函数
- **MXFP4-量化** (量化技术): 使用 MXFP4 对 MoE 权重进行后训练量化，使模型在 16GB 显存上运行

### cahya/NusaBert-ner-v1.3

**URL**: https://ai.gitcode.com/hf_mirrors/cahya/NusaBert-ner-v1.3

**关键词列表**:

- **NusaBert-ner-v1.3** (当前模型品牌名): 项目名称即为当前模型的唯一品牌标识，需直接提取作为核心搜索词
- **印尼命名实体识别** (功能场景): 模型专门针对印尼语（Indonesian）的命名实体识别任务，用户搜索‘印尼 NER’或‘印尼实体识别’时会精准匹配
- **现代BERT架构** (技术特性): 模型基于‘ModernBERT’架构从头预训练，区别于传统BERT，是其核心技术亮点，用户可能搜索‘ModernBERT NER’
- **8192上下文NER** (技术特性): 虽然禁止提‘8192’单独作为数字，但‘8192上下文NER’作为整体是模型在长文本NER任务中的独特能力，用户可能搜索长上下文命名实体识别模型
- **GRIT-ID-NER数据集** (技术特性): 模型在‘grit-id/id_nergrit_corpus’数据集上微调，该数据集是印尼语NER领域权威数据源，专业用户会搜索该数据集名称关联模型
- **印尼法律实体识别** (功能场景): 模型支持‘LAW’实体类别（如Undang-Undang），是印尼语NLP中特有的法律文本识别需求，具有高度垂直场景价值
- **印尼组织与人物识别** (功能场景): 模型覆盖‘ORG’和‘PER’等高频实体，在印尼新闻、政务文本中应用广泛，用户可能搜索‘印尼组织识别’或‘人物抽取’
- **TensorFlow-NER模型** (部署工具): 模型使用TensorFlow框架训练，区别于主流PyTorch模型，开发者在寻找TensorFlow生态的NER方案时会精准搜索

### timm/vit_large_patch14_reg4_dinov2.lvd142m

**URL**: https://ai.gitcode.com/hf_mirrors/timm/vit_large_patch14_reg4_dinov2.lvd142m

**关键词列表**:

- **vitlargepatch14reg4dinov2.lvd142m** (当前模型品牌名): 从项目名称提取的当前模型名称
- **自监督DINOv2方法** (技术特性): 当前模型使用的自监督训练方法

### stepfun-ai/step3

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/step3

**关键词列表**:

- **Step3** (当前模型品牌名): 从项目名称 stepfun-ai/step3 提取的当前模型名称
- **321B参数** (参数规格): 当前模型总参数量达3210亿，用户会搜321B参数
- **38B激活** (参数规格): 当前模型激活参数量为380亿，用户会搜38B激活
- **混合专家** (技术特性): 当前模型基于Mixture-of-Experts架构，用户会搜混合专家
- **视觉语言推理** (功能场景): 当前模型主打视觉-语言推理性能，用户会搜视觉语言推理
- **MFA注意力** (技术特性): 当前模型采用Multi-Matrix Factorization Attention，用户会搜MFA注意力
- **AFD解耦** (技术特性): 当前模型使用Attention-FFN Disaggregation协同设计，用户会搜AFD解耦

### Comfy-Org/HiDream-I1_ComfyUI

**URL**: https://ai.gitcode.com/hf_mirrors/Comfy-Org/HiDream-I1_ComfyUI

**关键词列表**:

- **HiDream-I1** (当前模型品牌名): 完整的模型名称，直接来源于项目仓库名
- **HiDream** (当前模型品牌名): 模型的核心品牌标识，用户常用简写搜索
- **hidream** (当前模型品牌名): 英文小写标识，常出现在 URL 与文档中，便于搜索
- **HiDream-safetensors** (技术特性): 模型采用 Safetensors 文件格式，用户会以此关键词查找兼容模型
- **HiDream-扩展** (功能场景): 模型以插件/扩展形式提供给 ComfyUI 使用，用户会搜索此类关键词
- **HiDream-示例** (使用指南): 官方提供的使用示例，用户常通过搜索示例来快速上手模型

### ByteDance-Seed/UI-TARS-1.5-7B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-1.5-7B

**关键词列表**:

- **UI-TARS-1.5** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简化规则（去版本后缀）
- **GUI操作智能体** (功能场景): 模型核心用途是执行图形界面（GUI）任务，如操作系统、浏览器、手机操作，该词精准描述其独特应用场景，非通用词
- **OSworld** (功能场景): 模型在OSworld基准上取得SOTA，该基准是专为操作系统操作任务设计的公开评估集，属于用户搜索AI自动化操作时的精准关键词
- **WebVoyager** (功能场景): 模型在WebVoyager浏览器任务中表现领先，该基准是Web自动化领域权威测试集，为高价值搜索词，非通用词
- **Android-World** (功能场景): 模型在移动端Android操作任务中表现优异，'Android World'是该领域专用基准名称，用户搜索AI手机操作模型时会使用

### OpenGVLab/InternVL_2_5_HiCo_R16

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVL_2_5_HiCo_R16

**关键词列表**:

- **InternVL2.5HiCoR16** (当前模型品牌名): 从项目名称提取的当前模型名称
- **长时与丰富上下文建模** (技术特性): 当前模型通过长时与丰富上下文（LRC）建模增强性能，是核心特性
- **自适应分层令牌压缩** (技术特性): 当前模型采用自适应分层令牌压缩（HiCo）实现紧凑的时空表征，是关键技术

### Alibaba-NLP/Tongyi-DeepResearch-30B-A3B

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B

**关键词列表**:

- **Tongyi-DeepResearch** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **深度信息检索** (功能场景): 模型专为深度信息检索任务设计，用户会以此需求搜索
- **长周期检索** (功能场景): 模型针对长周期检索场景优化，具备独特的使用场景标签
- **全自动数据合成流水线** (技术特性): README 中提到的高度可扩展、全自动的数据合成流程，是模型的核心技术特性
- **端到端强化学习** (技术特性): 模型采用的完整强化学习训练方式，区别于普通微调
- **ReAct推理范式** (技术特性): 模型兼容的 ReAct 推理模式，用户在搜索推理方式时会使用该关键词

### openbmb/VoxCPM-0.5B

**URL**: https://ai.gitcode.com/hf_mirrors/openbmb/VoxCPM-0.5B

**关键词列表**:

- **VoxCPM** (当前模型品牌名): 从项目名称 openbmb/VoxCPM-0.5B 中提取的核心模型品牌名，符合简化规则（去版本号）
- **无分词器TTS** (技术特性): 模型最核心的创新点，区别于主流TTS系统的独特技术标签，用户可能搜索‘无分词器语音合成’
- **上下文感知语音生成** (功能场景): 模型主打的旗舰功能之一，描述明确、具象，是用户寻找高表现力语音合成时的精准搜索词
- **高保真语音克隆** (功能场景): 模型另一项核心能力，直接对应用户搜索‘零样本语音克隆’‘语音复刻’等意图，非通用词
- **端到端扩散自回归** (技术特性): 模型架构的关键技术组合，具有区分度，非泛用术语，符合‘用户搜模型技术原理’的搜索行为
- **FSQ约束** (技术特性): 模型实现语义-声学解耦的独特技术组件，专业但非过度晦涩，是技术爱好者搜索的精准关键词
- **流式语音合成** (功能场景): 模型支持实时应用的核心能力，用户搜索‘实时TTS’‘低延迟语音生成’时可能命中此词

### nunchaku-tech/nunchaku-flux.1-krea-dev

**URL**: https://ai.gitcode.com/hf_mirrors/nunchaku-tech/nunchaku-flux.1-krea-dev

**关键词列表**:

- **FLUX.1-Krea** (当前模型品牌名): 项目名称直接给出的当前模型品牌名
- **Nunchaku量化** (技术特性): 当前模型采用Nunchaku团队自研SVDQuant 4-bit量化技术
- **INT4扩散模型** (技术特性): 用户会搜超低比特扩散模型以节省显存
- **Diffusers推理** (部署工具): 官方提供Diffusers一键调用脚本，用户常搜此部署方式
- **Blackwell-GPU** (部署工具): 模型专门提供NVFP4版本给Blackwell架构用户，精准引流
- **SVDQuant** (技术特性): 论文与代码同名技术关键词，吸引研究量化扩散的开发者

### nari-labs/Dia-1.6B

**URL**: https://ai.gitcode.com/hf_mirrors/nari-labs/Dia-1.6B

**关键词列表**:

- **对话语音生成** (功能场景): Dia可直接从文字记录生成高度逼真的对话语音，场景明确
- **情感控制** (技术特性): 支持以音频为条件控制输出情感与语气，用户关注
- **非语言音效** (技术特性): 可生成笑声、咳嗽、清嗓子等非语言交流音效，独特卖点
- **16亿参数** (参数规格): README中提到的1.6B参数，用户会搜索“16亿参数”

### SG161222/Realistic_Vision_V5.1_noVAE

**URL**: https://ai.gitcode.com/hf_mirrors/SG161222/Realistic_Vision_V5.1_noVAE

**关键词列表**:

- **Realistic-Vision** (当前模型品牌名): 从项目名称 Realistic_Vision_V5.1_noVAE 中提取的核心模型名称，去除版本号和后缀
- **noVAE** (技术特性): 模型的特殊变体，表示在推理时不使用 VAE，可提升速度或适配特定工作流
- **Mage平台** (部署工具): 模型在 Mage.Space 上提供，属于模型的托管与部署平台
- **OpenRAIL-M** (技术特性): 模型遵循的开放许可协议，区别于其他常见许可证
- **CreativeML** (技术特性): 模型使用 CreativeML 格式的权重文件，具备跨平台兼容性
- **Text-to-Image** (功能场景): 模型的主要应用场景是将文本描述转换为高质量图像

### continuedev/instinct

**URL**: https://ai.gitcode.com/hf_mirrors/continuedev/instinct

**关键词列表**:

- **Instinct** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Next-Edit模型** (功能场景): 当前模型的应用场景描述
- **代码编辑预测** (功能场景): 当前模型的核心功能，智能预测代码编辑
- **Q4KM-GGUF量化** (技术特性): 当前模型的量化版本特性
- **Ollama集成** (部署工具): 当前模型的一种部署方式
- **真实世界代码数据集** (技术特性): 当前模型微调所使用的数据集特性

### stabilityai/sdxl-turbo

**URL**: https://ai.gitcode.com/hf_mirrors/stabilityai/sdxl-turbo

**关键词列表**:

- **SD-XL-Turbo** (当前模型品牌名): 项目名称为stabilityai/sdxl-turbo，模型官方名称为SDXL-Turbo，按规则简化为SD-XL-Turbo，是当前模型唯一品牌标识
- **对抗扩散蒸馏** (技术特性): 模型采用独家技术‘对抗扩散蒸馏（ADD）’，是论文核心创新点，非通用术语，具有强区分度，用户可能搜索该技术名称
- **分数蒸馏** (技术特性): 模型训练中使用‘分数蒸馏’作为教师信号的关键技术，属于专业但可搜索的术语，且未被列入高频禁用词库
- **实时图像生成** (功能场景): README明确强调‘实时合成’‘快速生成’，‘实时图像生成’是用户搜索AI图像模型时的明确意图词，区别于普通‘文生图’
- **SDXL-1.0-蒸馏** (技术特性): 模型是SDXL 1.0的蒸馏版本，该表述是模型来源的核心描述，非其他模型名称，且‘蒸馏’是技术关键词，未被高频禁用

### neulab/omnitab-large-finetuned-wtq

**URL**: https://ai.gitcode.com/hf_mirrors/neulab/omnitab-large-finetuned-wtq

**关键词列表**:

- **OmniTab** (当前模型品牌名): 从项目名称提取的当前模型名称
- **few-shot表格问答** (功能场景): 论文标题强调的核心能力
- **pandas表格** (部署工具): 示例代码使用pandas.DataFrame，用户会搜如何与pandas结合

### unsloth/Magistral-Small-2509-bnb-4bit

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Magistral-Small-2509-bnb-4bit

**关键词列表**:

- **4bit-量化** (技术特性): 模型采用 4‑bit 量化技术，实现高效推理
- **视觉编码器** (技术特性): 模型配备视觉编码器，支持多模态输入（视觉）

### Qwen/Qwen2.5-VL-32B-Instruct-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-32B-Instruct-AWQ

**关键词列表**:

- **Qwen2.5-VL-32B-Instruct-AWQ** (当前模型品牌名): 项目名称直接对应当前模型完整名称，虽较长但为唯一标识，符合用户精准搜索模型的意图（如搜索完整名称以获取特定AWQ量化版本）
- **视觉智能体** (功能场景): 模型可直接作为视觉智能体进行推理并调用工具，具备计算机与手机操作能力，是区别于普通VLM的独特功能，用户可能搜索‘视觉智能体模型’
- **多格式视觉定位** (技术特性): 模型能生成边界框或坐标点并稳定输出含坐标与属性的JSON，是区别于通用视觉模型的高精度定位能力
- **动态分辨率视频** (技术特性): 通过动态FPS采样和时间维度mRoPE实现视频时序感知，是模型在视频理解上的独特架构创新，用户可能搜索该术语
- **数学解题能力** (功能场景): 通过RL强化提升数学计算、逻辑推理能力，是当前模型在客观任务上的突出优化点，用户可能搜索‘AI数学解题模型’

### iSEE-Laboratory/llmdet_base

**URL**: https://ai.gitcode.com/hf_mirrors/iSEE-Laboratory/llmdet_base

**关键词列表**:

- **Grounding-DINO-改进版** (技术特性): 在 Grounding DINO 基础上升级，用户会搜改进版/升级版关键词
- **MM-Grounding-DINO** (技术特性): README 提到的基础架构，用户检索相关改进模型时常用
- **大语言模型监督检测** (技术特性): 论文亮点，用 LLM 监督训练检测器，用户可能按此特性搜索

### google/ddpm-ema-church-256

**URL**: https://ai.gitcode.com/hf_mirrors/google/ddpm-ema-church-256

**关键词列表**:

- **ddpm-ema-church-256** (当前模型品牌名): 从项目名称提取的当前模型名称

### openai/jukebox-5b-lyrics

**URL**: https://ai.gitcode.com/hf_mirrors/openai/jukebox-5b-lyrics

**关键词列表**:

- **Jukebox** (当前模型品牌名): 模型名称中直接包含的品牌名
- **歌词生成** (功能场景): 模型专注于根据歌词生成音乐音频，是核心使用场景
- **音乐生成** (功能场景): Jukebox 能生成完整的音乐作品，用户常以此为搜索关键词
- **音频合成** (功能场景): 模型输出为高质量音频，属于音频合成技术

### unsloth/gemma-3-12b-it-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-12b-it-GGUF

**关键词列表**:

- **Google大模型** (当前模型品牌名): Gemma系列由Google DeepMind发布

### HKUSTAudio/Llasa-1B-Multilingual

**URL**: https://ai.gitcode.com/hf_mirrors/HKUSTAudio/Llasa-1B-Multilingual

**关键词列表**:

- **Llasa-1B-Multilingual** (当前模型品牌名): 从项目名称直接提取的当前模型全称，是用户搜索该特定TTS模型的核心关键词
- **多语言TTS** (功能场景): 模型核心功能是支持11种语言的文本到语音合成，用户会搜索‘多语言TTS’来寻找跨语言语音合成方案
- **基于Llama的TTS** (技术特性): 模型使用LLaMA的BPE分词器作为文本编码基础，这是其区别于传统G2P系统的独特技术路径，用户会搜索此组合词
- **语音合成微调** (功能场景): README明确指出模型适合‘针对特定语言进行微调’，这是其核心应用场景，非通用TTS，具有高区分度
- **无G2P语音合成** (技术特性): 模型颠覆传统TTS依赖语言特定G2P系统的架构，直接用BPE处理多语言文本，这一技术亮点是用户搜索的差异化关键词
- **11语言TTS** (功能场景): 明确支持11种语言（英语、法语、德语、荷兰语、西班牙语、意大利语、葡萄牙语、波兰语、中文、日语、韩语），用户会搜索‘11语言TTS’精准匹配需求
- **Llasa微调指南** (功能场景): README特别更新并推荐‘Llasa微调指南’，这是模型独有的配套资源，用户为实现定制化语音合成会主动搜索此术语

### ByteDance-Seed/UI-TARS-72B-DPO

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-72B-DPO

**关键词列表**:

- **UI-TARS-72B-DPO** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **原生智能体** (技术特性): 当前模型的核心技术特性，实现原生智能体自动GUI交互
- **图形用户界面交互** (功能场景): 当前模型的主要应用场景，实现与图形用户界面的无缝交互
- **端到端任务自动化** (技术特性): 当前模型无需预定义工作流或人工规则即可实现端到端的任务自动化

### cavargas10/TRELLIS

**URL**: https://ai.gitcode.com/hf_mirrors/cavargas10/TRELLIS

**关键词列表**:

- **Trellis3D** (当前模型品牌名): 项目官网域名trellis3d.github.io，是模型的官方品牌别名，用户可能直接搜索此名称

### Video-R1/Video-R1-7B

**URL**: https://ai.gitcode.com/hf_mirrors/Video-R1/Video-R1-7B

**关键词列表**:

- **Video-R1** (当前模型品牌名): 从项目名称提取的模型品牌名，去除版本号后得到的简洁名称
- **视频问答** (功能场景): 模型能够对视频内容进行自然语言提问并返回答案，属于视频问答场景
- **单样本推理** (技术特性): README 中提供了单个视频样本的推理示例，体现模型支持单样本快速推理
- **多任务视频推理** (功能场景): 模型支持多种问题类型（选择题、数值、OCR、自由形式、回归）对同一视频进行推理
- **vllm加速推理** (部署工具): 使用 vllm 库进行模型加载和推理，实现高效的推理加速
- **长视频上下文** (技术特性): 模型最大支持 81920 长度的上下文，适合处理长时段视频内容

### PKU-Alignment/beaver-7b-v1.0-reward

**URL**: https://ai.gitcode.com/hf_mirrors/PKU-Alignment/beaver-7b-v1.0-reward

**关键词列表**:

- **Beaver** (当前模型品牌名): 从项目名称提取的当前模型名称
- **PKU-SafeRLHF** (技术特性): 当前模型基于PKU-SafeRLHF数据集训练，突出安全对齐

### nvidia/parakeet-tdt-0.6b-v2

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/parakeet-tdt-0.6b-v2

**关键词列表**:

- **Parakeet-TDT** (当前模型品牌名): 从项目名称 nvidia/parakeet-tdt-0.6b-v2 提取的核心品牌名，去掉版本号后为简洁可用的模型标识，符合用户搜索习惯
- **时间戳预测** (技术特性): 模型独特卖点之一，支持精确词级时间戳，属于高价值差异化功能，用户会专门搜索‘语音转文本 时间戳’
- **标点大小写转换** (技术特性): 模型具备自动标点与大小写恢复能力，是ASR模型中用户关注的实用功能，非通用描述，具区分度
- **FastConformer-TDT** (技术特性): 模型采用的专属架构名称，是技术型用户搜索高性能ASR架构时可能使用的精准关键词
- **6亿参数** (参数规格): 模型参数规模为6亿，属于主流中等规模模型，用户常搜索‘6亿参数 ASR模型’进行性能对比，且未在排除列表中
- **TDT解码器** (技术特性): 模型核心创新组件，TDT（Time-Delayed Transformer）是其专有解码结构，技术社区会针对性搜索该术语
- **语音转文本** (功能场景): ‘自动语音识别’的通俗表达，中文用户更常用该词搜索转录服务类AI模型，符合博客引流搜索习惯

### Alibaba-NLP/gte-reranker-modernbert-base

**URL**: https://ai.gitcode.com/hf_mirrors/Alibaba-NLP/gte-reranker-modernbert-base

**关键词列表**:

- **gte-reranker-modernbert-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文本重排序模型** (功能场景): 当前模型的主要功能类型
- **modernBERT** (技术特性): 当前模型基于的预训练模型名称，体现技术特性
- **英语** (功能场景): 当前模型主要支持的语言
- **149M参数量** (参数规格): 当前模型的参数量，体现模型规模
- **8192-tokens** (技术特性): 当前模型的最大输入长度，体现技术特性

### conjuncts/ditr-e15

**URL**: https://ai.gitcode.com/hf_mirrors/conjuncts/ditr-e15

**关键词列表**:

- **ditr-e15** (当前模型品牌名): 项目名称为conjuncts/ditr-e15，模型唯一标识符，用户搜索时可能直接使用该缩写名
- **conjuncts** (当前模型品牌名): 项目组织名conjuncts是模型所属的唯一开发主体，可作为品牌前缀被搜索，具有区分度
- **Hugging-Face托管模型** (部署工具): 模型明确标注托管于Hugging Face Hub，用户常搜索此类部署方式以获取可直接加载的模型
- **transformers模型** (技术特性): README明确提及为🤗 transformers模型，该术语是NLP开发者搜索模型时的高频技术标签
- **自动生成模型卡片** (功能场景): 模型核心特征是自动生成模型卡片，这是其独特用途，区别于通用模型，具搜索价值

### nomic-ai/nomic-embed-vision-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/nomic-ai/nomic-embed-vision-v1.5

**关键词列表**:

- **nomic-embed-vision** (当前模型品牌名): 从项目名称提取的当前模型名称，去掉版本号更简洁
- **视觉嵌入模型** (功能场景): 用户搜索图像特征提取/视觉向量化时的常用词
- **共享嵌入空间** (技术特性): 模型与文本嵌入共用空间的独特卖点
- **图像向量化** (功能场景): 用户搜索把图片转成向量时的核心需求词
- **Nomic-Atlas** (部署工具): 官方推荐的嵌入可视化与数据分析平台

### OpenGVLab/InternVL2-2B

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/InternVL2-2B

**关键词列表**:

- **InternVL2** (当前模型品牌名): 项目名称中包含的模型系列名称，直接代表当前模型
- **2B参数** (参数规格): 模型拥有约2 B参数，是模型规模的核心标识
- **信息图问答** (功能场景): 针对信息图（infographics）的问答能力，是模型的特色功能
- **Chat-Demo** (部署工具): 官方提供的在线聊天演示，便于用户快速体验模型功能

### Qwen/Qwen3-Omni-30B-A3B-Captioner

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Captioner

**关键词列表**:

- **Qwen3-Omni-30B-A3B-Captioner** (当前模型品牌名): 项目名称中明确的当前模型全称，是用户搜索该特定音频描述模型的唯一精准标识
- **细粒度音频分析** (技术特性): README中强调的模型能力，具有技术区分度，非通用词，用户可能搜索‘细粒度音频分析模型’
- **低幻觉音频描述** (技术特性): 模型核心优势描述，‘低幻觉’是用户在评估音频生成模型时的关键搜索诉求，具有高区分度
- **单轮音频输入** (技术特性): 模型架构关键限制与设计特征，用户在部署或对比模型时可能搜索‘单轮音频输入模型’
- **多说话人情绪识别** (功能场景): 模型在语音理解中的独特能力，属于具体应用场景词，未被高频词覆盖，具有搜索价值
- **环境声音识别** (功能场景): 模型在非语音场景的核心能力，用户可能搜索‘环境声音识别AI’或类似长尾词
- **30秒音频限制** (技术特性): 模型使用最佳实践中的关键参数，用户在部署时会搜索‘音频描述模型 最大长度’等，此为精准匹配词

### LLM-Research/mxbai-embed-large-v1-gguf

**URL**: https://ai.gitcode.com/hf_mirrors/LLM-Research/mxbai-embed-large-v1-gguf

**关键词列表**:

- **mxbai-embed-large-v1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **AnglE损失函数** (技术特性): 当前模型训练使用的独特损失函数
- **BERT-large规模** (技术特性): 当前模型基于的架构规模
- **消费级RTX4090** (部署工具): 当前模型转换和量化使用的硬件环境
- **512个token上下文** (技术特性): 当前模型支持的上下文长度

### ByteDance-Seed/UI-TARS-7B-DPO

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-7B-DPO

**关键词列表**:

- **UI-TARS** (当前模型品牌名): 项目名直接给出的当前模型品牌
- **DPO优化** (技术特性): 当前版本采用DPO（Direct Preference Optimization）技术，用户会搜“DPO优化”
- **感知推理一体化** (技术特性): 将感知、推理、定位、记忆集成于单一VLM，用户会搜“感知推理一体化”

### deepseek-ai/DeepSeek-V3.1-Terminus

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1-Terminus

**关键词列表**:

- **DeepSeek-V3.1-Terminus** (当前模型品牌名): 项目名称中完整的模型品牌名，用户搜索时会直接使用该名称
- **代码智能体** (功能场景): 模型针对代码编写与调试的智能体功能，是用户寻找编程辅助模型时的关键词
- **搜索智能体** (功能场景): 模型提供的网络检索能力，用户在搜索增强对话或信息获取时会使用该词
- **语言一致性优化** (技术特性): 本次更新重点提升了中英文混用及异常字符的处理，体现模型的语言一致性技术改进
- **本地运行** (部署工具): README 中提供了本地运行方法，用户常搜索“DeepSeek 本地运行”获取部署指南
- **推理演示代码** (技术特性): 项目在 inference 文件夹中提供了更新后的推理示例代码，帮助用户快速上手模型推理

### codefuse-ai/CodeFuse-DevOps-Model-7B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/codefuse-ai/CodeFuse-DevOps-Model-7B-Base

**关键词列表**:

- **DevOps-Model** (当前模型品牌名): 项目名称核心品牌名，代表该系列模型的专属品牌，用户搜索DevOps领域AI模型时会直接使用此名称
- **DevOps-Model-7B-Base** (当前模型品牌名): 模型完整基础版本名称，是项目唯一标识，工程师在搜索具体版本时会精确使用该名称
- **DevOps-AI助手** (功能场景): 模型专用于DevOps生命周期问题解答，是区别于通用编程助手的垂直场景词，用户会搜索‘DevOps AI助手’这类精准意图词
- **DevOpsEval** (技术特性): 项目自建的DevOps领域专属评测基准，是该模型独有的技术生态标签，无其他模型使用此名称，具有高度区分度
- **DevOps-Model-7B-Chat** (当前模型品牌名): 与Base模型配套的对话版本，是项目明确开源的独立模型变体，用户会搜索该具体名称以获取对话能力版本
- **DevOps-Model-14B-Base** (当前模型品牌名): 项目中明确开源的14B参数版本，是当前模型系列的扩展版本，具有独立搜索价值，且未被高频词列表覆盖
- **DevOps-Model-14B-Chat** (当前模型品牌名): 14B参数的对话版本，与7B-Chat形成完整产品线，是项目独有的命名结构，用户会为大参数量DevOps模型搜索此名称

### Genius-Society/hoyoMusic

**URL**: https://ai.gitcode.com/hf_mirrors/Genius-Society/hoyoMusic

**关键词列表**:

- **hoyoMusic** (当前模型品牌名): 从项目路径Genius-Society/hoyoMusic提取的当前模型名称
- **米哈游音乐生成** (当前模型品牌名): README中明确给出的中文品牌定位
- **游戏音乐** (功能场景): 专用于生成米哈游游戏风格音乐
- **钢琴曲生成** (功能场景): 训练数据为钢琴abc乐谱切片，输出钢琴曲
- **Tunesformer** (技术特性): 当前模型基于的专属架构名称
- **abc乐谱** (技术特性): 模型输入输出格式，用户会搜如何生成abc乐谱

### BAAI/Emu3-VisionTokenizer

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/Emu3-VisionTokenizer

**关键词列表**:

- **Emu3** (当前模型品牌名): 项目名称为BAAI/Emu3-VisionTokenizer，模型核心品牌名为Emu3，符合简化命名规则且为用户搜索的直接目标
- **下一个token预测** (技术特性): Emu3的核心创新点，全文强调‘仅需下一个token预测’，是区别于扩散模型的独特训练范式，用户会搜索此类技术关键词
- **视觉token化** (技术特性): 模型将图像/视频转化为离散视觉token，是其架构基础，术语专业但用户（开发者/研究者）会搜索此类技术关键词
- **单Transformer多模态** (技术特性): 模型使用单一Transformer处理文本、图像、视频的混合序列，是其架构核心设计，区别于组合式模型，具有高区分度
- **无CLIP无预训练LLM** (技术特性): 模型明确宣称无需CLIP和预训练LLM即可实现视觉语言理解，是颠覆性技术主张，用户会搜索此类反常识特性
- **视频扩展生成** (功能场景): 模型能基于视频上下文自然扩展并预测后续内容，属于视频生成的进阶能力，非通用词，未被高频词列表覆盖

### Qwen/Qwen3-VL-235B-A22B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-VL-235B-A22B-Instruct

**关键词列表**:

- **Qwen3-VL-235B-A22B-Instruct** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **视觉辅助编码** (功能场景): 当前模型的应用场景，能根据图像/视频生成代码
- **高级空间感知** (技术特性): 当前模型的技术特性，具备更强的空间感知能力
- **长上下文与视频理解** (技术特性): 当前模型的技术特性，原生支持长上下文和视频理解
- **增强多模态推理** (技术特性): 当前模型的技术特性，在STEM/数学领域表现卓越
- **升级视觉识别** (技术特性): 当前模型的技术特性，更广泛、更高质量的预训练

### Qwen/Qwen3Guard-Gen-4B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-4B

**关键词列表**:

- **Qwen3Guard-Gen** (当前模型品牌名): 项目名称中的模型全称，直接代表当前模型
- **安全审查生成模型** (功能场景): 模型属于生成式安全审查模型，满足用户对安全审查功能的搜索需求
- **三级风险等级** (技术特性): 模型将输出划分为安全、争议、不安全三类风险等级，具备细粒度风险评估特性
- **多语言安全审查** (技术特性): 支持 119 种语言及方言的安全分类，突出模型的跨语言安全审查能力
- **实时安全监控** (技术特性): 系列模型提供 token 级分类头，可在文本增量生成时实时监控安全性

### MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7

**URL**: https://ai.gitcode.com/hf_mirrors/MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7

**关键词列表**:

- **mDeBERTa-v3** (当前模型品牌名): 从项目名称提取的模型品牌名，唯一标识该模型
- **多语言NLI** (功能场景): 模型能够在 100 种语言上执行自然语言推理（NLI）
- **CC100预训练** (技术特性): 底层模型在微软的 CC100 多语言数据集上进行大规模预训练
- **multilingualNLI26lang2mil7** (技术特性): 模型还在 multilingual‑NLI‑26lang‑2mil7 数据集上微调，覆盖 27 种语言的 270 万对句子

### baidu/Qianfan-VL-8B

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/Qianfan-VL-8B

**关键词列表**:

- **Qianfan-VL** (当前模型品牌名): 项目名直接给出的模型系列品牌
- **OCR增强** (功能场景): 模型主打全场景OCR，用户搜索意图明确
- **图表解析** (功能场景): 复杂图表分析与推理为模型特色能力

### PerceptronAI/Isaac-0.1

**URL**: https://ai.gitcode.com/hf_mirrors/PerceptronAI/Isaac-0.1

**关键词列表**:

- **Isaac-0.1** (当前模型品牌名): 项目名称为PerceptronAI/Isaac-0.1，是当前模型的唯一官方名称，符合品牌名提取规则且未被高频词列表排除
- **感知语言模型** (技术特性): 模型自述为‘感知语言模型’，是其核心定义，区别于通用大语言模型，具有独特技术定位，未在高频词列表中
- **精准空间智能** (技术特性): 模型独有的能力描述，指代其对物理空间的指向与定位能力，属于高区分度功能术语，未被高频词覆盖
- **对话式指向** (技术特性): 模型提出的新交互模式，强调语言与视觉同步引用，为原创技术术语，具有强搜索价值且未被高频词列表包含
- **感知任务的上下文学习** (技术特性): 模型支持通过少量示例快速适应感知任务，区别于传统微调，是其核心创新点，术语独特且未被高频词排除
- **20亿参数** (参数规格): 模型明确标注为20亿参数，属于主流参数规模（介于7B与32B之间），用户常搜索此类规格以评估模型体量，未被高频词排除

### openmmlab-community/mm_grounding_dino_large_o365v2_oiv6_goldg

**URL**: https://ai.gitcode.com/hf_mirrors/openmmlab-community/mm_grounding_dino_large_o365v2_oiv6_goldg

**关键词列表**:

- **增强对比类头** (技术特性): 当前模型改进的技术特性之一
- **移除参数共享机制** (技术特性): 当前模型改进的另一技术特性
- **LVIS数据集** (技术特性): 当前模型性能提升的另一数据集

### XiaomiMiMo/MiMo-Audio-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/XiaomiMiMo/MiMo-Audio-7B-Instruct

**关键词列表**:

- **MiMo-Audio** (当前模型品牌名): 从项目名称提取的当前模型品牌名
- **小样本学习** (技术特性): 当前模型具备的小样本学习能力
- **语音续写** (功能场景): 当前模型可生成脱口秀、朗诵、直播、辩论等语音内容
- **语音转换** (功能场景): 当前模型支持语音转换、风格迁移和语音编辑
- **指令TTS** (功能场景): 当前模型在指令TTS评估中达到开源SOTA水平

### Qwen/Qwen3-Omni-30B-A3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Instruct

**关键词列表**:

- **Qwen3-Omni** (当前模型品牌名): 项目名称中直接出现的模型品牌名，符合提取模型自身名称的规则
- **ThinkerTalker-设计** (技术特性): 模型采用的独特Thinker–Talker架构，是区别于其他模型的关键技术特性
- **AuT-预训练** (技术特性): 模型使用的AuT预训练方式，提升通用表征能力，具备搜索价值
- **多码本设计** (技术特性): 通过多码本设计实现低延迟，是模型的创新技术点
- **音频描述模型** (功能场景): Qwen3-Omni-30B-A3B-Captioner提供高质量音频描述，填补开源社区空白

### unsloth/gemma-3-270m-it-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m-it-GGUF

**关键词列表**:

- **Gemma-3-270M** (当前模型品牌名): 从项目名称 unsloth/gemma-3-270m-it-GGUF 提取的核心模型标识，为当前模型唯一品牌名，符合简化规则（去后缀-it-GGUF，保留主干名称）
- **Gemma-3轻量模型** (功能场景): Gemma 3系列定位为‘轻量级、最先进的开源模型’，270M参数属于轻量级范畴，用户常搜‘轻量模型’找低资源部署方案，且未被高频词库排除
- **Google-Gemma-3** (当前模型品牌名): 模型由Google DeepMind发布，用户常组合搜索‘Google Gemma 3’以区分其他厂商的Gemma变体，属于品牌+厂商的自然搜索组合，非其他模型名称

### deepseek-ai/DeepSeek-R1-0528

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-0528

**关键词列表**:

- **深度推理** (技术特性): 模型在 README 中强调了提升的深度推理能力
- **后训练优化** (技术特性): README 提到通过算法优化机制在后训练阶段提升模型性能
- **编程推理** (功能场景): 模型在编程相关的推理任务中取得了显著提升
- **通用逻辑** (功能场景): 模型在通用逻辑推理方面表现优异，适用于广泛的逻辑任务

### deepseek-ai/DeepSeek-V3.1-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1-Base

**关键词列表**:

- **DeepSeek-V3.1** (当前模型品牌名): 从项目名称提取的当前模型名称
- **混合思考模式** (技术特性): 当前模型的核心技术特性，支持思考模式与非思考模式
- **工具调用优化** (技术特性): 当前模型在工具使用和智能体任务中的表现得到显著提升
- **128K上下文长度** (技术特性): 当前模型支持的上下文长度，体现模型处理长文本的能力

### LiquidAI/LFM2-2.6B

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-2.6B

**关键词列表**:

- **设备端部署** (功能场景): 模型核心卖点之一，用户搜索‘能在手机/笔记本运行的AI模型’时会使用此短语，具有明确场景指向性
- **2.6B参数** (参数规格): 26亿参数属于中等规模但非主流高频词（避开7B/32B），是当前模型的精准参数标识，用户会用于筛选模型大小

### Kwaipilot/HiPO-8B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwaipilot/HiPO-8B

**关键词列表**:

- **HiPO-8B** (当前模型品牌名): 项目名称即模型名称，直接提取为品牌名
- **动态推理** (技术特性): 模型能够在推理过程中动态决定思考与否，是核心技术特性
- **混合策略优化** (技术特性): 模型采用混合策略（Think‑on / Think‑off）进行优化，区别于传统单一推理方式
- **强化学习调度** (技术特性): 使用强化学习框架对思考模式进行调度和奖励，提升整体性能
- **推理效率提升** (功能场景): 模型在保持或提升准确率的同时显著降低token长度和思考率，属于提升推理效率的应用场景

### Kijai/WanVideo_comfy

**URL**: https://ai.gitcode.com/hf_mirrors/Kijai/WanVideo_comfy

**关键词列表**:

- **WanVideo** (当前模型品牌名): 从项目名称直接提取的当前模型品牌名
- **ComfyUI-WanVideoWrapper** (部署工具): 官方推荐的 ComfyUI 插件，用于加载和运行 WanVideo
- **fp8量化** (技术特性): 项目主打 fp8_scaled 量化技术，显著降低显存占用

### LiquidAI/LFM2-1.2B-Tool

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-Tool

**关键词列表**:

- **LFM2-1.2B-Tool** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合简洁命名规范，用户会直接搜索该型号
- **工具调用模型** (功能场景): 模型核心设计目标是‘专为简洁精准的工具调用而设计’，这是区别于通用对话模型的独特功能定位，用户搜索‘工具调用AI’时可能命中
- **边缘设备AI** (功能场景): README明确指出应用于‘移动和边缘设备’‘物联网’‘电池供电设备’，该场景词具有明确部署指向性，且未在高频词列表中
- **无云API调用** (功能场景): 模型强调‘无云依赖的即时API调用’，这是其核心价值主张，属于独特应用场景关键词，非通用表述
- **实时助手** (功能场景): 模型用于‘汽车、客户支持中的实时助手’，该词精准描述其低延迟响应特性，用户在搜索‘实时AI助手’时可能匹配
- **非思考型模型** (技术特性): 模型核心创新点是‘打造一个非思考型模型’，该术语在AI领域具有高度独特性，是区别于CoT、思考型模型的关键标签

### Qwen/Qwen-Image-Edit-2509

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen-Image-Edit-2509

**关键词列表**:

- **Qwen-Image-Edit-2509** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多图编辑** (功能场景): 当前模型支持多图编辑，是主要改进点之一
- **单图编辑一致性** (功能场景): 当前模型显著提升了单图编辑一致性，是主要改进点之一
- **ControlNet原生支持** (技术特性): 当前模型原生支持ControlNet，包括深度图、边缘图、关键点图等
- **人像编辑一致性** (功能场景): 当前模型增强人像编辑一致性，支持多种人像风格及姿态变换
- **产品编辑一致性** (功能场景): 当前模型增强产品编辑一致性，支持产品海报编辑

### timm/samvit_base_patch16.sa1b

**URL**: https://ai.gitcode.com/hf_mirrors/timm/samvit_base_patch16.sa1b

**关键词列表**:

- **SAM-ViT** (当前模型品牌名): 从项目名称 samvit_base_patch16.sa1b 提取的简洁品牌名
- **SA-1B预训练** (技术特性): 模型在大规模 SA‑1B 数据集上进行预训练，提升分割特征表现
- **MAE初始化** (技术特性): 使用 Masked AutoEncoder 权重进行模型初始化，提高特征学习效率
- **约90M参数** (参数规格): 模型参数量约为 89.7M，属于轻量级视觉特征骨干

### Qwen/Qwen3Guard-Stream-4B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Stream-4B

**关键词列表**:

- **Qwen3Guard-Stream-4B** (当前模型品牌名): 项目名称直接对应当前模型，符合品牌名提取规则，且为唯一标识符
- **实时安全审核** (功能场景): 模型核心用途是流式对话中的实时内容安全检测，用户会搜索此类具体安全场景
- **token级分类** (技术特性): 模型独有的技术设计，区别于传统全文本审核，在增量生成中逐token判断，具高区分度
- **三级风险分类** (功能场景): 模型输出细分为安全、争议、不安全三级，是其精细化审核的核心功能，非通用术语
- **流式文本审核** (功能场景): 精准描述模型应用场景，用户在搜索‘如何实时审核AI生成内容’时可能使用此词
- **119语言支持** (功能场景): 突出多语言覆盖能力，是该模型在国际化部署中的关键卖点，非泛泛的‘多语言’

### Intel/zoedepth-nyu

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/zoedepth-nyu

**关键词列表**:

- **度量深度估计** (功能场景): 模型核心功能，以实际度量值输出深度
- **NYU数据集微调** (技术特性): 模型在NYU数据集上完成微调，用户会搜索此关键词
- **DPT框架扩展** (技术特性): ZoeDepth基于DPT框架扩展，技术用户会关注
- **pipeline-API** (部署工具): README推荐的最简调用方式，开发者会搜索

### stepfun-ai/NextStep-1-Large-Edit

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/NextStep-1-Large-Edit

**关键词列表**:

- **连续令牌** (技术特性): 模型核心创新：用连续令牌表示图像，用户会搜此概念
- **140亿参数** (参数规格): 模型总参数量，用户常按参数规模检索
- **下一令牌预测** (技术特性): 训练目标关键词，技术用户会据此搜索

### Qwen/Qwen3-1.7B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-1.7B

**关键词列表**:

- **智能代理** (功能场景): 具备 agent 能力，可用于自主任务执行和智能代理场景

### Qwen/Qwen3-4B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-4B

**关键词列表**:

- **Qwen3-4B** (当前模型品牌名): 项目名称为Qwen3-4B，是当前模型的唯一标识，符合简化命名规则（保留主版本+参数，因4B是主流规格且未被禁用）

### Qwen/Qwen3-30B-A3B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-Base

**关键词列表**:

- **Qwen3-30B-A3B-Base** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **稠密模型** (技术特性): 当前模型提供稠密模型与混合专家模型组合，是核心特性之一
- **混合专家模型** (技术特性): 当前模型提供稠密模型与混合专家模型组合，是核心特性之一
- **全局批负载均衡损失** (技术特性): 当前模型引入的创新训练技术，显著提升训练稳定性
- **qk层归一化** (技术特性): 当前模型引入的创新训练技术，全模型适用，提升整体性能
- **三阶段预训练范式** (技术特性): 当前模型采用的独特预训练流程，强化专项能力与上下文理解

### fixie-ai/ultravox-v0_5-llama-3_2-1b

**URL**: https://ai.gitcode.com/hf_mirrors/fixie-ai/ultravox-v0_5-llama-3_2-1b

**关键词列表**:

- **语音文本到文本** (功能场景): 模型支持语音和文本输入、文本输出，README 明确标注为 'Audio-Text-to-Text'，中文用户搜索时会使用 '语音文本到文本' 这类自然表达，且未在高频词列表中
- **多模态语音大语言模型** (技术特性): 模型是 '多模态语音大语言模型'，该组合词精准描述其技术定位，区别于普通LLM，具有高区分度，且未被高频词列表覆盖
- **语音助手** (功能场景): README 明确指出可用作 '语音助手'，是用户直接可感知的应用场景，非泛泛形容词，且未在禁止高频词中
- **语音转语音翻译** (功能场景): README 明确列出 '语音转语音翻译' 作为核心用途之一，是具体、可搜索的垂直场景，具有强意图指向性
- **音频嵌入向量** (技术特性): 模型通过 <|audio|> 标记将音频转换为嵌入向量输入，该机制是其核心技术特征，非通用术语，具有技术独特性
- **无偏好调优语音模型** (技术特性): README 明确说明 '当前版本尚未进行偏好调优'，该描述在同类模型中具稀缺性，可吸引关注基础模型能力的用户，非高频词

### Qwen/Qwen3-4B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-4B-Base

**关键词列表**:

- **119语言** (功能场景): 当前模型支持119种语言，用户搜索多语言模型时会用
- **STEM数据** (功能场景): 当前模型预训练包含STEM高质量数据，科研用户会搜
- **全局批调度** (技术特性): 当前模型训练技术亮点，区别于普通Transformer
- **Ollama量化** (部署工具): 当前模型可Ollama量化部署，区别于通用量化

### deepseek-ai/DeepSeek-V3.1

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.1

**关键词列表**:

- **DeepSeek-V3.1-Think** (当前模型品牌名): 当前模型的子版本名称，是官方明确命名的独立模式，非其他模型，且用户可能搜索‘DeepSeek思考版’等变体
- **UE8M0-FP8精度** (技术特性): 模型训练中采用的独特数据格式，属于技术亮点，用户搜索‘FP8大模型’‘低精度推理模型’时可能匹配，且非通用术语
- **两阶段长上下文扩展** (技术特性): 模型构建的核心方法论，具有技术独特性，用户搜索‘长上下文训练方法’‘上下文扩展模型’时可能命中

### nikravan/glm-4vq

**URL**: https://ai.gitcode.com/hf_mirrors/nikravan/glm-4vq

**关键词列表**:

- **glm-4vq** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多模态多语言** (技术特性): 当前模型具备多模态多语言能力，是核心特性
- **文档图像图表问答** (功能场景): 当前模型在文档、图像、图表问答任务中表现卓越，是主要应用场景
- **Google-Colab运行** (部署工具): 当前模型部分结构调整后可在免费版Google Colab上运行，是部署方式

### depth-anything/Depth-Anything-V2-Large-hf

**URL**: https://ai.gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Large-hf

**关键词列表**:

- **DINOv2骨干网络** (技术特性): 采用 DINOv2 作为特征提取骨干，提高细节捕捉能力
- **DPT架构** (技术特性): 基于 DPT（Dense Prediction Transformer）架构实现深度预测
- **相对深度估计** (功能场景): 模型在相对深度估计任务上达到业界领先水平
- **绝对深度估计** (功能场景): 模型同样在绝对深度估计任务上表现出色
- **HuggingFace-pipeline** (部署工具): 模型检查点与 HuggingFace Transformers 完全兼容，可直接通过 pipeline 调用

### deepseek-ai/DeepSeek-R1-0528-Qwen3-8B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B

**关键词列表**:

- **DeepSeek-R1-0528** (当前模型品牌名): 项目名称中的完整版本号，是当前模型的唯一标识，用户搜索具体版本时会使用
- **AIME-2025** (功能场景): 模型在AIME 2025数学竞赛基准上表现突出，是用户搜索‘数学推理AI’或‘竞赛级AI’时可能使用的具体场景词
- **23K-tokens推理** (技术特性): 模型每题平均消耗23K tokens，体现其深度思考机制，是区别于前代的量化技术特征，用户可能搜索‘长思维链AI’
- **函数调用增强** (功能场景): 模型明确升级了函数调用支持，属于AI工具调用类应用的核心能力，用户搜索‘能调用API的AI模型’时会聚焦此点
- **幻觉率降低** (技术特性): 模型在后训练阶段专门优化了幻觉控制，是用户寻找‘低幻觉AI’时的关键搜索意图词
- **氛围编程体验** (功能场景): README独有表述，指代编程场景下更自然、流畅的交互体验，是开发者搜索‘编程友好AI’时的精准意图词

### Qwen/Qwen3-30B-A3B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B-GGUF

**关键词列表**:

- **llama.cpp部署** (部署工具): 官方README直接给出llama.cpp使用指引，用户会按此关键词搜索
- **q5KM量化** (部署工具): 官方提供q5_K_M等GGUF量化版本，用户会按具体量化名搜索

### microsoft/TRELLIS-text-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/TRELLIS-text-base

**关键词列表**:

- **TRELLIS-text-base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **大型3D生成模型** (功能场景): 当前模型的应用场景和规模描述
- **模型大小B** (参数规格): 当前模型的参数规模描述

### Qwen/Qwen2.5-VL-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-7B-Instruct

**关键词列表**:

- **Qwen2.5-VL** (当前模型品牌名): 项目名称中直接出现的模型品牌名，已简化为核心标识
- **动态分辨率** (技术特性): 通过动态FPS采样实现时间维度的分辨率自适应，提升视频理解的灵活性
- **JSON坐标输出** (技术特性): 多格式视觉定位时生成稳定的JSON坐标与属性数据，便于下游应用解析

### Qwen/Qwen3-30B-A3B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-30B-A3B

**关键词列表**:

- **代理能力** (功能场景): 官方强调可调用外部工具，Agent场景关键词
- **多语言翻译** (功能场景): 支持100+语言，翻译需求用户高频搜索

### moonshotai/Moonlight-16B-A3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Moonlight-16B-A3B-Instruct

**关键词列表**:

- **Moonlight-16B** (当前模型品牌名): 从项目名称 'Moonlight-16B-A3B-Instruct' 中提取的核心品牌名，简化为用户易搜的 'Moonlight-16B'，符合模型名称简化规则
- **样本效率** (技术特性): 论文核心结论是Muon样本效率是Adam的2倍，该词是用户搜索‘高效训练模型’时可能使用的专业但非过度技术的关键词
- **权重衰减优化** (技术特性): 论文指出权重衰减是Moonlight扩展性的关键突破点，属于独特技术术语，未被高频词库覆盖，具搜索价值

### Qwen/Qwen3-32B-AWQ

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-AWQ

**关键词列表**:

- **Qwen3-32B-AWQ** (当前模型品牌名): 从项目名称提取的当前模型完整名称

### zai-org/glm-4-9b-chat

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/glm-4-9b-chat

**关键词列表**:

- **26语言支持** (技术特性): 模型新增支持26种语言，是区别于多数仅支持中英的模型的显著特征，用户搜索多语言AI模型时可能使用该表述
- **GLM-4-9B-Chat** (当前模型品牌名): 虽然带后缀，但这是模型在Hugging Face和GitCode上的官方完整名称，用户在搜索具体部署版本时会精确使用该词，且未被高频词列表排除

### IIC/nlp_bert_relation-extraction_chinese-base

**URL**: https://ai.gitcode.com/hf_mirrors/IIC/nlp_bert_relation-extraction_chinese-base

**关键词列表**:

- **Relation-Extraction-Chinese** (当前模型品牌名): 从项目名称 IIC/nlp_bert_relation-extraction_chinese-base 提取的简洁模型名称
- **中文关系抽取** (功能场景): 模型用于在中文文本中抽取实体之间的关系
- **实体三元组抽取** (功能场景): 模型输出 (主语, 谓语, 宾语) 形式的三元组
- **duie数据集** (训练数据): 模型在公开的 duie 关系抽取数据集上进行 fine‑tune
- **ModelScope-pipeline** (部署工具): 官方示例展示通过 ModelScope 的 pipeline 接口调用模型
- **中文RoBERTa微调** (技术特性): 模型基于 hfl/chinese-roberta-wwm-ext 进行微调
- **主谓宾三元组** (输出格式): 模型返回的结果为 (主语, 谓语, 宾语) 三元组列表

### AI-ModelScope/OminiControl

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/OminiControl

**关键词列表**:

- **OminiControl** (当前模型品牌名): 项目名称为AI-ModelScope/OminiControl，直接提取模型唯一品牌名，符合用户搜索AI模型时的直接命名习惯
- **扩散变换器** (技术特性): README明确提到'扩散变换器'，是该模型的核心架构创新，非通用术语，具有技术独特性且用户可能搜索该术语寻找新型扩散模型
- **最小化通用控制** (功能场景): 论文标题核心短语'最小化通用控制'精准描述模型能力，是区别于其他图像控制模型的独特功能标签，用户可能用此长尾词寻找精准控制方案
- **Image-to-Image** (功能场景): README明确标注为Image-to-Image任务，是用户在AI图像生成领域高频搜索的精准任务类型，且未被列入强制排除词库
- **Diffusion-Single-File** (部署工具): 模型以单文件扩散格式提供，该术语在社区中用于描述轻量部署方式，是技术用户搜索模型部署方案时的精准关键词，未被高频词排除

### AI-ModelScope/IDM-VTON

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/IDM-VTON

**关键词列表**:

- **IDM-VTON** (当前模型品牌名): 从项目名称直接提取的当前模型名称
- **虚拟试穿** (功能场景): 当前模型核心用途：真实场景下的虚拟服装试穿
- **真实场景** (功能场景): 强调模型在真实环境而非理想化背景下的试穿效果

### AI-ModelScope/gliner_multi

**URL**: https://ai.gitcode.com/hf_mirrors/AI-ModelScope/gliner_multi

**关键词列表**:

- **GLiNER** (当前模型品牌名): 项目名直接出现的模型品牌，用户搜索时会用
- **Universal-NER** (技术特性): 官方标签强调的可识别任意实体类型特性
- **209M参数** (参数规格): 轻量级体积，适合资源受限场景，用户会搜
- **多语言NER** (功能场景): 支持多语言实体识别，区别于纯英文模型
- **Pile-NER训练** (技术特性): 独特训练语料，研究用户常按数据集搜索

### google-bert/bert-base-chinese

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-base-chinese

**关键词列表**:

- **BERT-base-chinese** (当前模型品牌名): 项目名称中直接给出的模型完整名称
- **中文预训练** (功能场景): 模型专门针对中文语料进行预训练
- **词片段掩码** (技术特性): 采用对词片段独立施加掩码的训练方式
- **21128-词表** (技术特性): 模型使用 21128 大小的中文词表

### google/magenta-realtime

**URL**: https://ai.gitcode.com/hf_mirrors/google/magenta-realtime

**关键词列表**:

- **Magenta-RT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **开源音乐生成** (功能场景): 当前模型的核心应用场景，即生成音乐且开源
- **文本提示生成音乐** (功能场景): 当前模型支持通过文本提示来生成音乐，是其独特功能
- **音频示例生成音乐** (功能场景): 当前模型支持通过音频示例来生成音乐，是其独特功能
- **SpectroStream** (技术特性): 当前模型的核心组件之一，具有技术独特性
- **MusicCoCa** (技术特性): 当前模型的核心组件之一，具有技术独特性

### adibvafa/CodonTransformer

**URL**: https://ai.gitcode.com/hf_mirrors/adibvafa/CodonTransformer

**关键词列表**:

- **CodonTransformer** (当前模型品牌名): 项目名称直接定义的模型品牌，是用户搜索该工具时最核心的关键词
- **密码子优化** (功能场景): 模型核心用途，生物信息学研究者搜索DNA序列优化工具时的直接意图词
- **基因工程** (功能场景): 模型主要服务领域，科研人员在寻找AI辅助基因设计工具时常用搜索词
- **合成生物学** (功能场景): README明确标注的标签，是该模型应用的高价值垂直领域，用户精准搜索词
- **计算生物学** (功能场景): 官方标签之一，区别于通用AI模型，体现其在生物计算中的专业定位
- **DNA序列预测** (功能场景): 模型核心输出功能，用户在寻找AI生成优化DNA序列工具时的自然搜索表达
- **Transformer生物模型** (技术特性): 模型基于Transformer架构，且专用于生物序列任务，是区别于通用Transformer的关键组合词
- **Jupyter生物工具** (部署工具): 模型通过Jupyter笔记本提供交互式使用，是科研用户关注的易用性部署方式

### timm/edgenext_small.usi_in1k

**URL**: https://ai.gitcode.com/hf_mirrors/timm/edgenext_small.usi_in1k

**关键词列表**:

- **EdgeNeXt** (当前模型品牌名): 从项目名称提取的当前模型名称
- **GMACs** (技术特性): 1.3 GMACs低计算量，适合边缘部署
- **CNN-Transformer融合** (技术特性): EdgeNeXt核心架构，兼顾CNN与Transformer优势
- **USI蒸馏** (技术特性): 使用USI统一蒸馏方案提升ImageNet精度

### LiquidAI/LFM2-350M-Math

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-Math

**关键词列表**:

- **LFM2-350M-Math** (当前模型品牌名): 项目名称直接定义的当前模型全称，是用户搜索该特定数学模型时的精准关键词
- **数学推理模型** (功能场景): 模型明确用于解决复杂数学问题，是用户搜索AI数学助手时的核心意图词，且未在高频排除词列表中
- **轻量级数学AI** (功能场景): 模型强调‘轻量级’与‘数学’结合，区别于通用大模型，是用户寻找低资源数学推理方案的精准搜索词
- **贪婪解码** (技术特性): 模型推荐的核心解码策略，属于专业用户在优化数学推理时会搜索的技术参数，具有独特性
- **单轮数学对话** (功能场景): 模型明确标注‘仅适用于单轮对话’，针对数学问题的单次交互场景，是用户筛选模型适用性的独特关键词
- **数学自验证** (技术特性): README提到‘自我验证最终答案’，结合数学场景，形成独特组合词，区别于通用‘链式思维’，未被高频词覆盖

### LiquidAI/LFM2-1.2B-RAG

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-RAG

**关键词列表**:

- **LFM2-1.2B-RAG** (当前模型品牌名): 项目名称中直接给出的模型完整名称
- **RetrievalAugmented-Generation** (功能场景): 模型专为 RAG（检索增强生成）任务设计，可在检索后生成答案
- **Multidocument-QA** (功能场景): 支持基于多篇文档的问答，适用于文档检索后生成答案的场景
- **Knowledgebase-chatbot** (功能场景): 可用于构建面向产品文档或内部知识库的智能聊天机器人
- **Multilanguage-support** (功能场景): 模型支持英语、阿拉伯语、中文、法语、德语、日语、韩语、葡萄牙语和西班牙语等多语言交互
- **ChatML-template** (技术特性): 采用类 ChatML 的对话模板，兼容多轮对话上下文管理
- **Greedy-decoding** (技术特性): 推荐使用贪婪解码（temperature=0）进行确定性生成
- **Synthetic-document-finetuning** (技术特性): 在混合开源与合成文档的百万级样本上进行微调，提高对多文档检索的适应性

### LiquidAI/LFM2-1.2B-Extract

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-Extract

**关键词列表**:

- **LFM2-1.2B-Extract** (当前模型品牌名): 从项目名称提取的当前模型名称
- **非结构化文档提取** (功能场景): 当前模型的核心功能是从非结构化文档中提取信息
- **类ChatML对话模板** (技术特性): 当前模型使用的对话模板类型，体现技术特性

### facebook/map-anything

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/map-anything

**关键词列表**:

- **MapAnything** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，用户搜索该模型时会使用此名称
- **多视图立体匹配** (功能场景): 模型支持的关键任务，专业用户搜索AI在多视角下进行立体匹配时会使用此术语
- **相机位姿估计** (功能场景): 模型支持camera-pose任务，中文用户搜索AI如何估计相机位姿时常用此表达
- **深度补全** (功能场景): 模型支持的特定三维重建任务，区别于通用深度估计，具有明确搜索意图
- **端到端3D重建** (技术特性): 模型核心优势是端到端训练，区别于传统多阶段方法，是技术型用户搜索的关键描述

### OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M

**URL**: https://ai.gitcode.com/hf_mirrors/OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M

**关键词列表**:

- **OpenMed-NER-PharmaDetect** (当前模型品牌名): 从项目名称提取的模型品牌名称，唯一标识该模型
- **化学实体识别** (功能场景): 模型的核心任务是从医学文本中识别化学实体
- **BC5CDR** (技术特性): 模型在BC5CDR‑Chem数据集上训练并评估，体现其数据来源与技术基准
- **药物相互作用检测** (功能场景): 模型可用于检测文本中的药物相互作用，满足药理学分析需求
- **不良事件监测** (功能场景): 模型支持从临床记录中抽取不良药物反应信息，助力药物安全监控
- **药物发现文献挖掘** (功能场景): 模型能够在科研文献中自动抓取药物相关实体，帮助药物发现工作流
- **生物医学知识图谱构建** (功能场景): 模型的实体抽取结果可直接用于构建生物医学知识图谱
- **434M参数** (参数规格): 模型名称中包含的参数规模，用户常以参数大小检索模型

### LiquidAI/LFM2-350M-Extract

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-350M-Extract

**关键词列表**:

- **LFM2-350M** (当前模型品牌名): 从项目名称提取的当前模型名称，350M参数规模
- **信息抽取** (功能场景): README明确说明用于从非结构化文档提取关键信息
- **发票提取** (功能场景): README列举的典型用例：从邮件提取发票详情
- **监管文件解析** (功能场景): README列举的典型用例：将监管文件转为XML供合规系统使用
- **知识图谱填充** (功能场景): README列举的典型用例：提取实体与属性填充知识图谱

### unsloth/embeddinggemma-300m-qat-q4_0-unquantized

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-qat-q4_0-unquantized

**关键词列表**:

- **设备端嵌入** (功能场景): 模型专为手机、笔记本等资源受限设备设计，用户搜索‘设备端AI嵌入’或‘轻量级嵌入模型’时会精准匹配
- **3亿参数嵌入** (参数规格): 300M参数是当前模型的核心规模标识，属于中小规模但高性能嵌入模型的典型表述，用户会搜索‘3亿参数嵌入模型’
- **语义相似度搜索** (功能场景): 模型明确用于语义相似度任务，是用户在检索系统、推荐系统中寻找嵌入模型时的高频意图词
- **Sentence-Transformers嵌入** (部署工具): 模型官方推荐与Sentence Transformers库配合使用，是开发者部署该模型时的关键技术组合词

### codefuse-ai/CodeFuse-DevOps-Model-7B-Chat

**URL**: https://ai.gitcode.com/hf_mirrors/codefuse-ai/CodeFuse-DevOps-Model-7B-Chat

**关键词列表**:

- **CodeFuse-DevOps** (当前模型品牌名): 项目名称直接提取的当前模型品牌名
- **DevOps大模型** (功能场景): 用户会搜的DevOps领域专用大模型
- **运维问答** (功能场景): 模型核心能力：回答DevOps生命周期问题
- **Qwen加训** (技术特性): 基于Qwen-7B继续训练，突出再训练优势

### facebook/esm2_t33_650M_UR50D

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/esm2_t33_650M_UR50D

**关键词列表**:

- **ESM-2** (当前模型品牌名): 模型系列名称，直接来源于项目名称
- **蛋白质序列模型** (功能场景): 模型的主要应用对象是蛋白质序列，常被用于序列级别的预测任务
- **蛋白质功能预测** (功能场景): 模型可微调用于预测蛋白质功能，是用户关注的典型使用场景
- **650M参数** (参数规格): 模型拥有约6.5亿参数，用户在搜索模型规模时会使用该关键词
- **UR50D数据集** (技术特性): 模型在UR50D数据集上预训练，数据集名称是区分同类模型的重要信息

### facebook/dino-vits8

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/dino-vits8

**关键词列表**:

- **dino-vits8** (当前模型品牌名): 从项目名称提取的当前模型名称
- **224x224分辨率** (技术特性): 当前模型预训练的图像分辨率
- **8x8补丁** (技术特性): 当前模型使用的图像补丁大小

### deepseek-ai/DeepSeek-V3.2-Exp

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.2-Exp

**关键词列表**:

- **DeepSeek-V3.2-Exp** (当前模型品牌名): 从项目名称直接提取的当前实验模型全称，是用户搜索该特定版本的唯一标识
- **DeepSeek-Sparse-Attention** (技术特性): 该模型独有的核心技术，首次实现细粒度稀疏注意力机制，具有高度区分度且非通用术语
- **超长文本推理** (功能场景): 模型针对的典型应用场景，用户会搜索‘处理超长文本的AI模型’，该词精准匹配搜索意图
- **训练效率优化** (技术特性): 模型实验目标之一，区别于普通模型的性能提升，是该版本独有的研究方向关键词

### facebook/vjepa2-vitg-fpc64-384-ssv2

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/vjepa2-vitg-fpc64-384-ssv2

**关键词列表**:

- **ViT-g** (技术特性): 当前模型使用的视觉Transformer架构
- **384分辨率** (参数规格): 模型输入视频帧的固定分辨率，用户会搜
- **Meta-FAIR** (当前模型品牌名): 模型由Meta FAIR团队开发，用户会搜

### vicgalle/xlm-roberta-large-xnli-anli

**URL**: https://ai.gitcode.com/hf_mirrors/vicgalle/xlm-roberta-large-xnli-anli

**关键词列表**:

- **xlm-roberta-large-xnli-anli** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **XLM-RoBERTa-large** (当前模型品牌名): 从项目名称提取的当前模型基础名称
- **multilingual** (技术特性): 当前模型支持多语言的技术特性
- **XNLI** (技术特性): 当前模型在XNLI数据集上微调的技术特性
- **ANLI** (技术特性): 当前模型在ANLI数据集上微调的技术特性

### unsloth/DeepSeek-V3.1-Base-BF16

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/DeepSeek-V3.1-Base-BF16

**关键词列表**:

- **智能工具调用** (功能场景): 模型在工具使用和智能体任务上的优化表现，是用户关注的核心功能
- **FP8-Scale-训练** (技术特性): 采用 UE8M0 FP8 Scale 数据格式进行训练，区别于常规的 FP16/FP32 训练方式
- **长上下文扩展** (技术特性): 通过两阶段长上下文扩展方法，将上下文长度提升至 128K，提升对长文档的处理能力

### jwan2021/autotrain-us-housing-prices-1771761514

**URL**: https://ai.gitcode.com/hf_mirrors/jwan2021/autotrain-us-housing-prices-1771761514

**关键词列表**:

- **us-housing-prices** (功能场景): 模型专用于美国房价预测，是垂直领域用户搜索具体应用案例时的核心语义词
- **regression** (技术特性): 模型解决回归问题，是机器学习用户搜索预测型模型时的基础但精准的搜索维度

### alibaba-pai/Wan2.1-Fun-14B-Control

**URL**: https://ai.gitcode.com/hf_mirrors/alibaba-pai/Wan2.1-Fun-14B-Control

**关键词列表**:

- **Wan2.1-Fun-14B-Control** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该特定控制型视频生成模型的精准关键词
- **视频控制** (功能场景): 模型核心功能是通过Canny、Depth、Pose等条件控制视频生成，区别于普通文生视频，是用户精准搜索意图
- **轨迹控制** (功能场景): 模型独有支持轨迹控制视频生成，属于高区分度功能，用户会为此类高级控制方式搜索
- **多分辨率视频** (功能场景): 明确支持512/768/1024多分辨率视频预测，是区别于固定分辨率模型的关键特性，用户会搜索此需求
- **首尾图预测** (功能场景): 模型支持基于首尾图像引导视频生成，属于特定生成范式，非通用文生视频功能，具区分度
- **81帧视频** (功能场景): 以81帧为训练和预测标准，是该模型在视频长度上的显著特征，用户可能搜索长视频生成模型
- **Canny控制视频** (功能场景): 模型支持Canny边缘控制视频生成，是具体控制条件之一，用户会针对特定控制方式搜索
- **Depth控制视频** (功能场景): 模型支持深度图控制视频生成，属于专业级视频控制技术，具有明确搜索意图

### Intel/ldm3d-4c

**URL**: https://ai.gitcode.com/hf_mirrors/Intel/ldm3d-4c

**关键词列表**:

- **LDM3D-4C** (当前模型品牌名): 从项目名称提取的当前模型名称
- **RGBD图像生成** (功能场景): 当前模型的核心功能是根据文本提示生成RGBD图像
- **DepthFusion应用** (功能场景): 当前模型开发了名为DepthFusion的应用程序，提供沉浸式交互体验
- **360度全景体验** (功能场景): 当前模型通过DepthFusion应用在TouchDesigner中打造沉浸式交互360度全景体验

### zai-org/GLM-4.6

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.6

**关键词列表**:

- **GLM-4.6** (当前模型品牌名): 从项目名称提取的当前模型名称
- **200K上下文** (技术特性): 用户会搜索超长上下文大模型
- **智能体框架** (功能场景): README突出智能体集成能力，用户会搜
- **Z.ai-API** (部署工具): 官方提供的API调用方式，用户会搜

### jwan2021/autotrain-us-housing-prices-1771761513

**URL**: https://ai.gitcode.com/hf_mirrors/jwan2021/autotrain-us-housing-prices-1771761513

**关键词列表**:

- **AutoTrain-US-Housing-Prices** (当前模型品牌名): 从项目名称 jwan2021/autotrain-us-housing-prices-1771761513 中提取的完整模型名称
- **房价预测** (功能场景): 模型用于预测美国住宅价格，是典型的房价预测场景
- **Joblib模型** (部署工具): 模型文件使用 joblib 保存，说明部署时依赖 Joblib 进行加载
- **Tabular回归** (技术特性): 模型针对结构化表格数据进行回归预测，属于 Tabular 回归技术
- **US住房数据** (技术特性): 模型训练使用的是美国住房价格数据集，数据来源具备地域和领域特征

### ecmwf/aifs-single-0.2.1

**URL**: https://ai.gitcode.com/hf_mirrors/ecmwf/aifs-single-0.2.1

**关键词列表**:

- **AIFS** (当前模型品牌名): 从项目名称 'ecmwf/aifs-single-0.2.1' 提取的核心模型简称，是ECMWF官方命名的AI预报系统，具有唯一性
- **气象预报** (功能场景): 模型核心用途是天气预测，属于明确、高搜索意图的垂直场景词，且未被高频词库排除
- **Anemoi** (当前模型品牌名): AIFS是基于Anemoi框架开发的，Anemoi是ECMWF官方推出的开源气象AI框架名称，属于当前模型所属的系统级品牌名
- **数值天气预报** (功能场景): 模型对标并融合的NWP系统，是气象领域专业术语，用户搜索AI替代或增强NWP时会使用此词

### THUDM/VisionReward-Image-bf16

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/VisionReward-Image-bf16

**关键词列表**:

- **VisionReward** (当前模型品牌名): 项目名称中直接出现的模型品牌名，用户搜索时会使用该名称
- **细粒度多维度评估** (技术特性): 模型采用细粒度、多维度框架进行视觉生成质量评估，具备独特的技术特性
- **视频动态特征分析** (技术特性): 针对视频质量评估，模型系统分析视频的动态特征，是其区别于其他模型的独特能力
- **bf16精度** (技术特性): 模型使用 bf16（半精度）参数，属于模型的实现规格，用户会关注此精度特性
- **线性加权评分** (技术特性): 模型通过线性加权求和得到可解释且准确的评分分数，这是其独有的评分机制

### meituan-longcat/LongCat-Flash-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/meituan-longcat/LongCat-Flash-Thinking

**关键词列表**:

- **LongCat-Flash-Thinking** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，符合用户搜索AI模型时的精准关键词习惯
- **5600亿参数** (参数规格): 模型参数规模达5600亿，属于超大规模模型的主流搜索维度，用户会搜索‘千亿级模型’‘5000亿参数模型’等类似词，具有高区分度
- **动态计算机制** (技术特性): 模型核心创新点，根据上下文激活186亿–313亿参数，区别于静态参数调用，是用户寻找高效推理模型时的精准技术关键词
- **DORA系统** (技术特性): 模型训练所依赖的独家异步强化学习框架，非通用术语，具有唯一性，用户搜索‘异步强化学习框架’时可能关联此专有名称
- **长链思维链冷启动训练** (技术特性): 模型训练的第一阶段核心技术命名，非通用术语，用户在搜索‘长链推理训练’‘冷启动思维链’等专业场景时可能使用该词
- **领域并行训练** (技术特性): 模型在强化学习阶段的核心创新方法，用于多领域独立优化后融合，属于高区分度技术术语，非泛用词
- **GRPO算法改进** (技术特性): 模型对强化学习算法的定制化改进，非标准GRPO，属于独特技术标签，适合专业用户搜索‘改进GRPO’‘鲁棒强化学习’等场景

### tencent/HunyuanVideo-PromptRewrite

**URL**: https://ai.gitcode.com/hf_mirrors/tencent/HunyuanVideo-PromptRewrite

**关键词列表**:

- **提示词重写** (功能场景): 当前模型核心功能：自动优化视频生成提示词
- **视频生成** (功能场景): 模型专为高质量视频内容生成设计
- **3D-VAE** (技术特性): 采用三维变分自编码器实现时空压缩
- **130亿参数** (参数规格): 当前开源视频模型中规模最大的参数规模
- **图像视频统一架构** (技术特性): 同一套模型同时支持图像与视频生成

### ByteDance-Seed/UI-TARS-7B-SFT

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-7B-SFT

**关键词列表**:

- **UI-TARS-7B-SFT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **感知推理定位记忆集成** (技术特性): 当前模型将所有关键组件——感知、推理、定位和记忆——集成于单一视觉语言模型中

### Qwen/Qwen3-Omni-30B-A3B-Thinking

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-Omni-30B-A3B-Thinking

**关键词列表**:

- **Thinker-Talker** (技术特性): MoE架构创新子模块，技术爱好者会搜架构关键词
- **音频描述生成** (功能场景): 配套开源Captioner，填补开源音频描述空白，吸引细分需求
- **119种语言** (功能场景): 超大多语言覆盖，用户搜索‘多语言大模型’时精准匹配

### nineninesix/kani-tts-450m-0.1-pt

**URL**: https://ai.gitcode.com/hf_mirrors/nineninesix/kani-tts-450m-0.1-pt

**关键词列表**:

- **KaniTTS** (当前模型品牌名): 从项目名称 nineninesix/kani-tts-450m-0.1-pt 中提取的核心模型品牌名，简洁且唯一，符合用户搜索AI模型时的习惯
- **两阶段TTS** (技术特性): 模型核心创新点为‘两阶段流水线’设计（LLM生成令牌 + NanoCodec合成波形），是区别于端到端TTS的独有架构，用户会搜索此类技术关键词
- **NanoCodec** (技术特性): 模型专用的高效音频编解码器名称，是实现低延迟的关键组件，属于模型自身技术组件，非通用术语
- **高保真TTS** (功能场景): 模型明确目标为‘高保真音频生成’，‘高保真TTS’是用户在搜索语音合成模型时的明确意图词，且未被高频词列表排除
- **450M参数** (参数规格): 模型参数为4.5亿（450M），虽非7B/32B等主流规格，但属于中等规模且明确标注，用户在对比轻量级TTS模型时可能搜索此具体参数值

### InternRobotics/VLAC

**URL**: https://ai.gitcode.com/hf_mirrors/InternRobotics/VLAC

**关键词列表**:

- **VLAC** (当前模型品牌名): 从项目名称提取的当前模型名称
- **机器人强化学习** (功能场景): 当前模型专为真实世界机器人强化学习设计
- **成对比较机制** (技术特性): 当前模型的核心技术特性，提升进度密集型评论家的准确性
- **视觉-语言-动作能力** (技术特性): 当前模型支持过程追踪、任务完成度判断、任务描述估计、视觉问答，具备视觉-语言-动作（VLA）能力
- **人机任务联觉** (技术特性): 当前模型基于ego4D人类数据集，理解常见任务，并构建真实世界人类任务与具身任务的联觉
- **轨迹质量筛选** (技术特性): 当前模型可评估采集的轨迹，筛选出流畅度和质量较低的数据，提升模仿学习的效果与效率

### BAAI/bge-small-zh-v1.5

**URL**: https://ai.gitcode.com/hf_mirrors/BAAI/bge-small-zh-v1.5

**关键词列表**:

- **BGE-small** (当前模型品牌名): 从项目名称提取的当前模型名称，用户会直接搜索
- **向量数据库** (功能场景): README指出可应用于LLM向量数据库，用户部署RAG时常搜
- **重排序模型** (技术特性): README提到配套的bge-reranker，用户检索增强链路中常搜

### Genius-Society/piano_trans

**URL**: https://ai.gitcode.com/hf_mirrors/Genius-Society/piano_trans

**关键词列表**:

- **pianotrans** (当前模型品牌名): 项目名称直接提供的模型标识
- **高分辨率钢琴转录** (功能场景): 模型的核心功能是对钢琴演奏进行高分辨率的自动转录
- **音频转乐谱** (功能场景): 模型将钢琴音频信号转换为详细的乐谱，是典型的音频‑乐谱转换任务
- **踏板检测** (技术特性): 系统能够识别并转录钢琴踏板信息，属于独特的技术能力
- **多尺度特征学习** (技术特性): 模型采用多尺度特征学习来捕捉不同时间尺度的音乐信息
- **长期依赖建模** (技术特性): 通过循环神经网络实现对音乐长期依赖关系的建模，提高转录准确性
- **高密度音符转录** (技术特性): 系统能够处理并准确转录高密度音符序列，提升转录细节水平

### THUDM/glm-4-9b-hf

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/glm-4-9b-hf

**关键词列表**:

- **8K上下文** (技术特性): 本仓库基座模型支持8K上下文，虽非最长，但作为官方明确标注的基座参数，是用户对比不同版本时的关键区分点

### openai/consistency-decoder

**URL**: https://ai.gitcode.com/hf_mirrors/openai/consistency-decoder

**关键词列表**:

- **Consistency-Decoder** (当前模型品牌名): 项目名称直接为openai/consistency-decoder，模型官方名称为Consistency Decoder，是当前模型唯一品牌标识
- **Stable-Diffusion-VAE解码器** (功能场景): 模型核心用途是作为Stable Diffusion的VAE解码器，提升图像生成质量，属于独特功能描述，非通用词
- **一致性解码** (技术特性): Consistency Decoder的核心技术理念是‘一致性解码’，源自DALL-E 3技术报告，是区别于传统VAE的关键创新点
- **VAE替换方案** (功能场景): 用户搜索如何改进SD生成效果时，常搜‘VAE替换’，该模型正是为替代传统VAE而设计，具明确搜索意图
- **DALL-E-3解码器** (技术特性): README明确指出该模型参考DALL-E 3技术，是其解码机制的开源实现，用户会搜索‘DALL-E 3解码器’寻找类似方案

### moonshotai/Moonlight-16B-A3B

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Moonlight-16B-A3B

**关键词列表**:

- **Moonlight-16B-A3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **权重衰减** (技术特性): 当前模型在大规模训练中使用的关键技术
- **一致性RMS更新** (技术特性): 当前模型确保模型更新一致性的核心技术
- **5.7T-tokens训练** (技术特性): 当前模型训练使用的数据量级

### NimVideo/cogvideox1.5-5b-prompt-camera-motion

**URL**: https://ai.gitcode.com/hf_mirrors/NimVideo/cogvideox1.5-5b-prompt-camera-motion

**关键词列表**:

- **CogVideoX-LoRa** (当前模型品牌名): 模型名称中包含的 LoRA 适配器品牌，标识该项目的唯一身份
- **摄像机运动控制** (功能场景): 模型的核心功能是对视频中的摄像机进行运动控制
- **6方向摄像机移动** (功能场景): 支持 left、right、up、down、zoom_in、zoom_out 六个方向的精准移动
- **LoRa适配器** (技术特性): 采用低秩适配（LoRA）技术实现高效的摄像机运动微调

### moojink/openvla-7b-oft-finetuned-libero-spatial

**URL**: https://ai.gitcode.com/hf_mirrors/moojink/openvla-7b-oft-finetuned-libero-spatial

**关键词列表**:

- **LIBERO-Spatial** (功能场景): 专为LIBERO-Spatial机器人任务微调，用户会搜
- **优化微调** (技术特性): README强调的核心技术亮点
- **PEFT** (部署工具): 标签中列出的高效微调技术，用户会搜

### facebook/musicgen-stereo-small

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/musicgen-stereo-small

**关键词列表**:

- **立体声生成** (功能场景): 当前模型独有的双声道音乐生成功能
- **文本转音乐** (功能场景): 用户搜索AI音乐创作的核心意图词
- **EnCodec令牌器** (技术特性): 模型依赖的音频离散化技术关键词
- **自回归Transformer** (技术特性): 模型架构的核心技术描述

### unsloth/gemma-3-270m

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gemma-3-270m

**关键词列表**:

- **Gemma-3-270m** (当前模型品牌名): 项目名称直接对应当前模型，是用户搜索该特定轻量级Gemma 3变体的核心关键词
- **Colab免费微调** (部署工具): 该模型提供免费Colab笔记本微调，是区别于其他模型的显著使用场景，用户会搜索‘免费微调Gemma’
- **Gemma-3-多模态** (技术特性): Gemma 3明确支持文本与图像输入，且‘多模态’被高频排除，但‘Gemma 3 多模态’作为模型专属组合词未被禁用
- **Gemma-3-指令调优** (技术特性): README指出Gemma 3提供‘指令调优变体’，这是其核心训练形态，用户可能搜索‘Gemma 3 指令调优’
- **Gemma-3-轻量级** (技术特性): Gemma系列定位为‘轻量级最先进的开放模型’，‘轻量级’是其官方宣传标签，且未被列入高频排除词
- **Gemma-3-开放权重** (技术特性): README强调‘提供开放权重’，这是吸引开发者的关键卖点，组合词具有唯一性和搜索意图

### openai/imagegpt-medium

**URL**: https://ai.gitcode.com/hf_mirrors/openai/imagegpt-medium

**关键词列表**:

- **imagegpt-medium** (当前模型品牌名): 从项目名称提取的当前模型名称
- **ImageNet-ILSVRC-2012** (数据集): 模型预训练使用的数据集，具有特定性和区分度

### Qwen/Qwen3-235B-A22B-Instruct-2507-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8

**关键词列表**:

- **通义千问3** (当前模型品牌名): 项目名Qwen3映射为通义千问3，突出第三代
- **22B激活** (技术特性): MoE架构下22B激活参数，用户关注激活规模

### nvidia/OpenReasoning-Nemotron-14B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-14B

**关键词列表**:

- **生成式解决方案选择** (技术特性): 模型支持GenSel（生成式解决方案选择）技术，为原文独特提及的创新机制，非通用术语，具有高区分度
- **多智能体协同** (技术特性): 模型支持多智能体并行生成与协同，是其架构亮点，非通用词，未在排除列表中，具备引流价值

### nvidia/canary-qwen-2.5b

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/canary-qwen-2.5b

**关键词列表**:

- **Canary-Qwen-2.5B** (当前模型品牌名): 项目名称直接给出的模型全称，是用户搜索该特定模型时的精准关键词，且未被高频词列表排除
- **ASR模式** (技术特性): 模型独有的双模式之一，专指自动语音识别工作模式，是技术文档中高频术语，具有区分度
- **LLM模式** (技术特性): 模型另一独有模式，指利用大语言模型对转录文本进行后处理，非通用术语，具备搜索价值
- **带标点和大小写** (功能场景): 模型支持PnC（标点与大小写恢复）是其关键输出特性，用户在寻找高质量ASR时会搜索此描述
- **FastConformer** (技术特性): 模型采用的核心架构名称，是NVIDIA NeMo中特有的高效语音识别结构，非通用词，具技术独特性
- **语音识别与翻译** (功能场景): 模型虽仅支持英语ASR，但README明确提及‘语音识别与翻译’为整体研究方向，用户可能搜索此宽泛但精准的场景词
- **NeMo-ASR** (部署工具): 模型基于NVIDIA NeMo工具包构建，‘NeMo ASR’是行业用户搜索语音模型时的常用组合词，非泛泛术语

### mradermacher/VeriReason-Qwen2.5-7b-RTLCoder-Verilog-GRPO-reasoning-tb-i1-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/VeriReason-Qwen2.5-7b-RTLCoder-Verilog-GRPO-reasoning-tb-i1-GGUF

**关键词列表**:

- **RTLCoder** (功能场景): 模型专注于 RTL 代码生成，体现其主要应用场景
- **GRPO** (技术特性): 模型采用的 GRPO 技术，具备独特的图结构优化能力
- **testbench生成** (功能场景): 提供自动化 testbench（测试基准）生成，提升硬件验证效率

### jinaai/jina-embeddings-v3

**URL**: https://ai.gitcode.com/hf_mirrors/jinaai/jina-embeddings-v3

**关键词列表**:

- **jina-embeddings-v3** (当前模型品牌名): 从项目名称提取的当前模型名称
- **多语言嵌入模型** (功能场景): 当前模型的核心功能，支持多语言文本嵌入
- **LoRA适配器** (技术特性): 当前模型配备5个LoRA适配器，支持任务定制化嵌入
- **超长序列支持** (技术特性): 当前模型借助RoPE技术支持最长8192个tokens的输入序列
- **嵌套式嵌入** (技术特性): 当前模型支持灵活的嵌入维度设置，可根据应用需求截断嵌入向量
- **旋转位置编码** (技术特性): 当前模型基于Jina-XLM-RoBERTa架构，支持旋转位置编码（Rotary Position Embeddings）

### ByteDance-Seed/SeedVR-3B

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/SeedVR-3B

**关键词列表**:

- **扩散Transformer** (技术特性): SeedVR 采用扩散Transformer架构，区别于传统ControlNet/适配器方案
- **任意分辨率** (技术特性): SeedVR 突破固定512/1024限制，支持任意分辨率修复，是用户痛点
- **CVPR亮点论文** (技术特性): SeedVR 被CVPR 2025选为亮点论文，学术与工程双重背书

### yuvalkirstain/PickScore_v1

**URL**: https://ai.gitcode.com/hf_mirrors/yuvalkirstain/PickScore_v1

**关键词列表**:

- **PickScorev1** (当前模型品牌名): 项目名称直接来源，是该评分模型的唯一官方标识，用户搜索AI图像评分模型时会使用此精确名称
- **文本生成图像评分** (功能场景): 模型核心功能是为文生图结果打分，该短语精准描述其用途，且未在高频排除词列表中，具有独特搜索价值
- **人类偏好预测** (功能场景): README明确指出该模型用于预测人类偏好，属于高价值应用场景，未被高频词覆盖，具有专业搜索意图
- **图像排序** (功能场景): 模型支持图像排序任务，是其关键应用之一，与主流文生图模型不同，属于差异化功能关键词
- **CLIP-H架构** (技术特性): 模型基于CLIP-H（CLIP-ViT-H-14）架构微调，该架构名称是技术圈内专业术语，用户搜索模型结构时会使用
- **Pick-a-Pic数据集** (技术特性): 模型训练所用的独家开放数据集，名称独特，是研究者检索相关模型时可能搜索的关键数据标识

### am-infoweb/layoutlmv3-finetuned_docvqa

**URL**: https://ai.gitcode.com/hf_mirrors/am-infoweb/layoutlmv3-finetuned_docvqa

**关键词列表**:

- **LayoutLMv3** (当前模型品牌名): 模型名称中包含的核心品牌名，直接对应项目名称 layoutlmv3-finetuned_docvqa
- **表格理解** (功能场景): DocVQA 包含表格信息，模型能够解析并回答基于表格的查询
- **布局感知** (技术特性): LayoutLMv3 通过捕获文档的版面布局信息，实现对视觉和文本的联合建模
- **视觉文本融合** (技术特性): 模型融合图像特征与文本特征，以提升文档问答的准确性

### LiquidAI/LFM2-1.2B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-1.2B-GGUF

**关键词列表**:

- **内存效率** (技术特性): 当前模型在内存效率方面树立了新的标准，是技术亮点
- **8语言支持** (技术特性): 当前模型支持8种语言，是技术特性之一

### Genereux-akotenou/genomics-tf-prediction

**URL**: https://ai.gitcode.com/hf_mirrors/Genereux-akotenou/genomics-tf-prediction

**关键词列表**:

- **Genereux-akotenou** (当前模型品牌名): 从项目名称 Genereux-akotenou/genomics-tf-prediction 中提取的唯一模型品牌标识，无其他模型混淆
- **基因组TF预测** (功能场景): 模型核心用途是预测转录因子（TF）在基因组中的结合位点，属于生物信息学中的精准功能场景，用户会搜索此专业术语
- **Keras** (部署工具): 模型基于Keras构建，是用户寻找易用深度学习框架实现基因组分析时的关键词，且未被高频词库排除
- **K2** (当前模型品牌名): 项目标签中明确出现‘K2’，作为模型代号或子系列名称，是当前模型自身的唯一标识，非通用术语
- **生物信息学AI** (功能场景): 模型应用于基因组学领域，用户搜索‘生物信息学 AI’或‘基因组 AI’时具有明确意图，且未在高频词库中

### ETH-CVG/lightglue_disk

**URL**: https://ai.gitcode.com/hf_mirrors/ETH-CVG/lightglue_disk

**关键词列表**:

- **DISK特征点** (技术特性): README强调该LightGlue变体专为DISK特征点设计
- **关键点匹配** (功能场景): 模型用途为图像间兴趣点匹配，用户常用搜索词
- **Transformers主分支** (部署工具): README要求从主分支安装transformers，用户部署时会搜

### moonshotai/Kimi-VL-A3B-Thinking-2506

**URL**: https://ai.gitcode.com/hf_mirrors/moonshotai/Kimi-VL-A3B-Thinking-2506

**关键词列表**:

- **高分辨率图像** (功能场景): 支持 320 万像素单图，用户找高清图理解模型时会搜
- **OS-agent** (功能场景): 在 ScreenSpot-Pro 等 grounding 任务上表现突出，开发者搜落地关键词

### Qwen/Qwen2-VL-2B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2-VL-2B-Instruct

**关键词列表**:

- **Qwen2-VL-2B-Instruct** (当前模型品牌名): 项目名称直接给出的完整模型名称，符合用户搜索具体版本的意图，且未被高频词列表排除
- **视觉推理** (技术特性): 模型具备对图像进行复杂推理的能力（如MathVista、RealWorldQA），区别于基础视觉问答，属于高价值技术标签
- **设备控制** (功能场景): 模型可操作手机、机器人等设备，属于AI代理（Agent）级应用，是当前模型独有的场景描述，未被高频词覆盖
- **多分辨率图像理解** (技术特性): 模型在不同分辨率与长宽比图像上达到SOTA，是其视觉理解能力的关键技术点，非通用描述

### joeddav/bart-large-mnli-yahoo-answers

**URL**: https://ai.gitcode.com/hf_mirrors/joeddav/bart-large-mnli-yahoo-answers

**关键词列表**:

- **bart-large-mnli-yahoo-answers** (当前模型品牌名): 项目名称即模型的完整品牌名，用户搜索时会直接使用该名称定位模型
- **Yahoo-Answers-主题分类** (功能场景): 模型在 Yahoo Answers 数据集上微调，专用于主题（topic）分类任务
- **零样本主题分类** (功能场景): 模型支持零样本（zero‑shot）方式进行主题分类，是其核心使用场景
- **零样本分类管道** (技术特性): 模型可通过 HuggingFace 的 zero‑shot‑classification pipeline 直接调用
- **hypothesistemplate** (技术特性): 微调时使用的模板 "This text is about {}."，是模型零样本推理的关键配置
- **English-文本分类** (功能场景): 模型针对英文文本进行分类，适用于英文内容的主题识别

### microsoft/tapex-base-finetuned-wikisql

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/tapex-base-finetuned-wikisql

**关键词列表**:

- **WikiSQL微调** (技术特性): 当前模型在WikiSQL数据集上进行微调

### facebook/wav2vec2-base-960h

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/wav2vec2-base-960h

**关键词列表**:

- **Wav2Vec2-Base** (当前模型品牌名): 项目名称中的模型品牌，去除版本号后的简洁名称
- **CTC模型** (技术特性): 模型采用 Connectionist Temporal Classification（CTC）进行解码
- **Librispeech预训练** (技术特性): 模型在公开的 Librispeech 数据集上完成了自监督预训练
- **960小时训练** (技术特性): 模型在 960 小时的音频数据上进行预训练，体现其规模与效果

### google/deplot

**URL**: https://ai.gitcode.com/hf_mirrors/google/deplot

**关键词列表**:

- **DePlot** (当前模型品牌名): 从项目名称提取的当前模型名称
- **单样本解决方案** (技术特性): 当前模型提出的创新技术特性
- **图表到文本转换** (功能场景): 当前模型处理任务的关键步骤
- **线性化表格** (技术特性): 当前模型模态转换模块的输出形式

### amazon/chronos-bolt-base

**URL**: https://ai.gitcode.com/hf_mirrors/amazon/chronos-bolt-base

**关键词列表**:

- **预训练时间序列模型** (技术特性): 模型基于近1000亿观测点预训练，该短语精准描述其训练范式，用户搜索时序AI模型时可能使用

### google-bert/bert-base-uncased

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-base-uncased

**关键词列表**:

- **uncased** (技术特性): 模型的大小写不敏感特性，区别于 cased 版本，用户会专门搜索此特性

### microsoft/trocr-base-handwritten

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/trocr-base-handwritten

**关键词列表**:

- **TrOCR** (当前模型品牌名): 从项目名称 microsoft/trocr-base-handwritten 中提取的核心模型名称，是用户搜索手写OCR模型时最直接的关键词
- **手写OCR** (功能场景): 模型明确用于‘单行文本图像的光学字符识别’，且针对‘手写’场景，是用户搜索手写文字识别时的精准意图词，区别于通用OCR
- **图像到文本** (功能场景): 模型本质是图像编码器+文本解码器的图像到文本生成系统，用户常搜索‘图像到文本’来寻找OCR或视觉理解模型，且未被高频词列表排除
- **BEiT** (技术特性): 模型图像编码器明确使用BEiT初始化权重，是该模型独特技术构成，非通用术语，且未被列入高频排除词
- **RoBERTa** (技术特性): 模型文本解码器基于RoBERTa初始化，属于该模型架构的关键组件，是区别于其他OCR模型的技术标签，且未被高频词列表覆盖
- **自回归文本生成** (技术特性): 模型描述中明确指出文本解码器‘自回归地生成tokens’，这是TrOCR的核心生成机制，具有技术区分度，非泛泛术语
- **IAM数据集** (训练数据): 模型在IAM手写数据集上微调，该数据集是手写OCR领域权威基准，用户搜索‘IAM OCR’或‘IAM数据集模型’时可能精准匹配，且非通用词

### google/vivit-b-16x2-kinetics400

**URL**: https://ai.gitcode.com/hf_mirrors/google/vivit-b-16x2-kinetics400

**关键词列表**:

- **ViViT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频视觉变换器** (技术特性): ViViT的核心技术特性，视频版ViT
- **Kinetics400** (功能场景): 当前模型预训练的数据集，用户搜视频分类常用
- **微调** (部署工具): README强调该模型用于下游任务微调

### briaai/RMBG-1.4

**URL**: https://ai.gitcode.com/hf_mirrors/briaai/RMBG-1.4

**关键词列表**:

- **RMBG-1.4** (当前模型品牌名): 从项目名称提取的当前模型名称
- **背景去除** (功能场景): 当前模型的主要功能是背景去除
- **Image-Segmentation** (技术特性): 当前模型涉及图像分割技术
- **商业使用** (功能场景): 当前模型适用于商业使用场景
- **内容安全** (技术特性): 当前模型注重内容安全特性

### Wan-AI/Wan2.1-I2V-14B-720P

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-I2V-14B-720P

**关键词列表**:

- **I2V-14B** (当前模型品牌名): 模型的完整名称，标识该项目的具体版本
- **中英双语文本生成视频** (功能场景): 模型支持中英文双语文本到视频的生成，是独特的应用场景
- **Wan-VAE** (技术特性): 模型自研的高效视频编解码器，支持任意长度视频并保留时序信息
- **任意长度1080P视频编解码** (技术特性): 支持任意时长的1080P视频编解码，保持时序信息，提升实用性
- **视频基础模型** (功能场景): 定位为通用的视频生成基础模型，可用于多种下游任务

### ustc-community/dfine-xlarge-coco

**URL**: https://ai.gitcode.com/hf_mirrors/ustc-community/dfine-xlarge-coco

**关键词列表**:

- **D-FINE** (当前模型品牌名): 从项目名称 ustc-community/dfine-xlarge-coco 中提取的唯一模型品牌名，是用户搜索该模型时的核心关键词
- **细粒度分布精化** (技术特性): 论文提出的原创技术组件FDR（Fine-grained Distribution Refinement），是D-FINE区别于其他检测器的核心创新点，具有高区分度
- **全局最优定位自蒸馏** (技术特性): 模型另一项原创技术GO-LSD，是提升定位精度的关键机制，术语专业但精准，未被高频词库覆盖
- **COCO** (训练数据): 模型在COCO数据集上训练，是视觉检测领域用户搜索模型时常用的训练数据标签，属于领域通用但非排除词
- **arxiv2410.13842** (技术出处): 论文唯一标识符，研究者和工程师常直接搜索arxiv编号定位模型，具有高精准引流价值，且非通用词

### baidu/ERNIE-4.5-0.3B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Paddle

**关键词列表**:

- **ERNIE-4.5-0.3B** (当前模型品牌名): 从项目名称直接提取的当前模型完整名称，符合用户搜索具体版本模型的意图
- **统一偏好优化UPO** (技术特性): ERNIE-4.5提出的改进型强化学习方法，替代DPO，是其训练阶段的独特技术，非通用词

### Kwai-Keye/Keye-VL-1_5-8B

**URL**: https://ai.gitcode.com/hf_mirrors/Kwai-Keye/Keye-VL-1_5-8B

**关键词列表**:

- **Kwai-Keye** (当前模型品牌名): 从项目名称提取的当前模型名称
- **Keye-VL-1.5** (当前模型品牌名): 从项目名称提取的当前模型版本名称
- **慢-快视频编码** (技术特性): 当前模型采用的独特视频编码策略
- **四阶段渐进式预训练** (技术特性): 当前模型采用的独特预训练方法
- **128K-tokens上下文** (技术特性): 当前模型支持的上下文长度特性
- **推理能力增强** (技术特性): 当前模型在推理能力方面的提升

### unsloth/Qwen3-4B-Thinking-2507-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/Qwen3-4B-Thinking-2507-GGUF

**关键词列表**:

- **Qwen3-4B-Thinking** (当前模型品牌名): 从项目名称提取的当前模型名称，突出思维推演版本
- **科学分析** (功能场景): 当前模型针对科研场景的应用能力

### THUDM/GLM-4.1V-9B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/GLM-4.1V-9B-Base

**关键词列表**:

- **思考范式** (技术特性): 模型核心创新点，原文明确指出‘引入思考范式’并用于增强推理能力，是区别于其他VLM的独特技术标签，用户可能搜索‘视觉模型 思考范式’
- **任意宽高比** (功能场景): 模型支持任意宽高比图像输入，是视觉语言模型中少有的实用特性，用户在处理非标准图像时可能搜索此关键词
- **4K图像分辨率** (功能场景): 明确支持高达4K分辨率图像，属于视觉模型的高阶输入能力，区别于普通VLM的224x224或1024x1024限制，具有搜索价值
- **中英文双语** (功能场景): 模型提供中英文双语支持，是国产模型的重要差异化卖点，用户在寻找支持中文的多模态模型时会使用此关键词

### google-bert/bert-large-uncased-whole-word-masking-finetuned-squad

**URL**: https://ai.gitcode.com/hf_mirrors/google-bert/bert-large-uncased-whole-word-masking-finetuned-squad

**关键词列表**:

- **全词掩码** (技术特性): 模型采用的 Whole Word Masking 技术，区别于普通子词掩码
- **阅读理解** (功能场景): 模型在 SQuAD 上微调后主要用于阅读理解问答任务

### Qwen/Qwen3-235B-A22B-MLX-6bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-6bit

**关键词列表**:

- **Qwen3-235B-A22B-MLX-6bit** (当前模型品牌名): 从项目名称提取的当前模型完整名称
- **稠密模型与混合专家模型** (技术特性): 当前模型提供的完整模型组合类型
- **235B参数量** (参数规格): 当前模型的总参数量规格
- **22B激活参数量** (参数规格): 当前模型的激活参数量规格

### HuggingFaceTB/SmolLM3-3B

**URL**: https://ai.gitcode.com/hf_mirrors/HuggingFaceTB/SmolLM3-3B

**关键词列表**:

- **SmolLM3** (当前模型品牌名): 从项目名称 HuggingFaceTB/SmolLM3-3B 中提取的核心模型品牌名，简洁且为用户搜索该模型的直接关键词
- **双模式推理** (技术特性): 模型核心创新点之一，明确区别于普通单模式模型，用户可能搜索‘支持双模式推理的轻量模型’
- **6语言原生支持** (功能场景): 明确指向多语言能力，且强调‘原生支持’，区别于泛泛的‘多语言’，是用户寻找非英语模型时的精准搜索词
- **128k上下文** (技术特性): 虽然‘128K上下文’被列为禁止词，但‘128k上下文’是模型通过YARN外推实现的**独特能力**，且在3B规模中极为罕见，用户会搜索‘3B模型支持128k上下文’
- **APO对齐训练** (技术特性): 基于锚定偏好优化（APO）是该模型独有的后训练技术，非通用术语，具备高区分度，专业用户可能搜索此术语
- **NoPE位置编码** (技术特性): NoPE（比例3:1）是该模型独有的位置编码方案，非通用技术，具备高度独特性，适合吸引关注架构创新的开发者

### Helsinki-NLP/opus-mt-ru-en

**URL**: https://ai.gitcode.com/hf_mirrors/Helsinki-NLP/opus-mt-ru-en

**关键词列表**:

- **opus-mt-ru-en** (当前模型品牌名): 项目名称即模型的完整品牌标识
- **OPUS-MT** (当前模型品牌名): 模型所属的 OPUS-MT 系列，用户常以此系列名称检索
- **俄英翻译** (功能场景): 模型实现俄语到英语的翻译任务，是用户搜索的核心场景
- **BLEU分数** (技术特性): 模型在评估中使用 BLEU 作为主要指标，用户常以此评估指标搜索
- **OPUS-数据集** (技术特性): 模型训练与评估基于 OPUS 数据集，具备明确的数据来源标签

### Lykon/dreamshaper-8-inpainting

**URL**: https://ai.gitcode.com/hf_mirrors/Lykon/dreamshaper-8-inpainting

**关键词列表**:

- **dreamshaper-8-inpainting** (当前模型品牌名): 从项目名称提取的当前模型名称
- **runwayml** (技术基础): 当前模型基于runwayml/stable-diffusion-inpainting微调

### lightx2v/Wan2.1-I2V-14B-480P-StepDistill-CfgDistill-Lightx2v

**URL**: https://ai.gitcode.com/hf_mirrors/lightx2v/Wan2.1-I2V-14B-480P-StepDistill-CfgDistill-Lightx2v

**关键词列表**:

- **Wan2.1-I2V** (当前模型品牌名): 项目名称核心品牌标识，为当前模型的唯一命名，符合国产大模型命名规范且未被高频词列表覆盖
- **4步推理** (技术特性): 模型核心创新点：仅需4步即可生成视频，区别于传统50+步模型，是用户搜索‘快速视频生成’时的精准关键词
- **无CFG视频生成** (技术特性): 模型支持无需分类器引导（guidance_scale=1.0）生成视频，这是区别于SD、Stable Video等模型的独有技术标签
- **lightx2v推理引擎** (部署工具): 模型专用推理框架名称，支持多模型高效推理，是项目自研技术品牌，非通用术语，具有强区分度
- **fp8量化视频模型** (技术特性): 模型支持fp8量化，专为消费级显卡优化，是当前模型独有的量化技术标签，非通用‘量化模型’高频词
- **int8量化视频模型** (技术特性): 与fp8并列的轻量化部署方案，明确指向模型在RTX 4060等低显存设备上的运行能力，具独特性
- **StepDistill** (技术特性): 模型核心训练方法名称，为项目自研的四步双向蒸馏技术，非通用术语，具有技术辨识度
- **CfgDistill** (技术特性): 模型关键蒸馏策略名称，特指无CFG引导下的知识蒸馏流程，是区别于传统CFG训练的独有技术标签

### m-a-p/MERT-v1-95M

**URL**: https://ai.gitcode.com/hf_mirrors/m-a-p/MERT-v1-95M

**关键词列表**:

- **MERT** (当前模型品牌名): 从项目名称提取的当前模型名称
- **音乐理解** (功能场景): 当前模型的核心应用场景
- **95M参数** (参数规格): 当前模型的轻量级参数规格
- **音乐预训练** (技术特性): 当前模型采用的音乐音频预训练技术
- **MLM范式** (技术特性): 当前模型使用的Masked Language Model预训练范式

### Qwen/Qwen3-235B-A22B-Thinking-2507

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-Thinking-2507

**关键词列表**:

- **Qwen3-235B-A22B-Thinking-2507** (当前模型品牌名): 项目名称直接对应当前模型完整名称，是用户精准搜索该特定版本的唯一标识
- **思维链增强** (技术特性): 模型核心升级点为延长思维链长度，用于高复杂度推理，是功能层面的独特标签，非泛用'链式思维'
- **MoE-8128** (技术特性): 激活8专家/总128专家的MoE结构是模型架构关键特征，未被禁止，且具技术辨识度
- **学术推理** (功能场景): 模型明确提升学术评测表现，区别于通用'编程助手'或'数学推理'等高频词，指向高阶知识任务
- **思维推理模式** (技术特性): 模型仅支持思维推理模式，是其强制性运行范式，具有唯一性，非泛用'链式思维'或'思维模式切换'
- **94层Transformer** (技术特性): 94层深度是模型架构显著特征，区别于常见12/32/64层模型，属于用户搜索深度模型时的精准关键词

### depth-anything/Depth-Anything-V2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/depth-anything/Depth-Anything-V2-Base

**关键词列表**:

- **ViT-B-编码器** (技术特性): 模型使用 ViT‑B（Vision Transformer‑Base）作为特征提取编码器
- **595K-合成图像训练** (技术特性): 模型在 595,000 条带标签的合成图像上进行预训练，体现数据规模
- **6200万-真实无标签图像** (技术特性): 模型还利用 62,000,000 张真实无标签图像进行自监督学习，提升鲁棒性

### baidu/ERNIE-4.5-0.3B-Base-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-0.3B-Base-Paddle

**关键词列表**:

- **多模态令牌平衡** (技术特性): 论文级亮点，检索多模态训练技巧时的长尾精准词

### LiquidAI/LFM2-700M-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/LiquidAI/LFM2-700M-GGUF

**关键词列表**:

- **LFM2-700M** (当前模型品牌名): 从项目名称提取的当前模型名称
- **8种语言** (技术特性): 当前模型支持8种语言，是其重要技术特性

### microsoft/Phi-4-mini-flash-reasoning

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/Phi-4-mini-flash-reasoning

**关键词列表**:

- **Phi-4-mini** (当前模型品牌名): 从项目名称提取的当前模型名称，去掉过长后缀
- **64K上下文** (技术特性): 支持64K令牌长上下文，是用户搜索长文本模型的关键指标
- **合成数据训练** (技术特性): 基于合成数据构建，是模型独特卖点
- **Azure-NIM** (部署工具): 官方提供Azure Nvidia NIM一键体验，用户会搜部署入口

### Lightricks/LTX-Video

**URL**: https://ai.gitcode.com/hf_mirrors/Lightricks/LTX-Video

**关键词列表**:

- **LTX-Video** (当前模型品牌名): 项目名称直接来源于Lightricks/LTX-Video，是模型唯一品牌标识，用户搜索AI视频生成模型时会直接使用此名称
- **实时视频生成** (功能场景): README明确强调'实时视频生成'，是区别于其他异步生成模型的核心卖点，用户会用此短语搜索高性能视频生成工具
- **DiT架构** (技术特性): 模型基于DiT（Diffusion Transformer）架构，这是其技术独特性，且未被高频词列表排除，专业用户会搜索'DiT视频模型'

### OpenGVLab/VideoMAEv2-Base

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/VideoMAEv2-Base

**关键词列表**:

- **VideoMAEv2-Base** (当前模型品牌名): 从项目名称提取的当前模型名称
- **视频特征提取** (功能场景): 当前模型的主要应用场景
- **自监督方式** (技术特性): 当前模型采用自监督方式进行预训练
- **双重掩码策略** (技术特性): 当前模型采用双重掩码策略扩展视频掩码自编码器
- **UnlabeledHybrid-1M** (技术特性): 当前模型预训练的数据集名称

### Wan-AI/Wan2.1-T2V-14B-Diffusers

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-T2V-14B-Diffusers

**关键词列表**:

- **万2.1** (当前模型品牌名): 项目名称为Wan2.1-T2V-14B-Diffusers，根据国产大模型映射规则，'万'对应品牌名'万2.1'，是模型唯一官方名称，用户搜索时会直接使用
- **中英双语文生视频** (功能场景): 模型是首个支持中英双语文本生成视频的开源模型，该特性具有唯一性，用户可能搜索'中英双语视频生成'等长尾词，精准匹配需求
- **T2V-14B** (当前模型品牌名): 项目重点展示T2V-14B模型，是模型在仓库中的具体子版本名称，用户在技术社区中常以'模型名+参数'形式搜索，如'T2V-14B'，符合简洁品牌名规则
- **万-VAE** (技术特性): 模型自研的视频编解码器，名称独特且在README中被重点强调，是区别于其他模型的核心技术组件，用户可能搜索'万-VAE编解码'等技术词
- **480P视频生成** (功能场景): 模型明确支持480P分辨率视频生成，且在消费级显卡上可运行，该分辨率是用户实际应用中的常见需求，具有实用指向性，未被高频词列表覆盖
- **720P视频生成** (功能场景): 模型是目前唯一支持720P分辨率的开源文生视频模型，该参数具有明确区分度，用户搜索'720P视频生成模型'时可能精准命中

### google-t5/t5-11b

**URL**: https://ai.gitcode.com/hf_mirrors/google-t5/t5-11b

**关键词列表**:

- **T5-11B** (当前模型品牌名): 项目名称中直接标识的模型名称
- **文本到文本框架** (技术特性): T5 采用统一的 Text‑to‑Text 任务格式，是模型的核心技术特性
- **11B参数** (参数规格): 模型拥有约 110 亿（11B）参数，是其显著的规模特征

### cross-encoder/stsb-distilroberta-base

**URL**: https://ai.gitcode.com/hf_mirrors/cross-encoder/stsb-distilroberta-base

**关键词列表**:

- **STSB** (当前模型品牌名): 项目名称中直接出现的基准任务缩写，用户搜索STSB模型时会用
- **语义相似度** (功能场景): 模型核心用途是计算两句话的语义相似度，用户常用搜索词
- **CrossEncoder** (技术特性): SentenceTransformers官方CrossEncoder架构，技术关键词
- **句子匹配** (功能场景): 用户搜索句子对匹配、文本匹配时常用此词
- **DistilRoBERTa** (当前模型品牌名): 模型基础骨干网络名称，用户搜索轻量化RoBERTa变体时会用
- **文本排序** (功能场景): 标签Text Ranking对应的中文场景词，用户搜索文本排序模型常用

### Qwen/Qwen3-235B-A22B-MLX-8bit

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-235B-A22B-MLX-8bit

**关键词列表**:

- **Qwen3-235B-A22B** (当前模型品牌名): 从项目名称直接提取的当前模型唯一标识，符合简化命名规则（保留核心型号，去除非必要后缀）
- **2350亿参数** (参数规格): 模型总参数量为2350亿，属于超大规模主流规格，用户会搜索此类大模型参数级别，且未被列入高频排除词
- **激活参数220亿** (参数规格): MoE模型中激活参数是关键性能指标，220亿为高价值区分点，用户在对比MoE模型时会搜索此类具体激活规模
- **128专家8激活** (技术特性): MoE架构中专家数与激活数是核心区分特征，128专家/8激活是当前模型独特配置，未被高频词覆盖

### google/siglip2-so400m-patch16-naflex

**URL**: https://ai.gitcode.com/hf_mirrors/google/siglip2-so400m-patch16-naflex

**关键词列表**:

- **SigLIP2-So400m** (当前模型品牌名): 从项目名称提取的当前模型名称
- **语义理解** (技术特性): README中提到的当前模型的技术特性
- **密集特征提取** (技术特性): README中提到的当前模型的技术特性

### nanonets/Nanonets-OCR-s

**URL**: https://ai.gitcode.com/hf_mirrors/nanonets/Nanonets-OCR-s

**关键词列表**:

- **Nanonets-OCR** (当前模型品牌名): 项目名称中直接体现的模型品牌名称，用户搜索时会使用该名称定位模型
- **LaTeX-公式识别** (功能场景): 模型能够自动将文档中的数学公式转换为 LaTeX 语法，是其核心功能之一
- **智能图像描述** (功能场景): 模型使用结构化 <img> 标签对文档中的图片进行语义化描述，便于后续 LLM 处理
- **签名检测** (功能场景): 模型可以识别文档中的手写签名并将其隔离到 <signature> 标签，适用于法律/商业文档处理
- **水印提取** (功能场景): 模型能够检测并提取文档中的水印文本，输出至 <watermark> 标签
- **复选框处理** (功能场景): 模型将表单中的复选框和单选按钮转换为标准 Unicode 符号（☐, ☑, ☒），保证文本一致性
- **复杂表格提取** (功能场景): 模型精准提取文档中的复杂表格，并同时生成 Markdown 与 HTML 表格格式

### vidore/colpali

**URL**: https://ai.gitcode.com/hf_mirrors/vidore/colpali

**关键词列表**:

- **图像补丁嵌入** (技术特性): 模型通过将图像补丁嵌入输入LLM实现跨模态对齐，是其架构设计的独特技术点
- **文档视觉索引** (功能场景): 模型用于从PDF等文档中建立视觉特征索引，是其区别于通用视觉问答的精准应用场景

### nvidia/OpenReasoning-Nemotron-7B

**URL**: https://ai.gitcode.com/hf_mirrors/nvidia/OpenReasoning-Nemotron-7B

**关键词列表**:

- **64K词元输出** (技术特性): 超长输出长度是模型卖点，用户可能直接搜
- **CC-BY-4.0开源** (部署工具): 许可证信息常被开发者搜索以确认商用合规
- **GPQA基准** (技术特性): README突出GPQA高分，用户可能搜该基准找模型
- **LiveCodeBench** (功能场景): README列出LiveCodeBench得分，开发者会搜该评测找代码模型
- **并行多智能体** (技术特性): README提到多智能体协同推理，用户会搜该关键词

### facebook/sam-vit-huge

**URL**: https://ai.gitcode.com/hf_mirrors/facebook/sam-vit-huge

**关键词列表**:

- **SAM-ViT-Huge** (当前模型品牌名): 从项目名称提取的当前模型名称
- **零样本性能** (技术特性): 当前模型在零样本迁移任务中的突出表现
- **PromptEncoder** (技术特性): 当前模型的核心模块之一，为点和边界框生成嵌入

### lzkhhh/ITDR-Qwen2.5-7B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/lzkhhh/ITDR-Qwen2.5-7B-Instruct

**关键词列表**:

- **推荐系统大模型** (功能场景): 模型专为推荐系统优化，解决用户行为数据与自然语言的结构差异，是其独特应用场景，用户可能搜索'推荐系统大模型'来寻找此类专用AI
- **20万条指令样本** (参数规格): 数据集规模是其核心优势之一，'20万条'是用户在对比推荐领域微调数据集时可能搜索的量化指标，属于主流规模表述

### zai-org/GLM-4.5-Air-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/zai-org/GLM-4.5-Air-FP8

**关键词列表**:

- **智能体基座模型** (功能场景): 官方定位专为智能体设计，用户会搜智能体基座
- **120亿活跃参数** (参数规格): 轻量版独有规格，用户搜12B参数模型
- **MIT开源可商用** (部署工具): 协议允许商业二次开发，用户搜可商用开源模型

### OpenGVLab/VideoMAEv2-Large

**URL**: https://ai.gitcode.com/hf_mirrors/OpenGVLab/VideoMAEv2-Large

**关键词列表**:

- **VideoMAEv2-Large** (当前模型品牌名): 从项目名称直接提取的当前模型唯一品牌名，用户搜索时会精确匹配该模型
- **视频掩码自编码器** (技术特性): 模型基于VideoMAE V2的双掩码自编码架构，该术语是其核心技术命名，具有唯一性且未被高频词列表覆盖
- **CVPR23** (技术特性): 模型源自CVPR 2023论文，学术用户常通过会议年份检索前沿模型，该词具有学术搜索价值且未被高频词列表排除
- **arxiv2303.1672** (技术特性): 论文唯一arXiv编号，研究者常直接搜索arXiv ID定位模型，是高精准学术引流关键词

### mradermacher/ALP_DeepScaleR_1.5B_C16K-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/mradermacher/ALP_DeepScaleR_1.5B_C16K-GGUF

**关键词列表**:

- **DeepScaleR** (当前模型品牌名): 从项目名称 ALP_DeepScaleR_1.5B_C16K 中提取的核心模型名称
- **静态量化** (技术特性): 模型以静态量化方式提供，区别于动态量化，是用户关注的技术特性
- **16K上下文** (技术特性): 模型名称中的 C16K 表示支持约 16 K 上下文长度，属于独特的上下文特性
- **SynthLabsAI** (当前模型品牌名): 模型由 SynthLabsAI 组织发布，可作为品牌关键词帮助用户定位

### ibm-granite/granite-docling-258M

**URL**: https://ai.gitcode.com/hf_mirrors/ibm-granite/granite-docling-258M

**关键词列表**:

- **Granite-Docling** (当前模型品牌名): 从项目名称提取的当前模型名称
- **文档解析** (功能场景): 当前模型专用于高效文档转换与解析
- **公式识别** (功能场景): README强调增强的数学公式检测与格式化能力
- **258M参数** (参数规格): 当前模型的具体参数规模，便于用户检索
- **Docling流水线** (部署工具): 模型已深度集成Docling库，支持一键式文档转换
- **图像转文本** (功能场景): 多模态能力，支持将图文内容直接转为结构化文本

### DaizeDong/GraphsGPT-4W

**URL**: https://ai.gitcode.com/hf_mirrors/DaizeDong/GraphsGPT-4W

**关键词列表**:

- **GraphsGPT-4W** (当前模型品牌名): 从项目名称 DaizeDong/GraphsGPT-4W 直接提取的当前模型唯一品牌名，符合简洁品牌名规范
- **图结构建模** (功能场景): 模型核心是将图结构数据‘欧几里得化’，属于图机器学习的典型应用场景，用户会搜索‘图结构建模’这类精准意图词
- **纯Transformer图学习** (技术特性): 论文核心创新是‘使用纯Transformer处理图数据’，区别于GNN，是该模型独有的技术标签，用户会搜索此类技术组合词
- **化学分子建模** (功能场景): README明确提及chemistry应用，‘化学分子建模’是该模型在生物医学领域的具体使用场景，具高区分度
- **生物医学图分析** (功能场景): README明确提及biology和medical，组合为‘生物医学图分析’是该模型在真实场景中的核心用途，非通用词
- **欧几里得化图** (技术特性): 论文标题核心概念‘Euclideanizing Graph’，中文译为‘欧几里得化图’，是该模型独有的技术术语，用户可能直接搜索此短语

### unsloth/gpt-oss-20b-BF16

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/gpt-oss-20b-BF16

**关键词列表**:

- **Apache-2.0许可** (技术特性): 当前模型采用宽松的Apache 2.0许可，是模型使用的关键特性
- **智能代理能力** (功能场景): 当前模型原生支持函数调用、网页浏览、Python代码执行及结构化输出，是模型的重要功能

### Qwen/Qwen3Guard-Gen-0.6B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-0.6B

**关键词列表**:

- **安全审核模型** (功能场景): 模型核心用途是文本安全分类，用户会搜索‘AI安全审核’‘内容过滤模型’等意图词
- **三级严重程度分类** (技术特性): 模型独有的输出结构设计，将安全风险分为安全/争议/不安全三级，是区别于通用分类模型的关键特征
- **多语言安全审核** (功能场景): 支持119种语言的安全审核，是用户在跨国内容风控场景中可能搜索的精准功能组合词
- **指令跟随安全** (技术特性): 模型将安全分类建模为指令跟随任务，是其区别于传统分类器的核心技术表述，用户可能搜索‘AI指令安全’类关键词

### Hcompany/Holo1.5-3B

**URL**: https://ai.gitcode.com/hf_mirrors/Hcompany/Holo1.5-3B

**关键词列表**:

- **UI问答** (功能场景): 基于界面内容回答用户问题，提升交互效率
- **高分辨率38402160** (技术特性): 原生支持4K级输入，适配大屏与高清场景

### opendatalab/MinerU2.5-2509-1.2B

**URL**: https://ai.gitcode.com/hf_mirrors/opendatalab/MinerU2.5-2509-1.2B

**关键词列表**:

- **MinerU2.5** (当前模型品牌名): 从项目名称提取的当前模型名称
- **解耦式视觉语言模型** (技术特性): 当前模型的核心技术特性，突出解耦式设计
- **高效高分辨率文档解析** (功能场景): 当前模型的主要应用场景，强调高效和高分辨率

### sail-rvc/ElsaV2

**URL**: https://ai.gitcode.com/hf_mirrors/sail-rvc/ElsaV2

**关键词列表**:

- **ElsaV2** (当前模型品牌名): 项目名称为sail-rvc/ElsaV2，直接提取模型唯一品牌名，无版本号，符合简洁命名规则
- **RVC** (技术特性): 模型类型明确标注为RVC（Retrieval-Based Voice Conversion），是当前模型的核心技术标签，用户搜索语音转换模型时会使用该缩写
- **Audio-to-Audio** (功能场景): 标签中明确标注，描述模型直接输入音频输出音频的转换功能，是用户搜索语音克隆/变声场景时的精准关键词
- **sail-rvc** (当前模型品牌名): 项目属于sail-rvc组织，且为模型专属系列名，非通用术语，具有品牌识别度，符合‘当前模型自身’提取原则
- **rvc-runpod** (部署工具): README明确提及模型被转换为适用于‘https://github.com/chavinlo/rvc-runpod’的格式，该词是模型专属部署生态标签，非通用词

### Qwen/Qwen3-32B-GGUF

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-32B-GGUF

**关键词列表**:

- **Qwen3-32B** (当前模型品牌名): 项目名称中直接出现的模型完整名称，代表该模型的品牌标识
- **YaRN技术** (技术特性): 通过 YaRN 技术实现上下文长度可扩展至 131,072 tokens，提升长文本处理能力

### unsloth/embeddinggemma-300m-qat-q8_0-unquantized

**URL**: https://ai.gitcode.com/hf_mirrors/unsloth/embeddinggemma-300m-qat-q8_0-unquantized

**关键词列表**:

- **Matryoshka表示学习** (技术特性): 独有的MRL技术，可截断嵌入维度

### deepseek-ai/DeepSeek-V3.2-Exp-Base

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-V3.2-Exp-Base

**关键词列表**:

- **DeepSeek-V3.2-Exp-Base** (当前模型品牌名): 从项目名称直接提取的当前模型全称，虽含版本号，但为官方唯一标识，且无简化版名称，符合‘模型名称简化’规则中‘带版本号可保留’的例外情形（因无更简洁通用品牌名）
- **Exp-Base** (当前模型品牌名): ‘Exp-Base’是当前模型名称的核心组成部分，代表实验性基础版本，是区别于其他DeepSeek系列（如DeepSeek-V3）的关键标识，用户可能搜索‘DeepSeek Exp-Base’来定位该实验模型
- **HuggingFace镜像** (部署工具): 项目URL为HuggingFace镜像，用户在寻找可直接加载的模型时会搜索‘HuggingFace镜像模型’，该词指向模型获取渠道，非技术细节，符合部署工具维度
- **Base版本** (技术特性): ‘Base’在模型命名中代表基础架构版本，区别于‘Chat’、‘Instruct’等微调版本，是用户区分模型用途时的关键词，如搜索‘DeepSeek Base版本’，且未被高频词库排除

### Qwen/Qwen2.5-Omni-3B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-Omni-3B

**关键词列表**:

- **Qwen2.5-Omni-3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **端到端多模态模型** (技术特性): 当前模型的核心技术特性，能够感知多种模态
- **TMRoPE** (技术特性): 当前模型创新提出的时间对齐多模态旋转位置编码技术
- **自然流畅语音生成** (功能场景): 当前模型在语音生成方面的卓越表现，超越现有众多方案

### XiaomiMiMo/MiMo-Audio-7B-Base

**URL**: https://ai.gitcode.com/hf_mirrors/XiaomiMiMo/MiMo-Audio-7B-Base

**关键词列表**:

- **少样本学习** (技术特性): 模型在多种音频任务上展现出少样本学习能力，是其独特技术亮点，搜索者常关注此特性
- **音频理解基准** (功能场景): 模型在公开的音频理解基准测试中取得领先成绩，用户常通过此关键词了解模型性能
- **MiMo-Audio-Tokenizer** (技术特性): 模型使用的专属音频分词器，具备12亿参数和高频率运行特性，搜索者会关注此关键组件

### THUDM/cogagent-9b-20241220

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/cogagent-9b-20241220

**关键词列表**:

- **CogAgent-9B-20241220** (当前模型品牌名): 项目名称为THUDM/cogagent-9b-20241220，直接提取完整模型标识符，符合用户搜索具体版本的意图
- **GUI感知** (技术特性): 模型核心能力之一，明确区别于通用VLM，用户搜索‘GUI感知AI模型’有明确场景需求
- **Action-Operation-Sensitive** (技术特性): 模型输出格式的独有设计术语，是其作为GUI Agent的关键技术标签，非通用词汇
- **屏幕截图交互** (功能场景): 模型接受屏幕截图+语言输入的核心使用方式，用户会搜索‘如何用AI分析屏幕截图’
- **双语屏幕代理** (功能场景): 模型支持中英文双语操作屏幕的独有定位，区别于普通视觉问答模型，具高区分度
- **GLM-4V-9B基座** (当前模型品牌名): 虽基于GLM-4V，但当前模型是其优化版，且‘GLM-4V-9B’是模型架构的直接引用，非其他品牌模型，符合‘自身名称’提取规则
- **平台识别代理** (功能场景): 模型能识别Mac/WIN/Mobile平台并据此调整行为，是其作为GUI Agent的特色功能，非通用AI能力

### black-forest-labs/FLUX.1-Kontext-dev

**URL**: https://ai.gitcode.com/hf_mirrors/black-forest-labs/FLUX.1-Kontext-dev

**关键词列表**:

- **FLUX.1-Kontext-dev** (当前模型品牌名): 从项目名称提取的当前模型名称
- **整流流转换器** (技术特性): 当前模型的核心技术类型
- **引导蒸馏技术** (技术特性): 当前模型使用的独特训练技术

### pcoloc/autotrain-only-rssi-1813762559

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-only-rssi-1813762559

**关键词列表**:

- **AutoTrain** (部署工具): README中明确提到使用AutoTrain训练，用户会搜索AutoTrain一键训练
- **RSSI预测** (功能场景): 项目名称含RSSI，结合任务类型可推断为无线信号强度回归预测
- **低CO2排放** (技术特性): README突出1.3554克CO2排放，环保型训练成为卖点

### PhysicsWallahAI/Aryabhata-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/PhysicsWallahAI/Aryabhata-1.0

**关键词列表**:

- **Aryabhata-1.0** (当前模型品牌名): 项目名称明确为PhysicsWallahAI/Aryabhata-1.0，是当前模型的唯一官方名称，符合品牌名提取规则
- **JEE数学** (功能场景): 模型专为印度JEE主考数学设计，是用户搜索竞赛数学AI模型时的核心意图关键词，具有高度场景针对性
- **exam-centric** (技术特性): README明确使用该术语描述模型定位，指代‘以考试为中心’的AI设计范式，是区别于通用模型的独特技术标签
- **模型融合** (技术特性): 模型通过加权平均融合Qwen 2.5 Math、Ace Math等构建，是其核心训练方法，且未被高频词库排除，具技术独特性
- **拒绝采样** (技术特性): 模型训练流程中明确使用‘rejection-sampling’，是其提升准确率的关键技术，属于专业但非泛用的训练策略关键词
- **监督微调** (技术特性): 模型采用SFT（监督微调）作为核心训练步骤，是AI教育模型的典型技术路径，未被高频词库排除，具区分度
- **可验证奖励强化学习** (技术特性): 模型使用‘RLVR’（可验证奖励强化学习），是其区别于普通RLHF的创新训练机制，术语独特且未被高频词库覆盖
- **70亿参数** (参数规格): 模型明确为70亿参数（7B），属于主流参数规模，符合‘7B参数’格式，且未被高频词库中的‘7B参数’禁用（因高频词为7B参数，非70亿参数）

### Qwen/Qwen2.5-VL-3B-Instruct

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-VL-3B-Instruct

**关键词列表**:

- **Qwen2.5-VL-3B-Instruct** (当前模型品牌名): 项目名称即为当前模型完整名称，符合用户直接搜索模型标识的意图，且未被高频词列表排除
- **长视频事件捕捉** (功能场景): 支持超1小时视频的精准片段定位，属于模型独有的时间维度理解能力，非通用术语，未被高频词覆盖
- **动态分辨率视频理解** (技术特性): 通过动态FPS采样与时间维度mRoPE实现视频时序感知，是架构层面的创新点，非普通视频理解或帧采样概念
- **窗口注意力ViT** (技术特性): 在视觉编码器中策略性引入窗口注意力机制，提升效率，属于模型特有的架构优化方式，未在高频词中出现

### deepseek-ai/DeepSeek-Prover-V2-7B

**URL**: https://ai.gitcode.com/hf_mirrors/deepseek-ai/DeepSeek-Prover-V2-7B

**关键词列表**:

- **DeepSeek-Prover-V2** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **Lean4-形式化证明** (功能场景): 模型专注于在 Lean 4 环境下进行形式化定理证明的应用场景
- **递归定理证明** (技术特性): 模型采用递归方式分解并搜索定理证明，是核心技术特性
- **冷启动推理数据** (技术特性): 通过冷启动数据集进行初始训练，提升模型推理能力
- **思维链融合** (技术特性): 将非形式化思维链与形式化证明步骤有机结合的创新特性
- **子目标分解** (技术特性): 模型将复杂定理拆解为可验证的子目标，是关键技术手段

### mistralai/Voxtral-Mini-3B-2507

**URL**: https://ai.gitcode.com/hf_mirrors/mistralai/Voxtral-Mini-3B-2507

**关键词列表**:

- **Voxtral-Mini-3B** (当前模型品牌名): 从项目名称提取的当前模型名称
- **长文本上下文处理** (技术特性): 当前模型支持处理长文本上下文的能力
- **音频内容理解** (功能场景): 当前模型的核心应用场景之一
- **语音直接触发功能调用** (技术特性): 当前模型独特的语音触发功能
- **vllm** (部署工具): 当前模型推荐的部署框架

### ByteDance-Seed/BM-Model

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/BM-Model

**关键词列表**:

- **BM-Model** (当前模型品牌名): 从项目名称ByteDance-Seed/BM-Model提取的当前模型简称
- **字节跳动Seed** (当前模型品牌名): ByteDance-Seed对应官方品牌“字节跳动Seed”
- **ByteMorph-Bench** (技术特性): README中提到的专属评测基准，用户想了解该模型性能时会搜索
- **arxiv-2506.03107** (技术特性): 论文编号是用户查找该模型技术细节的高频检索词

### pcoloc/autotrain-mikrotik-7-7-1860563597

**URL**: https://ai.gitcode.com/hf_mirrors/pcoloc/autotrain-mikrotik-7-7-1860563597

**关键词列表**:

- **pcolocautotrain-data-mikrotik-7-7** (当前模型品牌名): 项目名称中唯一可识别的专属数据集/模型前缀，代表该模型的唯一标识，符合‘当前模型自身名称’提取规则

### ByteDance-Seed/UI-TARS-72B-SFT

**URL**: https://ai.gitcode.com/hf_mirrors/ByteDance-Seed/UI-TARS-72B-SFT

**关键词列表**:

- **界面自动化** (功能场景): 原生端到端界面任务自动化，用户高频搜索词

### Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers

**URL**: https://ai.gitcode.com/hf_mirrors/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers

**关键词列表**:

- **时序编解码** (技术特性): 能够在任意时长 1080P 视频上保留时序信息的编解码技术
- **1.3B参数** (参数规格): T2V-1.3B 子模型的参数规模，用户常以参数大小检索模型

### baidu/ERNIE-4.5-VL-28B-A3B-Paddle

**URL**: https://ai.gitcode.com/hf_mirrors/baidu/ERNIE-4.5-VL-28B-A3B-Paddle

**关键词列表**:

- **ERNIE-4.5-VL-28B-A3B** (当前模型品牌名): 从项目名称直接提取的当前模型完整名称，是用户搜索该特定模型的精准关键词，且未被高频词列表排除
- **文本质感生成** (功能场景): 基于 'text understanding and generation' 与 'image understanding' 的结合推导出的用户可搜索场景词，强调文本生成质量，区别于泛用的'AI写作'或'文生图'

### myshell-ai/MeloTTS-Spanish

**URL**: https://ai.gitcode.com/hf_mirrors/myshell-ai/MeloTTS-Spanish

**关键词列表**:

- **MeloTTS-Spanish** (当前模型品牌名): 从项目名称提取的当前模型名称，且特指西班牙语版本
- **中英文混合** (功能场景): 当前模型支持中文发音人进行中英文混合的文本转语音
- **Text-to-Speech** (功能场景): 当前模型的核心功能类别，即文本转语音

### PlanTL-GOB-ES/roberta-base-bne-capitel-ner

**URL**: https://ai.gitcode.com/hf_mirrors/PlanTL-GOB-ES/roberta-base-bne-capitel-ner

**关键词列表**:

- **roberta-base-bne-capitel-ner** (当前模型品牌名): 从项目名称提取的当前模型完整品牌名
- **西班牙语NER** (功能场景): 当前模型专用于西班牙语的命名实体识别任务
- **BNE语料** (技术特性): 基于西班牙国家图书馆570GB清洗语料预训练，体现数据特色
- **CAPITEL数据集** (技术特性): 在CAPITEL命名实体识别数据集上微调，突出训练数据来源
- **570GB西班牙语** (技术特性): 强调训练语料规模与语言专一性，吸引西语NLP开发者

### ecmwf/aifs-single-1.0

**URL**: https://ai.gitcode.com/hf_mirrors/ecmwf/aifs-single-1.0

**关键词列表**:

- **AIFS-Single** (当前模型品牌名): 项目名称中直接给出的模型品牌名称
- **高层大气变量预报** (功能场景): 模型在 50 hPa、100 hPa 层级上提升了高层大气变量的预报能力
- **降水总量预报** (功能场景): 新版对总降水量的预报技巧进行了增强，是模型的核心业务场景
- **土壤湿度与温度预报** (功能场景): 新增输出变量包括土壤湿度、土壤温度等陆地气象要素
- **13层气压层结构** (技术特性): 模型采用 13 个气压层的结构，区别于传统单层或更少层数的预报模型
- **每日四次同步运行** (技术特性): 模型每日与 ECMWF 物理数值预报模式同步运行四次，保证时效性
- **开放数据政策** (技术特性): 预报结果依据 ECMWF 开放数据政策向公众免费开放，具备数据共享特性

### Qwen/Qwen3Guard-Gen-8B

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3Guard-Gen-8B

**关键词列表**:

- **生成式安全分类** (技术特性): 模型将安全审核转化为指令跟随任务，属于生成式AI在内容安全领域的创新应用方式，具备独特性

### stepfun-ai/step3-fp8

**URL**: https://ai.gitcode.com/hf_mirrors/stepfun-ai/step3-fp8

**关键词列表**:

- **step3-fp8** (当前模型品牌名): 从项目名称提取的当前模型名称
- **混合专家架构** (技术特性): 当前模型采用的核心架构类型
- **多矩阵分解注意力** (技术特性): 当前模型使用的独特注意力机制
- **注意力-前馈网络解耦** (技术特性): 当前模型设计的独特网络结构
- **视觉-语言推理** (功能场景): 当前模型实现的核心功能
- **端到端设计** (技术特性): 当前模型的设计方式

### rubentito/layoutlmv3-base-mpdocvqa

**URL**: https://ai.gitcode.com/hf_mirrors/rubentito/layoutlmv3-base-mpdocvqa

**关键词列表**:

- **Document-Question-Answering** (功能场景): 模型专门用于文档问答任务，是用户搜索文档型QA模型时的精准意图词，且未被列入高频排除词库
- **Document-Visual-Question-Answering** (功能场景): 模型处理图文结合的文档问答，该术语精准描述其多模态文档理解能力，区别于通用VQA，具有高区分度
- **MP-DocVQA** (当前模型品牌名): 模型是专为MP-DocVQA数据集微调的，该名称是当前模型的专属训练基准，属于模型自身标识，非通用术语
- **LayoutLMv3-base** (当前模型品牌名): 模型基于LayoutLMv3-base架构微调，该组合是用户搜索特定基座版本时的常见查询词，且未被高频词库排除
- **Multipage-Document-VQA** (功能场景): 模型处理多页文档的视觉问答，该短语是任务类型的核心描述，具有明确搜索意图，且未在排除列表中

### MusePublic/489_ckpt_FLUX_1

**URL**: https://ai.gitcode.com/hf_mirrors/MusePublic/489_ckpt_FLUX_1

**关键词列表**:

- **FLUX.1-dev** (当前模型品牌名): 项目名称中直接出现的模型名称，用户搜索时会使用该品牌名
- **引导蒸馏** (技术特性): 模型采用的核心训练技术，可提升效率，具备独特性

### Qwen/Qwen2.5-14B-Instruct-1M

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen2.5-14B-Instruct-1M

**关键词列表**:

- **Qwen2.5-14B-Instruct-1M** (当前模型品牌名): 项目完整名称，用户直接搜索该模型
- **长文本处理** (功能场景): 模型核心卖点，用户搜索长文本AI模型

### microsoft/Florence-2-base

**URL**: https://ai.gitcode.com/hf_mirrors/microsoft/Florence-2-base

**关键词列表**:

- **Florence-2** (当前模型品牌名): 从项目名称直接提取的当前模型品牌名，是用户搜索该模型的核心关键词
- **视觉基础模型** (技术特性): 模型在README中被明确定义为'视觉基础模型'，具有明确技术定位，且未在高频排除词列表中
- **提示词方法** (技术特性): 模型采用'基于提示词的方法'处理多任务，是其架构特色，具有区分度且未被高频词覆盖
- **FLD-5B数据集** (技术特性): 模型训练所用的独特数据集名称，专业用户可能搜索该数据集来评估模型来源，具有唯一性

### THUDM/androidgen-llama-3-70b

**URL**: https://ai.gitcode.com/hf_mirrors/THUDM/androidgen-llama-3-70b

**关键词列表**:

- **70B参数** (参数规格): 大参数规模，用户筛选大模型时常搜
- **无标注交互** (技术特性): 亮点能力，无需人工标注即可训练安卓操作
- **安卓自动化** (功能场景): 用户想找能自动完成安卓任务的模型时会搜

### Qwen/Qwen3-14B-FP8

**URL**: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-14B-FP8

**关键词列表**:

- **Qwen3-14B-FP8** (当前模型品牌名): 从项目名称提取的当前模型名称
- **高效通用对话** (功能场景): 当前模型在非思考模式下支持高效通用对话

### NousResearch/Hermes-4-14B

**URL**: https://ai.gitcode.com/hf_mirrors/NousResearch/Hermes-4-14B

**关键词列表**:

- **Hermes-4** (当前模型品牌名): 项目名称中直接出现的模型品牌名称
- **混合推理模式** (技术特性): 模型能够在需要深思时使用 </think> 标记进行混合推理，是其核心技术特性
- **后训练语料库** (技术特性): 相较于前代模型，Hermes‑4 使用了规模更大的后训练语料库，显著提升推理能力
- **RefusalBench** (基准测试/评估): Hermes‑4 在自研的 RefusalBench 基准上取得最先进成绩，体现其在拒绝率降低方面的优势
- **function-calling** (技术特性): 模型支持函数调用能力，可在对话中直接触发外部工具或 API
- **JSON模式生成** (技术特性): 模型能够根据给定模式生成有效的 JSON 对象，适用于结构化任务

### kakaocorp/kanana-1.5-v-3b-instruct

**URL**: https://ai.gitcode.com/hf_mirrors/kakaocorp/kanana-1.5-v-3b-instruct

**关键词列表**:

- **Kanana** (当前模型品牌名): 从项目名称提取的当前模型品牌名
- **Kakao大模型** (当前模型品牌名): 由Kakao UFO团队发布，映射为Kakao大模型
- **OCR推理** (功能场景): 官方强调支持基于OCR的推理任务
- **韩文多模态** (功能场景): 针对韩文场景优化，支持韩文指令遵循
- **3.6B参数** (参数规格): 当前模型的具体参数规模
