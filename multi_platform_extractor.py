"""
å¤šå¹³å°AIå…³é”®è¯æå–æ¨¡å— - æ”¯æŒå¹¶å‘è°ƒç”¨å¤šä¸ªå¤§æ¨¡å‹å¹³å°
"""
import os
import re
import json
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional, Tuple
from openai import AsyncOpenAI
from dotenv import load_dotenv

from models import ModelInfo, KeywordResult
from base_extractor import BaseKeywordExtractor

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class MultiPlatformExtractor(BaseKeywordExtractor):
    """å¤šå¹³å°å…³é”®è¯æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤šä¸ªAIå®¢æˆ·ç«¯"""
        self.platforms = self._init_platforms()
        
    def _init_platforms(self) -> Dict[str, Dict]:
        """åˆå§‹åŒ–æ”¯æŒçš„å¹³å°é…ç½®"""
        platforms = {}
        
        # æœˆä¹‹æš—é¢ (Moonshot)
        if os.getenv("MOONSHOT_API_KEY"):
            platforms["moonshot"] = {
                "client": AsyncOpenAI(
                    api_key=os.getenv("MOONSHOT_API_KEY"),
                    base_url=os.getenv("MOONSHOT_BASE_URL", "https://api.moonshot.cn/v1"),
                ),
                "model": "kimi-k2-0905-preview",
                "name": "æœˆä¹‹æš—é¢",
                "enabled": True
            }
        
        # é˜¿é‡Œç™¾ç‚¼ (DashScope)
        if os.getenv("DASHSCOPE_API_KEY"):
            platforms["dashscope"] = {
                "client": AsyncOpenAI(
                    api_key=os.getenv("DASHSCOPE_API_KEY"),
                    base_url=os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1"),
                ),
                "model": os.getenv("DASHSCOPE_MODEL", "qwen-plus"),
                "name": "é˜¿é‡Œç™¾ç‚¼",
                "enabled": True
            }
        
        # OpenAI (å¦‚æœé…ç½®äº†)
        if os.getenv("OPENAI_API_KEY"):
            platforms["openai"] = {
                "client": AsyncOpenAI(
                    api_key=os.getenv("OPENAI_API_KEY"),
                    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                ),
                "model": os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                "name": "OpenAI",
                "enabled": True
            }
        
        # æ™ºè°±AI (å¦‚æœé…ç½®äº†)
        if os.getenv("ZHIPU_API_KEY"):
            platforms["zhipu"] = {
                "client": AsyncOpenAI(
                    api_key=os.getenv("ZHIPU_API_KEY"),
                    base_url=os.getenv("ZHIPU_BASE_URL", "https://open.bigmodel.cn/api/paas/v4"),
                ),
                "model": os.getenv("ZHIPU_MODEL", "glm-4"),
                "name": "æ™ºè°±AI",
                "enabled": True
            }
        
        # ä¸ƒç‰›äº‘ (å¦‚æœé…ç½®äº†)
        if os.getenv("QINIU_API_KEY"):
            platforms["qiniu"] = {
                "client": AsyncOpenAI(
                    api_key=os.getenv("QINIU_API_KEY"),
                    base_url=os.getenv("QINIU_BASE_URL", "https://openai.qiniu.com/v1"),
                ),
                "model": os.getenv("QINIU_MODEL", "gpt-oss-120b"),
                "name": "ä¸ƒç‰›äº‘",
                "enabled": True
            }
        
        # è…¾è®¯æ··å…ƒ (å¦‚æœé…ç½®äº†)
        if os.getenv("HUNYUAN_API_KEY"):
            platforms["hunyuan"] = {
                "client": AsyncOpenAI(
                    api_key=os.getenv("HUNYUAN_API_KEY"),
                    base_url=os.getenv("HUNYUAN_BASE_URL", "https://api.hunyuan.cloud.tencent.com/v1"),
                ),
                "model": os.getenv("HUNYUAN_MODEL", "hunyuan-turbos-latest"),
                "name": "è…¾è®¯æ··å…ƒ",
                "enabled": True
            }
        
        print(f"ğŸš€ åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒ {len(platforms)} ä¸ªå¹³å°:")
        for platform_id, config in platforms.items():
            print(f"   - {config['name']} ({platform_id}): {config['model']}")
        
        return platforms
    
    # build_prompt æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor
    
    async def extract_keywords_single_platform(self, model_info: ModelInfo, platform_id: str) -> Optional[Tuple[str, List[Dict[str, str]]]]:
        """ä½¿ç”¨å•ä¸ªå¹³å°æå–å…³é”®è¯"""
        if platform_id not in self.platforms or not self.platforms[platform_id]["enabled"]:
            return None
        
        platform = self.platforms[platform_id]
        client = platform["client"]
        model = platform["model"]
        platform_name = platform["name"]
        
        try:
            print(f"ğŸ”„ ä½¿ç”¨ {platform_name} æå–å…³é”®è¯...")
            
            prompt = self.build_prompt(model_info)
            
            # ä¸ºè…¾è®¯æ··å…ƒæ·»åŠ ç‰¹æ®Šå‚æ•°
            extra_params = {}
            if platform_id == "hunyuan":
                extra_params["extra_body"] = {"enable_enhancement": True}
            
            completion = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIé¡¹ç›®è¿è¥ä¸“å®¶å’ŒSEOå¤§å¸ˆï¼Œä¸“é—¨è´Ÿè´£ä»AIæ¨¡å‹é¡¹ç›®ä¸­æå–é«˜ä»·å€¼çš„å…³é”®è¯ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1200,  # è¿›ä¸€æ­¥å¢åŠ tokenæ•°é‡ï¼Œé¿å…å“åº”è¢«æˆªæ–­
                **extra_params
            )
            
            response_content = completion.choices[0].message.content
            
            # ä¸ºæ™ºè°±AIæ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            if platform_id == "zhipu":
                print(f"ğŸ” æ™ºè°±AIè°ƒè¯•ä¿¡æ¯:")
                print(f"   å“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
                print(f"   å“åº”å†…å®¹å‰500å­—ç¬¦:")
                print(f"   {response_content[:500]}")
                print(f"   å“åº”å†…å®¹å500å­—ç¬¦:")
                print(f"   {response_content[-500:]}")
                print(f"   å®Œæ•´å“åº”å†…å®¹:")
                print(f"   {response_content}")
                print(f"   å“åº”å†…å®¹ç±»å‹: {type(response_content)}")
            
            keywords = self._parse_keywords_response(response_content)
            
            if keywords:
                print(f"âœ… {platform_name} æˆåŠŸæå– {len(keywords)} ä¸ªå…³é”®è¯")
                return platform_id, keywords
            else:
                print(f"âŒ {platform_name} æœªèƒ½æå–åˆ°æœ‰æ•ˆå…³é”®è¯")
                return None
                
        except Exception as e:
            print(f"âŒ {platform_name} æå–å¤±è´¥: {e}")
            return None
    
    async def extract_keywords_concurrent(self, model_info: ModelInfo) -> Optional[KeywordResult]:
        """å¹¶å‘è°ƒç”¨å¤šä¸ªå¹³å°æå–å…³é”®è¯"""
        import time
        start_time = time.time()
        
        print(f"ğŸš€ å¹¶å‘è°ƒç”¨ {len(self.platforms)} ä¸ªå¹³å°æå–å…³é”®è¯...")
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for platform_id in self.platforms.keys():
            if self.platforms[platform_id]["enabled"]:
                task = self.extract_keywords_single_platform(model_info, platform_id)
                tasks.append(task)
        
        if not tasks:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å¹³å°")
            return None
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        successful_results = []
        for result in results:
            if isinstance(result, Exception):
                print(f"âŒ å¹³å°è°ƒç”¨å¼‚å¸¸: {result}")
            elif result is not None:
                platform_id, keywords = result
                successful_results.append((platform_id, keywords))
        
        if not successful_results:
            print("âŒ æ‰€æœ‰å¹³å°éƒ½æå–å¤±è´¥")
            return None
        
        # é€‰æ‹©æœ€ä½³ç»“æœï¼ˆä¼˜å…ˆé€‰æ‹©å…³é”®è¯æ•°é‡æœ€å¤šçš„ï¼‰
        best_platform_id, best_keywords = max(successful_results, key=lambda x: len(x[1]))
        best_platform_name = self.platforms[best_platform_id]["name"]
        
        elapsed_time = time.time() - start_time
        print(f"âœ… æœ€ä½³ç»“æœæ¥è‡ª {best_platform_name}: {len(best_keywords)} ä¸ªå…³é”®è¯ (æ€»è€—æ—¶: {elapsed_time:.1f}ç§’)")
        
        return KeywordResult(
            model_url=model_info.url,
            keywords=best_keywords
        )
    
    # _parse_keywords_response æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor
    
    # _validate_keyword, _clean_keyword, _fix_common_json_errors, _fix_truncated_json æ–¹æ³•å·²ç§»è‡³ BaseKeywordExtractor
    
    def extract_keywords(self, model_info: ModelInfo) -> Optional[KeywordResult]:
        """å®ç°æŠ½è±¡æ–¹æ³• - åŒæ­¥ç‰ˆæœ¬çš„å…³é”®è¯æå–"""
        return asyncio.run(self.extract_keywords_concurrent(model_info))
    
    async def extract_batch_keywords(self, model_infos: List[ModelInfo]) -> List[KeywordResult]:
        """æ‰¹é‡æå–å…³é”®è¯ï¼ˆwork-stealingç‰ˆæœ¬ï¼‰"""
        return await self._work_stealing_main(model_infos)
    
    async def _work_stealing_main(self, model_infos: List[ModelInfo]) -> List[KeywordResult]:
        """ä»»åŠ¡æ±  + work-stealing ä¸»é€»è¾‘"""
        import time
        start_time = time.time()
        
        total = len(model_infos)
        
        # è·å–å¯ç”¨çš„å¹³å°
        available_platforms = [pid for pid, config in self.platforms.items() if config["enabled"]]
        platform_count = len(available_platforms)
        
        if platform_count == 0:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å¹³å°")
            return []
        
        print(f"ğŸš€ ä»»åŠ¡æ± å¯åŠ¨ï¼Œæ¨¡å‹ {total} ä¸ªï¼Œå¹³å° {platform_count} ä¸ª")
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ— (ModelInfo, retry_count)
        queue = asyncio.Queue()
        for model_info in model_infos:
            await queue.put((model_info, 0))
        
        # å…±äº«ç»“æœåˆ—è¡¨å’Œé”
        results = []
        lock = asyncio.Lock()
        
        # åˆ›å»ºworkerä»»åŠ¡
        workers = []
        for platform_id in available_platforms:
            worker = asyncio.create_task(
                self._worker(platform_id, queue, results, lock, platform_count)
            )
            workers.append(worker)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await queue.join()
        
        # å–æ¶ˆæ‰€æœ‰worker
        for worker in workers:
            worker.cancel()
        
        # ç­‰å¾…workeræ¸…ç†å®Œæˆ
        await asyncio.gather(*workers, return_exceptions=True)
        
        # è®¡ç®—è€—æ—¶
        end_time = time.time()
        total_time = end_time - start_time
        avg_time = total_time / len(results) if results else 0
        
        print(f"ğŸš€ ä»»åŠ¡æ± å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(results)} ä¸ªæ¨¡å‹")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’ï¼Œå¹³å‡è€—æ—¶: {avg_time:.2f}ç§’/æ¨¡å‹")
        return results
    
    async def _worker(self, platform_id: str, queue: asyncio.Queue, results: List[KeywordResult], 
                     lock: asyncio.Lock, max_retries: int):
        """å•ä¸ªå¹³å°çš„workeråç¨‹"""
        platform_name = self.platforms[platform_id]["name"]
        success_count = 0
        
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                model_info, retry_count = queue.get_nowait()
                
                # å°è¯•å¤„ç†æ¨¡å‹
                result = await self.extract_keywords_single_platform(model_info, platform_id)
                
                if result:
                    # æˆåŠŸå¤„ç†
                    platform_id_result, keywords = result
                    keyword_result = KeywordResult(
                        model_url=model_info.url,
                        keywords=keywords
                    )
                    
                    # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ ç»“æœ
                    async with lock:
                        results.append(keyword_result)
                    
                    success_count += 1
                    queue.task_done()
                else:
                    # å¤„ç†å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                    if retry_count < max_retries - 1:
                        # é‡æ–°æ”¾å›é˜Ÿåˆ—ï¼Œå¢åŠ é‡è¯•æ¬¡æ•°
                        await queue.put((model_info, retry_count + 1))
                        queue.task_done()
                    else:
                        # æ‰€æœ‰å¹³å°éƒ½è¯•è¿‡äº†ï¼Œä¸¢å¼ƒ
                        print(f"âš ï¸  {model_info.project_name} æ‰€æœ‰å¹³å°å‡å¤±è´¥ï¼Œå·²ä¸¢å¼ƒ")
                        queue.task_done()
                        
            except asyncio.QueueEmpty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œworkeré€€å‡º
                break
            except Exception as e:
                # å•ä¸ªä»»åŠ¡å¼‚å¸¸ï¼Œä¸å½±å“å…¶ä»–ä»»åŠ¡
                print(f"âŒ {platform_name} å¤„ç†å¼‚å¸¸: {e}")
                try:
                    queue.task_done()
                except ValueError:
                    pass  # å¦‚æœtask_done()è¢«è°ƒç”¨å¤šæ¬¡ï¼Œå¿½ç•¥é”™è¯¯
        
        print(f"âœ… {platform_name} æˆåŠŸå¤„ç† {success_count} ä¸ª")
    
    async def extract_keywords_shard(self, platform_id: str, model_infos: List[ModelInfo], start_index: int) -> List[KeywordResult]:
        """å•ä¸ªå¹³å°å¤„ç†åˆ†ç‰‡"""
        platform_name = self.platforms[platform_id]["name"]
        shard_size = len(model_infos)
        
        print(f"ğŸ”„ {platform_name} å¼€å§‹å¤„ç†åˆ†ç‰‡ (æ¨¡å‹ {start_index+1}-{start_index+shard_size})")
        
        results = []
        for i, model_info in enumerate(model_infos):
            model_index = start_index + i + 1
            print(f"   è¿›åº¦: {model_index}/{start_index+shard_size} - {model_info.project_name}")
            
            # ä½¿ç”¨å•ä¸ªå¹³å°æå–å…³é”®è¯
            result = await self.extract_keywords_single_platform(model_info, platform_id)
            
            if result:
                platform_id_result, keywords = result
                keyword_result = KeywordResult(
                    model_url=model_info.url,
                    keywords=keywords
                )
                results.append(keyword_result)
                print(f"   âœ… æˆåŠŸæå– {len(keywords)} ä¸ªå…³é”®è¯")
            else:
                print(f"   âŒ æå–å¤±è´¥")
        
        print(f"âœ… {platform_name} åˆ†ç‰‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ {len(results)}/{shard_size} ä¸ªæ¨¡å‹")
        return results


# åŒæ­¥åŒ…è£…å™¨ï¼Œä¿æŒä¸åŸç‰ˆå…¼å®¹
class MultiPlatformExtractorSync:
    """å¤šå¹³å°å…³é”®è¯æå–å™¨ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self):
        self.async_extractor = MultiPlatformExtractor()
    
    def extract_keywords(self, model_info: ModelInfo) -> Optional[KeywordResult]:
        """åŒæ­¥ç‰ˆæœ¬çš„å…³é”®è¯æå–"""
        return asyncio.run(self.async_extractor.extract_keywords_concurrent(model_info))
    
    def extract_batch_keywords(self, model_infos: List[ModelInfo]) -> List[KeywordResult]:
        """åŒæ­¥ç‰ˆæœ¬çš„æ‰¹é‡æå–"""
        return asyncio.run(self.async_extractor.extract_batch_keywords(model_infos))
    
    def deduplicate_keywords(self, keyword_results: List[KeywordResult]) -> List[KeywordResult]:
        """åŒæ­¥ç‰ˆæœ¬çš„å…³é”®è¯å»é‡"""
        return self.async_extractor.deduplicate_keywords(keyword_results)


def test_multi_platform():
    """æµ‹è¯•å¤šå¹³å°æå–åŠŸèƒ½"""
    import asyncio
    from models import ModelInfo
    
    async def test_async():
        extractor = MultiPlatformExtractor()
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹ä¿¡æ¯
        test_model = ModelInfo(
            url="https://gitcode.com/hf_mirrors/internlm/Intern-S1-FP8",
            project_name="internlm/Intern-S1-FP8",
            readme="Intern-S1 æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¨ç†æ¨¡å‹ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒå’Œè§†é¢‘è¾“å…¥ã€‚",
            tags=["å¤šæ¨¡æ€", "æ¨ç†", "Transformers"]
        )
        
        # æµ‹è¯•å¹¶å‘æå–
        result = await extractor.extract_keywords_concurrent(test_model)
        
        if result:
            print(f"\næ¨¡å‹: {result.model_url}")
            print("æå–çš„å…³é”®è¯:")
            for kw in result.keywords:
                print(f"- {kw['keyword']} ({kw['dimension']}): {kw['reason']}")
        else:
            print("å…³é”®è¯æå–å¤±è´¥")
    
    asyncio.run(test_async())


if __name__ == "__main__":
    test_multi_platform()
